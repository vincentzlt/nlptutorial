{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,math,pprint\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram:\n",
    "    def __init__(self, f_name, n=1):\n",
    "        self.n = n\n",
    "        self.frq_dict = {}\n",
    "        self.vocab_size_dict = defaultdict(lambda: 0)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            self.frq_dict[str(i + 1)] = defaultdict(lambda: 0)\n",
    "\n",
    "        for line in open(f_name, \"r\", encoding=\"UTF-8\"):\n",
    "            line = line.split()\n",
    "            line.append(\"</s>\")\n",
    "            line.insert(0, \"<s>\")\n",
    "            for i in range(self.n):\n",
    "                _line_tp = self.line_tp(line, i + 1)\n",
    "                for j in _line_tp:\n",
    "                    self.frq_dict[str(i + 1)][\" \".join(j)] += 1\n",
    "\n",
    "        for i in range(self.n):\n",
    "            for w in self.frq_dict[str(i + 1)]:\n",
    "                self.vocab_size_dict[str(i + 1)] += self.frq_dict[str(i + 1)][\n",
    "                    w]\n",
    "\n",
    "    def line_tp(self, line, n):\n",
    "        _tp_list = []\n",
    "        len_line = len(line)\n",
    "        for i in range(n):\n",
    "            _tp_list.append(line[i:len_line - n + i + 1])\n",
    "        return list(zip(*_tp_list))\n",
    "\n",
    "    def calc_ngram_P(self, ngram_str):\n",
    "        n=len(ngram_str.split())\n",
    "        ngram_str_m1=\" \".join(ngram_str.split()[:-1])\n",
    "        if n == 1:\n",
    "            lambda_ = 0.95\n",
    "            vocab_size = 1000000\n",
    "            P = self.frq_dict[str(n)][ngram_str] / float(\n",
    "                self.vocab_size_dict[str(n)])\n",
    "            return lambda_ * P + (1 - lambda_) / vocab_size\n",
    "        else:\n",
    "            lambda_n_m1=self.calc_lambda_n_m1(ngram_str)\n",
    "            try:\n",
    "                P=self.frq_dict[str(n)][ngram_str]/float(self.frq_dict[str(n)][ngram_str_m1])\n",
    "            except ZeroDivisionError:\n",
    "                P=0\n",
    "            return lambda_n_m1*P+(1-lambda_n_m1)*self.calc_ngram_P(ngram_str.split()[-1])\n",
    "            \n",
    "    def calc_lambda_n_m1(self,ngram_str):\n",
    "        \n",
    "        n=len(ngram_str.split())\n",
    "        \n",
    "        c_w_m1_freq=self.frq_dict[str(n)][ngram_str]\n",
    "        \n",
    "        ngram_str_m1=\" \".join(ngram_str.split()[:-1])\n",
    "        \n",
    "        u_w_m1_count= len(set([u for u in self.frq_dict[str(n)] if u.split()[:-1]==ngram_str.split()[:-1]]))\n",
    "        return 1-u_w_m1_count/float(u_w_m1_count+c_w_m1_freq)\n",
    "    \n",
    "    def word_seg_viterbi(self,line,n_gram_model=1):\n",
    "        len_line=len(line)\n",
    "        best_edge=[None]*(len_line)\n",
    "        best_score=[0]*(len_line)\n",
    "        \n",
    "        for w_end in range(1,len_line+1):\n",
    "            best_score[w_end]=10000000000\n",
    "            for w_begin in range(0,len_line):\n",
    "                word=line[w_begin:w_end]\n",
    "                if word in self.frq_dict[str(n_gram_model)].keys():\n",
    "                    P_log_ng=-math.log(self.calc_ngram_P(word))\n",
    "                    score_=best_score[w_begin]+P_log_ng\n",
    "                    if score_<best_score[w_end]:\n",
    "                        best_score[w_end]=score_\n",
    "                        best_edge[w_end]=(w_begin,w_end)\n",
    "        words=[]\n",
    "        next_edge=best_edge[len(best_edge)-1]\n",
    "        while next_edge:\n",
    "            word=line[next_edge[0]:next_edge[1]]\n",
    "            words.append(word)\n",
    "            next_edge=best_edge[next_edge[0]]\n",
    "        words.reverse()\n",
    "        return words\n",
    "    \n",
    "    def word_seg_viterbi_file(self,f_name,n_gram_model=1):\n",
    "        for line in open(f_name,\"r\",encoding=\"UTF-8\"):\n",
    "            print(self.word_seg_viterbi(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[None]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=ngram(\"./wiki-ja-train.word\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "_.word_seg_viterbi_file(\"./wiki-ja-test.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
