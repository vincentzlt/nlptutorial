{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, math\n",
    "from collections import defaultdict\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_model(f_name):\n",
    "    n_gram_dict=defaultdict(lambda:0)\n",
    "    for line in open(f_name,\"r\",encoding=\"UTF-8\"):\n",
    "        line_split=line.split(\"\\t\")\n",
    "        n_gram_dict[line_split[0]]=line_split[1]\n",
    "    return n_gram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_new_n_gram_dict(old_n_gram_dict,n):\n",
    "    old_n=len(list(old_n_gram_dict.keys())[0].split())\n",
    "    if n>=old_n:\n",
    "        print(\"cant make new n_gram dict larger than original n_gram\")\n",
    "        return\n",
    "    new_n_gram_dict=defaultdict(lambda:0)\n",
    "    for old_n_gram in old_n_gram_dict:\n",
    "        old_n_gram_list=old_n_gram.split()\n",
    "        for i in range(n):\n",
    "            new_n_gram_dict[\" \".join(old_n_gram_list[i:i+n])]+=old_n_gram_dict[old_n_gram]\n",
    "            \n",
    "    return new_n_gram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c', 'd e f', 'b c d', 'c d e']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b c\n",
      "d e f\n",
      "b c d\n",
      "c d e\n"
     ]
    }
   ],
   "source": [
    "temp_dict={\"a b c\":1,\"b c d\":2,\"c d e\":3,\"d e f\":4}\n",
    "list(temp_dict.keys())\n",
    "for i in temp_dict:\n",
    "    print(i)\n",
    "t_=calc_new_n_gram_dict(temp_dict,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> increases   0.0007686395080707148\n",
      "\n",
      "is processed   0.0020325203252032522\n",
      "\n",
      "department ,   0.5\n",
      "\n",
      "75 %   1.0\n",
      "\n",
      "under the   0.2\n",
      "\n",
      "was nearly   0.012987012987012988\n",
      "\n",
      "Number =   1.0\n",
      "\n",
      "collection of   0.4\n",
      "\n",
      "reader processed   0.1\n",
      "\n",
      "reverse -RRB-   0.5\n",
      "\n",
      "interaction by   0.125\n",
      "\n",
      ", this   0.003368893879842785\n",
      "\n",
      "case ,   0.17647058823529413\n",
      "\n",
      "interactive translation   0.25\n",
      "\n",
      "format .   0.5\n",
      "\n",
      "automatically and   0.09523809523809523\n",
      "\n",
      "say that   0.14285714285714285\n",
      "\n",
      "sound on   0.05\n",
      "\n",
      "standard telegraph   0.07142857142857142\n",
      "\n",
      "case ''   0.058823529411764705\n",
      "\n",
      "proper nouns   0.14285714285714285\n",
      "\n",
      "in NIST   0.0018726591760299626\n",
      "\n",
      "of document\\/text   0.00089126559714795\n",
      "\n",
      "keyphrases .   0.3142857142857143\n",
      "\n",
      "key words   0.16666666666666666\n",
      "\n",
      "Computational Linguistics   1.0\n",
      "\n",
      "important topics   0.0625\n",
      "\n",
      "large quantity   0.043478260869565216\n",
      "\n",
      "very large   0.024390243902439025\n",
      "\n",
      "advanced scanning   0.4\n",
      "\n",
      "set appends   0.02564102564102564\n",
      "\n",
      "commercializing paper-to-computer   1.0\n",
      "\n",
      "until the   0.5\n",
      "\n",
      "vs. spontaneous   0.08333333333333333\n",
      "\n",
      "-LRB- WER   0.0027100271002710027\n",
      "\n",
      "digitize the   1.0\n",
      "\n",
      "phrases that   0.0625\n",
      "\n",
      "reader designed   0.2\n",
      "\n",
      "challenged and   1.0\n",
      "\n",
      "are spoken   0.004149377593360996\n",
      "\n",
      "specialized output   0.5\n",
      "\n",
      "Facebook -RRB-   1.0\n",
      "\n",
      "-LRB- Microsoft   0.0027100271002710027\n",
      "\n",
      "features\\/aspects ,   1.0\n",
      "\n",
      "effective .   0.3333333333333333\n",
      "\n",
      "basic approach   0.07692307692307693\n",
      "\n",
      "surfer model   1.0\n",
      "\n",
      "world ''   0.06666666666666667\n",
      "\n",
      "pumps last   0.5\n",
      "\n",
      "speaker or   0.05555555555555555\n",
      "\n",
      "Phonemes ,   1.0\n",
      "\n",
      "advantage of   0.8\n",
      "\n",
      "completely nonsensical   1.0\n",
      "\n",
      "transcription .   0.5\n",
      "\n",
      "'' a   0.015463917525773196\n",
      "\n",
      "readable human   0.3333333333333333\n",
      "\n",
      "summaries depending   0.046511627906976744\n",
      "\n",
      "and have   0.001445086705202312\n",
      "\n",
      "% on   0.02564102564102564\n",
      "\n",
      "hours of   0.5\n",
      "\n",
      "and Reinvestment   0.001445086705202312\n",
      "\n",
      "accuracy -RRB-   0.06451612903225806\n",
      "\n",
      "intelligence that   0.25\n",
      "\n",
      "The human   0.005208333333333333\n",
      "\n",
      "these simple   0.023809523809523808\n",
      "\n",
      "single datum   0.07142857142857142\n",
      "\n",
      "learning automatically   0.023255813953488372\n",
      "\n",
      "division of   0.5\n",
      "\n",
      "so far   0.03333333333333333\n",
      "\n",
      "translation requires   0.013513513513513514\n",
      "\n",
      "proposed a   0.2222222222222222\n",
      "\n",
      "incorporates a   1.0\n",
      "\n",
      "rate of   0.2727272727272727\n",
      "\n",
      "the learning   0.0006920415224913495\n",
      "\n",
      "A good   0.02\n",
      "\n",
      "way is   0.041666666666666664\n",
      "\n",
      "section called   0.16666666666666666\n",
      "\n",
      "lower levels   0.4\n",
      "\n",
      "term applies   0.1111111111111111\n",
      "\n",
      "constructs -RRB-   0.3333333333333333\n",
      "\n",
      "tried .   0.3333333333333333\n",
      "\n",
      "example where   0.012345679012345678\n",
      "\n",
      "publication of   0.6666666666666666\n",
      "\n",
      "promoting diversity   1.0\n",
      "\n",
      "averaged .   1.0\n",
      "\n",
      "they think   0.025\n",
      "\n",
      "spoken -RRB-   0.07142857142857142\n",
      "\n",
      "to discrete   0.0013280212483399733\n",
      "\n",
      "tagging or   0.08\n",
      "\n",
      "-LRB- IR   0.0027100271002710027\n",
      "\n",
      "experiment which   0.2\n",
      "\n",
      "than trying   0.022222222222222223\n",
      "\n",
      "for grammars   0.0036101083032490976\n",
      "\n",
      "occurring '   1.0\n",
      "\n",
      "strength score   0.2\n",
      "\n",
      "like ca   0.03571428571428571\n",
      "\n",
      "large ,   0.043478260869565216\n",
      "\n",
      "printing ,   1.0\n",
      "\n",
      "do you   0.038461538461538464\n",
      "\n",
      "required ,   0.14285714285714285\n",
      "\n",
      "ambiguities in   0.25\n",
      "\n",
      "languages tend   0.02\n",
      "\n",
      "were able   0.024390243902439025\n",
      "\n",
      "<s> Shepard   0.0007686395080707148\n",
      "\n",
      "NLP The   0.0425531914893617\n",
      "\n",
      "prisoners or   0.5\n",
      "\n",
      "itself to   0.2\n",
      "\n",
      "Iraq in   0.5\n",
      "\n",
      "of computational   0.00267379679144385\n",
      "\n",
      "which focuses   0.007246376811594203\n",
      "\n",
      "post-processed by   1.0\n",
      "\n",
      "The two   0.010416666666666666\n",
      "\n",
      "of ways   0.0017825311942959\n",
      "\n",
      "LexRank simply   0.08333333333333333\n",
      "\n",
      "assist human   1.0\n",
      "\n",
      "be statistically   0.004219409282700422\n",
      "\n",
      "about it   0.025\n",
      "\n",
      "of Lichtenstein   0.00089126559714795\n",
      "\n",
      "authoritative of   1.0\n",
      "\n",
      "weighted finite   0.3333333333333333\n",
      "\n",
      "say ,   0.2857142857142857\n",
      "\n",
      "of proper   0.00089126559714795\n",
      "\n",
      "<s> Relationship   0.0007686395080707148\n",
      "\n",
      "ACL ,   0.5\n",
      "\n",
      "<s> Aggregation   0.0007686395080707148\n",
      "\n",
      "As a   0.1111111111111111\n",
      "\n",
      "LMF -RRB-   1.0\n",
      "\n",
      "Health Record   0.5\n",
      "\n",
      "performance .   0.16666666666666666\n",
      "\n",
      "Italy ,   1.0\n",
      "\n",
      "computational power   0.2\n",
      "\n",
      "most basic   0.017241379310344827\n",
      "\n",
      "understanding is   0.06060606060606061\n",
      "\n",
      "lexical and   0.15384615384615385\n",
      "\n",
      "will mention   0.02857142857142857\n",
      "\n",
      "-LRB- based   0.005420054200542005\n",
      "\n",
      "Rule-based machine   0.5\n",
      "\n",
      "all unknowns   0.023255813953488372\n",
      "\n",
      "% error   0.02564102564102564\n",
      "\n",
      "opportunity rather   0.5\n",
      "\n",
      "instead recognizes   0.14285714285714285\n",
      "\n",
      "than only   0.044444444444444446\n",
      "\n",
      "humanities and   1.0\n",
      "\n",
      "the Lander   0.0006920415224913495\n",
      "\n",
      "supervised extractive   0.0625\n",
      "\n",
      ", G   0.0005614823133071309\n",
      "\n",
      "we can   0.06666666666666667\n",
      "\n",
      "for instance   0.018050541516245487\n",
      "\n",
      "the total   0.0006920415224913495\n",
      "\n",
      "Koine Greek   1.0\n",
      "\n",
      "networks can   0.07142857142857142\n",
      "\n",
      "10,000 to   1.0\n",
      "\n",
      "vol-2 Black   1.0\n",
      "\n",
      "entities -LRB-   0.14285714285714285\n",
      "\n",
      "convinced many   1.0\n",
      "\n",
      ", of   0.0022459292532285235\n",
      "\n",
      "an input-stream   0.007575757575757576\n",
      "\n",
      "Lexical choice   0.5\n",
      "\n",
      "or 45   0.0045045045045045045\n",
      "\n",
      "concept ,   0.25\n",
      "\n",
      "more strongly   0.010526315789473684\n",
      "\n",
      "identifying the   0.6666666666666666\n",
      "\n",
      "the needs   0.0006920415224913495\n",
      "\n",
      "occur in   0.4\n",
      "\n",
      "way as   0.041666666666666664\n",
      "\n",
      "out -LRB-   0.07142857142857142\n",
      "\n",
      "mid-1960s .   1.0\n",
      "\n",
      "Mobile Smartphones   0.3333333333333333\n",
      "\n",
      ", discontinuous   0.0005614823133071309\n",
      "\n",
      "assessment ,   1.0\n",
      "\n",
      "different classes   0.02040816326530612\n",
      "\n",
      "separate parts   0.1\n",
      "\n",
      "methods did   0.022727272727272728\n",
      "\n",
      "database queries   0.1\n",
      "\n",
      "loud .   1.0\n",
      "\n",
      "contain subjective   0.08333333333333333\n",
      "\n",
      "of parse   0.00089126559714795\n",
      "\n",
      "orthography .   0.5\n",
      "\n",
      "categories themselves   0.1111111111111111\n",
      "\n",
      "ambiguous when   0.08333333333333333\n",
      "\n",
      "a display   0.001226993865030675\n",
      "\n",
      "desired structure   0.2\n",
      "\n",
      "for more   0.007220216606498195\n",
      "\n",
      ", Edmund   0.0005614823133071309\n",
      "\n",
      "returns text   1.0\n",
      "\n",
      "for mental   0.0036101083032490976\n",
      "\n",
      "and named   0.001445086705202312\n",
      "\n",
      "larger source   0.0625\n",
      "\n",
      "typewritten pages   0.2\n",
      "\n",
      "well to   0.03571428571428571\n",
      "\n",
      "skilled linguist   1.0\n",
      "\n",
      "different approaches   0.02040816326530612\n",
      "\n",
      "Naive Bayes   1.0\n",
      "\n",
      "search Query   0.09090909090909091\n",
      "\n",
      "Independent ''   1.0\n",
      "\n",
      "milliseconds -RRB-   0.5\n",
      "\n",
      "than optimizing   0.022222222222222223\n",
      "\n",
      "selected based   0.5\n",
      "\n",
      "put this   0.25\n",
      "\n",
      "symbols or   0.3333333333333333\n",
      "\n",
      "on this   0.014150943396226415\n",
      "\n",
      "concepts .   0.4\n",
      "\n",
      "In 1974   0.009523809523809525\n",
      "\n",
      "selection is   1.0\n",
      "\n",
      "accomplish with   1.0\n",
      "\n",
      "includes -LRB-   0.14285714285714285\n",
      "\n",
      "structure that   0.08333333333333333\n",
      "\n",
      "English into   0.02702702702702703\n",
      "\n",
      "-RRB- in   0.01084010840108401\n",
      "\n",
      "ignore this   1.0\n",
      "\n",
      "vibrates per   1.0\n",
      "\n",
      "to their   0.0026560424966799467\n",
      "\n",
      "ELIZA sometimes   0.1111111111111111\n",
      "\n",
      ", particularly   0.0011229646266142617\n",
      "\n",
      "fonts used   0.3333333333333333\n",
      "\n",
      "the technique   0.0006920415224913495\n",
      "\n",
      "star scale   0.5\n",
      "\n",
      "getting ranked   0.25\n",
      "\n",
      "merging of   0.5\n",
      "\n",
      "the summers   0.0006920415224913495\n",
      "\n",
      "the annotation   0.0006920415224913495\n",
      "\n",
      "ATC simulators   0.2\n",
      "\n",
      "; Analysis   0.02127659574468085\n",
      "\n",
      "correct according   0.06666666666666667\n",
      "\n",
      "or 100000   0.0045045045045045045\n",
      "\n",
      "attribute grammars   0.5\n",
      "\n",
      "explicitly delimited   0.25\n",
      "\n",
      "transducer ,   0.5\n",
      "\n",
      "word breaks   0.016666666666666666\n",
      "\n",
      "campaigns within   0.5\n",
      "\n",
      "above all   0.07692307692307693\n",
      "\n",
      "produced by   0.3333333333333333\n",
      "\n",
      "legal documents   0.3333333333333333\n",
      "\n",
      "or EHR   0.0045045045045045045\n",
      "\n",
      "sentence ,   0.125\n",
      "\n",
      "available to   0.058823529411764705\n",
      "\n",
      "punctuation ,   0.2857142857142857\n",
      "\n",
      "NLP problems   0.0425531914893617\n",
      "\n",
      "best path   0.05555555555555555\n",
      "\n",
      "then be   0.02857142857142857\n",
      "\n",
      "such signals   0.008130081300813009\n",
      "\n",
      "States ?   0.14285714285714285\n",
      "\n",
      "<s> Battle   0.0007686395080707148\n",
      "\n",
      "Invoice OCR   1.0\n",
      "\n",
      "; while   0.02127659574468085\n",
      "\n",
      "pumps ''   0.5\n",
      "\n",
      "generation because   0.1111111111111111\n",
      "\n",
      ", if   0.005614823133071308\n",
      "\n",
      "of robustness   0.00089126559714795\n",
      "\n",
      "the leaders   0.0006920415224913495\n",
      "\n",
      "such problems   0.008130081300813009\n",
      "\n",
      "Perceptron ,   1.0\n",
      "\n",
      "understand that   0.14285714285714285\n",
      "\n",
      "helicopter .   0.25\n",
      "\n",
      "the prolific   0.0006920415224913495\n",
      "\n",
      "Part-of-speech tagging   0.5\n",
      "\n",
      "data table   0.012987012987012988\n",
      "\n",
      "compare their   0.14285714285714285\n",
      "\n",
      "it appropriately   0.008547008547008548\n",
      "\n",
      "that preclude   0.0035460992907801418\n",
      "\n",
      "inseparable part   1.0\n",
      "\n",
      "however ,   0.9230769230769231\n",
      "\n",
      "dispense with   1.0\n",
      "\n",
      "among named   0.125\n",
      "\n",
      "<s> Most   0.0015372790161414297\n",
      "\n",
      "applications such   0.04\n",
      "\n",
      "simplification Text-to-speech   1.0\n",
      "\n",
      "rendered view   1.0\n",
      "\n",
      "Norval ,   1.0\n",
      "\n",
      "1970s ,   0.3333333333333333\n",
      "\n",
      "from section   0.009615384615384616\n",
      "\n",
      "Johnstone ,   1.0\n",
      "\n",
      "we think   0.022222222222222223\n",
      "\n",
      "analysis algorithms   0.015384615384615385\n",
      "\n",
      "words were   0.01834862385321101\n",
      "\n",
      "light -RRB-   0.3333333333333333\n",
      "\n",
      ": lexical   0.00980392156862745\n",
      "\n",
      "often requires   0.022727272727272728\n",
      "\n",
      "<s> Approaches   0.0023059185242121443\n",
      "\n",
      "representing successive   0.5\n",
      "\n",
      "visual detection   0.5\n",
      "\n",
      "very rare   0.024390243902439025\n",
      "\n",
      "However some   0.02702702702702703\n",
      "\n",
      "mining ,   0.2\n",
      "\n",
      "shallow approaches   0.16666666666666666\n",
      "\n",
      "in four   0.003745318352059925\n",
      "\n",
      "published .   0.14285714285714285\n",
      "\n",
      "translate text   0.3333333333333333\n",
      "\n",
      "a system-generated   0.001226993865030675\n",
      "\n",
      "LexisNexis was   1.0\n",
      "\n",
      "<s> Chinese   0.0007686395080707148\n",
      "\n",
      "uttered before   0.3333333333333333\n",
      "\n",
      "fields ,   0.3333333333333333\n",
      "\n",
      "flatbed scanner   1.0\n",
      "\n",
      "included in   0.125\n",
      "\n",
      "required .   0.14285714285714285\n",
      "\n",
      "translated it   0.25\n",
      "\n",
      "are ,   0.004149377593360996\n",
      "\n",
      "with each   0.00546448087431694\n",
      "\n",
      "phrases and   0.1875\n",
      "\n",
      "relationship mentions   0.16666666666666666\n",
      "\n",
      "being used   0.05555555555555555\n",
      "\n",
      "seen -RRB-   0.1\n",
      "\n",
      "Klavans J.   1.0\n",
      "\n",
      "large number   0.08695652173913043\n",
      "\n",
      "Read vs.   1.0\n",
      "\n",
      "orthography to   0.5\n",
      "\n",
      "level ,   0.2\n",
      "\n",
      ": Vocabulary   0.00980392156862745\n",
      "\n",
      "instances of   0.6666666666666666\n",
      "\n",
      "example Wireless   0.012345679012345678\n",
      "\n",
      "Sager at   0.5\n",
      "\n",
      "to solve   0.005312084993359893\n",
      "\n",
      "TextRank was   0.14285714285714285\n",
      "\n",
      "rank individual   0.16666666666666666\n",
      "\n",
      "of ``   0.0071301247771836\n",
      "\n",
      "idea is   0.14285714285714285\n",
      "\n",
      "in essentially   0.0018726591760299626\n",
      "\n",
      "a solved   0.00245398773006135\n",
      "\n",
      "At Stanford   0.3333333333333333\n",
      "\n",
      "P. ,   1.0\n",
      "\n",
      "want not   0.16666666666666666\n",
      "\n",
      "common -LRB-   0.04\n",
      "\n",
      "or MLLT   0.0045045045045045045\n",
      "\n",
      "as :   0.003484320557491289\n",
      "\n",
      "the figure   0.0006920415224913495\n",
      "\n",
      "leftmost derivation   1.0\n",
      "\n",
      "and grammar   0.002890173410404624\n",
      "\n",
      "was delayed   0.012987012987012988\n",
      "\n",
      "be presented   0.004219409282700422\n",
      "\n",
      "meaningless tokens   1.0\n",
      "\n",
      "new application   0.041666666666666664\n",
      "\n",
      "software vendors   0.037037037037037035\n",
      "\n",
      "-LRB- ,   0.0027100271002710027\n",
      "\n",
      "tasks implemented   0.03125\n",
      "\n",
      "regression -LRB-   1.0\n",
      "\n",
      "only the   0.10526315789473684\n",
      "\n",
      "formulaic language   1.0\n",
      "\n",
      "merely copy   0.5\n",
      "\n",
      "UMLS -RRB-   1.0\n",
      "\n",
      "overlap ,   0.25\n",
      "\n",
      "is split   0.0040650406504065045\n",
      "\n",
      "moderate with   0.2\n",
      "\n",
      "They simply   0.3333333333333333\n",
      "\n",
      "containing examples   0.125\n",
      "\n",
      "limiting the   1.0\n",
      "\n",
      "'s Law   0.0196078431372549\n",
      "\n",
      "nascent online   1.0\n",
      "\n",
      "handwritten ,   0.5\n",
      "\n",
      "Extraction Algorithm   0.3333333333333333\n",
      "\n",
      "; Amplitude   0.02127659574468085\n",
      "\n",
      "consistent terminology   1.0\n",
      "\n",
      "-LRB- GPO   0.0027100271002710027\n",
      "\n",
      "<s> Programming   0.0015372790161414297\n",
      "\n",
      "explore the   0.25\n",
      "\n",
      "is both   0.0020325203252032522\n",
      "\n",
      "grammatical and   0.09090909090909091\n",
      "\n",
      "and do   0.001445086705202312\n",
      "\n",
      "of intermediary   0.00089126559714795\n",
      "\n",
      "-LRB- essentially   0.0027100271002710027\n",
      "\n",
      "visited and   1.0\n",
      "\n",
      "entropy has   0.2\n",
      "\n",
      "of reasoned   0.00089126559714795\n",
      "\n",
      "sounds are   0.13333333333333333\n",
      "\n",
      "languages in   0.02\n",
      "\n",
      "correct result   0.06666666666666667\n",
      "\n",
      "a whole   0.00245398773006135\n",
      "\n",
      "atmosphere -LRB-   1.0\n",
      "\n",
      "is focused   0.0020325203252032522\n",
      "\n",
      "understanding also   0.030303030303030304\n",
      "\n",
      "UK dealing   0.25\n",
      "\n",
      "High-performance fighter   1.0\n",
      "\n",
      "demonstration that   0.2\n",
      "\n",
      "their products   0.029411764705882353\n",
      "\n",
      "about feature   0.025\n",
      "\n",
      "the Defense   0.0006920415224913495\n",
      "\n",
      "medical informatics   0.16666666666666666\n",
      "\n",
      "typically evaluated   0.05555555555555555\n",
      "\n",
      "had to   0.07142857142857142\n",
      "\n",
      "text corpora   0.006289308176100629\n",
      "\n",
      "independence Isolated   1.0\n",
      "\n",
      "objective or   0.2\n",
      "\n",
      "fixed static   0.5\n",
      "\n",
      "methods more   0.022727272727272728\n",
      "\n",
      "approach described   0.02857142857142857\n",
      "\n",
      "or left-to-right   0.0045045045045045045\n",
      "\n",
      "Modern speech   0.3333333333333333\n",
      "\n",
      "Analysis Standardization   0.2\n",
      "\n",
      "EVALITA web   0.5\n",
      "\n",
      "testing accuracy   0.2\n",
      "\n",
      "it could   0.008547008547008548\n",
      "\n",
      "ten-year-long research   1.0\n",
      "\n",
      "original paper   0.07692307692307693\n",
      "\n",
      "quite expensive   0.125\n",
      "\n",
      "McCarthy coined   1.0\n",
      "\n",
      "It essentially   0.02631578947368421\n",
      "\n",
      "Evaluation -LRB-   0.1111111111111111\n",
      "\n",
      "to one   0.0026560424966799467\n",
      "\n",
      "generate high-quality   0.05555555555555555\n",
      "\n",
      "commonly teach   0.125\n",
      "\n",
      ", keyphrases   0.0005614823133071309\n",
      "\n",
      "Multimodal interaction   1.0\n",
      "\n",
      "answers that   0.08333333333333333\n",
      "\n",
      "<s> Important   0.0007686395080707148\n",
      "\n",
      "the easier   0.0006920415224913495\n",
      "\n",
      "is measured   0.006097560975609756\n",
      "\n",
      "which would   0.014492753623188406\n",
      "\n",
      "on lexicon   0.0047169811320754715\n",
      "\n",
      "and used   0.001445086705202312\n",
      "\n",
      "documents were   0.02631578947368421\n",
      "\n",
      "more appropriately   0.010526315789473684\n",
      "\n",
      "guided by   1.0\n",
      "\n",
      "tongues sharing   1.0\n",
      "\n",
      "various NLP   0.05555555555555555\n",
      "\n",
      "of Turney   0.0017825311942959\n",
      "\n",
      ", paragraphs   0.0005614823133071309\n",
      "\n",
      "most practical   0.017241379310344827\n",
      "\n",
      "usefulness of   1.0\n",
      "\n",
      "true only   0.5\n",
      "\n",
      "not typically   0.017857142857142856\n",
      "\n",
      "many neighbors   0.019230769230769232\n",
      "\n",
      "Universal Part-of-Speech   1.0\n",
      "\n",
      "complex images   0.041666666666666664\n",
      "\n",
      "RAF employs   1.0\n",
      "\n",
      "Performing grammatical   1.0\n",
      "\n",
      "automatic summary   0.08695652173913043\n",
      "\n",
      "campaign dedicated   0.2\n",
      "\n",
      "made with   0.0625\n",
      "\n",
      "range of   0.5714285714285714\n",
      "\n",
      "setting steer-point   0.2\n",
      "\n",
      "e.g. feature   0.017857142857142856\n",
      "\n",
      "difficult problem   0.03571428571428571\n",
      "\n",
      "single speaker   0.07142857142857142\n",
      "\n",
      "models .   0.11538461538461539\n",
      "\n",
      "the noise   0.0006920415224913495\n",
      "\n",
      "Jan Blommaert   1.0\n",
      "\n",
      "<s> They   0.0023059185242121443\n",
      "\n",
      "forward than   1.0\n",
      "\n",
      "Weizenbaum sidestepped   0.3333333333333333\n",
      "\n",
      "overcome these   0.5\n",
      "\n",
      "T vertices\\/unigrams   0.16666666666666666\n",
      "\n",
      "and simulation   0.001445086705202312\n",
      "\n",
      "stochastic .   0.125\n",
      "\n",
      "the Grace   0.0006920415224913495\n",
      "\n",
      "an allowable   0.007575757575757576\n",
      "\n",
      "be detected   0.004219409282700422\n",
      "\n",
      "some new   0.012048192771084338\n",
      "\n",
      "-LRB- the   0.02168021680216802\n",
      "\n",
      "even disappear   0.037037037037037035\n",
      "\n",
      "by statistics   0.005714285714285714\n",
      "\n",
      "complex sets   0.041666666666666664\n",
      "\n",
      "the context   0.004152249134948097\n",
      "\n",
      "throughout a   1.0\n",
      "\n",
      "summarization research   0.02\n",
      "\n",
      "table lookup   0.14285714285714285\n",
      "\n",
      "on computational   0.0047169811320754715\n",
      "\n",
      "unified mathematical   1.0\n",
      "\n",
      "parser that   0.0625\n",
      "\n",
      "subject of   0.25\n",
      "\n",
      "project ,   0.38461538461538464\n",
      "\n",
      "have explicit   0.009615384615384616\n",
      "\n",
      "Google used   0.25\n",
      "\n",
      "scanned images   0.3333333333333333\n",
      "\n",
      "IEEE Transactions   0.6666666666666666\n",
      "\n",
      "the open-access   0.0006920415224913495\n",
      "\n",
      "effectively utilize   0.3333333333333333\n",
      "\n",
      "e.g. who   0.017857142857142856\n",
      "\n",
      "sub-committee is   1.0\n",
      "\n",
      "speech of   0.006578947368421052\n",
      "\n",
      "E. Brill   0.25\n",
      "\n",
      "are broken   0.004149377593360996\n",
      "\n",
      "this method   0.01098901098901099\n",
      "\n",
      "at a   0.058823529411764705\n",
      "\n",
      "content alone   0.08333333333333333\n",
      "\n",
      "the APEXC   0.0006920415224913495\n",
      "\n",
      "language data   0.006756756756756757\n",
      "\n",
      "with 12   0.00546448087431694\n",
      "\n",
      "chapter ,   1.0\n",
      "\n",
      "beginning in   0.5\n",
      "\n",
      "5 consecutive   0.5\n",
      "\n",
      "document browsing   0.027777777777777776\n",
      "\n",
      "for statistical   0.007220216606498195\n",
      "\n",
      "often represented   0.022727272727272728\n",
      "\n",
      "HMMs learn   0.125\n",
      "\n",
      "or analysis   0.0045045045045045045\n",
      "\n",
      "-RRB- measure   0.0027100271002710027\n",
      "\n",
      ", many   0.0039303761931499155\n",
      "\n",
      "hence need   0.5\n",
      "\n",
      "scanned page   0.3333333333333333\n",
      "\n",
      "RSI became   1.0\n",
      "\n",
      "tools for   0.16666666666666666\n",
      "\n",
      "for keyphrase   0.0036101083032490976\n",
      "\n",
      "Work in   0.5\n",
      "\n",
      "parse trees   0.2222222222222222\n",
      "\n",
      "computer-generated weather   1.0\n",
      "\n",
      "Question processing   0.14285714285714285\n",
      "\n",
      "But from   0.16666666666666666\n",
      "\n",
      "Jefferson ,   1.0\n",
      "\n",
      "it aimed   0.008547008547008548\n",
      "\n",
      "algorithms for   0.11428571428571428\n",
      "\n",
      "other than   0.014285714285714285\n",
      "\n",
      "'s GenEx   0.0196078431372549\n",
      "\n",
      "analyzing it   0.2\n",
      "\n",
      "and others   0.002890173410404624\n",
      "\n",
      "randomly chosen   1.0\n",
      "\n",
      "approximation of   0.16666666666666666\n",
      "\n",
      "cursive characters   0.2\n",
      "\n",
      "have several   0.009615384615384616\n",
      "\n",
      "to robots   0.0013280212483399733\n",
      "\n",
      "management system   0.14285714285714285\n",
      "\n",
      "English verbs   0.02702702702702703\n",
      "\n",
      "was one   0.012987012987012988\n",
      "\n",
      "against feature   0.2\n",
      "\n",
      "parsing comes   0.03571428571428571\n",
      "\n",
      "some common   0.012048192771084338\n",
      "\n",
      "Duranti ,   1.0\n",
      "\n",
      "may vary   0.019230769230769232\n",
      "\n",
      "useful to   0.14285714285714285\n",
      "\n",
      "much better   0.045454545454545456\n",
      "\n",
      "tokens 12   0.14285714285714285\n",
      "\n",
      ", biographical   0.0005614823133071309\n",
      "\n",
      "-LRB- VTLN   0.0027100271002710027\n",
      "\n",
      "as decision   0.010452961672473868\n",
      "\n",
      "blind people   0.75\n",
      "\n",
      "a new   0.007361963190184049\n",
      "\n",
      "already discussed   0.2\n",
      "\n",
      "involve the   0.16666666666666666\n",
      "\n",
      ", hypothetical   0.0005614823133071309\n",
      "\n",
      "SR system   0.3333333333333333\n",
      "\n",
      "learner .   0.5\n",
      "\n",
      "matching the   0.2\n",
      "\n",
      "the Ohio   0.0006920415224913495\n",
      "\n",
      "the reason   0.0006920415224913495\n",
      "\n",
      "research to   0.023809523809523808\n",
      "\n",
      "In languages   0.009523809523809525\n",
      "\n",
      "include papers   0.037037037037037035\n",
      "\n",
      "the appropriate   0.0020761245674740486\n",
      "\n",
      "sentiment based   0.04\n",
      "\n",
      "Manual analysis   0.3333333333333333\n",
      "\n",
      "in excess   0.003745318352059925\n",
      "\n",
      "voice is   0.07692307692307693\n",
      "\n",
      "can sometimes   0.0055248618784530384\n",
      "\n",
      "pages concluded   0.14285714285714285\n",
      "\n",
      "convey .   0.3333333333333333\n",
      "\n",
      "less -RRB-   0.08333333333333333\n",
      "\n",
      "as easily   0.006968641114982578\n",
      "\n",
      "explained by   1.0\n",
      "\n",
      "contain rules   0.08333333333333333\n",
      "\n",
      "probabilities would   0.09090909090909091\n",
      "\n",
      ": for   0.00980392156862745\n",
      "\n",
      "Schegloff ,   1.0\n",
      "\n",
      "brain is   0.3333333333333333\n",
      "\n",
      "journal abstracts   0.3333333333333333\n",
      "\n",
      "this particular   0.01098901098901099\n",
      "\n",
      "`` Meaningful   0.005291005291005291\n",
      "\n",
      "them into   0.05263157894736842\n",
      "\n",
      "using ``   0.01694915254237288\n",
      "\n",
      "been applied   0.08823529411764706\n",
      "\n",
      "of automated   0.00089126559714795\n",
      "\n",
      ", Guy   0.0005614823133071309\n",
      "\n",
      "open-ended questions   1.0\n",
      "\n",
      "'' occur   0.005154639175257732\n",
      "\n",
      "many strokes   0.019230769230769232\n",
      "\n",
      "20th-century newspaper   1.0\n",
      "\n",
      "discussed between   0.14285714285714285\n",
      "\n",
      "split into   0.5\n",
      "\n",
      "find that   0.07692307692307693\n",
      "\n",
      "questions under   0.038461538461538464\n",
      "\n",
      "and waves   0.001445086705202312\n",
      "\n",
      "-RRB- it   0.0027100271002710027\n",
      "\n",
      "'' with   0.020618556701030927\n",
      "\n",
      "<s> Keyphrase   0.0023059185242121443\n",
      "\n",
      "The United   0.005208333333333333\n",
      "\n",
      "offs in   1.0\n",
      "\n",
      "possibilities ,   0.2\n",
      "\n",
      ", trigram   0.0011229646266142617\n",
      "\n",
      "languages -RRB-   0.04\n",
      "\n",
      "or service   0.0045045045045045045\n",
      "\n",
      "state transducers   0.07142857142857142\n",
      "\n",
      "recently updated   0.3333333333333333\n",
      "\n",
      "that these   0.010638297872340425\n",
      "\n",
      "In 1969   0.01904761904761905\n",
      "\n",
      "not in   0.008928571428571428\n",
      "\n",
      "the potentially   0.0006920415224913495\n",
      "\n",
      "high pollen   0.05555555555555555\n",
      "\n",
      "is testing   0.0020325203252032522\n",
      "\n",
      "his company   0.08333333333333333\n",
      "\n",
      "within a   0.2777777777777778\n",
      "\n",
      "judge is   0.25\n",
      "\n",
      "required to   0.14285714285714285\n",
      "\n",
      "Roger Schank   0.75\n",
      "\n",
      "the hypothesis   0.0006920415224913495\n",
      "\n",
      "might select   0.038461538461538464\n",
      "\n",
      "stemming or   0.5\n",
      "\n",
      "sentences with   0.013157894736842105\n",
      "\n",
      "or printed   0.0045045045045045045\n",
      "\n",
      "In 2004   0.009523809523809525\n",
      "\n",
      "false starts   0.5\n",
      "\n",
      "its history   0.02857142857142857\n",
      "\n",
      "is substantial   0.0020325203252032522\n",
      "\n",
      "a restricted   0.001226993865030675\n",
      "\n",
      "several choices   0.045454545454545456\n",
      "\n",
      "does a   0.2\n",
      "\n",
      "derivation -LRB-   0.5\n",
      "\n",
      "the person   0.002768166089965398\n",
      "\n",
      "the unsupervised   0.0006920415224913495\n",
      "\n",
      "an evaluation   0.007575757575757576\n",
      "\n",
      "developed a   0.11538461538461539\n",
      "\n",
      "stems in   0.5\n",
      "\n",
      "uses search   0.07142857142857142\n",
      "\n",
      "ROUGE is   0.4\n",
      "\n",
      "additional constraints   0.16666666666666666\n",
      "\n",
      "Speaker Independent   0.16666666666666666\n",
      "\n",
      "machine ''   0.012658227848101266\n",
      "\n",
      "text -RRB-   0.006289308176100629\n",
      "\n",
      "simple tasks   0.038461538461538464\n",
      "\n",
      "the country   0.0020761245674740486\n",
      "\n",
      ", exploring   0.0005614823133071309\n",
      "\n",
      "least five   0.2\n",
      "\n",
      ", what   0.0011229646266142617\n",
      "\n",
      "far more   0.25\n",
      "\n",
      "speech With   0.006578947368421052\n",
      "\n",
      "can also   0.04419889502762431\n",
      "\n",
      "as WordNet   0.003484320557491289\n",
      "\n",
      "offering WebOCR   1.0\n",
      "\n",
      "no pauses   0.07692307692307693\n",
      "\n",
      "especially of   0.06666666666666667\n",
      "\n",
      "are unable   0.004149377593360996\n",
      "\n",
      "textual summary   0.2\n",
      "\n",
      "weather data   0.14285714285714285\n",
      "\n",
      "of Engineers   0.0017825311942959\n",
      "\n",
      "could do   0.0625\n",
      "\n",
      "hard if-then   0.3333333333333333\n",
      "\n",
      "its suitability   0.02857142857142857\n",
      "\n",
      "document .   0.1388888888888889\n",
      "\n",
      "The next   0.005208333333333333\n",
      "\n",
      "main knowledge   0.125\n",
      "\n",
      "levels but   0.045454545454545456\n",
      "\n",
      "immediate neighbors   1.0\n",
      "\n",
      "Labov ,   1.0\n",
      "\n",
      "vendors speech   0.25\n",
      "\n",
      "necessary ,   0.1\n",
      "\n",
      "these tasks   0.047619047619047616\n",
      "\n",
      "'s many   0.0196078431372549\n",
      "\n",
      "even level   0.037037037037037035\n",
      "\n",
      "12 categories   0.2\n",
      "\n",
      "to disseminate   0.0013280212483399733\n",
      "\n",
      "15-20 million   1.0\n",
      "\n",
      "a probabilistic   0.001226993865030675\n",
      "\n",
      "Schiffrin ,   1.0\n",
      "\n",
      "broad ,   0.25\n",
      "\n",
      "a highly   0.001226993865030675\n",
      "\n",
      "PageRank ,   0.16666666666666666\n",
      "\n",
      "the distinctive   0.0006920415224913495\n",
      "\n",
      "encode in   1.0\n",
      "\n",
      "or its   0.0045045045045045045\n",
      "\n",
      "bites man   0.3333333333333333\n",
      "\n",
      "one must   0.015384615384615385\n",
      "\n",
      "12 ,   0.2\n",
      "\n",
      "of discrete   0.00089126559714795\n",
      "\n",
      "accuracy in   0.03225806451612903\n",
      "\n",
      "which will   0.021739130434782608\n",
      "\n",
      "that simple   0.0035460992907801418\n",
      "\n",
      "turned into   1.0\n",
      "\n",
      "using journal   0.01694915254237288\n",
      "\n",
      "have difficulty   0.009615384615384616\n",
      "\n",
      "for parsing   0.0036101083032490976\n",
      "\n",
      "a set   0.01717791411042945\n",
      "\n",
      "demonstration was   0.2\n",
      "\n",
      "creation of   1.0\n",
      "\n",
      ", potentially   0.0005614823133071309\n",
      "\n",
      "computationally ;   0.5\n",
      "\n",
      "to gather   0.0013280212483399733\n",
      "\n",
      "Ethnography of   1.0\n",
      "\n",
      "but much   0.014705882352941176\n",
      "\n",
      "'s seminal   0.0196078431372549\n",
      "\n",
      "application .   0.07142857142857142\n",
      "\n",
      "to develop   0.006640106241699867\n",
      "\n",
      "also considered   0.014492753623188406\n",
      "\n",
      "me the   1.0\n",
      "\n",
      "and Natural   0.001445086705202312\n",
      "\n",
      "the Ge'ez   0.0006920415224913495\n",
      "\n",
      "segmentation may   0.030303030303030304\n",
      "\n",
      "L'action GRACE   1.0\n",
      "\n",
      "expression generation   0.1\n",
      "\n",
      "Eight years   1.0\n",
      "\n",
      "a row   0.001226993865030675\n",
      "\n",
      "no incorrect   0.07692307692307693\n",
      "\n",
      "of structured   0.00089126559714795\n",
      "\n",
      "a mixture   0.001226993865030675\n",
      "\n",
      "implemented using   0.2\n",
      "\n",
      "`` foreign   0.005291005291005291\n",
      "\n",
      "summaries available   0.023255813953488372\n",
      "\n",
      "several phases   0.045454545454545456\n",
      "\n",
      "make use   0.05\n",
      "\n",
      "Yale which   0.5\n",
      "\n",
      "Because ROUGE   0.5\n",
      "\n",
      "time question   0.030303030303030304\n",
      "\n",
      "getting published   0.25\n",
      "\n",
      "Commercial applications   0.5\n",
      "\n",
      "increased from   0.6\n",
      "\n",
      "classes of   0.4\n",
      "\n",
      "the Sparkle   0.0006920415224913495\n",
      "\n",
      "Paragraph Structure   1.0\n",
      "\n",
      "data sources   0.025974025974025976\n",
      "\n",
      "8000 samples   1.0\n",
      "\n",
      "parsing of   0.07142857142857142\n",
      "\n",
      "must make   0.07142857142857142\n",
      "\n",
      "larger sequences   0.0625\n",
      "\n",
      "grammar having   0.02702702702702703\n",
      "\n",
      "allowable expression   0.5\n",
      "\n",
      "and creation   0.001445086705202312\n",
      "\n",
      "course be   0.3333333333333333\n",
      "\n",
      "likely part   0.0625\n",
      "\n",
      "3 ''   0.2\n",
      "\n",
      "sometimes called   0.07692307692307693\n",
      "\n",
      "himself with   0.5\n",
      "\n",
      "which describe   0.007246376811594203\n",
      "\n",
      "to documents   0.0013280212483399733\n",
      "\n",
      "overcome this   0.5\n",
      "\n",
      "not context-free   0.008928571428571428\n",
      "\n",
      "as Greek   0.003484320557491289\n",
      "\n",
      "<s> Recently   0.0007686395080707148\n",
      "\n",
      "genre .   0.5\n",
      "\n",
      "accent ,   1.0\n",
      "\n",
      "NLG input   0.047619047619047616\n",
      "\n",
      "worse if   1.0\n",
      "\n",
      "Aided summarization   0.3333333333333333\n",
      "\n",
      "cases one   0.05555555555555555\n",
      "\n",
      "voice-activation ,   1.0\n",
      "\n",
      "Longacre ,   1.0\n",
      "\n",
      "Importance of   1.0\n",
      "\n",
      "smaller sub-sounds   0.14285714285714285\n",
      "\n",
      "accurate recognition   0.14285714285714285\n",
      "\n",
      "as there   0.003484320557491289\n",
      "\n",
      "Spanish ,   0.5\n",
      "\n",
      "be seen   0.012658227848101266\n",
      "\n",
      "computer speech   0.022727272727272728\n",
      "\n",
      "transform of   0.2\n",
      "\n",
      "fine tune   0.5\n",
      "\n",
      "in order   0.013108614232209739\n",
      "\n",
      "script will   0.25\n",
      "\n",
      "practice ,   0.5\n",
      "\n",
      "out a   0.07142857142857142\n",
      "\n",
      "for creating   0.0036101083032490976\n",
      "\n",
      "generation :   0.2222222222222222\n",
      "\n",
      "mentions ''   0.3333333333333333\n",
      "\n",
      "Word sense   0.2857142857142857\n",
      "\n",
      "classifiers -RRB-   0.5\n",
      "\n",
      "navigation ,   0.5\n",
      "\n",
      "`` President   0.005291005291005291\n",
      "\n",
      "feasible to   0.5\n",
      "\n",
      "so has   0.03333333333333333\n",
      "\n",
      "Code ,   1.0\n",
      "\n",
      "second layer   0.2\n",
      "\n",
      "may fail   0.019230769230769232\n",
      "\n",
      "and lexical   0.001445086705202312\n",
      "\n",
      "cutoff to   1.0\n",
      "\n",
      "once you   1.0\n",
      "\n",
      "program would   0.045454545454545456\n",
      "\n",
      "simply by   0.08333333333333333\n",
      "\n",
      "purpose at   0.2\n",
      "\n",
      "fully solved   0.16666666666666666\n",
      "\n",
      "positive and   0.2857142857142857\n",
      "\n",
      "concurrently with   1.0\n",
      "\n",
      "more such   0.010526315789473684\n",
      "\n",
      "Semantic Evaluation   0.3333333333333333\n",
      "\n",
      "of Arabic   0.00089126559714795\n",
      "\n",
      "Task and   0.6666666666666666\n",
      "\n",
      "times throughout   0.2\n",
      "\n",
      ", George   0.0005614823133071309\n",
      "\n",
      "general learning   0.045454545454545456\n",
      "\n",
      "on which   0.014150943396226415\n",
      "\n",
      "segmentation Sentence   0.030303030303030304\n",
      "\n",
      "trainer .   1.0\n",
      "\n",
      "solve algebra   0.25\n",
      "\n",
      ", wrote   0.0005614823133071309\n",
      "\n",
      "the best   0.008996539792387544\n",
      "\n",
      "structures in   0.2\n",
      "\n",
      "analogy and   1.0\n",
      "\n",
      ", mail   0.0005614823133071309\n",
      "\n",
      "<s> Formal   0.0007686395080707148\n",
      "\n",
      "coherence and   0.6666666666666666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps ,   0.5\n",
      "\n",
      "especially input   0.13333333333333333\n",
      "\n",
      "ways by   0.125\n",
      "\n",
      "see Tablet   0.05\n",
      "\n",
      "noise and   0.125\n",
      "\n",
      "or neutral   0.0045045045045045045\n",
      "\n",
      "what might   0.03125\n",
      "\n",
      "<s> What   0.0030745580322828594\n",
      "\n",
      "NLP algorithms   0.0425531914893617\n",
      "\n",
      "products '   0.25\n",
      "\n",
      "closely tied   0.2\n",
      "\n",
      "multiple approaches   0.07692307692307693\n",
      "\n",
      "is available   0.0020325203252032522\n",
      "\n",
      "are robust   0.004149377593360996\n",
      "\n",
      "' -RRB-   0.05263157894736842\n",
      "\n",
      "'s first   0.0196078431372549\n",
      "\n",
      "sources ,   0.16666666666666666\n",
      "\n",
      "output scores   0.038461538461538464\n",
      "\n",
      "deployed was   0.5\n",
      "\n",
      "new insights   0.041666666666666664\n",
      "\n",
      "<s> Encouraging   0.0007686395080707148\n",
      "\n",
      "positive -RRB-   0.14285714285714285\n",
      "\n",
      "tags .   0.3333333333333333\n",
      "\n",
      "of four   0.00089126559714795\n",
      "\n",
      "After 30   0.3333333333333333\n",
      "\n",
      "match the   0.3333333333333333\n",
      "\n",
      "Problem Solving   1.0\n",
      "\n",
      "Jelinek F.   0.5\n",
      "\n",
      "and Grass   0.001445086705202312\n",
      "\n",
      "operating on   0.5\n",
      "\n",
      "Each frame   0.16666666666666666\n",
      "\n",
      "who ''   0.1\n",
      "\n",
      "; By   0.02127659574468085\n",
      "\n",
      "parser generators   0.0625\n",
      "\n",
      "statistics :   0.125\n",
      "\n",
      "e.g. the   0.05357142857142857\n",
      "\n",
      "appear .   0.0625\n",
      "\n",
      "hopefully better   1.0\n",
      "\n",
      "-LRB- this   0.0027100271002710027\n",
      "\n",
      "the systems   0.0020761245674740486\n",
      "\n",
      "systems which   0.017857142857142856\n",
      "\n",
      "extraction depends   0.03225806451612903\n",
      "\n",
      "coarticulation ,   1.0\n",
      "\n",
      "Canada ?   0.16666666666666666\n",
      "\n",
      ", the   0.058394160583941604\n",
      "\n",
      "to the   0.10225763612217796\n",
      "\n",
      "requires in-depth   0.0625\n",
      "\n",
      "of science   0.00089126559714795\n",
      "\n",
      "contain words   0.08333333333333333\n",
      "\n",
      "Laclau ,   1.0\n",
      "\n",
      "language-specific changes   1.0\n",
      "\n",
      "a technique   0.001226993865030675\n",
      "\n",
      "recognition technology   0.008264462809917356\n",
      "\n",
      "<s> LexisNexis   0.0007686395080707148\n",
      "\n",
      "<s> With   0.003843197540353574\n",
      "\n",
      "only as   0.02631578947368421\n",
      "\n",
      "existing so   0.2\n",
      "\n",
      "These are   0.11764705882352941\n",
      "\n",
      "ROUGE-1 only   0.2\n",
      "\n",
      "'' 100   0.005154639175257732\n",
      "\n",
      "Noise in   1.0\n",
      "\n",
      "campaign is   0.2\n",
      "\n",
      "sometimes preferred   0.07692307692307693\n",
      "\n",
      "found Intelligent   0.07142857142857142\n",
      "\n",
      "from 50   0.009615384615384616\n",
      "\n",
      "a stationary   0.00245398773006135\n",
      "\n",
      ", Emanuel   0.0011229646266142617\n",
      "\n",
      "agreement among   0.3333333333333333\n",
      "\n",
      "multiply .   1.0\n",
      "\n",
      ", including   0.004491858506457047\n",
      "\n",
      "explicit by   0.2\n",
      "\n",
      "Optical character   0.6666666666666666\n",
      "\n",
      "When a   0.14285714285714285\n",
      "\n",
      "closely approximates   0.2\n",
      "\n",
      "Machine Summarization   0.1111111111111111\n",
      "\n",
      "deterministic rule   0.25\n",
      "\n",
      "become more   0.25\n",
      "\n",
      "the answer   0.009688581314878892\n",
      "\n",
      "Europe began   0.2\n",
      "\n",
      "accurate transcription   0.14285714285714285\n",
      "\n",
      "undertake harder   1.0\n",
      "\n",
      "Hulth used   0.3333333333333333\n",
      "\n",
      "interface .   0.25\n",
      "\n",
      "syllables but   0.5\n",
      "\n",
      "functions such   0.5\n",
      "\n",
      "English are   0.02702702702702703\n",
      "\n",
      "character error   0.045454545454545456\n",
      "\n",
      "methods achieved   0.022727272727272728\n",
      "\n",
      "UPV -RRB-   1.0\n",
      "\n",
      "The importance   0.005208333333333333\n",
      "\n",
      "predicted pollen   0.5\n",
      "\n",
      "the letters   0.0006920415224913495\n",
      "\n",
      "mobile email   0.5\n",
      "\n",
      "1964 to   1.0\n",
      "\n",
      "system .   0.11827956989247312\n",
      "\n",
      "some other   0.08433734939759036\n",
      "\n",
      "generic response   0.3333333333333333\n",
      "\n",
      "text more   0.006289308176100629\n",
      "\n",
      "them but   0.05263157894736842\n",
      "\n",
      "then we   0.05714285714285714\n",
      "\n",
      "Swedish pilots   1.0\n",
      "\n",
      "small knowledge   0.1111111111111111\n",
      "\n",
      "OCR -RRB-   0.02040816326530612\n",
      "\n",
      "are those   0.004149377593360996\n",
      "\n",
      "enumerated all   1.0\n",
      "\n",
      "elements of   0.25\n",
      "\n",
      "1990 dissertation   0.3333333333333333\n",
      "\n",
      "Speaker Dependent   0.16666666666666666\n",
      "\n",
      ", Adam   0.0005614823133071309\n",
      "\n",
      "intelligence ,   0.125\n",
      "\n",
      "expressed in   0.16666666666666666\n",
      "\n",
      "has turned   0.011904761904761904\n",
      "\n",
      "model mechanisms   0.03333333333333333\n",
      "\n",
      "common feature   0.04\n",
      "\n",
      "summary is   0.047619047619047616\n",
      "\n",
      "speech caused   0.006578947368421052\n",
      "\n",
      "complicated backgrounds   0.3333333333333333\n",
      "\n",
      "which has   0.050724637681159424\n",
      "\n",
      "This sequence   0.015873015873015872\n",
      "\n",
      "distinguish between   0.4\n",
      "\n",
      ", bigrams   0.0011229646266142617\n",
      "\n",
      "Greek and   0.3333333333333333\n",
      "\n",
      "The common   0.005208333333333333\n",
      "\n",
      "<s> Increasingly   0.0015372790161414297\n",
      "\n",
      "are broader   0.004149377593360996\n",
      "\n",
      "which had   0.007246376811594203\n",
      "\n",
      "learn it   0.07692307692307693\n",
      "\n",
      "implementation of   1.0\n",
      "\n",
      "Gene Ontology   1.0\n",
      "\n",
      "repeated relations   0.5\n",
      "\n",
      "as hidden   0.003484320557491289\n",
      "\n",
      "input to   0.07317073170731707\n",
      "\n",
      "1991 A   0.3333333333333333\n",
      "\n",
      "many types   0.019230769230769232\n",
      "\n",
      "Subsequently a   1.0\n",
      "\n",
      "Recently ,   1.0\n",
      "\n",
      "<s> While   0.0023059185242121443\n",
      "\n",
      "good ''   0.07692307692307693\n",
      "\n",
      "possible -LRB-   0.041666666666666664\n",
      "\n",
      "segments and   0.2\n",
      "\n",
      "<s> Front-End   0.0007686395080707148\n",
      "\n",
      "an automatic   0.015151515151515152\n",
      "\n",
      "evaluation :   0.037037037037037035\n",
      "\n",
      "The successful   0.005208333333333333\n",
      "\n",
      "newspaper .   0.3333333333333333\n",
      "\n",
      "<s> Issues   0.0015372790161414297\n",
      "\n",
      "a startlingly   0.001226993865030675\n",
      "\n",
      "produce a   0.13636363636363635\n",
      "\n",
      "to predict   0.0026560424966799467\n",
      "\n",
      "or automatically   0.009009009009009009\n",
      "\n",
      "succeeding on   1.0\n",
      "\n",
      "came into   0.5\n",
      "\n",
      "complex question   0.041666666666666664\n",
      "\n",
      "interested in   1.0\n",
      "\n",
      "distinctive initial   0.5\n",
      "\n",
      "effective in   0.3333333333333333\n",
      "\n",
      "This task   0.031746031746031744\n",
      "\n",
      "Two vertices   0.14285714285714285\n",
      "\n",
      "translation process   0.02702702702702703\n",
      "\n",
      "of many   0.0017825311942959\n",
      "\n",
      "important -RRB-   0.0625\n",
      "\n",
      "the Artificial   0.0006920415224913495\n",
      "\n",
      "left-recursion and   1.0\n",
      "\n",
      "'' approaches   0.010309278350515464\n",
      "\n",
      "is unclear   0.0020325203252032522\n",
      "\n",
      "for sound   0.0036101083032490976\n",
      "\n",
      "worth noting   0.5\n",
      "\n",
      "to distinguish   0.006640106241699867\n",
      "\n",
      "tasks .   0.125\n",
      "\n",
      "routed through   0.5\n",
      "\n",
      "this regard   0.01098901098901099\n",
      "\n",
      "in multiple   0.0018726591760299626\n",
      "\n",
      "into its   0.01282051282051282\n",
      "\n",
      "even languages   0.037037037037037035\n",
      "\n",
      "unclear whether   1.0\n",
      "\n",
      "Input -RRB-   0.5\n",
      "\n",
      "vibration ,   1.0\n",
      "\n",
      "a meaning   0.00245398773006135\n",
      "\n",
      "States Air   0.14285714285714285\n",
      "\n",
      "The acoustic   0.005208333333333333\n",
      "\n",
      "step -RRB-   0.06666666666666667\n",
      "\n",
      "volume and   0.25\n",
      "\n",
      "For nouns   0.01639344262295082\n",
      "\n",
      "for evaluation   0.0036101083032490976\n",
      "\n",
      "inter-annotator agreement   1.0\n",
      "\n",
      "or sentences   0.0045045045045045045\n",
      "\n",
      "interest .   0.09090909090909091\n",
      "\n",
      ", PAM   0.0005614823133071309\n",
      "\n",
      "evident that   0.5\n",
      "\n",
      "ways .   0.125\n",
      "\n",
      "<s> Initial   0.0007686395080707148\n",
      "\n",
      "-LRB- Wilensky   0.0027100271002710027\n",
      "\n",
      "not represent   0.008928571428571428\n",
      "\n",
      "of potential   0.0017825311942959\n",
      "\n",
      "has 2   0.011904761904761904\n",
      "\n",
      "ambiguities and   0.25\n",
      "\n",
      "by air   0.011428571428571429\n",
      "\n",
      "question or   0.023809523809523808\n",
      "\n",
      "Stages The   1.0\n",
      "\n",
      "-LRB- citation   0.03523035230352303\n",
      "\n",
      "both isloated   0.03225806451612903\n",
      "\n",
      "expect that   0.3333333333333333\n",
      "\n",
      "questions in   0.038461538461538464\n",
      "\n",
      "answer 90   0.03333333333333333\n",
      "\n",
      "example text   0.012345679012345678\n",
      "\n",
      "-LRB- NER   0.0027100271002710027\n",
      "\n",
      "a paper   0.001226993865030675\n",
      "\n",
      "or match   0.0045045045045045045\n",
      "\n",
      "Intuitively ,   1.0\n",
      "\n",
      "as knowledge   0.003484320557491289\n",
      "\n",
      "semantic theories   0.047619047619047616\n",
      "\n",
      "summarization .   0.12\n",
      "\n",
      "you see   0.07692307692307693\n",
      "\n",
      "what day   0.03125\n",
      "\n",
      "Lexical segmentation   0.5\n",
      "\n",
      "that requires   0.0070921985815602835\n",
      "\n",
      "metrics in   0.1111111111111111\n",
      "\n",
      ", Eurospeech\\/ICSLP   0.0005614823133071309\n",
      "\n",
      "will be   0.2571428571428571\n",
      "\n",
      "began planning   0.14285714285714285\n",
      "\n",
      "hand-produced rules   1.0\n",
      "\n",
      "NLG system   0.09523809523809523\n",
      "\n",
      "for both   0.0036101083032490976\n",
      "\n",
      "methods .   0.022727272727272728\n",
      "\n",
      "English for   0.02702702702702703\n",
      "\n",
      "an optimal   0.007575757575757576\n",
      "\n",
      ": Translation   0.00980392156862745\n",
      "\n",
      "training systems   0.03571428571428571\n",
      "\n",
      "divided into   0.6666666666666666\n",
      "\n",
      "Santoni B.   1.0\n",
      "\n",
      "splitting is   0.5\n",
      "\n",
      "type is   0.14285714285714285\n",
      "\n",
      "article is   0.034482758620689655\n",
      "\n",
      "blocks world   0.25\n",
      "\n",
      ", commanding   0.0005614823133071309\n",
      "\n",
      "sound should   0.1\n",
      "\n",
      "boundaries .   0.36363636363636365\n",
      "\n",
      ", adjectives   0.0005614823133071309\n",
      "\n",
      "use either   0.013888888888888888\n",
      "\n",
      "associated word   0.25\n",
      "\n",
      "the expression   0.001384083044982699\n",
      "\n",
      "hand-compiled list   1.0\n",
      "\n",
      "Using almost   0.5\n",
      "\n",
      "a result   0.0036809815950920245\n",
      "\n",
      "many different   0.07692307692307693\n",
      "\n",
      "POS tags   0.15384615384615385\n",
      "\n",
      "Guidelines see   0.5\n",
      "\n",
      "been heard   0.014705882352941176\n",
      "\n",
      "way ,   0.041666666666666664\n",
      "\n",
      "farther forward   1.0\n",
      "\n",
      "acoustic and   0.16666666666666666\n",
      "\n",
      "counter examples   1.0\n",
      "\n",
      "weather reports   0.2857142857142857\n",
      "\n",
      "isolated-word recognizers   1.0\n",
      "\n",
      "database ,   0.1\n",
      "\n",
      "air is   0.2\n",
      "\n",
      "the Senseval   0.0006920415224913495\n",
      "\n",
      "tests the   0.5\n",
      "\n",
      "matrix ,   1.0\n",
      "\n",
      "unlike brain   1.0\n",
      "\n",
      "must produce   0.07142857142857142\n",
      "\n",
      "This phenomenon   0.031746031746031744\n",
      "\n",
      "<s> ﻿Natural   0.0007686395080707148\n",
      "\n",
      "pre-defined or   0.5\n",
      "\n",
      "referring expressions   0.5\n",
      "\n",
      "identify and   0.08333333333333333\n",
      "\n",
      "`` supervised   0.026455026455026454\n",
      "\n",
      "signal is   0.16666666666666666\n",
      "\n",
      "to end   0.0026560424966799467\n",
      "\n",
      "vehicle Navigation   1.0\n",
      "\n",
      "aid in   0.75\n",
      "\n",
      "of sentence-level   0.00089126559714795\n",
      "\n",
      "linguistics ,   0.4\n",
      "\n",
      "a shortened   0.001226993865030675\n",
      "\n",
      "theory and   0.07692307692307693\n",
      "\n",
      "systems analyze   0.008928571428571428\n",
      "\n",
      "translation or   0.013513513513513514\n",
      "\n",
      "the UK   0.002768166089965398\n",
      "\n",
      "case of   0.35294117647058826\n",
      "\n",
      "good for   0.07692307692307693\n",
      "\n",
      "Evaluation The   0.1111111111111111\n",
      "\n",
      "different profile   0.02040816326530612\n",
      "\n",
      "processing task   0.018518518518518517\n",
      "\n",
      "need is   0.047619047619047616\n",
      "\n",
      "Therefore ,   1.0\n",
      "\n",
      "historically -RRB-   0.5\n",
      "\n",
      "of concern   0.00089126559714795\n",
      "\n",
      "evaluation step   0.037037037037037035\n",
      "\n",
      "underlying knowledge   0.3333333333333333\n",
      "\n",
      "a rich   0.0036809815950920245\n",
      "\n",
      "printed documents   0.08333333333333333\n",
      "\n",
      "why HMMs   0.14285714285714285\n",
      "\n",
      "salience .   1.0\n",
      "\n",
      "stages are   0.5\n",
      "\n",
      "correlate with   0.6666666666666666\n",
      "\n",
      "simple English   0.038461538461538464\n",
      "\n",
      "is ``   0.0040650406504065045\n",
      "\n",
      "reasons that   0.5\n",
      "\n",
      "these topics   0.023809523809523808\n",
      "\n",
      "learning techniques   0.023255813953488372\n",
      "\n",
      "Michigan ,   1.0\n",
      "\n",
      "character is   0.09090909090909091\n",
      "\n",
      "of language   0.004456327985739751\n",
      "\n",
      "Army Avionics   0.25\n",
      "\n",
      ", phrases   0.0005614823133071309\n",
      "\n",
      "breathing was   1.0\n",
      "\n",
      "statistical machine   0.09090909090909091\n",
      "\n",
      "often a   0.022727272727272728\n",
      "\n",
      "Janet Kolodner   0.5\n",
      "\n",
      "shared-task events   1.0\n",
      "\n",
      "multilingual corpus   0.3333333333333333\n",
      "\n",
      "LUNAR ,   0.6666666666666666\n",
      "\n",
      "US Navy   0.14285714285714285\n",
      "\n",
      "role as   0.25\n",
      "\n",
      "common to   0.04\n",
      "\n",
      "like English   0.07142857142857142\n",
      "\n",
      "with manually   0.00546448087431694\n",
      "\n",
      "realizations as   1.0\n",
      "\n",
      "a feature   0.00245398773006135\n",
      "\n",
      "and large-scale   0.001445086705202312\n",
      "\n",
      "of tourism   0.00089126559714795\n",
      "\n",
      "'' tagging   0.005154639175257732\n",
      "\n",
      "user ,   0.07142857142857142\n",
      "\n",
      "a count   0.001226993865030675\n",
      "\n",
      "would generate   0.018867924528301886\n",
      "\n",
      "essentially they   0.125\n",
      "\n",
      "whereby words   1.0\n",
      "\n",
      "with the   0.15300546448087432\n",
      "\n",
      "what they   0.03125\n",
      "\n",
      "1966 ,   0.3333333333333333\n",
      "\n",
      "generated texts   0.06666666666666667\n",
      "\n",
      "languages See   0.02\n",
      "\n",
      "survey of   1.0\n",
      "\n",
      "<s> Glass-box   0.0007686395080707148\n",
      "\n",
      "or function   0.0045045045045045045\n",
      "\n",
      "machine recognition   0.012658227848101266\n",
      "\n",
      "top level   0.2\n",
      "\n",
      "all natural   0.023255813953488372\n",
      "\n",
      "has proven   0.011904761904761904\n",
      "\n",
      "IR and   0.3333333333333333\n",
      "\n",
      "talk page   1.0\n",
      "\n",
      "to existing   0.0013280212483399733\n",
      "\n",
      "are exploited   0.004149377593360996\n",
      "\n",
      "capturing data   1.0\n",
      "\n",
      "sets ,   0.09090909090909091\n",
      "\n",
      "Robyn Carston   1.0\n",
      "\n",
      "-RRB- up   0.0027100271002710027\n",
      "\n",
      ", Computer   0.0005614823133071309\n",
      "\n",
      "of idioms   0.00089126559714795\n",
      "\n",
      "'' by   0.02577319587628866\n",
      "\n",
      "walks and   0.5\n",
      "\n",
      "The various   0.005208333333333333\n",
      "\n",
      "-RRB- examples   0.0027100271002710027\n",
      "\n",
      "would consist   0.018867924528301886\n",
      "\n",
      "is being   0.006097560975609756\n",
      "\n",
      "paper Shipibo   0.09090909090909091\n",
      "\n",
      "input .   0.04878048780487805\n",
      "\n",
      "duplicate or   0.5\n",
      "\n",
      "word stems   0.016666666666666666\n",
      "\n",
      "multi-document summarization   0.75\n",
      "\n",
      "The final   0.005208333333333333\n",
      "\n",
      "easily be   0.1111111111111111\n",
      "\n",
      ", articulation   0.0005614823133071309\n",
      "\n",
      "given approach   0.08333333333333333\n",
      "\n",
      "sentences ,   0.10526315789473684\n",
      "\n",
      "the augmented   0.0006920415224913495\n",
      "\n",
      "rare .   0.5\n",
      "\n",
      "of rules   0.00267379679144385\n",
      "\n",
      "we try   0.022222222222222223\n",
      "\n",
      "summarization exactly   0.02\n",
      "\n",
      "used for   0.13274336283185842\n",
      "\n",
      "proceeds in   1.0\n",
      "\n",
      "abstracts ,   0.5\n",
      "\n",
      "Extraction techniques   0.3333333333333333\n",
      "\n",
      "various term   0.05555555555555555\n",
      "\n",
      "at run-time   0.014705882352941176\n",
      "\n",
      "democratizing data   0.5\n",
      "\n",
      "translation -RRB-   0.02702702702702703\n",
      "\n",
      "even ,   0.037037037037037035\n",
      "\n",
      "also needs   0.014492753623188406\n",
      "\n",
      "of triples   0.00089126559714795\n",
      "\n",
      "automatic translation   0.08695652173913043\n",
      "\n",
      "more categories   0.010526315789473684\n",
      "\n",
      "consideration neural   0.3333333333333333\n",
      "\n",
      "sentences ``   0.02631578947368421\n",
      "\n",
      "length using   0.125\n",
      "\n",
      "be for   0.004219409282700422\n",
      "\n",
      "answers to   0.08333333333333333\n",
      "\n",
      "part-of-speech ,   0.06666666666666667\n",
      "\n",
      "it agrees   0.008547008547008548\n",
      "\n",
      "are delimited   0.012448132780082987\n",
      "\n",
      "-LRB- context-free   0.0027100271002710027\n",
      "\n",
      ", Talmy   0.0005614823133071309\n",
      "\n",
      "Algorithms Both   0.5\n",
      "\n",
      "all get   0.023255813953488372\n",
      "\n",
      "<s> Anaphora   0.0007686395080707148\n",
      "\n",
      "the reference   0.0006920415224913495\n",
      "\n",
      "2,026,329 -RRB-   1.0\n",
      "\n",
      "payment systems   1.0\n",
      "\n",
      "coarse-grained relations   1.0\n",
      "\n",
      "acoustic noise   0.3333333333333333\n",
      "\n",
      "be implemented   0.008438818565400843\n",
      "\n",
      "Typhoon currently   1.0\n",
      "\n",
      ", classroom   0.0005614823133071309\n",
      "\n",
      "improved .   0.25\n",
      "\n",
      "or discourse   0.009009009009009009\n",
      "\n",
      "prisoners ?   0.5\n",
      "\n",
      "also :   0.028985507246376812\n",
      "\n",
      "that may   0.0070921985815602835\n",
      "\n",
      "the purpose   0.001384083044982699\n",
      "\n",
      "theorists of   1.0\n",
      "\n",
      "Like keyphrase   0.5\n",
      "\n",
      "conversational content   1.0\n",
      "\n",
      "-RRB- as   0.008130081300813009\n",
      "\n",
      "shallow methods   0.16666666666666666\n",
      "\n",
      "by taking   0.005714285714285714\n",
      "\n",
      "model will   0.03333333333333333\n",
      "\n",
      "a science   0.00245398773006135\n",
      "\n",
      "phone ,   0.5\n",
      "\n",
      "instructed to   1.0\n",
      "\n",
      "of each   0.006238859180035651\n",
      "\n",
      "for summarization   0.0036101083032490976\n",
      "\n",
      "in logical   0.0018726591760299626\n",
      "\n",
      "major degradation   0.08333333333333333\n",
      "\n",
      "language or   0.013513513513513514\n",
      "\n",
      "morphology of   0.14285714285714285\n",
      "\n",
      "data where   0.012987012987012988\n",
      "\n",
      "by combining   0.005714285714285714\n",
      "\n",
      "its entirety   0.02857142857142857\n",
      "\n",
      "70s the   1.0\n",
      "\n",
      "done in   0.45454545454545453\n",
      "\n",
      "<s> Machine   0.0023059185242121443\n",
      "\n",
      "and recall   0.002890173410404624\n",
      "\n",
      "are presented   0.004149377593360996\n",
      "\n",
      "bites dog   0.3333333333333333\n",
      "\n",
      "time warping   0.12121212121212122\n",
      "\n",
      "25 %   1.0\n",
      "\n",
      "expression ,   0.2\n",
      "\n",
      "that time   0.0035460992907801418\n",
      "\n",
      "human-ratings and   1.0\n",
      "\n",
      "Penn -RRB-   0.1111111111111111\n",
      "\n",
      "current commercial   0.14285714285714285\n",
      "\n",
      "objective sentences   0.2\n",
      "\n",
      "processing uses   0.018518518518518517\n",
      "\n",
      "to enable   0.0013280212483399733\n",
      "\n",
      "place to   0.25\n",
      "\n",
      "testing for   0.2\n",
      "\n",
      "concepts are   0.4\n",
      "\n",
      "each state   0.022222222222222223\n",
      "\n",
      "capable of   1.0\n",
      "\n",
      "the steady   0.001384083044982699\n",
      "\n",
      "-LRB- digital   0.0027100271002710027\n",
      "\n",
      "earliest-used machine   0.5\n",
      "\n",
      "cases ,   0.3888888888888889\n",
      "\n",
      "and Snyder   0.001445086705202312\n",
      "\n",
      "speech from   0.006578947368421052\n",
      "\n",
      "language -RRB-   0.013513513513513514\n",
      "\n",
      "When we   0.14285714285714285\n",
      "\n",
      "by relying   0.005714285714285714\n",
      "\n",
      "key theorists   0.16666666666666666\n",
      "\n",
      "systems for   0.017857142857142856\n",
      "\n",
      "possible answers   0.041666666666666664\n",
      "\n",
      "`` Computer   0.005291005291005291\n",
      "\n",
      "English in   0.02702702702702703\n",
      "\n",
      "from it   0.009615384615384616\n",
      "\n",
      "solved first   0.2\n",
      "\n",
      "quoting people   1.0\n",
      "\n",
      "<s> Prominent   0.0007686395080707148\n",
      "\n",
      "= Machine   0.1111111111111111\n",
      "\n",
      "MCE -RRB-   1.0\n",
      "\n",
      "model information   0.03333333333333333\n",
      "\n",
      "<s> Current   0.0023059185242121443\n",
      "\n",
      "acts or   0.3333333333333333\n",
      "\n",
      "Makoto Nagao   1.0\n",
      "\n",
      "which often   0.007246376811594203\n",
      "\n",
      "influenced by   1.0\n",
      "\n",
      "as separate   0.003484320557491289\n",
      "\n",
      "directly .   0.2\n",
      "\n",
      ", HMM-based   0.0005614823133071309\n",
      "\n",
      "e.g. pictures   0.017857142857142856\n",
      "\n",
      "in these   0.0056179775280898875\n",
      "\n",
      "LexRank is   0.08333333333333333\n",
      "\n",
      "regions .   0.5\n",
      "\n",
      "which a   0.014492753623188406\n",
      "\n",
      "and combining   0.001445086705202312\n",
      "\n",
      "grounded in   1.0\n",
      "\n",
      "From these   1.0\n",
      "\n",
      "want to   0.8333333333333334\n",
      "\n",
      "system to   0.053763440860215055\n",
      "\n",
      "e.g. ``   0.017857142857142856\n",
      "\n",
      "R. Schroeder   0.16666666666666666\n",
      "\n",
      "and recording   0.001445086705202312\n",
      "\n",
      "for English   0.0036101083032490976\n",
      "\n",
      "about following   0.025\n",
      "\n",
      "The method   0.005208333333333333\n",
      "\n",
      "tasks in   0.09375\n",
      "\n",
      "camp ''   0.25\n",
      "\n",
      "places ,   0.5\n",
      "\n",
      "Furthermore ,   1.0\n",
      "\n",
      "application of   0.2857142857142857\n",
      "\n",
      "this book   0.01098901098901099\n",
      "\n",
      "to message   0.0013280212483399733\n",
      "\n",
      "services ,   0.3333333333333333\n",
      "\n",
      "sense ,   0.125\n",
      "\n",
      "new domains   0.041666666666666664\n",
      "\n",
      "greatly affect   0.14285714285714285\n",
      "\n",
      "successful finished   0.1111111111111111\n",
      "\n",
      "hits than   1.0\n",
      "\n",
      "label discourse   1.0\n",
      "\n",
      "the search   0.0006920415224913495\n",
      "\n",
      "Behind this   1.0\n",
      "\n",
      "attempts at   0.3333333333333333\n",
      "\n",
      "the course   0.0006920415224913495\n",
      "\n",
      "considered good   0.1111111111111111\n",
      "\n",
      "context to   0.030303030303030304\n",
      "\n",
      "consists of   1.0\n",
      "\n",
      "environment .   0.3333333333333333\n",
      "\n",
      "main drawback   0.125\n",
      "\n",
      "1974 Ray   1.0\n",
      "\n",
      "Each word   0.16666666666666666\n",
      "\n",
      "potential to   0.2857142857142857\n",
      "\n",
      "some grammar   0.012048192771084338\n",
      "\n",
      "computer .   0.06818181818181818\n",
      "\n",
      "that output   0.0035460992907801418\n",
      "\n",
      "presented to   0.16666666666666666\n",
      "\n",
      "the final   0.002768166089965398\n",
      "\n",
      "starts with   0.5\n",
      "\n",
      "answers .   0.08333333333333333\n",
      "\n",
      "news stories   0.07692307692307693\n",
      "\n",
      "how well   0.20689655172413793\n",
      "\n",
      "apply to   0.4\n",
      "\n",
      "proposed .   0.1111111111111111\n",
      "\n",
      "can not   0.08287292817679558\n",
      "\n",
      ", Mariani   0.0005614823133071309\n",
      "\n",
      "you have   0.15384615384615385\n",
      "\n",
      "precision -   0.2\n",
      "\n",
      "ones in   0.1\n",
      "\n",
      "is required   0.0040650406504065045\n",
      "\n",
      "is true   0.0020325203252032522\n",
      "\n",
      "Polar Lander   1.0\n",
      "\n",
      "local document   0.3333333333333333\n",
      "\n",
      "a verb   0.007361963190184049\n",
      "\n",
      "new utterance   0.041666666666666664\n",
      "\n",
      "filtered from   0.3333333333333333\n",
      "\n",
      "not pursued   0.008928571428571428\n",
      "\n",
      "tagging program   0.04\n",
      "\n",
      "a context-free   0.0036809815950920245\n",
      "\n",
      "coherent summary   0.2\n",
      "\n",
      "boundaries may   0.09090909090909091\n",
      "\n",
      "analysis --   0.015384615384615385\n",
      "\n",
      "and minimum   0.001445086705202312\n",
      "\n",
      "4-gram matching   1.0\n",
      "\n",
      "several ambiguous   0.045454545454545456\n",
      "\n",
      "a threshold   0.0036809815950920245\n",
      "\n",
      "Around the   1.0\n",
      "\n",
      "expect ;   0.3333333333333333\n",
      "\n",
      "text 's   0.006289308176100629\n",
      "\n",
      "documents with   0.05263157894736842\n",
      "\n",
      "arguably -RRB-   0.5\n",
      "\n",
      "has wide   0.011904761904761904\n",
      "\n",
      ", organization   0.0011229646266142617\n",
      "\n",
      "two classes   0.034482758620689655\n",
      "\n",
      "American prisoners   0.2\n",
      "\n",
      "systems developed   0.017857142857142856\n",
      "\n",
      "the original   0.006920415224913495\n",
      "\n",
      "2006 ,   0.3333333333333333\n",
      "\n",
      "increasingly complex   0.3333333333333333\n",
      "\n",
      "Transform ,   1.0\n",
      "\n",
      "is felt   0.0020325203252032522\n",
      "\n",
      "power increased   0.25\n",
      "\n",
      "150 separate   0.5\n",
      "\n",
      "one has   0.015384615384615385\n",
      "\n",
      "<s> Commanders   0.0007686395080707148\n",
      "\n",
      "Linguistics ''   0.3333333333333333\n",
      "\n",
      "then applies   0.02857142857142857\n",
      "\n",
      "question focus   0.023809523809523808\n",
      "\n",
      "BLEU .   0.3333333333333333\n",
      "\n",
      "different way   0.02040816326530612\n",
      "\n",
      "particularly effective   0.2\n",
      "\n",
      "Error Rates   0.5\n",
      "\n",
      "ca n't   1.0\n",
      "\n",
      "to texts   0.0013280212483399733\n",
      "\n",
      "the voice   0.0006920415224913495\n",
      "\n",
      "in the   0.2602996254681648\n",
      "\n",
      "a US   0.00245398773006135\n",
      "\n",
      "and nouns   0.001445086705202312\n",
      "\n",
      "reCAPTCHA system   1.0\n",
      "\n",
      ", followed   0.0005614823133071309\n",
      "\n",
      ", EMNLP   0.0005614823133071309\n",
      "\n",
      "creating pre-defined   0.14285714285714285\n",
      "\n",
      "major database   0.08333333333333333\n",
      "\n",
      ", Richard   0.0005614823133071309\n",
      "\n",
      "Prolog generally   1.0\n",
      "\n",
      "lowering of   1.0\n",
      "\n",
      "the diagramming   0.001384083044982699\n",
      "\n",
      "standards and   0.2\n",
      "\n",
      "marker vs.   1.0\n",
      "\n",
      "to read   0.0013280212483399733\n",
      "\n",
      "that an   0.0035460992907801418\n",
      "\n",
      "Speech processing   0.03225806451612903\n",
      "\n",
      "of Natural   0.00089126559714795\n",
      "\n",
      "a prior   0.001226993865030675\n",
      "\n",
      "approach -RRB-   0.05714285714285714\n",
      "\n",
      "<s> Interactive   0.0007686395080707148\n",
      "\n",
      "person who   0.05263157894736842\n",
      "\n",
      "language modeling   0.006756756756756757\n",
      "\n",
      "conversation or   0.25\n",
      "\n",
      "architecture uses   0.5\n",
      "\n",
      "<s> Profile   0.0007686395080707148\n",
      "\n",
      "prose text   1.0\n",
      "\n",
      "are certain   0.004149377593360996\n",
      "\n",
      "<s> Warren   0.0007686395080707148\n",
      "\n",
      "an easy   0.007575757575757576\n",
      "\n",
      "manual evaluation   0.5\n",
      "\n",
      "example -LRB-   0.012345679012345678\n",
      "\n",
      "several summarization   0.045454545454545456\n",
      "\n",
      "of Canada   0.0017825311942959\n",
      "\n",
      "differing contexts   1.0\n",
      "\n",
      "of word-forms   0.00089126559714795\n",
      "\n",
      "author of   0.3333333333333333\n",
      "\n",
      ", MT   0.0011229646266142617\n",
      "\n",
      "frame has   0.5\n",
      "\n",
      "user .   0.21428571428571427\n",
      "\n",
      "that says   0.0035460992907801418\n",
      "\n",
      "'' text   0.005154639175257732\n",
      "\n",
      "commands or   0.2\n",
      "\n",
      "contexts make   0.14285714285714285\n",
      "\n",
      "Lander used   0.5\n",
      "\n",
      "with regards   0.00546448087431694\n",
      "\n",
      "a variety   0.008588957055214725\n",
      "\n",
      "based only   0.018518518518518517\n",
      "\n",
      "scanner to   0.3333333333333333\n",
      "\n",
      ", NN   0.0005614823133071309\n",
      "\n",
      "'s informativeness   0.0196078431372549\n",
      "\n",
      "text-to-speech technology   0.25\n",
      "\n",
      "all four   0.023255813953488372\n",
      "\n",
      "pre-existing corpus   0.5\n",
      "\n",
      "2001 -RRB-   0.5\n",
      "\n",
      "1978 -RRB-   0.6666666666666666\n",
      "\n",
      "of connected   0.00089126559714795\n",
      "\n",
      "tools mostly   0.16666666666666666\n",
      "\n",
      "indiscriminate .   1.0\n",
      "\n",
      "both linguistic   0.03225806451612903\n",
      "\n",
      "% accurate   0.05128205128205128\n",
      "\n",
      "and data   0.005780346820809248\n",
      "\n",
      "co-occurrence in   0.3333333333333333\n",
      "\n",
      "OCR technology   0.1836734693877551\n",
      "\n",
      "normalize for   1.0\n",
      "\n",
      "it can   0.05128205128205128\n",
      "\n",
      "The Georgetown   0.015625\n",
      "\n",
      "Microphone on   1.0\n",
      "\n",
      "shapes of   0.6666666666666666\n",
      "\n",
      "The Archaeology   0.005208333333333333\n",
      "\n",
      "Measuring progress   1.0\n",
      "\n",
      "produce useful   0.045454545454545456\n",
      "\n",
      "actions .   1.0\n",
      "\n",
      "compiler ,   0.3333333333333333\n",
      "\n",
      "might be   0.23076923076923078\n",
      "\n",
      "approximation thereof   0.16666666666666666\n",
      "\n",
      "are used   0.03319502074688797\n",
      "\n",
      "two include   0.034482758620689655\n",
      "\n",
      "ATNs ''   0.3333333333333333\n",
      "\n",
      "F35 Lightning   1.0\n",
      "\n",
      "have approached   0.009615384615384616\n",
      "\n",
      "How ,   0.14285714285714285\n",
      "\n",
      "-LRB- often   0.005420054200542005\n",
      "\n",
      "as overall   0.003484320557491289\n",
      "\n",
      "segmentation problems   0.06060606060606061\n",
      "\n",
      "Extrinsic evaluation   0.5\n",
      "\n",
      "of navigation   0.00089126559714795\n",
      "\n",
      "create some   0.058823529411764705\n",
      "\n",
      "problem from   0.022727272727272728\n",
      "\n",
      "`` recommendation   0.010582010582010581\n",
      "\n",
      "forecasts from   0.2\n",
      "\n",
      "The most   0.026041666666666668\n",
      "\n",
      "This section   0.031746031746031744\n",
      "\n",
      "One might   0.07692307692307693\n",
      "\n",
      "systems that   0.0625\n",
      "\n",
      "and parsing   0.001445086705202312\n",
      "\n",
      "currently .   0.14285714285714285\n",
      "\n",
      "schemata .   1.0\n",
      "\n",
      "dictionary entries   0.14285714285714285\n",
      "\n",
      "also many   0.014492753623188406\n",
      "\n",
      "also capitalized   0.014492753623188406\n",
      "\n",
      "Efficient algorithms   1.0\n",
      "\n",
      ", isolated   0.0005614823133071309\n",
      "\n",
      "notable early   1.0\n",
      "\n",
      "task requires   0.023809523809523808\n",
      "\n",
      "Grammatical dependency   1.0\n",
      "\n",
      "Fourier Transform   0.3333333333333333\n",
      "\n",
      "most positive   0.017241379310344827\n",
      "\n",
      "This work   0.031746031746031744\n",
      "\n",
      "-LRB- Meehan   0.0027100271002710027\n",
      "\n",
      "contain strings   0.08333333333333333\n",
      "\n",
      "usually a   0.03125\n",
      "\n",
      "-LRB- Carbonell   0.0027100271002710027\n",
      "\n",
      "semantic constraints   0.047619047619047616\n",
      "\n",
      "improve machine   0.07692307692307693\n",
      "\n",
      "accuracy of   0.12903225806451613\n",
      "\n",
      "`` Apparatus   0.005291005291005291\n",
      "\n",
      "'' and   0.06701030927835051\n",
      "\n",
      "thus avoiding   0.1\n",
      "\n",
      "single binary   0.07142857142857142\n",
      "\n",
      "second step   0.2\n",
      "\n",
      "but steadily   0.014705882352941176\n",
      "\n",
      "of key   0.00089126559714795\n",
      "\n",
      "comprehensive model   0.2\n",
      "\n",
      "impressive results   0.5\n",
      "\n",
      "requiring knowledge   0.5\n",
      "\n",
      "such ambiguity   0.024390243902439025\n",
      "\n",
      "between lexical   0.05128205128205128\n",
      "\n",
      "Parsing :   0.2\n",
      "\n",
      "too expensive   0.3333333333333333\n",
      "\n",
      "into consideration   0.01282051282051282\n",
      "\n",
      "pruned to   1.0\n",
      "\n",
      "IT technology   1.0\n",
      "\n",
      "<s> Goldberg   0.0007686395080707148\n",
      "\n",
      "phrase-structure grammars   1.0\n",
      "\n",
      "doctors -RRB-   0.3333333333333333\n",
      "\n",
      "to foster   0.0013280212483399733\n",
      "\n",
      "any significant   0.03225806451612903\n",
      "\n",
      "pilots flying   0.5\n",
      "\n",
      "portable ,   0.3333333333333333\n",
      "\n",
      "allows the   0.375\n",
      "\n",
      "<s> Higher   0.0007686395080707148\n",
      "\n",
      "which even   0.007246376811594203\n",
      "\n",
      "is another   0.0040650406504065045\n",
      "\n",
      "of pollen   0.0017825311942959\n",
      "\n",
      "edges are   0.14285714285714285\n",
      "\n",
      "of a   0.08199643493761141\n",
      "\n",
      "pattern has   0.16666666666666666\n",
      "\n",
      "digital texts   0.14285714285714285\n",
      "\n",
      "Advanced ,   0.2\n",
      "\n",
      "spelling .   1.0\n",
      "\n",
      "physics that   1.0\n",
      "\n",
      "lattice -RRB-   1.0\n",
      "\n",
      "how to   0.10344827586206896\n",
      "\n",
      "This strategy   0.015873015873015872\n",
      "\n",
      "connected directly   0.2\n",
      "\n",
      "of linguistics   0.00089126559714795\n",
      "\n",
      "by Piron   0.005714285714285714\n",
      "\n",
      "'' This   0.005154639175257732\n",
      "\n",
      "accuracy for   0.06451612903225806\n",
      "\n",
      "other to   0.014285714285714285\n",
      "\n",
      "it even   0.008547008547008548\n",
      "\n",
      "feature statistical   0.07692307692307693\n",
      "\n",
      "a unified   0.001226993865030675\n",
      "\n",
      "subscription department   1.0\n",
      "\n",
      "been devoted   0.014705882352941176\n",
      "\n",
      "Approaches Bernard   0.3333333333333333\n",
      "\n",
      "are being   0.008298755186721992\n",
      "\n",
      "Some scholars   0.047619047619047616\n",
      "\n",
      "compute various   0.5\n",
      "\n",
      "nice side   0.25\n",
      "\n",
      "result is   0.18181818181818182\n",
      "\n",
      "for developing   0.007220216606498195\n",
      "\n",
      "source -   0.041666666666666664\n",
      "\n",
      "analyzed and   0.2\n",
      "\n",
      "because many   0.03333333333333333\n",
      "\n",
      "then noun   0.02857142857142857\n",
      "\n",
      "H. Shepard   0.5\n",
      "\n",
      "classifier is   0.14285714285714285\n",
      "\n",
      ", UPV   0.0005614823133071309\n",
      "\n",
      "-- to   0.04\n",
      "\n",
      "the documents   0.0020761245674740486\n",
      "\n",
      "information is   0.043478260869565216\n",
      "\n",
      "applies a   0.2857142857142857\n",
      "\n",
      "of sublanguage   0.0017825311942959\n",
      "\n",
      "are ranked   0.004149377593360996\n",
      "\n",
      "text structure   0.006289308176100629\n",
      "\n",
      "that are   0.05319148936170213\n",
      "\n",
      "similarity to   0.1\n",
      "\n",
      "reasonable approximation   0.5\n",
      "\n",
      "important by   0.0625\n",
      "\n",
      "objectives :   0.5\n",
      "\n",
      "agrees with   1.0\n",
      "\n",
      "written-out number   1.0\n",
      "\n",
      "one used   0.015384615384615385\n",
      "\n",
      "not mark   0.008928571428571428\n",
      "\n",
      "goals of   1.0\n",
      "\n",
      "HLT ,   1.0\n",
      "\n",
      "and final   0.001445086705202312\n",
      "\n",
      "to build   0.0013280212483399733\n",
      "\n",
      "Potter ,   1.0\n",
      "\n",
      "pilot effectiveness   0.2\n",
      "\n",
      "from that   0.009615384615384616\n",
      "\n",
      "and depth   0.001445086705202312\n",
      "\n",
      "help determine   0.1111111111111111\n",
      "\n",
      "1971 Terry   0.3333333333333333\n",
      "\n",
      ", pitch   0.0005614823133071309\n",
      "\n",
      "very widely   0.024390243902439025\n",
      "\n",
      "Sensory ,   1.0\n",
      "\n",
      "but that   0.04411764705882353\n",
      "\n",
      "Translation ''   0.3333333333333333\n",
      "\n",
      "France installing   0.25\n",
      "\n",
      "approach 90   0.02857142857142857\n",
      "\n",
      "at its   0.014705882352941176\n",
      "\n",
      "digits ``   1.0\n",
      "\n",
      "these two   0.023809523809523808\n",
      "\n",
      "rise to   0.5\n",
      "\n",
      "discors pour   1.0\n",
      "\n",
      ", rarity   0.0005614823133071309\n",
      "\n",
      "probabilities not   0.09090909090909091\n",
      "\n",
      "custom software   0.5\n",
      "\n",
      "the National   0.001384083044982699\n",
      "\n",
      "a document   0.008588957055214725\n",
      "\n",
      "performed through   0.1\n",
      "\n",
      "to arrive   0.0013280212483399733\n",
      "\n",
      "parameters ,   0.25\n",
      "\n",
      "features ''   0.038461538461538464\n",
      "\n",
      "speech dynamics   0.006578947368421052\n",
      "\n",
      "be generated   0.004219409282700422\n",
      "\n",
      "Corpus was   0.125\n",
      "\n",
      "Gismo .   0.5\n",
      "\n",
      "users sometimes   0.1111111111111111\n",
      "\n",
      "horoscope machines   1.0\n",
      "\n",
      "-RRB- and   0.05420054200542006\n",
      "\n",
      "where clear   0.02857142857142857\n",
      "\n",
      "up the   0.045454545454545456\n",
      "\n",
      "technologies --   0.25\n",
      "\n",
      "unrealistically high   1.0\n",
      "\n",
      "continues to   1.0\n",
      "\n",
      "tagging ,   0.08\n",
      "\n",
      "with ``   0.01639344262295082\n",
      "\n",
      "Organization ,   1.0\n",
      "\n",
      "of non-annotated   0.00089126559714795\n",
      "\n",
      "'' it   0.005154639175257732\n",
      "\n",
      "comparable .   1.0\n",
      "\n",
      "processor speeds   1.0\n",
      "\n",
      "recommendations and   1.0\n",
      "\n",
      "government .   0.3333333333333333\n",
      "\n",
      "toy project   0.5\n",
      "\n",
      "<s> Langues   0.0007686395080707148\n",
      "\n",
      "Whether NLP   0.5\n",
      "\n",
      "-LRB- icon   0.0027100271002710027\n",
      "\n",
      ", an   0.005614823133071308\n",
      "\n",
      "<s> Rule-based   0.0007686395080707148\n",
      "\n",
      "Smith went   1.0\n",
      "\n",
      "2,000 or   0.5\n",
      "\n",
      "enumerate every   1.0\n",
      "\n",
      "Edward Robinson   1.0\n",
      "\n",
      "analysis Sublanguage   0.015384615384615385\n",
      "\n",
      "became an   0.2\n",
      "\n",
      "The Army   0.005208333333333333\n",
      "\n",
      "small integer   0.1111111111111111\n",
      "\n",
      "applications in   0.08\n",
      "\n",
      "perfectly ,   1.0\n",
      "\n",
      "Speech understanding   0.03225806451612903\n",
      "\n",
      "complexity while   0.08333333333333333\n",
      "\n",
      "language like   0.006756756756756757\n",
      "\n",
      "evaluation criteria   0.037037037037037035\n",
      "\n",
      "such template-matching   0.008130081300813009\n",
      "\n",
      "online resource   0.125\n",
      "\n",
      "simple bar   0.038461538461538464\n",
      "\n",
      "words just   0.009174311926605505\n",
      "\n",
      "of simpler   0.0017825311942959\n",
      "\n",
      "Annex on   1.0\n",
      "\n",
      "the sample   0.0006920415224913495\n",
      "\n",
      "the information   0.0034602076124567475\n",
      "\n",
      "clear .   0.25\n",
      "\n",
      "`` text   0.005291005291005291\n",
      "\n",
      "& OnlineOCR   0.25\n",
      "\n",
      "a watertight   0.001226993865030675\n",
      "\n",
      "Languages with   0.3333333333333333\n",
      "\n",
      "useful in   0.14285714285714285\n",
      "\n",
      "these actions   0.023809523809523808\n",
      "\n",
      "; A   0.02127659574468085\n",
      "\n",
      "distinct vowels   0.14285714285714285\n",
      "\n",
      "either user-specified   0.1\n",
      "\n",
      "grammar Text   0.02702702702702703\n",
      "\n",
      "<s> Narrow   0.0007686395080707148\n",
      "\n",
      "more qualities   0.010526315789473684\n",
      "\n",
      "entropy ,   0.2\n",
      "\n",
      "including ,   0.07142857142857142\n",
      "\n",
      "and 2009   0.001445086705202312\n",
      "\n",
      "Fighter Technology   1.0\n",
      "\n",
      "used in   0.20353982300884957\n",
      "\n",
      "to keep   0.0026560424966799467\n",
      "\n",
      "be nested   0.004219409282700422\n",
      "\n",
      ", James   0.0022459292532285235\n",
      "\n",
      "be linked   0.008438818565400843\n",
      "\n",
      "recognition refers   0.008264462809917356\n",
      "\n",
      "more complicated   0.010526315789473684\n",
      "\n",
      "F-score ,   1.0\n",
      "\n",
      "some topic   0.012048192771084338\n",
      "\n",
      "text normalization   0.006289308176100629\n",
      "\n",
      "writer with   1.0\n",
      "\n",
      "truck A   1.0\n",
      "\n",
      "the summary   0.005536332179930796\n",
      "\n",
      "dynamics of   0.5\n",
      "\n",
      "concept is   0.25\n",
      "\n",
      "can perform   0.0055248618784530384\n",
      "\n",
      "entropy classifier   0.2\n",
      "\n",
      "OCR and   0.02040816326530612\n",
      "\n",
      "2007 .   0.4\n",
      "\n",
      "medical professionals   0.16666666666666666\n",
      "\n",
      "headed by   1.0\n",
      "\n",
      "them -LRB-   0.05263157894736842\n",
      "\n",
      "ratings :   0.1111111111111111\n",
      "\n",
      "defined as   0.16666666666666666\n",
      "\n",
      "stochastic matrix   0.125\n",
      "\n",
      "to himself   0.0013280212483399733\n",
      "\n",
      "to assess   0.0013280212483399733\n",
      "\n",
      "more formally   0.010526315789473684\n",
      "\n",
      "Mr. Smith   0.5\n",
      "\n",
      "language have   0.006756756756756757\n",
      "\n",
      ": Speech   0.00980392156862745\n",
      "\n",
      "and shallowest   0.001445086705202312\n",
      "\n",
      "Reading the   0.5\n",
      "\n",
      "<s> Conferences   0.0007686395080707148\n",
      "\n",
      "hand coding   0.07142857142857142\n",
      "\n",
      "and search   0.001445086705202312\n",
      "\n",
      "conference rooms   0.5\n",
      "\n",
      "were ``   0.024390243902439025\n",
      "\n",
      "a chunk   0.007361963190184049\n",
      "\n",
      "an AI-complete   0.007575757575757576\n",
      "\n",
      ", maximum   0.0005614823133071309\n",
      "\n",
      "approach .   0.05714285714285714\n",
      "\n",
      "decide :   0.25\n",
      "\n",
      "particular part   0.07692307692307693\n",
      "\n",
      "restaurant reviews   0.5\n",
      "\n",
      "worlds ''   1.0\n",
      "\n",
      "select the   0.3333333333333333\n",
      "\n",
      "weaker .   1.0\n",
      "\n",
      "Thus ,   0.9166666666666666\n",
      "\n",
      "accommodate left   0.2\n",
      "\n",
      "to guide   0.0013280212483399733\n",
      "\n",
      "dBase system   1.0\n",
      "\n",
      "comprising multiple   0.5\n",
      "\n",
      "innovative Web-based   1.0\n",
      "\n",
      "add them   1.0\n",
      "\n",
      ", Elinor   0.0005614823133071309\n",
      "\n",
      "movies ,   1.0\n",
      "\n",
      "at all   0.07352941176470588\n",
      "\n",
      "the analog   0.0006920415224913495\n",
      "\n",
      ", interlingual   0.0011229646266142617\n",
      "\n",
      "meets two   0.5\n",
      "\n",
      "help improve   0.1111111111111111\n",
      "\n",
      "Algorithms which   0.5\n",
      "\n",
      "Other segmentation   0.14285714285714285\n",
      "\n",
      "\\/ target-language-independent   0.3333333333333333\n",
      "\n",
      "Google published   0.25\n",
      "\n",
      "the HMM   0.0006920415224913495\n",
      "\n",
      "take into   0.3\n",
      "\n",
      "did fail   0.2\n",
      "\n",
      "usually can   0.03125\n",
      "\n",
      "consumption -RRB-   1.0\n",
      "\n",
      "a societal   0.001226993865030675\n",
      "\n",
      "In addition   0.02857142857142857\n",
      "\n",
      ", but   0.02695115103874228\n",
      "\n",
      "verb -LRB-   0.15384615384615385\n",
      "\n",
      "determine if   0.21739130434782608\n",
      "\n",
      "these apply   0.023809523809523808\n",
      "\n",
      "with storing   0.00546448087431694\n",
      "\n",
      "merged with   1.0\n",
      "\n",
      "where syllables   0.02857142857142857\n",
      "\n",
      "be solved   0.004219409282700422\n",
      "\n",
      ", Carla   0.0005614823133071309\n",
      "\n",
      "object ,   0.5\n",
      "\n",
      "of complexity   0.00089126559714795\n",
      "\n",
      "Dyer developed   1.0\n",
      "\n",
      "become clear   0.25\n",
      "\n",
      "'' from   0.005154639175257732\n",
      "\n",
      "subject -RRB-   0.125\n",
      "\n",
      "is produced   0.0040650406504065045\n",
      "\n",
      "keyphrase extractor   0.05263157894736842\n",
      "\n",
      "producing more   0.3333333333333333\n",
      "\n",
      "or characters   0.0045045045045045045\n",
      "\n",
      "translation tries   0.013513513513513514\n",
      "\n",
      "or words   0.0045045045045045045\n",
      "\n",
      "like what   0.03571428571428571\n",
      "\n",
      "between the   0.1794871794871795\n",
      "\n",
      "the possibility   0.002768166089965398\n",
      "\n",
      "to ''   0.0026560424966799467\n",
      "\n",
      "true keyphrases   0.5\n",
      "\n",
      "use a   0.05555555555555555\n",
      "\n",
      "sentence extraction   0.020833333333333332\n",
      "\n",
      "with C4   0.00546448087431694\n",
      "\n",
      "on absorbing   0.0047169811320754715\n",
      "\n",
      "deterministic rules   0.25\n",
      "\n",
      "one detail   0.015384615384615385\n",
      "\n",
      "ends a   0.5\n",
      "\n",
      "keeping the   0.5\n",
      "\n",
      "various levels   0.05555555555555555\n",
      "\n",
      "What are   0.36363636363636365\n",
      "\n",
      "the difficulty   0.0006920415224913495\n",
      "\n",
      "a recent   0.001226993865030675\n",
      "\n",
      "general use   0.045454545454545456\n",
      "\n",
      "discussed in   0.14285714285714285\n",
      "\n",
      "for tense   0.0036101083032490976\n",
      "\n",
      "James Deese   0.25\n",
      "\n",
      "not words   0.026785714285714284\n",
      "\n",
      "the complexity   0.005536332179930796\n",
      "\n",
      "While there   0.2\n",
      "\n",
      "source documents   0.125\n",
      "\n",
      "so-called discriminative   0.3333333333333333\n",
      "\n",
      "picture on   0.25\n",
      "\n",
      "a strong   0.00245398773006135\n",
      "\n",
      "<s> Such   0.006149116064565719\n",
      "\n",
      "as objective   0.003484320557491289\n",
      "\n",
      "do something   0.038461538461538464\n",
      "\n",
      ", information   0.0011229646266142617\n",
      "\n",
      ", medial   0.0005614823133071309\n",
      "\n",
      "assignment of   0.5\n",
      "\n",
      "paradigm of   0.3333333333333333\n",
      "\n",
      "the finite   0.0006920415224913495\n",
      "\n",
      "to estimate   0.00398406374501992\n",
      "\n",
      "improvements .   0.5\n",
      "\n",
      ", intelligent   0.0005614823133071309\n",
      "\n",
      "between those   0.02564102564102564\n",
      "\n",
      "GenEx algorithm   1.0\n",
      "\n",
      "so it   0.06666666666666667\n",
      "\n",
      "CKY algorithm   1.0\n",
      "\n",
      "of substantial   0.00089126559714795\n",
      "\n",
      "Typical questions   0.5\n",
      "\n",
      "words coming   0.009174311926605505\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov models   0.3333333333333333\n",
      "\n",
      "is technology   0.0020325203252032522\n",
      "\n",
      "unambiguously identified   1.0\n",
      "\n",
      "that specific   0.0035460992907801418\n",
      "\n",
      "This covers   0.031746031746031744\n",
      "\n",
      "Gee ,   1.0\n",
      "\n",
      "explore what   0.25\n",
      "\n",
      "unknown and   1.0\n",
      "\n",
      "precisely an   1.0\n",
      "\n",
      "structures ,   0.2\n",
      "\n",
      "multiscript texts   1.0\n",
      "\n",
      ", Ingria   0.0005614823133071309\n",
      "\n",
      "to determine   0.014608233731739707\n",
      "\n",
      "is edited   0.0020325203252032522\n",
      "\n",
      "since words   0.1\n",
      "\n",
      "determines the   0.6666666666666666\n",
      "\n",
      "typically produces   0.05555555555555555\n",
      "\n",
      "NLP methods   0.02127659574468085\n",
      "\n",
      "low pollen   0.3333333333333333\n",
      "\n",
      ", online   0.0016844469399213925\n",
      "\n",
      "alternative right-hand-sides   0.3333333333333333\n",
      "\n",
      "Bayes classifier   0.3333333333333333\n",
      "\n",
      "important .   0.0625\n",
      "\n",
      "requires specialized   0.0625\n",
      "\n",
      "decisions or   0.1\n",
      "\n",
      "the accompanying   0.0006920415224913495\n",
      "\n",
      "in NLP   0.0149812734082397\n",
      "\n",
      "linguistics .   0.05\n",
      "\n",
      "human beings   0.021739130434782608\n",
      "\n",
      "One can   0.07692307692307693\n",
      "\n",
      "The SATZ   0.005208333333333333\n",
      "\n",
      "to act   0.0026560424966799467\n",
      "\n",
      "production has   0.3333333333333333\n",
      "\n",
      "domains ASR   0.125\n",
      "\n",
      "camera .   0.5\n",
      "\n",
      "translation Transfer-based   0.013513513513513514\n",
      "\n",
      "<s> ROUGE-1   0.0007686395080707148\n",
      "\n",
      "earliest such   0.5\n",
      "\n",
      "Web .   0.2222222222222222\n",
      "\n",
      "in reconfiguring   0.0018726591760299626\n",
      "\n",
      "+ Mobile   0.16666666666666666\n",
      "\n",
      "of 1,500   0.00089126559714795\n",
      "\n",
      "the larger   0.0006920415224913495\n",
      "\n",
      "High-order n-gram   1.0\n",
      "\n",
      "even where   0.037037037037037035\n",
      "\n",
      "because the   0.13333333333333333\n",
      "\n",
      "filter returns   0.5\n",
      "\n",
      "start of   0.2857142857142857\n",
      "\n",
      "LexRank and   0.08333333333333333\n",
      "\n",
      ", hopefully   0.0005614823133071309\n",
      "\n",
      "using ATC   0.01694915254237288\n",
      "\n",
      "automatically the   0.047619047619047616\n",
      "\n",
      "classification ''   0.29411764705882354\n",
      "\n",
      "hard task   0.16666666666666666\n",
      "\n",
      "encourage systems   1.0\n",
      "\n",
      "empirical solutions   1.0\n",
      "\n",
      "science -LRB-   0.1\n",
      "\n",
      "on specific   0.0047169811320754715\n",
      "\n",
      "So far   0.3333333333333333\n",
      "\n",
      "but far   0.014705882352941176\n",
      "\n",
      "colloquially termed   1.0\n",
      "\n",
      "answers from   0.16666666666666666\n",
      "\n",
      ": compare   0.00980392156862745\n",
      "\n",
      "problem was   0.022727272727272728\n",
      "\n",
      "wife of   1.0\n",
      "\n",
      "The shapes   0.005208333333333333\n",
      "\n",
      "task ,   0.09523809523809523\n",
      "\n",
      "is reported   0.0020325203252032522\n",
      "\n",
      "a choice   0.001226993865030675\n",
      "\n",
      "sub-problems ,   1.0\n",
      "\n",
      "involves several   0.1\n",
      "\n",
      "of document   0.00089126559714795\n",
      "\n",
      "whereas in   0.3333333333333333\n",
      "\n",
      "understanding .   0.06060606060606061\n",
      "\n",
      "of computerized   0.0017825311942959\n",
      "\n",
      "semantic interpretation   0.047619047619047616\n",
      "\n",
      "the success   0.001384083044982699\n",
      "\n",
      "Brown Corpus   0.8571428571428571\n",
      "\n",
      "people create   0.0625\n",
      "\n",
      "sequences are   0.1111111111111111\n",
      "\n",
      "listens for   1.0\n",
      "\n",
      "ROUGE-1 values   0.2\n",
      "\n",
      "token ,   0.25\n",
      "\n",
      "no knowledge   0.07692307692307693\n",
      "\n",
      "rules defining   0.023255813953488372\n",
      "\n",
      ", grammar   0.0005614823133071309\n",
      "\n",
      "sampling rate   1.0\n",
      "\n",
      "this approach   0.02197802197802198\n",
      "\n",
      "20,000 words   1.0\n",
      "\n",
      "with human   0.01092896174863388\n",
      "\n",
      "Deborah Schiffrin   0.5\n",
      "\n",
      "% .   0.23076923076923078\n",
      "\n",
      "the difficulties   0.0006920415224913495\n",
      "\n",
      "'' arguably   0.005154639175257732\n",
      "\n",
      "system determine   0.010752688172043012\n",
      "\n",
      ", sentiment   0.0005614823133071309\n",
      "\n",
      "approach was   0.02857142857142857\n",
      "\n",
      "is no   0.0020325203252032522\n",
      "\n",
      "that interact   0.0035460992907801418\n",
      "\n",
      "an algorithm   0.022727272727272728\n",
      "\n",
      "regardless of   1.0\n",
      "\n",
      "other fields   0.014285714285714285\n",
      "\n",
      "other work   0.014285714285714285\n",
      "\n",
      "choices -LRB-   0.2\n",
      "\n",
      "environment ,   0.16666666666666666\n",
      "\n",
      "system at   0.010752688172043012\n",
      "\n",
      "Penn Treebank   0.6666666666666666\n",
      "\n",
      "A relationship   0.02\n",
      "\n",
      "the Gene   0.0006920415224913495\n",
      "\n",
      "to see   0.0026560424966799467\n",
      "\n",
      "patents .   1.0\n",
      "\n",
      "discourse grammar   0.027777777777777776\n",
      "\n",
      "and worked   0.001445086705202312\n",
      "\n",
      "Books like   1.0\n",
      "\n",
      "process that   0.05555555555555555\n",
      "\n",
      "algorithms requires   0.02857142857142857\n",
      "\n",
      "<s> Statistics   0.0023059185242121443\n",
      "\n",
      "for terms   0.0036101083032490976\n",
      "\n",
      "it uses   0.017094017094017096\n",
      "\n",
      "make a   0.2\n",
      "\n",
      "good search   0.07692307692307693\n",
      "\n",
      "imprints for   1.0\n",
      "\n",
      "size -RRB-   0.16666666666666666\n",
      "\n",
      "effective and   0.16666666666666666\n",
      "\n",
      "those East   0.045454545454545456\n",
      "\n",
      "agreement about   0.3333333333333333\n",
      "\n",
      "by teletype   0.005714285714285714\n",
      "\n",
      "2002 a   0.5\n",
      "\n",
      "some measure   0.012048192771084338\n",
      "\n",
      "parsers and   0.07692307692307693\n",
      "\n",
      "as gold   0.003484320557491289\n",
      "\n",
      "extraction -LRB-   0.06451612903225806\n",
      "\n",
      "often difficult   0.022727272727272728\n",
      "\n",
      "include :   0.1111111111111111\n",
      "\n",
      "Aided Human   0.3333333333333333\n",
      "\n",
      "Guy Cook   1.0\n",
      "\n",
      "The Turney   0.005208333333333333\n",
      "\n",
      "answer questions   0.03333333333333333\n",
      "\n",
      "Often a   0.3333333333333333\n",
      "\n",
      "near each   1.0\n",
      "\n",
      "A parser   0.02\n",
      "\n",
      "head hurts   1.0\n",
      "\n",
      "A high   0.02\n",
      "\n",
      "`` set   0.005291005291005291\n",
      "\n",
      "no subtypes   0.07692307692307693\n",
      "\n",
      "a precise   0.001226993865030675\n",
      "\n",
      "in 1982   0.0018726591760299626\n",
      "\n",
      "by supplying   0.005714285714285714\n",
      "\n",
      "in healthcare   0.0018726591760299626\n",
      "\n",
      "users after   0.1111111111111111\n",
      "\n",
      "expensive to   0.14285714285714285\n",
      "\n",
      "detect the   1.0\n",
      "\n",
      "happen between   1.0\n",
      "\n",
      "in CSR   0.0018726591760299626\n",
      "\n",
      "Analysis and   0.2\n",
      "\n",
      "article ,   0.10344827586206896\n",
      "\n",
      "more unmanageable   0.010526315789473684\n",
      "\n",
      "meanings depending   0.25\n",
      "\n",
      "comparing its   0.5\n",
      "\n",
      "an infinitive   0.007575757575757576\n",
      "\n",
      "some degree   0.024096385542168676\n",
      "\n",
      "most prior   0.017241379310344827\n",
      "\n",
      "2.0 The   0.5\n",
      "\n",
      "classroom lectures   1.0\n",
      "\n",
      ", John   0.002807411566535654\n",
      "\n",
      "a clarification   0.001226993865030675\n",
      "\n",
      "as weapon   0.003484320557491289\n",
      "\n",
      "When several   0.14285714285714285\n",
      "\n",
      "Precision measures   1.0\n",
      "\n",
      "of optical   0.00089126559714795\n",
      "\n",
      "<s> DTW   0.0007686395080707148\n",
      "\n",
      "Hidden Markov   1.0\n",
      "\n",
      "software Desktop   0.037037037037037035\n",
      "\n",
      "and compare   0.002890173410404624\n",
      "\n",
      "Pronunciation evaluation   1.0\n",
      "\n",
      "has included   0.011904761904761904\n",
      "\n",
      "<s> Computationally   0.0007686395080707148\n",
      "\n",
      "was drawn   0.012987012987012988\n",
      "\n",
      "Lehnert 1981   0.3333333333333333\n",
      "\n",
      "on corpora   0.0047169811320754715\n",
      "\n",
      "and recognition   0.001445086705202312\n",
      "\n",
      "`` zero   0.005291005291005291\n",
      "\n",
      "limited .   0.2\n",
      "\n",
      "we wanted   0.022222222222222223\n",
      "\n",
      "using neural   0.01694915254237288\n",
      "\n",
      "contribute to   1.0\n",
      "\n",
      "successful demonstration   0.1111111111111111\n",
      "\n",
      "require to   0.045454545454545456\n",
      "\n",
      "answered questions   0.6\n",
      "\n",
      "different people   0.02040816326530612\n",
      "\n",
      "the norm   0.0006920415224913495\n",
      "\n",
      "data records   0.012987012987012988\n",
      "\n",
      "-RRB- involved   0.0027100271002710027\n",
      "\n",
      "for computer   0.010830324909747292\n",
      "\n",
      "generalized ATNs   1.0\n",
      "\n",
      "Bernard Vauquois   1.0\n",
      "\n",
      "-LRB- some   0.0027100271002710027\n",
      "\n",
      "United States   0.7777777777777778\n",
      "\n",
      "-LRB- orally   0.0027100271002710027\n",
      "\n",
      "with speech   0.01092896174863388\n",
      "\n",
      "direction of   0.3333333333333333\n",
      "\n",
      "potentially exponential   0.3333333333333333\n",
      "\n",
      "methods to   0.09090909090909091\n",
      "\n",
      "computer gaming   0.022727272727272728\n",
      "\n",
      "during the   0.4\n",
      "\n",
      "the computer   0.001384083044982699\n",
      "\n",
      "polarity ''   0.25\n",
      "\n",
      "were similar   0.024390243902439025\n",
      "\n",
      "and is   0.008670520231213872\n",
      "\n",
      "parser is   0.1875\n",
      "\n",
      "readily conveyed   0.3333333333333333\n",
      "\n",
      "MMR -RRB-   1.0\n",
      "\n",
      "data analysis   0.012987012987012988\n",
      "\n",
      "Both methods   0.3333333333333333\n",
      "\n",
      "occur on   0.2\n",
      "\n",
      "sounds ''   0.06666666666666667\n",
      "\n",
      "sold to   0.3333333333333333\n",
      "\n",
      "like supervised   0.03571428571428571\n",
      "\n",
      "Activity -LRB-   1.0\n",
      "\n",
      "the NLP   0.0006920415224913495\n",
      "\n",
      "with word   0.01639344262295082\n",
      "\n",
      "ranking -LRB-   0.14285714285714285\n",
      "\n",
      "printed records   0.08333333333333333\n",
      "\n",
      "-LRB- -LRB-   0.0027100271002710027\n",
      "\n",
      "Engineers ,   0.5\n",
      "\n",
      "includes a   0.14285714285714285\n",
      "\n",
      "line as   0.3333333333333333\n",
      "\n",
      "them with   0.05263157894736842\n",
      "\n",
      "Environmental noise   1.0\n",
      "\n",
      "; and   0.0851063829787234\n",
      "\n",
      "Referring expression   1.0\n",
      "\n",
      "The objects   0.005208333333333333\n",
      "\n",
      "a 70   0.001226993865030675\n",
      "\n",
      "over an   0.08333333333333333\n",
      "\n",
      ": Rules   0.0196078431372549\n",
      "\n",
      "Corporation originally   0.25\n",
      "\n",
      "the editor   0.0006920415224913495\n",
      "\n",
      "that can   0.04609929078014184\n",
      "\n",
      "ears ,   1.0\n",
      "\n",
      "by parser   0.005714285714285714\n",
      "\n",
      "a simple   0.001226993865030675\n",
      "\n",
      ", definition   0.0005614823133071309\n",
      "\n",
      "centroid sentence   0.5\n",
      "\n",
      "classification decisions   0.058823529411764705\n",
      "\n",
      "sentiment about   0.04\n",
      "\n",
      "is unable   0.0020325203252032522\n",
      "\n",
      "system in   0.021505376344086023\n",
      "\n",
      "the structure   0.0020761245674740486\n",
      "\n",
      "tasks is   0.03125\n",
      "\n",
      ", proper   0.0005614823133071309\n",
      "\n",
      "recognition task   0.01652892561983471\n",
      "\n",
      "a similar   0.001226993865030675\n",
      "\n",
      "Supervised text   1.0\n",
      "\n",
      "own assumptions   0.16666666666666666\n",
      "\n",
      "Steven DeRose   1.0\n",
      "\n",
      "are commonly   0.004149377593360996\n",
      "\n",
      ": Information   0.00980392156862745\n",
      "\n",
      "a naive   0.001226993865030675\n",
      "\n",
      "navigation systems   0.5\n",
      "\n",
      "are statistical   0.004149377593360996\n",
      "\n",
      "those utility   0.045454545454545456\n",
      "\n",
      "perfect -LRB-   1.0\n",
      "\n",
      "the letter   0.0006920415224913495\n",
      "\n",
      "his or   0.08333333333333333\n",
      "\n",
      "thus reducing   0.1\n",
      "\n",
      "explicitly promoting   0.25\n",
      "\n",
      "systems become   0.008928571428571428\n",
      "\n",
      "<s> Perspectives   0.0007686395080707148\n",
      "\n",
      "both of   0.06451612903225806\n",
      "\n",
      "etc. .   0.4090909090909091\n",
      "\n",
      "linguistically meaningful   1.0\n",
      "\n",
      "a sentiment   0.00245398773006135\n",
      "\n",
      "new cross-discipline   0.041666666666666664\n",
      "\n",
      "have complex   0.009615384615384616\n",
      "\n",
      "data entry   0.03896103896103896\n",
      "\n",
      "He decided   0.125\n",
      "\n",
      "hands ,   1.0\n",
      "\n",
      "and are   0.0072254335260115606\n",
      "\n",
      "was of   0.012987012987012988\n",
      "\n",
      "several -RRB-   0.045454545454545456\n",
      "\n",
      "Computer Science   0.16666666666666666\n",
      "\n",
      "more easily   0.010526315789473684\n",
      "\n",
      "type validity   0.07142857142857142\n",
      "\n",
      "rushing to   1.0\n",
      "\n",
      "see what   0.05\n",
      "\n",
      "a single   0.011042944785276074\n",
      "\n",
      "by visual   0.005714285714285714\n",
      "\n",
      "Rules post-processed   0.3333333333333333\n",
      "\n",
      "do ''   0.038461538461538464\n",
      "\n",
      "shop or   1.0\n",
      "\n",
      ", whereas   0.0011229646266142617\n",
      "\n",
      "process Main   0.027777777777777776\n",
      "\n",
      ", large-vocabulary   0.0005614823133071309\n",
      "\n",
      "be kept   0.004219409282700422\n",
      "\n",
      "at characters   0.014705882352941176\n",
      "\n",
      "discourse .   0.027777777777777776\n",
      "\n",
      "useful for   0.21428571428571427\n",
      "\n",
      "ICASSP ,   1.0\n",
      "\n",
      ", mathematical   0.0005614823133071309\n",
      "\n",
      "more ,   0.010526315789473684\n",
      "\n",
      ", why   0.0011229646266142617\n",
      "\n",
      "examples where   0.041666666666666664\n",
      "\n",
      "and often   0.004335260115606936\n",
      "\n",
      "pictures or   1.0\n",
      "\n",
      "edited and   1.0\n",
      "\n",
      "examples as   0.041666666666666664\n",
      "\n",
      "task entirely   0.023809523809523808\n",
      "\n",
      "and counter   0.001445086705202312\n",
      "\n",
      "similarity between   0.2\n",
      "\n",
      "For example   0.6229508196721312\n",
      "\n",
      "felt -RRB-   1.0\n",
      "\n",
      "recognized with   0.16666666666666666\n",
      "\n",
      "information are   0.021739130434782608\n",
      "\n",
      "real-world examples   0.16666666666666666\n",
      "\n",
      "banking system   1.0\n",
      "\n",
      "they can   0.15\n",
      "\n",
      "this sentence   0.01098901098901099\n",
      "\n",
      "Information extraction   0.2\n",
      "\n",
      "and legal   0.001445086705202312\n",
      "\n",
      "with Swedish   0.00546448087431694\n",
      "\n",
      "be also   0.004219409282700422\n",
      "\n",
      "for determining   0.007220216606498195\n",
      "\n",
      "candidacies and   1.0\n",
      "\n",
      "sequences that   0.1111111111111111\n",
      "\n",
      "already been   0.4\n",
      "\n",
      "Russian sentences   1.0\n",
      "\n",
      "probably important   0.25\n",
      "\n",
      ", Gina   0.0005614823133071309\n",
      "\n",
      "2 -RRB-   0.2\n",
      "\n",
      "<s> Recognizing   0.0007686395080707148\n",
      "\n",
      "contain names   0.08333333333333333\n",
      "\n",
      "vocabulary .   0.25\n",
      "\n",
      "one summary   0.015384615384615385\n",
      "\n",
      "most upper   0.017241379310344827\n",
      "\n",
      "warping Dynamic   0.25\n",
      "\n",
      "not .   0.017857142857142856\n",
      "\n",
      "DeRose used   0.2\n",
      "\n",
      "conditions Environmental   0.2\n",
      "\n",
      "identification .   0.2\n",
      "\n",
      "worked on   0.4\n",
      "\n",
      "laws calling   1.0\n",
      "\n",
      "between automatically   0.02564102564102564\n",
      "\n",
      "and does   0.001445086705202312\n",
      "\n",
      ", can   0.003368893879842785\n",
      "\n",
      "be different   0.004219409282700422\n",
      "\n",
      "about 1965   0.025\n",
      "\n",
      "nuggets of   1.0\n",
      "\n",
      "grammar for   0.02702702702702703\n",
      "\n",
      "suitable -LRB-   0.25\n",
      "\n",
      "University included   0.1111111111111111\n",
      "\n",
      "in supervised   0.0018726591760299626\n",
      "\n",
      "evaluation -LRB-   0.018518518518518517\n",
      "\n",
      "variation across   1.0\n",
      "\n",
      "developed RSI   0.038461538461538464\n",
      "\n",
      "very effective   0.024390243902439025\n",
      "\n",
      "of phonetic   0.00089126559714795\n",
      "\n",
      "and 1980s   0.002890173410404624\n",
      "\n",
      "current state   0.14285714285714285\n",
      "\n",
      "masculine ,   1.0\n",
      "\n",
      "probabilities .   0.18181818181818182\n",
      "\n",
      "produces usable   0.25\n",
      "\n",
      "are remarkably   0.004149377593360996\n",
      "\n",
      "modern parsers   0.2\n",
      "\n",
      ": TextRank   0.0196078431372549\n",
      "\n",
      "Parsers are   0.5\n",
      "\n",
      "or a   0.08558558558558559\n",
      "\n",
      "BORIS system   1.0\n",
      "\n",
      "discussed above   0.14285714285714285\n",
      "\n",
      "book-new .   1.0\n",
      "\n",
      "adjacent sounds   0.16666666666666666\n",
      "\n",
      "browsing by   1.0\n",
      "\n",
      "Features might   1.0\n",
      "\n",
      "<s> QA   0.0007686395080707148\n",
      "\n",
      "Knowledge on   0.5\n",
      "\n",
      "other academic   0.014285714285714285\n",
      "\n",
      "of texts   0.0017825311942959\n",
      "\n",
      "formats like   1.0\n",
      "\n",
      "feasible the   0.5\n",
      "\n",
      "error rates   0.25\n",
      "\n",
      "Clancy 's   1.0\n",
      "\n",
      "Ideally ,   1.0\n",
      "\n",
      "a collection   0.00245398773006135\n",
      "\n",
      "be answered   0.004219409282700422\n",
      "\n",
      "and Canada   0.001445086705202312\n",
      "\n",
      "the abbreviation   0.0006920415224913495\n",
      "\n",
      "the action   0.0006920415224913495\n",
      "\n",
      "lack of   1.0\n",
      "\n",
      "some form   0.04819277108433735\n",
      "\n",
      "it runs   0.008547008547008548\n",
      "\n",
      "that combine   0.0035460992907801418\n",
      "\n",
      "figure out   0.5\n",
      "\n",
      "an American   0.007575757575757576\n",
      "\n",
      "In English   0.01904761904761905\n",
      "\n",
      "technique used   0.14285714285714285\n",
      "\n",
      "words not   0.009174311926605505\n",
      "\n",
      "is angry   0.0020325203252032522\n",
      "\n",
      "William Labov   0.5\n",
      "\n",
      "the culture   0.0006920415224913495\n",
      "\n",
      "book a   0.125\n",
      "\n",
      "perhaps ,   0.16666666666666666\n",
      "\n",
      "its polarity   0.02857142857142857\n",
      "\n",
      "the Amount   0.0006920415224913495\n",
      "\n",
      "been debated   0.014705882352941176\n",
      "\n",
      "information overload   0.021739130434782608\n",
      "\n",
      "Research Projects   0.125\n",
      "\n",
      "required translation   0.14285714285714285\n",
      "\n",
      "structure of   0.3333333333333333\n",
      "\n",
      "Latin alphabet   0.25\n",
      "\n",
      "years various   0.047619047619047616\n",
      "\n",
      "content selection   0.08333333333333333\n",
      "\n",
      "Systems based   0.25\n",
      "\n",
      "Arbor ,   1.0\n",
      "\n",
      "without confusions   0.07692307692307693\n",
      "\n",
      "as opposed   0.003484320557491289\n",
      "\n",
      "and replicated   0.001445086705202312\n",
      "\n",
      "The grammar   0.010416666666666666\n",
      "\n",
      "<s> At   0.0023059185242121443\n",
      "\n",
      "people speaking   0.125\n",
      "\n",
      "to 7   0.00398406374501992\n",
      "\n",
      "produce the   0.13636363636363635\n",
      "\n",
      "the parser   0.002768166089965398\n",
      "\n",
      "user interface   0.07142857142857142\n",
      "\n",
      "triples or   0.3333333333333333\n",
      "\n",
      "e.g. marking   0.017857142857142856\n",
      "\n",
      "method and   0.0625\n",
      "\n",
      "review .   0.3333333333333333\n",
      "\n",
      "processing ;   0.018518518518518517\n",
      "\n",
      ": GRASSHOPPER   0.00980392156862745\n",
      "\n",
      "Shepard went   0.3333333333333333\n",
      "\n",
      "-LRB- Asia   0.0027100271002710027\n",
      "\n",
      "its definition   0.02857142857142857\n",
      "\n",
      "reference model   0.125\n",
      "\n",
      "adding sentences   0.5\n",
      "\n",
      "sentence is   0.041666666666666664\n",
      "\n",
      "a supervised   0.00245398773006135\n",
      "\n",
      "in conjunction   0.003745318352059925\n",
      "\n",
      "than computers   0.022222222222222223\n",
      "\n",
      "questions ,   0.3076923076923077\n",
      "\n",
      "France has   0.25\n",
      "\n",
      "product of   0.14285714285714285\n",
      "\n",
      "different sentences   0.061224489795918366\n",
      "\n",
      "which undertook   0.007246376811594203\n",
      "\n",
      "humans in   0.08333333333333333\n",
      "\n",
      "word delimiter   0.016666666666666666\n",
      "\n",
      "Recognition -LRB-   0.125\n",
      "\n",
      "SIGGEN portion   1.0\n",
      "\n",
      "exigencies of   1.0\n",
      "\n",
      "on sentences   0.0047169811320754715\n",
      "\n",
      "properties as   0.25\n",
      "\n",
      "annotation and   0.25\n",
      "\n",
      "visible light   0.3333333333333333\n",
      "\n",
      "redundancy in   0.6666666666666666\n",
      "\n",
      "then include   0.02857142857142857\n",
      "\n",
      "grammar rules   0.13513513513513514\n",
      "\n",
      "most negative   0.017241379310344827\n",
      "\n",
      "done with   0.18181818181818182\n",
      "\n",
      "tools require   0.16666666666666666\n",
      "\n",
      "management Question   0.14285714285714285\n",
      "\n",
      "formal grammar   0.2222222222222222\n",
      "\n",
      "Words in   0.25\n",
      "\n",
      "a non-whitespace   0.001226993865030675\n",
      "\n",
      "'' such   0.005154639175257732\n",
      "\n",
      "be satisfactory   0.004219409282700422\n",
      "\n",
      "number .   0.046511627906976744\n",
      "\n",
      "on neat   0.0047169811320754715\n",
      "\n",
      "a time   0.00245398773006135\n",
      "\n",
      "GRM library   1.0\n",
      "\n",
      "= Noun   0.1111111111111111\n",
      "\n",
      "mark the   0.3333333333333333\n",
      "\n",
      "Latin .   0.25\n",
      "\n",
      "annotating texts   1.0\n",
      "\n",
      "generic machine-generated   0.3333333333333333\n",
      "\n",
      "`` mentions   0.005291005291005291\n",
      "\n",
      "2,000 words   0.5\n",
      "\n",
      "involves the   0.2\n",
      "\n",
      "QA research   0.047619047619047616\n",
      "\n",
      "language usually   0.006756756756756757\n",
      "\n",
      "cards for   1.0\n",
      "\n",
      "for language   0.0036101083032490976\n",
      "\n",
      "speech data   0.006578947368421052\n",
      "\n",
      "partly statistical   1.0\n",
      "\n",
      "Vietnamese ,   1.0\n",
      "\n",
      "are widely   0.004149377593360996\n",
      "\n",
      "- processing   0.0625\n",
      "\n",
      "pre-structured database   1.0\n",
      "\n",
      "to resolve   0.00398406374501992\n",
      "\n",
      "-RRB- has   0.008130081300813009\n",
      "\n",
      "Objectives The   1.0\n",
      "\n",
      "A second   0.02\n",
      "\n",
      "the user   0.0034602076124567475\n",
      "\n",
      "key phrases   0.16666666666666666\n",
      "\n",
      "Eurofighter Typhoon   1.0\n",
      "\n",
      "geospatial questions   1.0\n",
      "\n",
      "also important   0.014492753623188406\n",
      "\n",
      "evaluation .   0.05555555555555555\n",
      "\n",
      "Before getting   0.5\n",
      "\n",
      "of virtual   0.00089126559714795\n",
      "\n",
      "we say   0.044444444444444446\n",
      "\n",
      "languages or   0.02\n",
      "\n",
      "developed for   0.038461538461538464\n",
      "\n",
      ", research   0.0011229646266142617\n",
      "\n",
      "Language Processing   0.25\n",
      "\n",
      "-LRB- May   0.005420054200542005\n",
      "\n",
      "appears in   0.2\n",
      "\n",
      "alternative approach   0.3333333333333333\n",
      "\n",
      "Schank and   0.4\n",
      "\n",
      "release or   0.3333333333333333\n",
      "\n",
      "related questions   0.06666666666666667\n",
      "\n",
      "systems trade   0.008928571428571428\n",
      "\n",
      "summaries do   0.023255813953488372\n",
      "\n",
      "techniques offer   0.043478260869565216\n",
      "\n",
      "the United   0.004844290657439446\n",
      "\n",
      "Orleans ''   0.5\n",
      "\n",
      "QA is   0.047619047619047616\n",
      "\n",
      "more principled   0.010526315789473684\n",
      "\n",
      "subjective sentences   0.16666666666666666\n",
      "\n",
      "results reported   0.047619047619047616\n",
      "\n",
      "'s speech   0.0196078431372549\n",
      "\n",
      "LexRank paper   0.08333333333333333\n",
      "\n",
      "Automotive speech   1.0\n",
      "\n",
      "sometimes had   0.07692307692307693\n",
      "\n",
      "needs the   0.1\n",
      "\n",
      "by voice   0.011428571428571429\n",
      "\n",
      "`` um   0.005291005291005291\n",
      "\n",
      "software resources   0.037037037037037035\n",
      "\n",
      "judge its   0.25\n",
      "\n",
      "independent systems   0.5\n",
      "\n",
      "recognized draft   0.16666666666666666\n",
      "\n",
      "LR parsers   1.0\n",
      "\n",
      "generally ,   0.09090909090909091\n",
      "\n",
      "and methodologies   0.001445086705202312\n",
      "\n",
      "are 9   0.004149377593360996\n",
      "\n",
      "engine .   0.6666666666666666\n",
      "\n",
      "a German   0.001226993865030675\n",
      "\n",
      "and R.   0.001445086705202312\n",
      "\n",
      "only study   0.02631578947368421\n",
      "\n",
      "of Generation   0.00089126559714795\n",
      "\n",
      "1952 and   0.5\n",
      "\n",
      "a keyphrase   0.00245398773006135\n",
      "\n",
      "and extract   0.001445086705202312\n",
      "\n",
      "a vocabulary   0.001226993865030675\n",
      "\n",
      "is quite   0.0020325203252032522\n",
      "\n",
      "<s> Described   0.0007686395080707148\n",
      "\n",
      "coherent sequences   0.2\n",
      "\n",
      "separate out   0.1\n",
      "\n",
      "article then   0.034482758620689655\n",
      "\n",
      "or length   0.0045045045045045045\n",
      "\n",
      "typically one   0.05555555555555555\n",
      "\n",
      "by silence   0.005714285714285714\n",
      "\n",
      "system -LRB-   0.021505376344086023\n",
      "\n",
      "so-called delta   0.3333333333333333\n",
      "\n",
      "and consonants   0.001445086705202312\n",
      "\n",
      "surrounding consonants   0.2\n",
      "\n",
      "automatically learning   0.047619047619047616\n",
      "\n",
      "question ,   0.2619047619047619\n",
      "\n",
      "be included   0.004219409282700422\n",
      "\n",
      "word with   0.016666666666666666\n",
      "\n",
      "commonly tagged   0.125\n",
      "\n",
      "to normalize   0.0013280212483399733\n",
      "\n",
      "`` advanced   0.005291005291005291\n",
      "\n",
      "into basic   0.01282051282051282\n",
      "\n",
      "system proposed   0.010752688172043012\n",
      "\n",
      "special types   0.2\n",
      "\n",
      "a category   0.001226993865030675\n",
      "\n",
      "three or   0.3333333333333333\n",
      "\n",
      "networks are   0.07142857142857142\n",
      "\n",
      "routing to   0.3333333333333333\n",
      "\n",
      "1997 ,   0.5\n",
      "\n",
      "split it   0.25\n",
      "\n",
      "the idea   0.001384083044982699\n",
      "\n",
      "determine the   0.391304347826087\n",
      "\n",
      "of reviews   0.00089126559714795\n",
      "\n",
      "compute the   0.5\n",
      "\n",
      "a dialogue   0.00245398773006135\n",
      "\n",
      ", natural   0.0005614823133071309\n",
      "\n",
      "mainly came   0.16666666666666666\n",
      "\n",
      "second aim   0.1\n",
      "\n",
      "lattices represented   1.0\n",
      "\n",
      "alphabet ,   0.6666666666666666\n",
      "\n",
      "being based   0.05555555555555555\n",
      "\n",
      "or Arabic   0.0045045045045045045\n",
      "\n",
      "social sciences   0.14285714285714285\n",
      "\n",
      "Some attempts   0.047619047619047616\n",
      "\n",
      "small text   0.1111111111111111\n",
      "\n",
      "because there   0.06666666666666667\n",
      "\n",
      "were limited   0.024390243902439025\n",
      "\n",
      "of 15-20   0.00089126559714795\n",
      "\n",
      "constraints .   0.25\n",
      "\n",
      "to sort   0.0013280212483399733\n",
      "\n",
      "; rejecting   0.0425531914893617\n",
      "\n",
      "textbook is   0.5\n",
      "\n",
      "model ,   0.1\n",
      "\n",
      "task-based evaluations   0.75\n",
      "\n",
      "as phoneme   0.003484320557491289\n",
      "\n",
      "represented using   0.16666666666666666\n",
      "\n",
      "still just   0.06666666666666667\n",
      "\n",
      "Booth and   1.0\n",
      "\n",
      "predicate logic   1.0\n",
      "\n",
      "simple implementations   0.038461538461538464\n",
      "\n",
      "a probability   0.001226993865030675\n",
      "\n",
      "that produce   0.0035460992907801418\n",
      "\n",
      "essentially to   0.125\n",
      "\n",
      "Telephony and   1.0\n",
      "\n",
      "new scientific   0.041666666666666664\n",
      "\n",
      "a coherent   0.00245398773006135\n",
      "\n",
      "harder tasks   0.14285714285714285\n",
      "\n",
      "-RRB- Around   0.0027100271002710027\n",
      "\n",
      "to incorporate   0.0013280212483399733\n",
      "\n",
      "sentences begin   0.013157894736842105\n",
      "\n",
      "Piron 's   0.3333333333333333\n",
      "\n",
      "noise ,   0.125\n",
      "\n",
      "With isolated   0.14285714285714285\n",
      "\n",
      "text illustrates   0.006289308176100629\n",
      "\n",
      ", ``   0.01403705783267827\n",
      "\n",
      "can have   0.011049723756906077\n",
      "\n",
      "narrowest and   1.0\n",
      "\n",
      "In corpus   0.009523809523809525\n",
      "\n",
      "system recognizes   0.010752688172043012\n",
      "\n",
      "'' each   0.005154639175257732\n",
      "\n",
      "in 1933   0.0018726591760299626\n",
      "\n",
      "text on   0.006289308176100629\n",
      "\n",
      "needed for   0.09523809523809523\n",
      "\n",
      "assembling output   1.0\n",
      "\n",
      ": A   0.00980392156862745\n",
      "\n",
      "a case   0.001226993865030675\n",
      "\n",
      "huge handmade   1.0\n",
      "\n",
      "such name   0.008130081300813009\n",
      "\n",
      "German taggers   0.25\n",
      "\n",
      "By having   0.3333333333333333\n",
      "\n",
      "Scotland with   0.2\n",
      "\n",
      "computer-aided analysis   0.3333333333333333\n",
      "\n",
      ", task-based   0.0005614823133071309\n",
      "\n",
      "and Romanseval   0.001445086705202312\n",
      "\n",
      "input -LRB-   0.04878048780487805\n",
      "\n",
      "with them   0.01639344262295082\n",
      "\n",
      "lot and   0.3333333333333333\n",
      "\n",
      "commands issued   0.2\n",
      "\n",
      "and post-secondary   0.001445086705202312\n",
      "\n",
      "-RRB- one   0.0027100271002710027\n",
      "\n",
      "have higher   0.009615384615384616\n",
      "\n",
      "schemes frequently   0.5\n",
      "\n",
      "metric -LRB-   0.3333333333333333\n",
      "\n",
      "some tasks   0.012048192771084338\n",
      "\n",
      "of discourses   0.00089126559714795\n",
      "\n",
      "Advanced reasoning   0.2\n",
      "\n",
      "to describe   0.0026560424966799467\n",
      "\n",
      "NLG applications   0.047619047619047616\n",
      "\n",
      "candidates so   0.2\n",
      "\n",
      "The rise   0.005208333333333333\n",
      "\n",
      "a wide   0.00245398773006135\n",
      "\n",
      "There has   0.18181818181818182\n",
      "\n",
      "thereof -RRB-   1.0\n",
      "\n",
      "are actually   0.004149377593360996\n",
      "\n",
      "new set   0.041666666666666664\n",
      "\n",
      "human geography   0.021739130434782608\n",
      "\n",
      "used that   0.008849557522123894\n",
      "\n",
      "`` pseudo-pilot   0.005291005291005291\n",
      "\n",
      "not hear   0.008928571428571428\n",
      "\n",
      "usually measured   0.03125\n",
      "\n",
      "profile may   0.3333333333333333\n",
      "\n",
      "semiotics ,   1.0\n",
      "\n",
      "when such   0.05714285714285714\n",
      "\n",
      "content of   0.08333333333333333\n",
      "\n",
      "previous Section   0.3333333333333333\n",
      "\n",
      "media .   0.16666666666666666\n",
      "\n",
      ", Malcolm   0.0005614823133071309\n",
      "\n",
      "issues relating   0.2\n",
      "\n",
      "Charles Goodwin   1.0\n",
      "\n",
      "It stands   0.02631578947368421\n",
      "\n",
      "plateaued and   1.0\n",
      "\n",
      "cause much   0.5\n",
      "\n",
      "becomes easier   0.5\n",
      "\n",
      "an interlingual   0.007575757575757576\n",
      "\n",
      "which class   0.007246376811594203\n",
      "\n",
      "voice dialing   0.07692307692307693\n",
      "\n",
      "word -LRB-   0.016666666666666666\n",
      "\n",
      "shapes .   0.3333333333333333\n",
      "\n",
      "of grammar   0.0017825311942959\n",
      "\n",
      "works It   0.5\n",
      "\n",
      "vendors .   0.25\n",
      "\n",
      "of bottom-up   0.00089126559714795\n",
      "\n",
      "virtual currency   1.0\n",
      "\n",
      "knowledge or   0.037037037037037035\n",
      "\n",
      "to write   0.0013280212483399733\n",
      "\n",
      "grammar '   0.02702702702702703\n",
      "\n",
      "choice in   0.125\n",
      "\n",
      "English and   0.08108108108108109\n",
      "\n",
      "D. Das   0.2\n",
      "\n",
      "correct output   0.06666666666666667\n",
      "\n",
      "called evaluation   0.1111111111111111\n",
      "\n",
      "red .   1.0\n",
      "\n",
      ", D   0.0005614823133071309\n",
      "\n",
      "<s> Results   0.0007686395080707148\n",
      "\n",
      "-LRB- among   0.005420054200542005\n",
      "\n",
      "created ,   0.2857142857142857\n",
      "\n",
      "as business   0.003484320557491289\n",
      "\n",
      "The Eurofighter   0.005208333333333333\n",
      "\n",
      "Desktop &   1.0\n",
      "\n",
      "symbol in   0.25\n",
      "\n",
      "which means   0.028985507246376812\n",
      "\n",
      "language can   0.006756756756756757\n",
      "\n",
      "been used   0.07352941176470588\n",
      "\n",
      "QA More   0.047619047619047616\n",
      "\n",
      "tree -LRB-   1.0\n",
      "\n",
      "shifting to   1.0\n",
      "\n",
      "include Chinese   0.037037037037037035\n",
      "\n",
      "could co-occur   0.0625\n",
      "\n",
      "LexRank score   0.08333333333333333\n",
      "\n",
      "a domain-specific   0.001226993865030675\n",
      "\n",
      ", multilingual   0.0005614823133071309\n",
      "\n",
      "is not   0.03861788617886179\n",
      "\n",
      "<s> Xerox   0.0007686395080707148\n",
      "\n",
      "about unigrams   0.025\n",
      "\n",
      "but only   0.014705882352941176\n",
      "\n",
      "An ISO   0.0625\n",
      "\n",
      "often ,   0.022727272727272728\n",
      "\n",
      "that participate   0.0035460992907801418\n",
      "\n",
      "Man dog   0.5\n",
      "\n",
      "Page ,   1.0\n",
      "\n",
      "year or   0.16666666666666666\n",
      "\n",
      "on work   0.0047169811320754715\n",
      "\n",
      "kind ,   0.09090909090909091\n",
      "\n",
      "suffix ''   1.0\n",
      "\n",
      ", relative   0.0005614823133071309\n",
      "\n",
      "this understanding   0.01098901098901099\n",
      "\n",
      "begin with   0.6666666666666666\n",
      "\n",
      "accurately -LRB-   0.5\n",
      "\n",
      "improvements in   0.5\n",
      "\n",
      "input feature   0.024390243902439025\n",
      "\n",
      "which simulates   0.007246376811594203\n",
      "\n",
      "output to   0.038461538461538464\n",
      "\n",
      "theory -RRB-   0.07692307692307693\n",
      "\n",
      "<s> Anaphor   0.0007686395080707148\n",
      "\n",
      "OCR accuracy   0.02040816326530612\n",
      "\n",
      "carried out   0.5\n",
      "\n",
      "late 1960s   0.1111111111111111\n",
      "\n",
      "sold by   0.3333333333333333\n",
      "\n",
      "can determine   0.011049723756906077\n",
      "\n",
      "under ultraviolet   0.2\n",
      "\n",
      "2012 -RRB-   1.0\n",
      "\n",
      "is again   0.0020325203252032522\n",
      "\n",
      "Rescoring is   1.0\n",
      "\n",
      "machine representation   0.02531645569620253\n",
      "\n",
      "and development   0.002890173410404624\n",
      "\n",
      "vary in   0.5\n",
      "\n",
      "or an   0.009009009009009009\n",
      "\n",
      "and so   0.008670520231213872\n",
      "\n",
      "by giving   0.005714285714285714\n",
      "\n",
      "and atmosphere   0.001445086705202312\n",
      "\n",
      "since 2000   0.1\n",
      "\n",
      "subtasks .   0.5\n",
      "\n",
      "and Plot   0.001445086705202312\n",
      "\n",
      "in similar   0.0018726591760299626\n",
      "\n",
      "pre -   1.0\n",
      "\n",
      ", slowly   0.0005614823133071309\n",
      "\n",
      "systems perform   0.008928571428571428\n",
      "\n",
      "harmonic mean   1.0\n",
      "\n",
      "the mid-1960s   0.0006920415224913495\n",
      "\n",
      "French in   0.125\n",
      "\n",
      "mapping each   0.5\n",
      "\n",
      "been displaced   0.014705882352941176\n",
      "\n",
      "we do   0.022222222222222223\n",
      "\n",
      "inaccurate or   1.0\n",
      "\n",
      "why applying   0.14285714285714285\n",
      "\n",
      "method .   0.125\n",
      "\n",
      "a modal   0.001226993865030675\n",
      "\n",
      "a matter   0.001226993865030675\n",
      "\n",
      "well captured   0.03571428571428571\n",
      "\n",
      "probabilistically at   1.0\n",
      "\n",
      "on OCR   0.0047169811320754715\n",
      "\n",
      "this prior   0.01098901098901099\n",
      "\n",
      "results suggest   0.047619047619047616\n",
      "\n",
      "interface commercially   0.25\n",
      "\n",
      "indicate that   0.3333333333333333\n",
      "\n",
      ", human   0.003368893879842785\n",
      "\n",
      "with his   0.00546448087431694\n",
      "\n",
      "state-of-the-art abstractive   0.5\n",
      "\n",
      "paper documents   0.09090909090909091\n",
      "\n",
      "edges ?   0.2857142857142857\n",
      "\n",
      "confirmed by   1.0\n",
      "\n",
      "triple probabilities   1.0\n",
      "\n",
      "Slembrouck ,   1.0\n",
      "\n",
      "on part-of-speech   0.0047169811320754715\n",
      "\n",
      "-- including   0.04\n",
      "\n",
      "associate discrete   0.5\n",
      "\n",
      "Church used   0.3333333333333333\n",
      "\n",
      "National Federation   0.3333333333333333\n",
      "\n",
      "need to   0.47619047619047616\n",
      "\n",
      "libraries for   0.5\n",
      "\n",
      ", abstraction   0.0005614823133071309\n",
      "\n",
      "of 98   0.00089126559714795\n",
      "\n",
      "the Mars   0.0006920415224913495\n",
      "\n",
      "like Chinese   0.07142857142857142\n",
      "\n",
      "solid state   1.0\n",
      "\n",
      "with it   0.01092896174863388\n",
      "\n",
      "and rule   0.001445086705202312\n",
      "\n",
      "doing as   0.5\n",
      "\n",
      "Penn tag   0.2222222222222222\n",
      "\n",
      "computer language   0.022727272727272728\n",
      "\n",
      "conjunction ,   0.3333333333333333\n",
      "\n",
      "considered a   0.1111111111111111\n",
      "\n",
      "Arabic and   0.25\n",
      "\n",
      "looking to   0.4\n",
      "\n",
      "The parser   0.005208333333333333\n",
      "\n",
      "importance is   0.16666666666666666\n",
      "\n",
      "linguistic rules   0.0625\n",
      "\n",
      "taught to   0.3333333333333333\n",
      "\n",
      "judgement or   0.3333333333333333\n",
      "\n",
      "for understanding   0.0036101083032490976\n",
      "\n",
      "; or   0.02127659574468085\n",
      "\n",
      "more robust   0.021052631578947368\n",
      "\n",
      "With discontinuous   0.14285714285714285\n",
      "\n",
      "all possible   0.06976744186046512\n",
      "\n",
      "the input   0.005536332179930796\n",
      "\n",
      "disabilities who   0.25\n",
      "\n",
      "Content determination   1.0\n",
      "\n",
      "Michael Stubbs   0.25\n",
      "\n",
      "and character   0.001445086705202312\n",
      "\n",
      "combining the   0.25\n",
      "\n",
      "both affine   0.03225806451612903\n",
      "\n",
      "extraction Answer   0.03225806451612903\n",
      "\n",
      ", typewritten   0.0011229646266142617\n",
      "\n",
      "was sold   0.012987012987012988\n",
      "\n",
      "abbreviations that   0.2\n",
      "\n",
      "information ,   0.043478260869565216\n",
      "\n",
      "approaches are   0.03571428571428571\n",
      "\n",
      "and check   0.001445086705202312\n",
      "\n",
      "following -LRB-   0.06666666666666667\n",
      "\n",
      "many systems   0.019230769230769232\n",
      "\n",
      "aspects of   0.8571428571428571\n",
      "\n",
      "many sentences   0.019230769230769232\n",
      "\n",
      "the printed   0.0006920415224913495\n",
      "\n",
      "metrics often   0.1111111111111111\n",
      "\n",
      "found by   0.07142857142857142\n",
      "\n",
      "into an   0.02564102564102564\n",
      "\n",
      "often and   0.022727272727272728\n",
      "\n",
      "<s> Big   0.0007686395080707148\n",
      "\n",
      "<s> Potentially   0.0007686395080707148\n",
      "\n",
      "research direction   0.023809523809523808\n",
      "\n",
      "into subfields   0.01282051282051282\n",
      "\n",
      "digital .   0.14285714285714285\n",
      "\n",
      "would contribute   0.018867924528301886\n",
      "\n",
      "general speech   0.045454545454545456\n",
      "\n",
      "costly training   1.0\n",
      "\n",
      ", widely   0.0005614823133071309\n",
      "\n",
      "human might   0.021739130434782608\n",
      "\n",
      "the Alenia   0.0006920415224913495\n",
      "\n",
      "Langues vol-2   1.0\n",
      "\n",
      "function of   0.125\n",
      "\n",
      "annotated and   0.5\n",
      "\n",
      "join different   1.0\n",
      "\n",
      "segment ,   0.2222222222222222\n",
      "\n",
      "more accurate   0.031578947368421054\n",
      "\n",
      "Bottom-up parsing   1.0\n",
      "\n",
      "largest speech   1.0\n",
      "\n",
      "forums -LRB-   1.0\n",
      "\n",
      "a specialised   0.001226993865030675\n",
      "\n",
      ", strategies   0.0005614823133071309\n",
      "\n",
      ", along   0.0005614823133071309\n",
      "\n",
      "Application-Oriented OCR   1.0\n",
      "\n",
      "two general   0.034482758620689655\n",
      "\n",
      "successful systems   0.1111111111111111\n",
      "\n",
      "recognition .   0.05785123966942149\n",
      "\n",
      "information display   0.021739130434782608\n",
      "\n",
      "binary classification   0.5\n",
      "\n",
      "`` diverse   0.005291005291005291\n",
      "\n",
      "have become   0.009615384615384616\n",
      "\n",
      "due especially   0.2\n",
      "\n",
      "distinct ideas   0.14285714285714285\n",
      "\n",
      "typical large-vocabulary   0.1111111111111111\n",
      "\n",
      "to find   0.010624169986719787\n",
      "\n",
      "about 12   0.025\n",
      "\n",
      ", automates   0.0005614823133071309\n",
      "\n",
      "an equivalent   0.007575757575757576\n",
      "\n",
      "-LRB- ME   0.0027100271002710027\n",
      "\n",
      "provide summaries   0.16666666666666666\n",
      "\n",
      "was all   0.012987012987012988\n",
      "\n",
      "controllers Training   0.3333333333333333\n",
      "\n",
      "with little   0.00546448087431694\n",
      "\n",
      "two categories   0.034482758620689655\n",
      "\n",
      "on my   0.0047169811320754715\n",
      "\n",
      "Black-box evaluation   0.5\n",
      "\n",
      "a robot   0.001226993865030675\n",
      "\n",
      "user-specified or   0.5\n",
      "\n",
      "Described above   1.0\n",
      "\n",
      "tagset by   1.0\n",
      "\n",
      "as HMM   0.003484320557491289\n",
      "\n",
      "even appears   0.037037037037037035\n",
      "\n",
      "be gained   0.004219409282700422\n",
      "\n",
      "-LRB- in   0.005420054200542005\n",
      "\n",
      "its application   0.02857142857142857\n",
      "\n",
      "development ,   0.16666666666666666\n",
      "\n",
      "represented themselves   0.16666666666666666\n",
      "\n",
      "others -RRB-   0.08333333333333333\n",
      "\n",
      "simple conditions   0.038461538461538464\n",
      "\n",
      "learn explicit   0.07692307692307693\n",
      "\n",
      "1954 -RRB-   0.3333333333333333\n",
      "\n",
      "fluency to   1.0\n",
      "\n",
      ", are   0.0011229646266142617\n",
      "\n",
      "the keyboard   0.0006920415224913495\n",
      "\n",
      "Note also   0.1111111111111111\n",
      "\n",
      "Kintsch ,   1.0\n",
      "\n",
      "On the   0.3333333333333333\n",
      "\n",
      "language learning   0.006756756756756757\n",
      "\n",
      "introducing models   1.0\n",
      "\n",
      "and searching   0.001445086705202312\n",
      "\n",
      "included :   0.125\n",
      "\n",
      "in most   0.00749063670411985\n",
      "\n",
      "was tested   0.012987012987012988\n",
      "\n",
      "Parsing can   0.2\n",
      "\n",
      "processes used   0.4\n",
      "\n",
      "response ,   0.5\n",
      "\n",
      "an automated   0.007575757575757576\n",
      "\n",
      "what sense   0.03125\n",
      "\n",
      "reproducing formatted   1.0\n",
      "\n",
      "-LRB- Schank   0.0027100271002710027\n",
      "\n",
      "nice beach   0.25\n",
      "\n",
      "end of   0.25\n",
      "\n",
      "political discourse   0.3333333333333333\n",
      "\n",
      "be computed   0.004219409282700422\n",
      "\n",
      "to automated   0.0013280212483399733\n",
      "\n",
      "report -LRB-   0.25\n",
      "\n",
      "correlation between   0.5\n",
      "\n",
      "count for   0.2\n",
      "\n",
      "examples ?   0.041666666666666664\n",
      "\n",
      "much less   0.045454545454545456\n",
      "\n",
      "and address   0.001445086705202312\n",
      "\n",
      "as to   0.013937282229965157\n",
      "\n",
      "of organized   0.00089126559714795\n",
      "\n",
      "a text   0.01717791411042945\n",
      "\n",
      "theoretical perspectives   0.3333333333333333\n",
      "\n",
      "associated score   0.25\n",
      "\n",
      "the relevant   0.0006920415224913495\n",
      "\n",
      "not sufficient   0.008928571428571428\n",
      "\n",
      "GRASSHOPPER incorporates   0.3333333333333333\n",
      "\n",
      "an embedded   0.007575757575757576\n",
      "\n",
      "all view   0.023255813953488372\n",
      "\n",
      "involved fully   0.3333333333333333\n",
      "\n",
      "as sentence   0.006968641114982578\n",
      "\n",
      "is slow   0.0020325203252032522\n",
      "\n",
      "been parse   0.014705882352941176\n",
      "\n",
      "confusions with   1.0\n",
      "\n",
      "some set   0.012048192771084338\n",
      "\n",
      "of reproducing   0.00089126559714795\n",
      "\n",
      "Critical Genre   0.5\n",
      "\n",
      "kept either   1.0\n",
      "\n",
      "neural nets   0.06666666666666667\n",
      "\n",
      "simply requires   0.08333333333333333\n",
      "\n",
      "<s> Knowledge   0.0007686395080707148\n",
      "\n",
      "important subproblem   0.0625\n",
      "\n",
      "than T   0.022222222222222223\n",
      "\n",
      "<s> Why   0.0015372790161414297\n",
      "\n",
      "question posed   0.047619047619047616\n",
      "\n",
      "would produce   0.03773584905660377\n",
      "\n",
      "pilot workload   0.2\n",
      "\n",
      "analyzing a   0.2\n",
      "\n",
      "can benefit   0.011049723756906077\n",
      "\n",
      "is easily   0.0020325203252032522\n",
      "\n",
      "entire words   0.3333333333333333\n",
      "\n",
      "which merged   0.007246376811594203\n",
      "\n",
      "A shallow   0.04\n",
      "\n",
      "internet discussion   1.0\n",
      "\n",
      "the Sociologist   0.0006920415224913495\n",
      "\n",
      "that now   0.0035460992907801418\n",
      "\n",
      "translator must   0.14285714285714285\n",
      "\n",
      "next token   0.14285714285714285\n",
      "\n",
      "list -LRB-   0.09090909090909091\n",
      "\n",
      "first occurrence   0.030303030303030304\n",
      "\n",
      "question understanding   0.023809523809523808\n",
      "\n",
      "other similar   0.014285714285714285\n",
      "\n",
      "and EUROPARL   0.001445086705202312\n",
      "\n",
      "up ''   0.045454545454545456\n",
      "\n",
      "nodes should   0.14285714285714285\n",
      "\n",
      "List of   1.0\n",
      "\n",
      "but rather   0.029411764705882353\n",
      "\n",
      "were the   0.024390243902439025\n",
      "\n",
      "easy to   1.0\n",
      "\n",
      "` kit   0.125\n",
      "\n",
      "in several   0.003745318352059925\n",
      "\n",
      "processing ''   0.037037037037037035\n",
      "\n",
      "from systems   0.009615384615384616\n",
      "\n",
      "spaces ,   0.2\n",
      "\n",
      "information to   0.08695652173913043\n",
      "\n",
      "comes to   0.2\n",
      "\n",
      "exploit domain-specific   1.0\n",
      "\n",
      "-LRB- which   0.008130081300813009\n",
      "\n",
      "speech tagger   0.006578947368421052\n",
      "\n",
      "POS tagging   0.38461538461538464\n",
      "\n",
      "more effective   0.010526315789473684\n",
      "\n",
      "guide the   1.0\n",
      "\n",
      "interpretable rules   1.0\n",
      "\n",
      "beyond which   0.16666666666666666\n",
      "\n",
      "of tokens   0.0017825311942959\n",
      "\n",
      "and ICR   0.002890173410404624\n",
      "\n",
      "to an   0.0013280212483399733\n",
      "\n",
      "Such a   0.125\n",
      "\n",
      "reasoning .   0.14285714285714285\n",
      "\n",
      "Recall can   0.3333333333333333\n",
      "\n",
      "taking a   0.2\n",
      "\n",
      "Software -LRB-   0.5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approaches ,   0.03571428571428571\n",
      "\n",
      "Since OCR   0.2\n",
      "\n",
      "performed an   0.1\n",
      "\n",
      "rank ``   0.16666666666666666\n",
      "\n",
      "is clearly   0.0040650406504065045\n",
      "\n",
      "right ''   0.1\n",
      "\n",
      "1965 based   0.25\n",
      "\n",
      "noun 40   0.07142857142857142\n",
      "\n",
      "= Human   0.1111111111111111\n",
      "\n",
      "in Italy   0.0018726591760299626\n",
      "\n",
      "The target   0.005208333333333333\n",
      "\n",
      "to ones   0.0013280212483399733\n",
      "\n",
      "function words   0.125\n",
      "\n",
      "currently the   0.14285714285714285\n",
      "\n",
      "tagging was   0.08\n",
      "\n",
      "using a   0.1694915254237288\n",
      "\n",
      "or structured   0.0045045045045045045\n",
      "\n",
      "perspective ,   0.25\n",
      "\n",
      "algorithm implicitly   0.03571428571428571\n",
      "\n",
      "that they   0.024822695035460994\n",
      "\n",
      ", quite   0.0005614823133071309\n",
      "\n",
      "which entertaining   0.007246376811594203\n",
      "\n",
      "trade offs   0.5\n",
      "\n",
      "automatically focus   0.047619047619047616\n",
      "\n",
      "and sources   0.001445086705202312\n",
      "\n",
      "français .   1.0\n",
      "\n",
      "discussion groups   0.5\n",
      "\n",
      "-LRB- HLDA   0.0027100271002710027\n",
      "\n",
      "contain the   0.16666666666666666\n",
      "\n",
      "ones .   0.2\n",
      "\n",
      "of social   0.0017825311942959\n",
      "\n",
      "Competing semantic   1.0\n",
      "\n",
      "segmentation tools   0.06060606060606061\n",
      "\n",
      "continuously rendered   1.0\n",
      "\n",
      "abbreviated to   1.0\n",
      "\n",
      "rejecting ``   0.6666666666666666\n",
      "\n",
      "only five   0.02631578947368421\n",
      "\n",
      "perform a   0.2727272727272727\n",
      "\n",
      "bank .   1.0\n",
      "\n",
      "summarization -RRB-   0.02\n",
      "\n",
      "has used   0.011904761904761904\n",
      "\n",
      "small local   0.1111111111111111\n",
      "\n",
      "revolutionized bill   1.0\n",
      "\n",
      "to limit   0.0026560424966799467\n",
      "\n",
      "attempts to   0.5\n",
      "\n",
      "minimal complexity   1.0\n",
      "\n",
      ", previously   0.0005614823133071309\n",
      "\n",
      "walking more   0.3333333333333333\n",
      "\n",
      "wrote an   0.3333333333333333\n",
      "\n",
      "be trained   0.004219409282700422\n",
      "\n",
      "not lead   0.008928571428571428\n",
      "\n",
      "Narrow but   1.0\n",
      "\n",
      "which occur   0.007246376811594203\n",
      "\n",
      "front door   1.0\n",
      "\n",
      "Web or   0.1111111111111111\n",
      "\n",
      "the pollen   0.0006920415224913495\n",
      "\n",
      "Systems corp.   0.08333333333333333\n",
      "\n",
      "by decomposing   0.005714285714285714\n",
      "\n",
      "semi-supervised ''   0.5\n",
      "\n",
      "`` unsupervised   0.005291005291005291\n",
      "\n",
      "individuals that   1.0\n",
      "\n",
      "<s> Types   0.0015372790161414297\n",
      "\n",
      "a bilingual   0.001226993865030675\n",
      "\n",
      "a digital   0.00245398773006135\n",
      "\n",
      "often of   0.022727272727272728\n",
      "\n",
      "Mellon University   1.0\n",
      "\n",
      "be either   0.004219409282700422\n",
      "\n",
      "extraction of   0.0967741935483871\n",
      "\n",
      ": objective   0.00980392156862745\n",
      "\n",
      "specific right   0.047619047619047616\n",
      "\n",
      "allow spoken   0.2\n",
      "\n",
      "'s gonna   0.0196078431372549\n",
      "\n",
      "these numbers   0.047619047619047616\n",
      "\n",
      "summaries -LRB-   0.046511627906976744\n",
      "\n",
      "the moderate   0.0020761245674740486\n",
      "\n",
      "its best   0.02857142857142857\n",
      "\n",
      "in recognizing   0.003745318352059925\n",
      "\n",
      "door ''   0.5\n",
      "\n",
      "Speech When   0.03225806451612903\n",
      "\n",
      "<s> Specifically   0.0007686395080707148\n",
      "\n",
      "evaluation has   0.018518518518518517\n",
      "\n",
      "; this   0.06382978723404255\n",
      "\n",
      "is exactly   0.0020325203252032522\n",
      "\n",
      "one ,   0.06153846153846154\n",
      "\n",
      "long-time translator   1.0\n",
      "\n",
      "-LRB- c   0.0027100271002710027\n",
      "\n",
      "effort .   0.25\n",
      "\n",
      "DUC 2001   1.0\n",
      "\n",
      "Dr. Kenneth   1.0\n",
      "\n",
      "they would   0.025\n",
      "\n",
      "keyphrase extraction   0.631578947368421\n",
      "\n",
      "research were   0.023809523809523808\n",
      "\n",
      "DARPA funding   0.25\n",
      "\n",
      "-RRB- mark   0.0027100271002710027\n",
      "\n",
      "The algorithm   0.005208333333333333\n",
      "\n",
      "a word   0.013496932515337423\n",
      "\n",
      "to upload   0.0013280212483399733\n",
      "\n",
      "to treat   0.0013280212483399733\n",
      "\n",
      "as conveniently   0.003484320557491289\n",
      "\n",
      "contains embedded   0.1\n",
      "\n",
      "each word   0.1111111111111111\n",
      "\n",
      "Additional aspects   1.0\n",
      "\n",
      "be needed   0.004219409282700422\n",
      "\n",
      "from any   0.009615384615384616\n",
      "\n",
      "the approach   0.0006920415224913495\n",
      "\n",
      "generate a   0.3333333333333333\n",
      "\n",
      "create both   0.058823529411764705\n",
      "\n",
      "exactly how   0.3333333333333333\n",
      "\n",
      "Recognition is   0.125\n",
      "\n",
      "`` Speaker   0.010582010582010581\n",
      "\n",
      "<s> Research   0.0015372790161414297\n",
      "\n",
      "that handles   0.0035460992907801418\n",
      "\n",
      "HAMS =   1.0\n",
      "\n",
      "segment in   0.1111111111111111\n",
      "\n",
      "with images   0.00546448087431694\n",
      "\n",
      "against a   0.2\n",
      "\n",
      "currency for   1.0\n",
      "\n",
      "sophisticated questioners   0.14285714285714285\n",
      "\n",
      ", tag   0.0005614823133071309\n",
      "\n",
      "some work   0.012048192771084338\n",
      "\n",
      "<s> HMMs   0.0023059185242121443\n",
      "\n",
      ", both   0.0016844469399213925\n",
      "\n",
      "speeches ,   1.0\n",
      "\n",
      "of syntax   0.0017825311942959\n",
      "\n",
      "a particular   0.0049079754601227\n",
      "\n",
      "are starting   0.004149377593360996\n",
      "\n",
      "Australian Air   0.5\n",
      "\n",
      "preselects small   1.0\n",
      "\n",
      "while capturing   0.05\n",
      "\n",
      "feature\\/aspect is   1.0\n",
      "\n",
      "wave from   0.1111111111111111\n",
      "\n",
      ", dimensionality   0.0005614823133071309\n",
      "\n",
      "social science   0.07142857142857142\n",
      "\n",
      "and you   0.004335260115606936\n",
      "\n",
      "highly .   0.1111111111111111\n",
      "\n",
      "NLP .   0.10638297872340426\n",
      "\n",
      "application requirements   0.07142857142857142\n",
      "\n",
      "entity about   0.2\n",
      "\n",
      "various combinations   0.05555555555555555\n",
      "\n",
      "is what   0.0040650406504065045\n",
      "\n",
      "endeavors such   1.0\n",
      "\n",
      "an underlying   0.007575757575757576\n",
      "\n",
      "it works   0.008547008547008548\n",
      "\n",
      "Emergent grammar   1.0\n",
      "\n",
      "individual characters   0.08333333333333333\n",
      "\n",
      "segmentation that   0.030303030303030304\n",
      "\n",
      "Leeuwen ,   1.0\n",
      "\n",
      "were called   0.024390243902439025\n",
      "\n",
      "to save   0.0013280212483399733\n",
      "\n",
      "President Biden   0.25\n",
      "\n",
      ", addressed   0.0005614823133071309\n",
      "\n",
      "build on   0.3333333333333333\n",
      "\n",
      "represented as   0.3333333333333333\n",
      "\n",
      "the concepts   0.0006920415224913495\n",
      "\n",
      "one or   0.03076923076923077\n",
      "\n",
      "generates summaries   0.3333333333333333\n",
      "\n",
      "further information   0.125\n",
      "\n",
      "RCA collaborated   0.2\n",
      "\n",
      ", similarities   0.0005614823133071309\n",
      "\n",
      "system typically   0.010752688172043012\n",
      "\n",
      "automatically ,   0.047619047619047616\n",
      "\n",
      "Greek ,   0.3333333333333333\n",
      "\n",
      "-- Pointwise   0.04\n",
      "\n",
      "Lawrence Rabiner   1.0\n",
      "\n",
      "unsupervised ,   0.125\n",
      "\n",
      "that area   0.0035460992907801418\n",
      "\n",
      "Palm OS   1.0\n",
      "\n",
      "other languages   0.07142857142857142\n",
      "\n",
      "an email   0.007575757575757576\n",
      "\n",
      "the whole   0.0006920415224913495\n",
      "\n",
      "automatic summarization   0.08695652173913043\n",
      "\n",
      "text corpus   0.012578616352201259\n",
      "\n",
      "then combining   0.02857142857142857\n",
      "\n",
      "subject to   0.125\n",
      "\n",
      "-RRB- words   0.0027100271002710027\n",
      "\n",
      "the improvement   0.0006920415224913495\n",
      "\n",
      "than a   0.1111111111111111\n",
      "\n",
      "training .   0.03571428571428571\n",
      "\n",
      "Front-End speech   1.0\n",
      "\n",
      "states that   0.25\n",
      "\n",
      "accuracy above   0.03225806451612903\n",
      "\n",
      "sounds it   0.06666666666666667\n",
      "\n",
      "Automated essay   0.5\n",
      "\n",
      "words have   0.009174311926605505\n",
      "\n",
      "how air   0.034482758620689655\n",
      "\n",
      "list approach   0.09090909090909091\n",
      "\n",
      "of abbreviations   0.0017825311942959\n",
      "\n",
      "G-loads .   1.0\n",
      "\n",
      "Charniak points   1.0\n",
      "\n",
      "because a   0.03333333333333333\n",
      "\n",
      "the sounds   0.001384083044982699\n",
      "\n",
      "meant and   0.5\n",
      "\n",
      "well a   0.03571428571428571\n",
      "\n",
      "`` Call   0.005291005291005291\n",
      "\n",
      "the sense   0.0006920415224913495\n",
      "\n",
      "between posts   0.02564102564102564\n",
      "\n",
      "of languages   0.00089126559714795\n",
      "\n",
      "Evaluation techniques   0.1111111111111111\n",
      "\n",
      "Pang and   0.3333333333333333\n",
      "\n",
      "units are   0.2857142857142857\n",
      "\n",
      "written languages   0.19230769230769232\n",
      "\n",
      "IBM and   0.3333333333333333\n",
      "\n",
      "studies and   0.25\n",
      "\n",
      "an answer   0.015151515151515152\n",
      "\n",
      "weaknesses .   1.0\n",
      "\n",
      "A number   0.06\n",
      "\n",
      "the recognition   0.001384083044982699\n",
      "\n",
      "control ,   0.2\n",
      "\n",
      "and produce   0.002890173410404624\n",
      "\n",
      "prepare formal   1.0\n",
      "\n",
      "EHR -RRB-   0.3333333333333333\n",
      "\n",
      "were started   0.024390243902439025\n",
      "\n",
      "scaling system   1.0\n",
      "\n",
      ", improving   0.0005614823133071309\n",
      "\n",
      "are further   0.004149377593360996\n",
      "\n",
      "IMR -RRB-   0.5\n",
      "\n",
      "relationships between   0.16666666666666666\n",
      "\n",
      "SHRDLU simulated   0.16666666666666666\n",
      "\n",
      "of TextRank   0.00089126559714795\n",
      "\n",
      "TextRank ,   0.14285714285714285\n",
      "\n",
      "recognition but   0.008264462809917356\n",
      "\n",
      "algorithms are   0.05714285714285714\n",
      "\n",
      "many keyphrases   0.019230769230769232\n",
      "\n",
      "tags used   0.3333333333333333\n",
      "\n",
      "dogs ''   0.5714285714285714\n",
      "\n",
      "fade away   1.0\n",
      "\n",
      "and built   0.001445086705202312\n",
      "\n",
      "the other   0.005536332179930796\n",
      "\n",
      "applies to   0.14285714285714285\n",
      "\n",
      "1979 -RRB-   1.0\n",
      "\n",
      "Extractive methods   1.0\n",
      "\n",
      "a context   0.00245398773006135\n",
      "\n",
      "a damping   0.001226993865030675\n",
      "\n",
      "template ,   0.25\n",
      "\n",
      "would never   0.018867924528301886\n",
      "\n",
      "while others   0.2\n",
      "\n",
      "abruptly at   1.0\n",
      "\n",
      "the serial   0.0006920415224913495\n",
      "\n",
      "of tasks   0.00089126559714795\n",
      "\n",
      "system developed   0.010752688172043012\n",
      "\n",
      "dog ''   0.3333333333333333\n",
      "\n",
      "A. van   0.2\n",
      "\n",
      "are likely   0.016597510373443983\n",
      "\n",
      "summaries automatically   0.023255813953488372\n",
      "\n",
      "of telephony   0.00089126559714795\n",
      "\n",
      "entertaining can   0.5\n",
      "\n",
      "Acoustical signals   0.5\n",
      "\n",
      "DOE -RRB-   1.0\n",
      "\n",
      "Shipibo .   0.5\n",
      "\n",
      ", complicating   0.0005614823133071309\n",
      "\n",
      "step and   0.06666666666666667\n",
      "\n",
      "capabilities of   0.2\n",
      "\n",
      "the harder   0.0020761245674740486\n",
      "\n",
      "all quantitative   0.023255813953488372\n",
      "\n",
      "programmed by   0.5\n",
      "\n",
      "or her   0.009009009009009009\n",
      "\n",
      "concentrates on   1.0\n",
      "\n",
      "extremely expensive   0.25\n",
      "\n",
      "the specification   0.001384083044982699\n",
      "\n",
      "model .   0.06666666666666667\n",
      "\n",
      "The extractor   0.005208333333333333\n",
      "\n",
      "-LRB- Journal   0.0027100271002710027\n",
      "\n",
      "be checked   0.004219409282700422\n",
      "\n",
      "conditions in   0.2\n",
      "\n",
      "and some   0.002890173410404624\n",
      "\n",
      "adjectives and   0.3333333333333333\n",
      "\n",
      "French were   0.25\n",
      "\n",
      "of computer   0.0035650623885918\n",
      "\n",
      "to evaluate   0.005312084993359893\n",
      "\n",
      "nonsensical to   1.0\n",
      "\n",
      "Computer Speech   0.3333333333333333\n",
      "\n",
      "also considerable   0.014492753623188406\n",
      "\n",
      "a simulation   0.001226993865030675\n",
      "\n",
      "at conclusions   0.014705882352941176\n",
      "\n",
      "are different   0.004149377593360996\n",
      "\n",
      "Manfred R.   1.0\n",
      "\n",
      "boards and   1.0\n",
      "\n",
      "noise -LRB-   0.125\n",
      "\n",
      "other task   0.014285714285714285\n",
      "\n",
      "to improve   0.01195219123505976\n",
      "\n",
      "graph-based ranking   1.0\n",
      "\n",
      "-LRB- Keyphrase   0.0027100271002710027\n",
      "\n",
      "can only   0.011049723756906077\n",
      "\n",
      "the notable   0.0006920415224913495\n",
      "\n",
      "this context   0.02197802197802198\n",
      "\n",
      "HMMs are   0.25\n",
      "\n",
      "well that   0.03571428571428571\n",
      "\n",
      "numbers which   0.14285714285714285\n",
      "\n",
      "brain recognizes   0.3333333333333333\n",
      "\n",
      "attitude may   0.5\n",
      "\n",
      "since ROUGE-1   0.1\n",
      "\n",
      "characterized by   0.5\n",
      "\n",
      ", enables   0.0005614823133071309\n",
      "\n",
      "objects and   0.2\n",
      "\n",
      "plus some   1.0\n",
      "\n",
      "of grammatical   0.00089126559714795\n",
      "\n",
      "wave .   0.2222222222222222\n",
      "\n",
      "affective state   1.0\n",
      "\n",
      "The success   0.005208333333333333\n",
      "\n",
      "speakers .   0.25\n",
      "\n",
      "able to   1.0\n",
      "\n",
      "still ''   0.06666666666666667\n",
      "\n",
      "of Peru   0.00089126559714795\n",
      "\n",
      "fall in   0.25\n",
      "\n",
      "<s> Coreference   0.0007686395080707148\n",
      "\n",
      "a year   0.001226993865030675\n",
      "\n",
      "parse a   0.1111111111111111\n",
      "\n",
      "trivial word   0.25\n",
      "\n",
      "opposite of   1.0\n",
      "\n",
      "Isles and   1.0\n",
      "\n",
      "restaurant ,   0.5\n",
      "\n",
      "if the   0.35714285714285715\n",
      "\n",
      "earlier in   0.25\n",
      "\n",
      "task of   0.21428571428571427\n",
      "\n",
      "for several   0.007220216606498195\n",
      "\n",
      "applications including   0.04\n",
      "\n",
      "One step   0.07692307692307693\n",
      "\n",
      "including sentiment   0.07142857142857142\n",
      "\n",
      "individual trained   0.08333333333333333\n",
      "\n",
      "d'évaluation de   1.0\n",
      "\n",
      "Vulcan program   0.5\n",
      "\n",
      "i.e. the   0.2631578947368421\n",
      "\n",
      "negative ,   0.125\n",
      "\n",
      "machine translation   0.4936708860759494\n",
      "\n",
      "these sounds   0.023809523809523808\n",
      "\n",
      "requires significant   0.0625\n",
      "\n",
      "the number   0.004844290657439446\n",
      "\n",
      "seen the   0.1\n",
      "\n",
      "possible on   0.041666666666666664\n",
      "\n",
      "The recognition   0.005208333333333333\n",
      "\n",
      "SHRDLU ,   0.16666666666666666\n",
      "\n",
      "when integrated   0.02857142857142857\n",
      "\n",
      "final sounds   0.1111111111111111\n",
      "\n",
      "describe words   0.16666666666666666\n",
      "\n",
      "size of   0.16666666666666666\n",
      "\n",
      "all such   0.023255813953488372\n",
      "\n",
      "per minute   0.25\n",
      "\n",
      "model all   0.03333333333333333\n",
      "\n",
      "to seize   0.0013280212483399733\n",
      "\n",
      "task can   0.023809523809523808\n",
      "\n",
      "by no   0.005714285714285714\n",
      "\n",
      "from machine   0.019230769230769232\n",
      "\n",
      "know document   0.5\n",
      "\n",
      "<s> Even   0.0007686395080707148\n",
      "\n",
      ", sentence   0.0005614823133071309\n",
      "\n",
      "Word splitting   0.2857142857142857\n",
      "\n",
      "aircraft ,   0.2857142857142857\n",
      "\n",
      "spoken sentence   0.07142857142857142\n",
      "\n",
      "individual morphemes   0.08333333333333333\n",
      "\n",
      "technology is   0.13636363636363635\n",
      "\n",
      "the same   0.01522491349480969\n",
      "\n",
      "robustness in   0.25\n",
      "\n",
      "OnlineOCR practically   0.3333333333333333\n",
      "\n",
      "foster the   1.0\n",
      "\n",
      "probabilistic division   0.14285714285714285\n",
      "\n",
      "a corpus   0.0036809815950920245\n",
      "\n",
      "deal primarily   0.25\n",
      "\n",
      "Merging of   1.0\n",
      "\n",
      "investigates the   1.0\n",
      "\n",
      "system using   0.010752688172043012\n",
      "\n",
      "is crucial   0.0020325203252032522\n",
      "\n",
      "text based   0.006289308176100629\n",
      "\n",
      "summary in   0.047619047619047616\n",
      "\n",
      "Stylistics -LRB-   1.0\n",
      "\n",
      "Navigation Systems   1.0\n",
      "\n",
      "in-depth knowledge   0.6666666666666666\n",
      "\n",
      "'' summary   0.005154639175257732\n",
      "\n",
      "LexRank has   0.08333333333333333\n",
      "\n",
      "understand the   0.2857142857142857\n",
      "\n",
      "algorithms .   0.11428571428571428\n",
      "\n",
      "rule-based machine   0.14285714285714285\n",
      "\n",
      "large data   0.043478260869565216\n",
      "\n",
      "systems dynamically   0.008928571428571428\n",
      "\n",
      "of war   0.00089126559714795\n",
      "\n",
      "garden path   1.0\n",
      "\n",
      "untagged corpus   1.0\n",
      "\n",
      "Service has   1.0\n",
      "\n",
      "determination :   1.0\n",
      "\n",
      "power resulting   0.25\n",
      "\n",
      "having `   0.2\n",
      "\n",
      "<s> Informally   0.0007686395080707148\n",
      "\n",
      "are based   0.02074688796680498\n",
      "\n",
      "<s> metrics   0.0007686395080707148\n",
      "\n",
      "equivalence relations   0.5\n",
      "\n",
      "that should   0.0070921985815602835\n",
      "\n",
      "sense and   0.125\n",
      "\n",
      "those surrounding   0.045454545454545456\n",
      "\n",
      "defining programming   1.0\n",
      "\n",
      "global `   0.3333333333333333\n",
      "\n",
      "evaluation data   0.018518518518518517\n",
      "\n",
      "FoG ,   0.5\n",
      "\n",
      "be described   0.004219409282700422\n",
      "\n",
      "universal encyclopedia   0.3333333333333333\n",
      "\n",
      ", plus   0.0005614823133071309\n",
      "\n",
      "neighbors ,   0.3333333333333333\n",
      "\n",
      "the JAS-39   0.0006920415224913495\n",
      "\n",
      "or worse   0.0045045045045045045\n",
      "\n",
      "it 's   0.008547008547008548\n",
      "\n",
      "devoted exclusively   0.2\n",
      "\n",
      "of 200   0.00089126559714795\n",
      "\n",
      ", Hindle   0.0005614823133071309\n",
      "\n",
      "of whether   0.00089126559714795\n",
      "\n",
      "available resources   0.058823529411764705\n",
      "\n",
      "M-346 Master   1.0\n",
      "\n",
      "ISO\\/TC37\\/SC4 .   1.0\n",
      "\n",
      "-RRB- .   0.27371273712737126\n",
      "\n",
      "the lexicon   0.0006920415224913495\n",
      "\n",
      "can function   0.0055248618784530384\n",
      "\n",
      "small incremental   0.1111111111111111\n",
      "\n",
      "extrinsic performance   0.16666666666666666\n",
      "\n",
      "text in   0.050314465408805034\n",
      "\n",
      "were conducted   0.024390243902439025\n",
      "\n",
      "-RRB- Hands-free   0.0027100271002710027\n",
      "\n",
      "programs to   0.09090909090909091\n",
      "\n",
      "words ,   0.13761467889908258\n",
      "\n",
      "Processes may   1.0\n",
      "\n",
      "Text-to-speech Text-proofing   1.0\n",
      "\n",
      "backup methods   1.0\n",
      "\n",
      "between text   0.02564102564102564\n",
      "\n",
      "for Greek   0.0036101083032490976\n",
      "\n",
      "local '   0.3333333333333333\n",
      "\n",
      "regard to   0.8\n",
      "\n",
      "if uttered   0.03571428571428571\n",
      "\n",
      "of segmentation   0.00089126559714795\n",
      "\n",
      "Interspeech -RRB-   1.0\n",
      "\n",
      "parsed efficiently   0.25\n",
      "\n",
      "and interjection   0.001445086705202312\n",
      "\n",
      "this character   0.01098901098901099\n",
      "\n",
      "'' continued   0.005154639175257732\n",
      "\n",
      "a qualitative   0.00245398773006135\n",
      "\n",
      "Applied Intelligence   0.5\n",
      "\n",
      "considered as   0.1111111111111111\n",
      "\n",
      "of modern   0.00089126559714795\n",
      "\n",
      "by heteroscedastic   0.005714285714285714\n",
      "\n",
      "can occur   0.0055248618784530384\n",
      "\n",
      "The features   0.005208333333333333\n",
      "\n",
      "Street Journal   0.6666666666666666\n",
      "\n",
      "and researchers   0.001445086705202312\n",
      "\n",
      "composing Braille   1.0\n",
      "\n",
      "procedures used   0.25\n",
      "\n",
      ", too   0.0005614823133071309\n",
      "\n",
      "while ratings   0.05\n",
      "\n",
      ", rejecting   0.0005614823133071309\n",
      "\n",
      "not capitalize   0.008928571428571428\n",
      "\n",
      "RCA Drum   0.2\n",
      "\n",
      "parser proposes   0.0625\n",
      "\n",
      "Louise J.   1.0\n",
      "\n",
      "medical records   0.3333333333333333\n",
      "\n",
      "stream is   0.5\n",
      "\n",
      "ports .   1.0\n",
      "\n",
      "these T   0.023809523809523808\n",
      "\n",
      "recognizing hand-printed   0.2\n",
      "\n",
      "than speech   0.022222222222222223\n",
      "\n",
      "selecting duplicate   0.2\n",
      "\n",
      "to +5   0.0013280212483399733\n",
      "\n",
      "precise function   0.3333333333333333\n",
      "\n",
      "with machine   0.00546448087431694\n",
      "\n",
      "angle .   1.0\n",
      "\n",
      "the system   0.01384083044982699\n",
      "\n",
      "Machine Aided   0.1111111111111111\n",
      "\n",
      "grammatical analysis   0.09090909090909091\n",
      "\n",
      "due to   0.4\n",
      "\n",
      "information deemed   0.021739130434782608\n",
      "\n",
      "word use   0.016666666666666666\n",
      "\n",
      "accurate simply   0.14285714285714285\n",
      "\n",
      ", once   0.0005614823133071309\n",
      "\n",
      "best algorithms   0.05555555555555555\n",
      "\n",
      "interpretation capabilities   0.5\n",
      "\n",
      "Recall this   0.3333333333333333\n",
      "\n",
      "covariance transform   0.5\n",
      "\n",
      "translation software   0.04054054054054054\n",
      "\n",
      "oriented systems   1.0\n",
      "\n",
      "has to   0.05952380952380952\n",
      "\n",
      "and writing   0.001445086705202312\n",
      "\n",
      "south east   1.0\n",
      "\n",
      "dictation system   1.0\n",
      "\n",
      "collection .   0.2\n",
      "\n",
      "classifying short-time   0.2\n",
      "\n",
      "generators of   0.5\n",
      "\n",
      "assign positive   0.2\n",
      "\n",
      "other modifying   0.014285714285714285\n",
      "\n",
      "is some   0.0020325203252032522\n",
      "\n",
      "-LRB- HMT   0.0027100271002710027\n",
      "\n",
      "related data   0.06666666666666667\n",
      "\n",
      "two simple   0.034482758620689655\n",
      "\n",
      "three basic   0.3333333333333333\n",
      "\n",
      "can serve   0.011049723756906077\n",
      "\n",
      "Adda 1999   0.5\n",
      "\n",
      "an application   0.015151515151515152\n",
      "\n",
      "high rank   0.05555555555555555\n",
      "\n",
      "Knowledge of   0.5\n",
      "\n",
      "11 point   1.0\n",
      "\n",
      "OnlineOCR or   0.3333333333333333\n",
      "\n",
      "measure based   0.09090909090909091\n",
      "\n",
      "complex problem   0.041666666666666664\n",
      "\n",
      "recognition models   0.008264462809917356\n",
      "\n",
      "entry from   0.25\n",
      "\n",
      "disparate fields   1.0\n",
      "\n",
      "ARRA -RRB-   1.0\n",
      "\n",
      "text itself   0.006289308176100629\n",
      "\n",
      "those using   0.045454545454545456\n",
      "\n",
      "and not   0.011560693641618497\n",
      "\n",
      "instance of   0.14285714285714285\n",
      "\n",
      "NLP system   0.0851063829787234\n",
      "\n",
      "NLP is   0.02127659574468085\n",
      "\n",
      "numbers after   0.14285714285714285\n",
      "\n",
      "estimate sentence   0.25\n",
      "\n",
      "<s> Full   0.0007686395080707148\n",
      "\n",
      "and LOB   0.001445086705202312\n",
      "\n",
      "by Homayoon   0.005714285714285714\n",
      "\n",
      "slowly but   0.5\n",
      "\n",
      "elements from   0.25\n",
      "\n",
      "meaning ;   0.043478260869565216\n",
      "\n",
      "center ,   1.0\n",
      "\n",
      "been based   0.014705882352941176\n",
      "\n",
      "was only   0.012987012987012988\n",
      "\n",
      "word recognition   0.016666666666666666\n",
      "\n",
      "not trivial   0.008928571428571428\n",
      "\n",
      "See chart   0.16666666666666666\n",
      "\n",
      "methods QA   0.022727272727272728\n",
      "\n",
      "or some   0.013513513513513514\n",
      "\n",
      "processed incorrectly   0.16666666666666666\n",
      "\n",
      "compared syntactic   0.14285714285714285\n",
      "\n",
      "Dragon Systems   1.0\n",
      "\n",
      "translation ,   0.10810810810810811\n",
      "\n",
      "converted the   0.3333333333333333\n",
      "\n",
      "native speaker   1.0\n",
      "\n",
      "not all   0.017857142857142856\n",
      "\n",
      "The AT&T   0.005208333333333333\n",
      "\n",
      "because longer   0.03333333333333333\n",
      "\n",
      "more compactly   0.010526315789473684\n",
      "\n",
      "surprisingly disruptive   0.3333333333333333\n",
      "\n",
      ", June   0.0005614823133071309\n",
      "\n",
      "-LRB- rescoring   0.0027100271002710027\n",
      "\n",
      "over many   0.08333333333333333\n",
      "\n",
      "computer read   0.022727272727272728\n",
      "\n",
      "using an   0.03389830508474576\n",
      "\n",
      "linguist to   0.5\n",
      "\n",
      "message understanding   0.5\n",
      "\n",
      "utterance ``   0.3333333333333333\n",
      "\n",
      "N-best list   1.0\n",
      "\n",
      "have so-called   0.009615384615384616\n",
      "\n",
      "requires six   0.0625\n",
      "\n",
      "was considerable   0.012987012987012988\n",
      "\n",
      "or nonexistent   0.0045045045045045045\n",
      "\n",
      "be correct   0.004219409282700422\n",
      "\n",
      "leverages the   1.0\n",
      "\n",
      "of named   0.00089126559714795\n",
      "\n",
      "telegraph code   1.0\n",
      "\n",
      "handwriting .   0.5\n",
      "\n",
      "Their methods   0.5\n",
      "\n",
      "Generation -LRB-   0.5\n",
      "\n",
      "assign a   0.4\n",
      "\n",
      "WebOCR &   0.75\n",
      "\n",
      "are clearly   0.004149377593360996\n",
      "\n",
      "substantial financial   0.2\n",
      "\n",
      "used varies   0.008849557522123894\n",
      "\n",
      "John Swales   0.25\n",
      "\n",
      "voicemail to   1.0\n",
      "\n",
      "each unigram   0.044444444444444446\n",
      "\n",
      "a good   0.0049079754601227\n",
      "\n",
      "<s> Manual   0.0015372790161414297\n",
      "\n",
      "infinitive marker   1.0\n",
      "\n",
      "zero ''   1.0\n",
      "\n",
      "method of   0.125\n",
      "\n",
      "or they   0.0045045045045045045\n",
      "\n",
      "Open-domain question   1.0\n",
      "\n",
      "summaries with   0.046511627906976744\n",
      "\n",
      "additional clues   0.16666666666666666\n",
      "\n",
      "without it   0.07692307692307693\n",
      "\n",
      "University 's   0.1111111111111111\n",
      "\n",
      "paraphrase .   1.0\n",
      "\n",
      "Automatic learning   0.1111111111111111\n",
      "\n",
      "a reader   0.001226993865030675\n",
      "\n",
      "for What   0.0036101083032490976\n",
      "\n",
      "manually designed   0.25\n",
      "\n",
      "unambiguous .   0.5\n",
      "\n",
      "but when   0.014705882352941176\n",
      "\n",
      "new odd   0.041666666666666664\n",
      "\n",
      "what class   0.03125\n",
      "\n",
      ", though   0.003368893879842785\n",
      "\n",
      "mathematical framework   0.5\n",
      "\n",
      "dimensionality reduction   1.0\n",
      "\n",
      "algorithm ,   0.10714285714285714\n",
      "\n",
      "International continued   1.0\n",
      "\n",
      "which he   0.007246376811594203\n",
      "\n",
      "strategy to   0.6\n",
      "\n",
      "an isolated   0.007575757575757576\n",
      "\n",
      "applications Robotics   0.04\n",
      "\n",
      "for businesses   0.0036101083032490976\n",
      "\n",
      "outside world   0.5\n",
      "\n",
      "summaries ,   0.06976744186046512\n",
      "\n",
      "Many words   0.16666666666666666\n",
      "\n",
      "separators -RRB-   1.0\n",
      "\n",
      "lot more   0.3333333333333333\n",
      "\n",
      "discrete characters   0.3333333333333333\n",
      "\n",
      "1982 -RRB-   0.3333333333333333\n",
      "\n",
      "learning from   0.046511627906976744\n",
      "\n",
      "DARPA -LRB-   0.25\n",
      "\n",
      "pollen count   0.07692307692307693\n",
      "\n",
      "data in   0.025974025974025976\n",
      "\n",
      "system was   0.053763440860215055\n",
      "\n",
      "article ``   0.034482758620689655\n",
      "\n",
      "Substantial test   0.5\n",
      "\n",
      ", error-prone   0.0005614823133071309\n",
      "\n",
      "inflection is   1.0\n",
      "\n",
      "Wireless World   1.0\n",
      "\n",
      "programming language   0.2\n",
      "\n",
      "overlap should   0.25\n",
      "\n",
      "evident way   0.5\n",
      "\n",
      "have developed   0.009615384615384616\n",
      "\n",
      "Intelligent ''   0.3333333333333333\n",
      "\n",
      "work based   0.041666666666666664\n",
      "\n",
      "of TF-IDF   0.00089126559714795\n",
      "\n",
      "<s> E.   0.0007686395080707148\n",
      "\n",
      "multiple source   0.07692307692307693\n",
      "\n",
      "Sonic Extractor   1.0\n",
      "\n",
      "disabilities People   0.25\n",
      "\n",
      ", etc.   0.011229646266142616\n",
      "\n",
      "time in   0.030303030303030304\n",
      "\n",
      "and Speech   0.001445086705202312\n",
      "\n",
      "Communication .   1.0\n",
      "\n",
      "especially interested   0.06666666666666667\n",
      "\n",
      "systems include   0.008928571428571428\n",
      "\n",
      "known labeled   0.038461538461538464\n",
      "\n",
      "the bi-directional   0.0006920415224913495\n",
      "\n",
      "more accurately   0.010526315789473684\n",
      "\n",
      "Savic Naomi   1.0\n",
      "\n",
      "The choice   0.005208333333333333\n",
      "\n",
      "have made   0.009615384615384616\n",
      "\n",
      "east .   1.0\n",
      "\n",
      "any case   0.0967741935483871\n",
      "\n",
      "shorter the   0.5\n",
      "\n",
      "by one   0.005714285714285714\n",
      "\n",
      "the harmonic   0.0006920415224913495\n",
      "\n",
      "score -LRB-   0.16666666666666666\n",
      "\n",
      "science ,   0.4\n",
      "\n",
      ", vehicle   0.0005614823133071309\n",
      "\n",
      "equivalent questions   0.2\n",
      "\n",
      "during machine   0.1\n",
      "\n",
      "to settle   0.0013280212483399733\n",
      "\n",
      "Eagles Guidelines   1.0\n",
      "\n",
      "now named   0.15384615384615385\n",
      "\n",
      "and performance   0.001445086705202312\n",
      "\n",
      "also lead   0.014492753623188406\n",
      "\n",
      "went in   0.2\n",
      "\n",
      "of automatically   0.0017825311942959\n",
      "\n",
      "Top-down parsing   1.0\n",
      "\n",
      "and stochastic   0.001445086705202312\n",
      "\n",
      "of 1956   0.00089126559714795\n",
      "\n",
      "network -LRB-   0.16666666666666666\n",
      "\n",
      "was most   0.012987012987012988\n",
      "\n",
      "we rank   0.022222222222222223\n",
      "\n",
      "task-based -LRB-   0.25\n",
      "\n",
      "very similar   0.0975609756097561\n",
      "\n",
      "Gdaniec C.   1.0\n",
      "\n",
      "in fundamentally   0.0018726591760299626\n",
      "\n",
      "proper lexical   0.14285714285714285\n",
      "\n",
      "what linguistic   0.03125\n",
      "\n",
      "produce models   0.045454545454545456\n",
      "\n",
      "the tasks   0.0006920415224913495\n",
      "\n",
      "are currently   0.008298755186721992\n",
      "\n",
      "just robustness   0.1111111111111111\n",
      "\n",
      "With IT   0.14285714285714285\n",
      "\n",
      "the EMR   0.0006920415224913495\n",
      "\n",
      "are performed   0.004149377593360996\n",
      "\n",
      "as horoscope   0.003484320557491289\n",
      "\n",
      "so simply   0.03333333333333333\n",
      "\n",
      "main ''   0.125\n",
      "\n",
      "as nouns   0.003484320557491289\n",
      "\n",
      "multilingual textual   0.3333333333333333\n",
      "\n",
      "answer a   0.03333333333333333\n",
      "\n",
      "same characters   0.04\n",
      "\n",
      "factors ,   0.3333333333333333\n",
      "\n",
      "decisions are   0.1\n",
      "\n",
      "NIST role   0.5\n",
      "\n",
      "input which   0.024390243902439025\n",
      "\n",
      "fields of   0.3333333333333333\n",
      "\n",
      "transmitting by   1.0\n",
      "\n",
      "that detected   0.0035460992907801418\n",
      "\n",
      "produces all   0.25\n",
      "\n",
      "proper syntax   0.14285714285714285\n",
      "\n",
      "entity recognition   0.4\n",
      "\n",
      ", producing   0.0005614823133071309\n",
      "\n",
      "recognition performance   0.03305785123966942\n",
      "\n",
      "might expect   0.038461538461538464\n",
      "\n",
      "a great   0.00245398773006135\n",
      "\n",
      "multi-way scale   1.0\n",
      "\n",
      "these problems   0.023809523809523808\n",
      "\n",
      "TextRank While   0.07142857142857142\n",
      "\n",
      "One such   0.07692307692307693\n",
      "\n",
      "of Latin-script   0.00089126559714795\n",
      "\n",
      "person .   0.05263157894736842\n",
      "\n",
      "include all   0.037037037037037035\n",
      "\n",
      "have tested   0.009615384615384616\n",
      "\n",
      "sizes generally   0.3333333333333333\n",
      "\n",
      "whom -RRB-   0.5\n",
      "\n",
      ": Convert   0.0196078431372549\n",
      "\n",
      "and non-annotated   0.001445086705202312\n",
      "\n",
      "highest ROUGE-1   0.3333333333333333\n",
      "\n",
      "multiple part-of-speech   0.07692307692307693\n",
      "\n",
      "all ,   0.06976744186046512\n",
      "\n",
      "agree on   0.3333333333333333\n",
      "\n",
      "weapon release   0.5\n",
      "\n",
      "just keeping   0.1111111111111111\n",
      "\n",
      "phrases may   0.0625\n",
      "\n",
      "by expanding   0.005714285714285714\n",
      "\n",
      "starts ,   0.5\n",
      "\n",
      "Broadly ,   1.0\n",
      "\n",
      "systems read   0.008928571428571428\n",
      "\n",
      "objectives of   0.5\n",
      "\n",
      "languages is   0.02\n",
      "\n",
      "corpora ''   0.09090909090909091\n",
      "\n",
      "other structure   0.014285714285714285\n",
      "\n",
      "later became   0.1\n",
      "\n",
      "the frequency   0.0006920415224913495\n",
      "\n",
      "Question classes   0.2857142857142857\n",
      "\n",
      "upgrade a   1.0\n",
      "\n",
      "e.g. Noise   0.017857142857142856\n",
      "\n",
      "if-then rules   1.0\n",
      "\n",
      "clusters .   1.0\n",
      "\n",
      "from knowledge   0.009615384615384616\n",
      "\n",
      "strongly to   0.5\n",
      "\n",
      "not explicitly   0.008928571428571428\n",
      "\n",
      "target -LRB-   0.09090909090909091\n",
      "\n",
      "than extraction   0.022222222222222223\n",
      "\n",
      "1946 by   1.0\n",
      "\n",
      "Intrinsic vs.   0.3333333333333333\n",
      "\n",
      "have not   0.019230769230769232\n",
      "\n",
      "perform an   0.09090909090909091\n",
      "\n",
      "speech signal   0.006578947368421052\n",
      "\n",
      "and Martin   0.001445086705202312\n",
      "\n",
      "consisted of   1.0\n",
      "\n",
      "with recognition   0.00546448087431694\n",
      "\n",
      "illustrates some   0.5\n",
      "\n",
      "In 1949   0.009523809523809525\n",
      "\n",
      "authors claimed   0.4\n",
      "\n",
      "names ,   0.2857142857142857\n",
      "\n",
      "very small   0.04878048780487805\n",
      "\n",
      "regards to   1.0\n",
      "\n",
      "legal word   0.3333333333333333\n",
      "\n",
      "forms .   0.16666666666666666\n",
      "\n",
      "polarity on   0.125\n",
      "\n",
      "Statistical Main   0.1111111111111111\n",
      "\n",
      "utilize an   0.5\n",
      "\n",
      "Recognition of   0.25\n",
      "\n",
      "ways :   0.25\n",
      "\n",
      "that capture   0.0035460992907801418\n",
      "\n",
      "questioned the   1.0\n",
      "\n",
      "STT ''   1.0\n",
      "\n",
      "of mouse   0.00089126559714795\n",
      "\n",
      "are complicated   0.004149377593360996\n",
      "\n",
      "bridge the   1.0\n",
      "\n",
      "1990s ,   0.3333333333333333\n",
      "\n",
      "dog bites   0.3333333333333333\n",
      "\n",
      "compare generated   0.14285714285714285\n",
      "\n",
      "answers can   0.08333333333333333\n",
      "\n",
      "creating more   0.14285714285714285\n",
      "\n",
      "language characters   0.006756756756756757\n",
      "\n",
      "going to   0.25\n",
      "\n",
      "format called   0.5\n",
      "\n",
      "models have   0.038461538461538464\n",
      "\n",
      "can exploit   0.0055248618784530384\n",
      "\n",
      "as blogs   0.003484320557491289\n",
      "\n",
      "large ;   0.043478260869565216\n",
      "\n",
      "of oral   0.00089126559714795\n",
      "\n",
      "of elementary   0.00089126559714795\n",
      "\n",
      "first raised   0.030303030303030304\n",
      "\n",
      "early 20th-century   0.1\n",
      "\n",
      "methods -LRB-   0.045454545454545456\n",
      "\n",
      "Army Corps   0.5\n",
      "\n",
      "a closed-captioning   0.001226993865030675\n",
      "\n",
      "entities ''   0.14285714285714285\n",
      "\n",
      "is ambiguous   0.0020325203252032522\n",
      "\n",
      "popular example   0.1111111111111111\n",
      "\n",
      "the predicted   0.0006920415224913495\n",
      "\n",
      "the theory   0.0020761245674740486\n",
      "\n",
      "about 25   0.025\n",
      "\n",
      "with references   0.00546448087431694\n",
      "\n",
      "and coverage   0.001445086705202312\n",
      "\n",
      "the automatic   0.001384083044982699\n",
      "\n",
      "a series   0.007361963190184049\n",
      "\n",
      ", rushing   0.0005614823133071309\n",
      "\n",
      "the informal   0.0006920415224913495\n",
      "\n",
      ", taught   0.0005614823133071309\n",
      "\n",
      "Wodak ,   1.0\n",
      "\n",
      "inflectional morphology   1.0\n",
      "\n",
      "abstraction Broadly   0.25\n",
      "\n",
      "2000 ,   0.3333333333333333\n",
      "\n",
      "diversity ''   0.25\n",
      "\n",
      "underlying formal   0.3333333333333333\n",
      "\n",
      "to match   0.0026560424966799467\n",
      "\n",
      "and documents   0.001445086705202312\n",
      "\n",
      "only want   0.02631578947368421\n",
      "\n",
      "University researchers   0.1111111111111111\n",
      "\n",
      "given data   0.041666666666666664\n",
      "\n",
      "characters which   0.125\n",
      "\n",
      "strategy gets   0.2\n",
      "\n",
      "talk-in-interaction .   1.0\n",
      "\n",
      "on general   0.0047169811320754715\n",
      "\n",
      "to analyze   0.0013280212483399733\n",
      "\n",
      "why automatic   0.14285714285714285\n",
      "\n",
      "is hard   0.0020325203252032522\n",
      "\n",
      "without a   0.07692307692307693\n",
      "\n",
      "93-95 %   1.0\n",
      "\n",
      "vital .   1.0\n",
      "\n",
      "the data   0.002768166089965398\n",
      "\n",
      "algorithms fall   0.02857142857142857\n",
      "\n",
      "sentences are   0.09210526315789473\n",
      "\n",
      "dynamic motion   0.2\n",
      "\n",
      "Each article   0.16666666666666666\n",
      "\n",
      "the syntactic   0.0006920415224913495\n",
      "\n",
      "not require   0.008928571428571428\n",
      "\n",
      ": Neural   0.00980392156862745\n",
      "\n",
      ", sentences   0.0011229646266142617\n",
      "\n",
      "levels even   0.045454545454545456\n",
      "\n",
      "a fluent   0.001226993865030675\n",
      "\n",
      "also continue   0.014492753623188406\n",
      "\n",
      "normalization .   0.3333333333333333\n",
      "\n",
      "manner rather   0.25\n",
      "\n",
      "words by   0.009174311926605505\n",
      "\n",
      "Another good   0.07692307692307693\n",
      "\n",
      "<s> Open-domain   0.0007686395080707148\n",
      "\n",
      "retrieval -LRB-   0.14285714285714285\n",
      "\n",
      "The progress   0.005208333333333333\n",
      "\n",
      "`` Fundamentals   0.010582010582010581\n",
      "\n",
      "express this   0.2\n",
      "\n",
      "accelerations and   1.0\n",
      "\n",
      "to Xerox   0.0013280212483399733\n",
      "\n",
      "the mid-90s   0.0006920415224913495\n",
      "\n",
      "theory Conversation   0.07692307692307693\n",
      "\n",
      "a stream   0.001226993865030675\n",
      "\n",
      "resolve some   0.25\n",
      "\n",
      "Technolangue\\/Easy project   0.5\n",
      "\n",
      "difference can   0.25\n",
      "\n",
      "task should   0.023809523809523808\n",
      "\n",
      "available soon   0.058823529411764705\n",
      "\n",
      "the simple   0.0006920415224913495\n",
      "\n",
      "sample of   0.3333333333333333\n",
      "\n",
      "or weapon   0.0045045045045045045\n",
      "\n",
      "which have   0.014492753623188406\n",
      "\n",
      "well their   0.03571428571428571\n",
      "\n",
      "statically beforehand   1.0\n",
      "\n",
      "Trek .   1.0\n",
      "\n",
      "results over   0.047619047619047616\n",
      "\n",
      "computers for   0.1111111111111111\n",
      "\n",
      "be adequately   0.004219409282700422\n",
      "\n",
      "carried on   0.5\n",
      "\n",
      "highest probability   0.3333333333333333\n",
      "\n",
      "he had   0.14285714285714285\n",
      "\n",
      "would contain   0.018867924528301886\n",
      "\n",
      "reduce acoustic   1.0\n",
      "\n",
      "EndWar and   1.0\n",
      "\n",
      "current text   0.14285714285714285\n",
      "\n",
      "due both   0.4\n",
      "\n",
      "been superseded   0.014705882352941176\n",
      "\n",
      "summarization in   0.04\n",
      "\n",
      "<s> Throughout   0.0007686395080707148\n",
      "\n",
      "Size Grows   1.0\n",
      "\n",
      "ten years   1.0\n",
      "\n",
      "of prisoner-of-war   0.00089126559714795\n",
      "\n",
      "heuristic final   0.3333333333333333\n",
      "\n",
      "hit you   1.0\n",
      "\n",
      "rather than   0.875\n",
      "\n",
      "mechanized sorting   1.0\n",
      "\n",
      "devices for   0.25\n",
      "\n",
      "differences It   0.3333333333333333\n",
      "\n",
      "gold standards   0.16666666666666666\n",
      "\n",
      ", Jonathan   0.0005614823133071309\n",
      "\n",
      "translate between   0.16666666666666666\n",
      "\n",
      "Multilingual -LRB-   1.0\n",
      "\n",
      "appear near   0.0625\n",
      "\n",
      "highly structured   0.1111111111111111\n",
      "\n",
      "This term   0.015873015873015872\n",
      "\n",
      "recognition :   0.01652892561983471\n",
      "\n",
      "probabilistic rules   0.14285714285714285\n",
      "\n",
      "In a   0.01904761904761905\n",
      "\n",
      "would require   0.05660377358490566\n",
      "\n",
      "documents at   0.02631578947368421\n",
      "\n",
      "Peru ,   0.5\n",
      "\n",
      "current QA   0.14285714285714285\n",
      "\n",
      "aircraft .   0.14285714285714285\n",
      "\n",
      "left and   0.3333333333333333\n",
      "\n",
      "rubric includes   1.0\n",
      "\n",
      "from Turney   0.009615384615384616\n",
      "\n",
      "ATN -RRB-   1.0\n",
      "\n",
      "other 10   0.014285714285714285\n",
      "\n",
      "an abstractive   0.015151515151515152\n",
      "\n",
      "Perhaps the   1.0\n",
      "\n",
      "answering methods   0.08333333333333333\n",
      "\n",
      "soon become   0.3333333333333333\n",
      "\n",
      "they require   0.05\n",
      "\n",
      "corpus -   0.03225806451612903\n",
      "\n",
      "stored more   1.0\n",
      "\n",
      "whole words   0.1111111111111111\n",
      "\n",
      "confusion with   1.0\n",
      "\n",
      "the summaries   0.002768166089965398\n",
      "\n",
      "credit card   1.0\n",
      "\n",
      "returning a   1.0\n",
      "\n",
      "of parser   0.0017825311942959\n",
      "\n",
      "1978 Kurzweil   0.3333333333333333\n",
      "\n",
      "All the   1.0\n",
      "\n",
      "mark was   0.3333333333333333\n",
      "\n",
      "right answer   0.1\n",
      "\n",
      "whole of   0.1111111111111111\n",
      "\n",
      "resulting graph   0.25\n",
      "\n",
      "in generating   0.0018726591760299626\n",
      "\n",
      "other punctuation   0.014285714285714285\n",
      "\n",
      "of information   0.004456327985739751\n",
      "\n",
      "would reduce   0.018867924528301886\n",
      "\n",
      "processing -LRB-   0.07407407407407407\n",
      "\n",
      "universities around   1.0\n",
      "\n",
      "can represent   0.011049723756906077\n",
      "\n",
      "syntactic ,   0.07692307692307693\n",
      "\n",
      "interaction The   0.125\n",
      "\n",
      "the Advanced   0.0006920415224913495\n",
      "\n",
      "Word-sense disambiguation   1.0\n",
      "\n",
      "into several   0.01282051282051282\n",
      "\n",
      "a preposition   0.001226993865030675\n",
      "\n",
      "doctors ,   0.3333333333333333\n",
      "\n",
      ", clean   0.0005614823133071309\n",
      "\n",
      "MEAD -RRB-   1.0\n",
      "\n",
      "as ME   0.003484320557491289\n",
      "\n",
      "stands for   1.0\n",
      "\n",
      "translation would   0.02702702702702703\n",
      "\n",
      "importance of   0.5\n",
      "\n",
      "Research into   0.125\n",
      "\n",
      "they rephrase   0.025\n",
      "\n",
      "the ones   0.001384083044982699\n",
      "\n",
      "language without   0.006756756756756757\n",
      "\n",
      "constructs -LRB-   0.3333333333333333\n",
      "\n",
      "action .   0.2\n",
      "\n",
      "after 2,000   0.08333333333333333\n",
      "\n",
      ", neutral   0.0005614823133071309\n",
      "\n",
      "-LRB- plural   0.0027100271002710027\n",
      "\n",
      "Although the   0.375\n",
      "\n",
      "the Baum-Welch   0.0006920415224913495\n",
      "\n",
      "rule induction   0.3333333333333333\n",
      "\n",
      "Their algorithm   0.5\n",
      "\n",
      "least one   0.2\n",
      "\n",
      "left ,   0.16666666666666666\n",
      "\n",
      "for translation   0.0036101083032490976\n",
      "\n",
      "and decelerations   0.001445086705202312\n",
      "\n",
      "the graph   0.004152249134948097\n",
      "\n",
      "to automatically   0.00796812749003984\n",
      "\n",
      "Spitzer 's   1.0\n",
      "\n",
      "Royal Aerospace   0.5\n",
      "\n",
      "pilot to   0.4\n",
      "\n",
      "To avoid   0.1111111111111111\n",
      "\n",
      "summaries .   0.13953488372093023\n",
      "\n",
      "entry has   0.25\n",
      "\n",
      "Bobrow 's   1.0\n",
      "\n",
      "the form   0.0006920415224913495\n",
      "\n",
      "Voice commands   0.2\n",
      "\n",
      "those concerning   0.045454545454545456\n",
      "\n",
      "speaking -RRB-   0.125\n",
      "\n",
      ", Stephen   0.0005614823133071309\n",
      "\n",
      "Descartes proposed   1.0\n",
      "\n",
      "Graph This   1.0\n",
      "\n",
      "to manipulate   0.0026560424966799467\n",
      "\n",
      "a sublanguage   0.001226993865030675\n",
      "\n",
      "scores are   0.2\n",
      "\n",
      "monetary value   1.0\n",
      "\n",
      "Major issues   0.5\n",
      "\n",
      "less complex   0.08333333333333333\n",
      "\n",
      "generic summaries   0.3333333333333333\n",
      "\n",
      "Project ,   1.0\n",
      "\n",
      ", TNO   0.0005614823133071309\n",
      "\n",
      "more readily   0.010526315789473684\n",
      "\n",
      "reference that   0.125\n",
      "\n",
      "estimation and   1.0\n",
      "\n",
      "trainee controller   1.0\n",
      "\n",
      "results may   0.047619047619047616\n",
      "\n",
      "Unsourced material   1.0\n",
      "\n",
      "insufficient .   1.0\n",
      "\n",
      "' pyramid   0.05263157894736842\n",
      "\n",
      "to have   0.013280212483399735\n",
      "\n",
      "wrote a   0.16666666666666666\n",
      "\n",
      "only real   0.02631578947368421\n",
      "\n",
      "or ''   0.0045045045045045045\n",
      "\n",
      "e.g. Known   0.017857142857142856\n",
      "\n",
      "to segment   0.00398406374501992\n",
      "\n",
      "walk is   0.2\n",
      "\n",
      "<s> Hidden   0.0023059185242121443\n",
      "\n",
      "performed ,   0.2\n",
      "\n",
      "<s> Context-free   0.0007686395080707148\n",
      "\n",
      "is also   0.02032520325203252\n",
      "\n",
      "NLP tasks   0.0425531914893617\n",
      "\n",
      "statistical analysis   0.030303030303030304\n",
      "\n",
      "words accidentally   0.009174311926605505\n",
      "\n",
      "processors or   1.0\n",
      "\n",
      "LL parsers   1.0\n",
      "\n",
      "-RRB- amongst   0.0027100271002710027\n",
      "\n",
      "How to   0.2857142857142857\n",
      "\n",
      "pass .   1.0\n",
      "\n",
      "also prefer   0.014492753623188406\n",
      "\n",
      ", Z   0.0005614823133071309\n",
      "\n",
      "1989 ?   0.5\n",
      "\n",
      "be digitalized   0.004219409282700422\n",
      "\n",
      "interfaces Symantec   0.5\n",
      "\n",
      "or XML   0.0045045045045045045\n",
      "\n",
      "world with   0.06666666666666667\n",
      "\n",
      "art .   0.5\n",
      "\n",
      "a translator   0.0036809815950920245\n",
      "\n",
      ", MySpace   0.0005614823133071309\n",
      "\n",
      "an EMR   0.007575757575757576\n",
      "\n",
      "impact of   0.5\n",
      "\n",
      "-RRB- Commissioned   0.0027100271002710027\n",
      "\n",
      "<s> Overview   0.0015372790161414297\n",
      "\n",
      "code readers   0.14285714285714285\n",
      "\n",
      "both to   0.12903225806451613\n",
      "\n",
      "of itself   0.00089126559714795\n",
      "\n",
      "compare automatic   0.14285714285714285\n",
      "\n",
      "play in   1.0\n",
      "\n",
      "machine that   0.012658227848101266\n",
      "\n",
      "scanner that   0.3333333333333333\n",
      "\n",
      "E. ,   0.25\n",
      "\n",
      "top-down expansion   0.25\n",
      "\n",
      "in all   0.0056179775280898875\n",
      "\n",
      "processing step   0.018518518518518517\n",
      "\n",
      "exclusively to   1.0\n",
      "\n",
      "to disambiguate   0.00398406374501992\n",
      "\n",
      "Part-of-Speech Tagset   1.0\n",
      "\n",
      "enough information   0.2\n",
      "\n",
      "POS-taggers ,   1.0\n",
      "\n",
      "LexRank The   0.08333333333333333\n",
      "\n",
      "symbols defined   0.3333333333333333\n",
      "\n",
      "generated text   0.13333333333333333\n",
      "\n",
      "of whole   0.0017825311942959\n",
      "\n",
      "processed with   0.3333333333333333\n",
      "\n",
      "learning the   0.023255813953488372\n",
      "\n",
      "-LRB- linguistics   0.005420054200542005\n",
      "\n",
      "and an   0.004335260115606936\n",
      "\n",
      "-LRB- probabilistic   0.0027100271002710027\n",
      "\n",
      "this work   0.01098901098901099\n",
      "\n",
      "them which   0.05263157894736842\n",
      "\n",
      "columns and   1.0\n",
      "\n",
      "of question   0.00267379679144385\n",
      "\n",
      "grammars that   0.07142857142857142\n",
      "\n",
      "new approaches   0.041666666666666664\n",
      "\n",
      "shown in   0.4\n",
      "\n",
      "-LRB- counselling   0.0027100271002710027\n",
      "\n",
      "In practice   0.009523809523809525\n",
      "\n",
      "all cases   0.023255813953488372\n",
      "\n",
      "about speech   0.05\n",
      "\n",
      "the given   0.001384083044982699\n",
      "\n",
      "to apply   0.0013280212483399733\n",
      "\n",
      "be moderate   0.004219409282700422\n",
      "\n",
      "printed text   0.25\n",
      "\n",
      "is affected   0.0020325203252032522\n",
      "\n",
      "multimedia documents   0.5\n",
      "\n",
      ", Speereo   0.0005614823133071309\n",
      "\n",
      "as OnlineOCR   0.003484320557491289\n",
      "\n",
      "ROUGE-1 -LRB-   0.2\n",
      "\n",
      "projection followed   1.0\n",
      "\n",
      "conflicting objectives   1.0\n",
      "\n",
      "since it   0.2\n",
      "\n",
      ", would   0.0016844469399213925\n",
      "\n",
      "decide that   0.25\n",
      "\n",
      "it affects   0.008547008547008548\n",
      "\n",
      "algorithms that   0.05714285714285714\n",
      "\n",
      "example of   0.08641975308641975\n",
      "\n",
      "personal computers   0.25\n",
      "\n",
      "causing it   1.0\n",
      "\n",
      "learning disabilities   0.023255813953488372\n",
      "\n",
      "Given enough   0.07142857142857142\n",
      "\n",
      "be analyzed   0.004219409282700422\n",
      "\n",
      "meanings according   0.25\n",
      "\n",
      "Management command   1.0\n",
      "\n",
      "translation Main   0.013513513513513514\n",
      "\n",
      "the rules   0.0034602076124567475\n",
      "\n",
      "Today there   1.0\n",
      "\n",
      "the Unix   0.001384083044982699\n",
      "\n",
      "'' all   0.005154639175257732\n",
      "\n",
      "text rather   0.006289308176100629\n",
      "\n",
      "suggest that   0.3333333333333333\n",
      "\n",
      "result of   0.2727272727272727\n",
      "\n",
      "This system   0.015873015873015872\n",
      "\n",
      "financial benefits   0.25\n",
      "\n",
      "require minimal   0.045454545454545456\n",
      "\n",
      "country .   0.5\n",
      "\n",
      "typically finds   0.05555555555555555\n",
      "\n",
      "on increasingly   0.0047169811320754715\n",
      "\n",
      "provide manually   0.16666666666666666\n",
      "\n",
      "inference algorithms   0.25\n",
      "\n",
      "discussions in   0.3333333333333333\n",
      "\n",
      "powerful grammars   1.0\n",
      "\n",
      "corpora in   0.09090909090909091\n",
      "\n",
      "than what   0.022222222222222223\n",
      "\n",
      "cockpit functions   0.5\n",
      "\n",
      "contains only   0.1\n",
      "\n",
      "algorithm .   0.14285714285714285\n",
      "\n",
      "worked ,   0.2\n",
      "\n",
      "fields such   0.16666666666666666\n",
      "\n",
      "<s> LR   0.0007686395080707148\n",
      "\n",
      "`` nine   0.005291005291005291\n",
      "\n",
      "<s> Methods   0.0023059185242121443\n",
      "\n",
      "<s> require   0.0007686395080707148\n",
      "\n",
      "categories -LRB-   0.1111111111111111\n",
      "\n",
      "from 10,000   0.009615384615384616\n",
      "\n",
      "in two   0.0018726591760299626\n",
      "\n",
      "on less   0.0047169811320754715\n",
      "\n",
      "very specific   0.024390243902439025\n",
      "\n",
      "desired answers   0.2\n",
      "\n",
      "<s> An   0.008455034588777863\n",
      "\n",
      "and domain   0.001445086705202312\n",
      "\n",
      "input data   0.14634146341463414\n",
      "\n",
      "in color   0.0018726591760299626\n",
      "\n",
      "indeed ,   0.3333333333333333\n",
      "\n",
      "a genetic   0.001226993865030675\n",
      "\n",
      "at IBM   0.014705882352941176\n",
      "\n",
      "by inputting   0.005714285714285714\n",
      "\n",
      "and relevant   0.001445086705202312\n",
      "\n",
      "real-valued vectors   0.3333333333333333\n",
      "\n",
      "Harris 's   0.2222222222222222\n",
      "\n",
      "ambiguous .   0.25\n",
      "\n",
      "Consultant -LRB-   1.0\n",
      "\n",
      "comprehensive theories   0.2\n",
      "\n",
      "eliminate the   0.5\n",
      "\n",
      "they join   0.025\n",
      "\n",
      "individual sentences   0.08333333333333333\n",
      "\n",
      "would fail   0.018867924528301886\n",
      "\n",
      "a pollen   0.001226993865030675\n",
      "\n",
      "a question   0.008588957055214725\n",
      "\n",
      "to protect   0.0013280212483399733\n",
      "\n",
      "as weights   0.003484320557491289\n",
      "\n",
      "least historically   0.2\n",
      "\n",
      "human judges   0.043478260869565216\n",
      "\n",
      "then chosen   0.02857142857142857\n",
      "\n",
      "domain-specific keyphrase   0.5\n",
      "\n",
      "speaker reads   0.05555555555555555\n",
      "\n",
      "; in   0.02127659574468085\n",
      "\n",
      "Alenia Aermacchi   1.0\n",
      "\n",
      "QA Before   0.047619047619047616\n",
      "\n",
      "the informational   0.0006920415224913495\n",
      "\n",
      "Many real   0.08333333333333333\n",
      "\n",
      "accuracy under   0.03225806451612903\n",
      "\n",
      "reported -LRB-   0.2\n",
      "\n",
      "and orthography   0.001445086705202312\n",
      "\n",
      "likelihood linear   0.6666666666666666\n",
      "\n",
      "questions .   0.07692307692307693\n",
      "\n",
      "an earlier   0.007575757575757576\n",
      "\n",
      "Royal Australian   0.5\n",
      "\n",
      "assumption ,   0.5\n",
      "\n",
      "Air Force   0.6666666666666666\n",
      "\n",
      "normal speech   0.5\n",
      "\n",
      "end abruptly   0.125\n",
      "\n",
      "document gives   0.027777777777777776\n",
      "\n",
      "with deep   0.00546448087431694\n",
      "\n",
      "<s> Deferred   0.0007686395080707148\n",
      "\n",
      "shows ,   1.0\n",
      "\n",
      "a task   0.0036809815950920245\n",
      "\n",
      "Prior implementations   1.0\n",
      "\n",
      "As with   0.05555555555555555\n",
      "\n",
      "MorphoChallenge Semi-supervised   1.0\n",
      "\n",
      "determine what   0.043478260869565216\n",
      "\n",
      "growing field   0.5\n",
      "\n",
      "meaningful way   0.125\n",
      "\n",
      "entities in   0.14285714285714285\n",
      "\n",
      "discourse turns   0.027777777777777776\n",
      "\n",
      "systems in   0.008928571428571428\n",
      "\n",
      "employed within   1.0\n",
      "\n",
      "but machines   0.014705882352941176\n",
      "\n",
      "sold his   0.3333333333333333\n",
      "\n",
      "of allowable   0.00089126559714795\n",
      "\n",
      "depth ''   0.3333333333333333\n",
      "\n",
      "repeated as   0.5\n",
      "\n",
      "major component   0.08333333333333333\n",
      "\n",
      "free beer   0.25\n",
      "\n",
      "must also   0.07142857142857142\n",
      "\n",
      "non-annotated data   1.0\n",
      "\n",
      "of users   0.0017825311942959\n",
      "\n",
      "whole word   0.1111111111111111\n",
      "\n",
      "in spirit   0.0018726591760299626\n",
      "\n",
      "being able   0.05555555555555555\n",
      "\n",
      "grammatical information   0.09090909090909091\n",
      "\n",
      "an article   0.015151515151515152\n",
      "\n",
      "entities ,   0.2857142857142857\n",
      "\n",
      ", list   0.0005614823133071309\n",
      "\n",
      "between words   0.05128205128205128\n",
      "\n",
      "learn such   0.07692307692307693\n",
      "\n",
      "have on   0.009615384615384616\n",
      "\n",
      "has 4   0.011904761904761904\n",
      "\n",
      "for gestures   0.0036101083032490976\n",
      "\n",
      "6 to   0.75\n",
      "\n",
      "are grounded   0.008298755186721992\n",
      "\n",
      "group of   0.5\n",
      "\n",
      "remains another   0.25\n",
      "\n",
      "particular words   0.07692307692307693\n",
      "\n",
      "includes transfer-based   0.14285714285714285\n",
      "\n",
      ", similarity   0.0005614823133071309\n",
      "\n",
      "-RRB- Video   0.0027100271002710027\n",
      "\n",
      "Profile templates   1.0\n",
      "\n",
      "dynamic study   0.2\n",
      "\n",
      "analysis system   0.015384615384615385\n",
      "\n",
      "aim is   0.5\n",
      "\n",
      "-RRB- a   0.005420054200542005\n",
      "\n",
      "1966 .   0.3333333333333333\n",
      "\n",
      "example by   0.024691358024691357\n",
      "\n",
      "US Army   0.14285714285714285\n",
      "\n",
      "pronoun ,   1.0\n",
      "\n",
      "Unix Consultant   0.5\n",
      "\n",
      "Language Generation   0.08333333333333333\n",
      "\n",
      "it does   0.008547008547008548\n",
      "\n",
      "in massive   0.0018726591760299626\n",
      "\n",
      "paper -RRB-   0.09090909090909091\n",
      "\n",
      "is distorted   0.0040650406504065045\n",
      "\n",
      "these heuristics   0.023809523809523808\n",
      "\n",
      "easier part   0.125\n",
      "\n",
      "and how   0.004335260115606936\n",
      "\n",
      "2004 -RRB-   0.3333333333333333\n",
      "\n",
      "a generated   0.001226993865030675\n",
      "\n",
      "subjectivity of   0.5\n",
      "\n",
      "align recorded   1.0\n",
      "\n",
      "with Tom   0.00546448087431694\n",
      "\n",
      "manually created   0.25\n",
      "\n",
      "use hidden   0.013888888888888888\n",
      "\n",
      "other types   0.014285714285714285\n",
      "\n",
      "commercial interest   0.09090909090909091\n",
      "\n",
      "Schank at   0.2\n",
      "\n",
      "NLP task   0.02127659574468085\n",
      "\n",
      "'s methods   0.0196078431372549\n",
      "\n",
      "the relevance   0.0006920415224913495\n",
      "\n",
      "profile captures   0.3333333333333333\n",
      "\n",
      "content that   0.08333333333333333\n",
      "\n",
      "frequently used   0.5\n",
      "\n",
      ", a   0.02695115103874228\n",
      "\n",
      "performance only   0.05555555555555555\n",
      "\n",
      "translating texts   0.25\n",
      "\n",
      "product reviews   0.14285714285714285\n",
      "\n",
      "semantics .   0.07142857142857142\n",
      "\n",
      "to separate   0.0013280212483399733\n",
      "\n",
      "Tags usually   1.0\n",
      "\n",
      "difficult than   0.10714285714285714\n",
      "\n",
      "be derived   0.008438818565400843\n",
      "\n",
      "put a   0.25\n",
      "\n",
      "left-to-right .   1.0\n",
      "\n",
      "effectiveness .   0.3333333333333333\n",
      "\n",
      "and Nelson   0.001445086705202312\n",
      "\n",
      "usually from   0.03125\n",
      "\n",
      "exploring the   1.0\n",
      "\n",
      "his work   0.08333333333333333\n",
      "\n",
      "general personal   0.045454545454545456\n",
      "\n",
      "using conventional   0.01694915254237288\n",
      "\n",
      "pick the   1.0\n",
      "\n",
      "is phonetically   0.0020325203252032522\n",
      "\n",
      "pars -LRB-   1.0\n",
      "\n",
      ", Politics   0.0005614823133071309\n",
      "\n",
      "analyzing the   0.2\n",
      "\n",
      "appear in   0.4375\n",
      "\n",
      "region in   1.0\n",
      "\n",
      ", audio   0.0011229646266142617\n",
      "\n",
      ", archiving   0.0005614823133071309\n",
      "\n",
      "with two   0.01092896174863388\n",
      "\n",
      "easier on   0.125\n",
      "\n",
      "operators need   1.0\n",
      "\n",
      "the relative   0.0006920415224913495\n",
      "\n",
      "inference algorithm   0.25\n",
      "\n",
      "in specific   0.003745318352059925\n",
      "\n",
      "Sentiment Analysis   0.16666666666666666\n",
      "\n",
      "special challenges   0.2\n",
      "\n",
      "a compiler   0.0036809815950920245\n",
      "\n",
      "pragmatics to   0.3333333333333333\n",
      "\n",
      "have helped   0.009615384615384616\n",
      "\n",
      "analog wave   0.5\n",
      "\n",
      "Extrinsic evaluations   0.5\n",
      "\n",
      "sublanguage of   0.3333333333333333\n",
      "\n",
      "the screen   0.0006920415224913495\n",
      "\n",
      "-LRB- role   0.0027100271002710027\n",
      "\n",
      "evaluation ,   0.05555555555555555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "warnings from   1.0\n",
      "\n",
      ", words   0.0011229646266142617\n",
      "\n",
      "classification looks   0.058823529411764705\n",
      "\n",
      "co-occurring neighbors   1.0\n",
      "\n",
      "that match   0.0035460992907801418\n",
      "\n",
      "WYSIWYM framework   1.0\n",
      "\n",
      "To upgrade   0.1111111111111111\n",
      "\n",
      "1928 the   1.0\n",
      "\n",
      "and eigenvector   0.001445086705202312\n",
      "\n",
      "like Page\\/Lex\\/TextRank   0.03571428571428571\n",
      "\n",
      "techniques on   0.043478260869565216\n",
      "\n",
      "Canada .   0.16666666666666666\n",
      "\n",
      "; An   0.02127659574468085\n",
      "\n",
      "of incorrect   0.00089126559714795\n",
      "\n",
      "the approximate   0.0006920415224913495\n",
      "\n",
      "evaluation In   0.018518518518518517\n",
      "\n",
      "coefficients and   0.25\n",
      "\n",
      "very much   0.024390243902439025\n",
      "\n",
      "gestures in   0.5\n",
      "\n",
      "discouraged the   1.0\n",
      "\n",
      "translated in   0.25\n",
      "\n",
      "as if   0.003484320557491289\n",
      "\n",
      "just a   0.2222222222222222\n",
      "\n",
      "User profiling   0.5\n",
      "\n",
      ", Inc.   0.0011229646266142617\n",
      "\n",
      "the introduction   0.0006920415224913495\n",
      "\n",
      "used similar   0.008849557522123894\n",
      "\n",
      "and Command   0.001445086705202312\n",
      "\n",
      "lists that   1.0\n",
      "\n",
      "ISO standards   0.5\n",
      "\n",
      "themselves as   0.25\n",
      "\n",
      "-LRB- Speereo   0.0027100271002710027\n",
      "\n",
      "but the   0.04411764705882353\n",
      "\n",
      "contents of   1.0\n",
      "\n",
      "an abbreviation   0.007575757575757576\n",
      "\n",
      "there are   0.375\n",
      "\n",
      "the surrounding   0.001384083044982699\n",
      "\n",
      "parse reranking   0.1111111111111111\n",
      "\n",
      "surprising popularity   1.0\n",
      "\n",
      "six -LRB-   0.5\n",
      "\n",
      "<s> Another   0.009992313604919293\n",
      "\n",
      "Nikolas Rose   1.0\n",
      "\n",
      "A simplified   0.02\n",
      "\n",
      "most natural   0.034482758620689655\n",
      "\n",
      "extraction Task   0.03225806451612903\n",
      "\n",
      "Higher rates   1.0\n",
      "\n",
      "features in   0.038461538461538464\n",
      "\n",
      "speech full   0.006578947368421052\n",
      "\n",
      "approach has   0.02857142857142857\n",
      "\n",
      "passages to   0.5\n",
      "\n",
      "Evaluation As   0.1111111111111111\n",
      "\n",
      "various optimization   0.05555555555555555\n",
      "\n",
      "order ,   0.14285714285714285\n",
      "\n",
      "screen of   1.0\n",
      "\n",
      "As access   0.05555555555555555\n",
      "\n",
      "human assessments   0.021739130434782608\n",
      "\n",
      "Teun A.   1.0\n",
      "\n",
      "phrases are   0.0625\n",
      "\n",
      "of spoken   0.0017825311942959\n",
      "\n",
      ": Determine   0.00980392156862745\n",
      "\n",
      "some states   0.012048192771084338\n",
      "\n",
      "using unweighted   0.01694915254237288\n",
      "\n",
      "door being   0.25\n",
      "\n",
      "new part   0.041666666666666664\n",
      "\n",
      "Approaches One   0.3333333333333333\n",
      "\n",
      "weights to   0.4\n",
      "\n",
      "path ,   0.5\n",
      "\n",
      "creating an   0.2857142857142857\n",
      "\n",
      "informatics .   1.0\n",
      "\n",
      "approaches Supervised   0.03571428571428571\n",
      "\n",
      "even in   0.07407407407407407\n",
      "\n",
      "which research   0.007246376811594203\n",
      "\n",
      "nodes to   0.14285714285714285\n",
      "\n",
      "in Canada   0.0018726591760299626\n",
      "\n",
      "linguists would   0.3333333333333333\n",
      "\n",
      "digitalized :   1.0\n",
      "\n",
      "power ,   0.25\n",
      "\n",
      "isolation .   0.5\n",
      "\n",
      "of other   0.0035650623885918\n",
      "\n",
      "continuous speech   0.5\n",
      "\n",
      "test environment   0.1\n",
      "\n",
      "guessed at   1.0\n",
      "\n",
      "language-processing tasks   1.0\n",
      "\n",
      "The Future   0.005208333333333333\n",
      "\n",
      "in computers   0.0018726591760299626\n",
      "\n",
      "Shepard 's   0.3333333333333333\n",
      "\n",
      "these same   0.023809523809523808\n",
      "\n",
      "<s> Real   0.0015372790161414297\n",
      "\n",
      "distinction with   0.2\n",
      "\n",
      "More detailed   0.1111111111111111\n",
      "\n",
      "single document   0.07142857142857142\n",
      "\n",
      "contractions like   0.5\n",
      "\n",
      "availability of   1.0\n",
      "\n",
      "chunk of   1.0\n",
      "\n",
      ", using   0.005614823133071308\n",
      "\n",
      "now common   0.07692307692307693\n",
      "\n",
      "the coherence   0.0006920415224913495\n",
      "\n",
      "adjust\\/correct the   1.0\n",
      "\n",
      "fighter trainer   0.16666666666666666\n",
      "\n",
      "rank unigrams   0.16666666666666666\n",
      "\n",
      "-LRB- SWER   0.0027100271002710027\n",
      "\n",
      "if it   0.07142857142857142\n",
      "\n",
      "be ``   0.004219409282700422\n",
      "\n",
      "as vertices   0.003484320557491289\n",
      "\n",
      "An intrinsic   0.125\n",
      "\n",
      "scores significantly   0.2\n",
      "\n",
      "translation simultaneously   0.013513513513513514\n",
      "\n",
      "be electronically   0.004219409282700422\n",
      "\n",
      "order to   0.5714285714285714\n",
      "\n",
      "named Interspeech   0.14285714285714285\n",
      "\n",
      "smaller dictionary   0.14285714285714285\n",
      "\n",
      "on Mirage   0.0047169811320754715\n",
      "\n",
      "typical to   0.1111111111111111\n",
      "\n",
      "Another possible   0.07692307692307693\n",
      "\n",
      "networks has   0.07142857142857142\n",
      "\n",
      "<s> High-order   0.0007686395080707148\n",
      "\n",
      "room acoustics   1.0\n",
      "\n",
      "probability of   0.14285714285714285\n",
      "\n",
      "an interactive   0.007575757575757576\n",
      "\n",
      "and by   0.001445086705202312\n",
      "\n",
      "granted a   1.0\n",
      "\n",
      "parsers will   0.15384615384615385\n",
      "\n",
      "While supervised   0.2\n",
      "\n",
      "and Lifeline   0.001445086705202312\n",
      "\n",
      "even with   0.037037037037037035\n",
      "\n",
      "the features   0.0034602076124567475\n",
      "\n",
      "funding to   0.125\n",
      "\n",
      "trade speed   0.5\n",
      "\n",
      "be parsed   0.004219409282700422\n",
      "\n",
      "very simple   0.04878048780487805\n",
      "\n",
      "of the   0.17379679144385027\n",
      "\n",
      "compensate for   1.0\n",
      "\n",
      "→ dogs   0.3333333333333333\n",
      "\n",
      "In 1950   0.01904761904761905\n",
      "\n",
      "In other   0.01904761904761905\n",
      "\n",
      "is rarely   0.0020325203252032522\n",
      "\n",
      "Unsupervised taggers   0.16666666666666666\n",
      "\n",
      "in vastly   0.0018726591760299626\n",
      "\n",
      "reported accuracy   0.2\n",
      "\n",
      "error types   0.08333333333333333\n",
      "\n",
      "; Each   0.02127659574468085\n",
      "\n",
      "only in   0.05263157894736842\n",
      "\n",
      "where phrases   0.02857142857142857\n",
      "\n",
      "spun it   1.0\n",
      "\n",
      "and determining   0.001445086705202312\n",
      "\n",
      "for accuracy   0.0036101083032490976\n",
      "\n",
      "closed-captioning of   1.0\n",
      "\n",
      "unsupervised ``   0.125\n",
      "\n",
      "techniques to   0.17391304347826086\n",
      "\n",
      "it might   0.008547008547008548\n",
      "\n",
      "the key   0.0006920415224913495\n",
      "\n",
      "College -LRB-   0.5\n",
      "\n",
      "to locate   0.0013280212483399733\n",
      "\n",
      "statistical engine   0.030303030303030304\n",
      "\n",
      "information .   0.08695652173913043\n",
      "\n",
      "OS .   0.5\n",
      "\n",
      "rescoring -RRB-   1.0\n",
      "\n",
      "selects important   0.5\n",
      "\n",
      "`` classification   0.015873015873015872\n",
      "\n",
      "especially useful   0.06666666666666667\n",
      "\n",
      "been developed   0.014705882352941176\n",
      "\n",
      "data was   0.012987012987012988\n",
      "\n",
      "We assume   0.14285714285714285\n",
      "\n",
      "been learned   0.029411764705882353\n",
      "\n",
      "that read   0.0035460992907801418\n",
      "\n",
      ": Word   0.00980392156862745\n",
      "\n",
      "that minimizes   0.0070921985815602835\n",
      "\n",
      "the broadcast   0.0006920415224913495\n",
      "\n",
      "increasing G-loads   0.3333333333333333\n",
      "\n",
      "is 2,000   0.0020325203252032522\n",
      "\n",
      "are confusable   0.004149377593360996\n",
      "\n",
      "training and   0.03571428571428571\n",
      "\n",
      "Significant advances   1.0\n",
      "\n",
      "since 1965   0.1\n",
      "\n",
      "using all   0.01694915254237288\n",
      "\n",
      "the management   0.0006920415224913495\n",
      "\n",
      "sometimes open-ended   0.07692307692307693\n",
      "\n",
      "ELIZA worked   0.1111111111111111\n",
      "\n",
      "documents generally   0.02631578947368421\n",
      "\n",
      ", resolve   0.0005614823133071309\n",
      "\n",
      "picture distortion   0.25\n",
      "\n",
      ", such   0.019651880965749578\n",
      "\n",
      "keep a   0.3333333333333333\n",
      "\n",
      "reading machine   0.125\n",
      "\n",
      "different issue   0.02040816326530612\n",
      "\n",
      "a pre-processing   0.001226993865030675\n",
      "\n",
      "distorted by   0.5\n",
      "\n",
      "correct answer   0.06666666666666667\n",
      "\n",
      "lead to   1.0\n",
      "\n",
      "incorrect ones   0.3333333333333333\n",
      "\n",
      "man-hours worked   1.0\n",
      "\n",
      "system for   0.021505376344086023\n",
      "\n",
      "-RRB- provides   0.0027100271002710027\n",
      "\n",
      "current research   0.14285714285714285\n",
      "\n",
      "recent years   0.5\n",
      "\n",
      "know is   0.5\n",
      "\n",
      "limited type   0.1\n",
      "\n",
      "step is   0.06666666666666667\n",
      "\n",
      "sound clip   0.1\n",
      "\n",
      "is prone   0.0020325203252032522\n",
      "\n",
      "of any   0.00267379679144385\n",
      "\n",
      "classifier for   0.14285714285714285\n",
      "\n",
      ", understanding   0.0005614823133071309\n",
      "\n",
      "VTLN -RRB-   1.0\n",
      "\n",
      "include the   0.18518518518518517\n",
      "\n",
      "7 distinct   0.14285714285714285\n",
      "\n",
      "are ``   0.004149377593360996\n",
      "\n",
      "Ray Kurzweil   1.0\n",
      "\n",
      "deep understanding   0.2857142857142857\n",
      "\n",
      "Moore 's   1.0\n",
      "\n",
      "the high   0.001384083044982699\n",
      "\n",
      "public opinion   1.0\n",
      "\n",
      "is non-trivial   0.0020325203252032522\n",
      "\n",
      "is dependency   0.0020325203252032522\n",
      "\n",
      "the theoretical   0.0006920415224913495\n",
      "\n",
      "parts of   1.0\n",
      "\n",
      "an hour   0.007575757575757576\n",
      "\n",
      "air traffic   0.6\n",
      "\n",
      "lines segments   0.3333333333333333\n",
      "\n",
      "been done   0.029411764705882353\n",
      "\n",
      "polarity helped   0.125\n",
      "\n",
      "map to   0.5\n",
      "\n",
      "can then   0.0055248618784530384\n",
      "\n",
      "a collect   0.001226993865030675\n",
      "\n",
      "part-of-speech assignment   0.06666666666666667\n",
      "\n",
      "and ATIS   0.001445086705202312\n",
      "\n",
      "use or   0.027777777777777776\n",
      "\n",
      "Harris beginning   0.1111111111111111\n",
      "\n",
      "left-most derivations   0.5\n",
      "\n",
      "machine-learning algorithms   0.25\n",
      "\n",
      "simultaneously meets   0.5\n",
      "\n",
      ", speech-to-text   0.0005614823133071309\n",
      "\n",
      "which may   0.007246376811594203\n",
      "\n",
      "on-line ,   0.3333333333333333\n",
      "\n",
      "The management   0.005208333333333333\n",
      "\n",
      "Linguistics defines   0.3333333333333333\n",
      "\n",
      "to and   0.0013280212483399733\n",
      "\n",
      "group at   0.25\n",
      "\n",
      "memorandum ``   1.0\n",
      "\n",
      "Dependence vs.   1.0\n",
      "\n",
      "In 1629   0.009523809523809525\n",
      "\n",
      "and\\/or aural   0.3333333333333333\n",
      "\n",
      "translation has   0.02702702702702703\n",
      "\n",
      "a period   0.00245398773006135\n",
      "\n",
      ", Harrison   0.0005614823133071309\n",
      "\n",
      "differences in   0.3333333333333333\n",
      "\n",
      ", plural   0.0005614823133071309\n",
      "\n",
      "Evaluating summaries   1.0\n",
      "\n",
      "In some   0.0380952380952381\n",
      "\n",
      "results for   0.047619047619047616\n",
      "\n",
      "Challenges shared-task   1.0\n",
      "\n",
      "classifying a   0.4\n",
      "\n",
      "exactly this   0.3333333333333333\n",
      "\n",
      "<s> Stages   0.0007686395080707148\n",
      "\n",
      "Some tag   0.047619047619047616\n",
      "\n",
      "identities of   1.0\n",
      "\n",
      "unexpected features   1.0\n",
      "\n",
      "the fields   0.0006920415224913495\n",
      "\n",
      "weights .   0.4\n",
      "\n",
      "software has   0.037037037037037035\n",
      "\n",
      "language understanding   0.0945945945945946\n",
      "\n",
      "The Duchess   0.005208333333333333\n",
      "\n",
      "efficient manner   0.3333333333333333\n",
      "\n",
      "syntactic and   0.15384615384615385\n",
      "\n",
      "meaning in   0.08695652173913043\n",
      "\n",
      "information that   0.021739130434782608\n",
      "\n",
      "relief is   1.0\n",
      "\n",
      "-LRB- stationary   0.0027100271002710027\n",
      "\n",
      "include stages   0.037037037037037035\n",
      "\n",
      "sentences for   0.013157894736842105\n",
      "\n",
      "<s> Evaluating   0.0015372790161414297\n",
      "\n",
      "goal is   0.42857142857142855\n",
      "\n",
      "In recent   0.01904761904761905\n",
      "\n",
      "other automatic   0.014285714285714285\n",
      "\n",
      "representation ,   0.15789473684210525\n",
      "\n",
      "systems must   0.008928571428571428\n",
      "\n",
      "languages semantics   0.02\n",
      "\n",
      "compared -   0.14285714285714285\n",
      "\n",
      "the noun   0.0006920415224913495\n",
      "\n",
      "Brain has   1.0\n",
      "\n",
      "large quantities   0.08695652173913043\n",
      "\n",
      "never be   0.4\n",
      "\n",
      "covers the   0.5\n",
      "\n",
      "language documents   0.006756756756756757\n",
      "\n",
      "is leading   0.0020325203252032522\n",
      "\n",
      "Use ''   0.5\n",
      "\n",
      "non-Western scripts   1.0\n",
      "\n",
      "identified in   0.2\n",
      "\n",
      ", determine   0.003368893879842785\n",
      "\n",
      "ranking over   0.14285714285714285\n",
      "\n",
      "very deep   0.024390243902439025\n",
      "\n",
      "computer in   0.045454545454545456\n",
      "\n",
      "processing in   0.037037037037037035\n",
      "\n",
      "heuristics with   0.5\n",
      "\n",
      "translating .   0.25\n",
      "\n",
      "a commercial   0.00245398773006135\n",
      "\n",
      ", opens   0.0005614823133071309\n",
      "\n",
      "be broken   0.004219409282700422\n",
      "\n",
      "others have   0.08333333333333333\n",
      "\n",
      "clues in   0.3333333333333333\n",
      "\n",
      "capabilities and   0.2\n",
      "\n",
      "limits -LRB-   1.0\n",
      "\n",
      "name must   0.2\n",
      "\n",
      "that dispense   0.0035460992907801418\n",
      "\n",
      "Canada are   0.16666666666666666\n",
      "\n",
      "state computers   0.07142857142857142\n",
      "\n",
      "other research   0.014285714285714285\n",
      "\n",
      "fancy statistics   1.0\n",
      "\n",
      ", Brenton   0.0005614823133071309\n",
      "\n",
      "role the   0.25\n",
      "\n",
      "the mechanical   0.0006920415224913495\n",
      "\n",
      ", 1976   0.0011229646266142617\n",
      "\n",
      "heavy-noise ,   1.0\n",
      "\n",
      "first stage   0.030303030303030304\n",
      "\n",
      "radiology report   1.0\n",
      "\n",
      "cases and   0.05555555555555555\n",
      "\n",
      "data about   0.012987012987012988\n",
      "\n",
      "is digital   0.0020325203252032522\n",
      "\n",
      "typically include   0.05555555555555555\n",
      "\n",
      "linguistic and   0.0625\n",
      "\n",
      "book Language   0.125\n",
      "\n",
      "algorithms optimized   0.02857142857142857\n",
      "\n",
      "paper-intensive industry   1.0\n",
      "\n",
      "Pallet 1998   0.5\n",
      "\n",
      "have used   0.019230769230769232\n",
      "\n",
      ", psycholinguistics   0.0005614823133071309\n",
      "\n",
      "larger collection   0.0625\n",
      "\n",
      "in spite   0.0018726591760299626\n",
      "\n",
      "sentiment with   0.04\n",
      "\n",
      "prune away   1.0\n",
      "\n",
      "had a   0.2857142857142857\n",
      "\n",
      "return ?   0.5\n",
      "\n",
      "An ongoing   0.0625\n",
      "\n",
      ", Alessandro   0.0005614823133071309\n",
      "\n",
      "usually operate   0.03125\n",
      "\n",
      "-RRB- applications   0.0027100271002710027\n",
      "\n",
      "another -RRB-   0.07692307692307693\n",
      "\n",
      "an active   0.007575757575757576\n",
      "\n",
      "require significant   0.045454545454545456\n",
      "\n",
      "quantitatively comparing   1.0\n",
      "\n",
      "simply do   0.08333333333333333\n",
      "\n",
      "are marked   0.004149377593360996\n",
      "\n",
      "include a   0.1111111111111111\n",
      "\n",
      "marketing .   1.0\n",
      "\n",
      "using votes   0.01694915254237288\n",
      "\n",
      "`` in   0.010582010582010581\n",
      "\n",
      "interpret and   1.0\n",
      "\n",
      "an open   0.015151515151515152\n",
      "\n",
      "prefer the   0.5\n",
      "\n",
      "in-depth analysis   0.3333333333333333\n",
      "\n",
      "easily copied   0.1111111111111111\n",
      "\n",
      "the fact   0.002768166089965398\n",
      "\n",
      "answer extraction   0.06666666666666667\n",
      "\n",
      "a kind   0.001226993865030675\n",
      "\n",
      "was hoping   0.012987012987012988\n",
      "\n",
      "detection and   0.5\n",
      "\n",
      "overall speech   0.16666666666666666\n",
      "\n",
      "discuss the   1.0\n",
      "\n",
      "what a   0.09375\n",
      "\n",
      ", as   0.01291409320606401\n",
      "\n",
      "done by   0.18181818181818182\n",
      "\n",
      "others can   0.08333333333333333\n",
      "\n",
      "not seen   0.008928571428571428\n",
      "\n",
      "of Energy   0.00089126559714795\n",
      "\n",
      "a top-down   0.001226993865030675\n",
      "\n",
      "`` barmaid   0.010582010582010581\n",
      "\n",
      "aids for   1.0\n",
      "\n",
      "Nearest-neighbor have   1.0\n",
      "\n",
      "context and   0.12121212121212122\n",
      "\n",
      "of selecting   0.00089126559714795\n",
      "\n",
      "source can   0.041666666666666664\n",
      "\n",
      "rich languages   0.2\n",
      "\n",
      "Granada Pallet   0.5\n",
      "\n",
      "site .   1.0\n",
      "\n",
      "semantics without   0.07142857142857142\n",
      "\n",
      "verbalization .   1.0\n",
      "\n",
      "techniques .   0.043478260869565216\n",
      "\n",
      "popular strategy   0.1111111111111111\n",
      "\n",
      "compiled newswire   1.0\n",
      "\n",
      "processing .   0.12962962962962962\n",
      "\n",
      "implemented in   0.2\n",
      "\n",
      "Wallace Chafe   1.0\n",
      "\n",
      "run each   0.2\n",
      "\n",
      "using machine   0.01694915254237288\n",
      "\n",
      "fusion techniques   1.0\n",
      "\n",
      "some sort   0.012048192771084338\n",
      "\n",
      "Server OCR   1.0\n",
      "\n",
      "World Wide   0.5714285714285714\n",
      "\n",
      "the following   0.004844290657439446\n",
      "\n",
      "4 star   0.2\n",
      "\n",
      "us to   0.5\n",
      "\n",
      "to 150   0.0013280212483399733\n",
      "\n",
      "at Stanford   0.014705882352941176\n",
      "\n",
      "vertices should   0.1111111111111111\n",
      "\n",
      "those organised   0.045454545454545456\n",
      "\n",
      "area are   0.09090909090909091\n",
      "\n",
      "Flickinger D.   1.0\n",
      "\n",
      "are directly   0.004149377593360996\n",
      "\n",
      "rules for   0.046511627906976744\n",
      "\n",
      "find only   0.07692307692307693\n",
      "\n",
      "characters rather   0.0625\n",
      "\n",
      "to run   0.0013280212483399733\n",
      "\n",
      "replicated his   1.0\n",
      "\n",
      "extrinsic evaluation   0.5\n",
      "\n",
      "data-to-text systems   1.0\n",
      "\n",
      "PC can   0.25\n",
      "\n",
      "of DA   0.00089126559714795\n",
      "\n",
      "this reason   0.02197802197802198\n",
      "\n",
      "rewrite it   1.0\n",
      "\n",
      "basic sub-signals   0.07692307692307693\n",
      "\n",
      "counselling -RRB-   1.0\n",
      "\n",
      "this way   0.02197802197802198\n",
      "\n",
      "1998 Language   0.25\n",
      "\n",
      "same way   0.04\n",
      "\n",
      "Introduction and   1.0\n",
      "\n",
      "from its   0.009615384615384616\n",
      "\n",
      "display for   0.5\n",
      "\n",
      "ranking task   0.14285714285714285\n",
      "\n",
      "A problem   0.02\n",
      "\n",
      "to think   0.0013280212483399733\n",
      "\n",
      "is search   0.0020325203252032522\n",
      "\n",
      "heuristic post-processing   0.3333333333333333\n",
      "\n",
      "Many documents   0.08333333333333333\n",
      "\n",
      "Harris had   0.1111111111111111\n",
      "\n",
      "was painstakingly   0.012987012987012988\n",
      "\n",
      "or program   0.0045045045045045045\n",
      "\n",
      "Another popular   0.07692307692307693\n",
      "\n",
      "about specific   0.025\n",
      "\n",
      "J. ,   0.6666666666666666\n",
      "\n",
      "of small   0.00089126559714795\n",
      "\n",
      "with n   0.00546448087431694\n",
      "\n",
      "transfer-based ,   0.3333333333333333\n",
      "\n",
      "animation ,   1.0\n",
      "\n",
      "and generate   0.001445086705202312\n",
      "\n",
      "a degree   0.001226993865030675\n",
      "\n",
      "this step   0.01098901098901099\n",
      "\n",
      "which can   0.036231884057971016\n",
      "\n",
      "<s> Grammatical   0.0007686395080707148\n",
      "\n",
      "propositions ,   1.0\n",
      "\n",
      "ELIZA .   0.1111111111111111\n",
      "\n",
      "-RRB- vibration   0.0027100271002710027\n",
      "\n",
      "n't vice   0.25\n",
      "\n",
      "character recognition   0.5\n",
      "\n",
      "issue on   0.125\n",
      "\n",
      "is less   0.0020325203252032522\n",
      "\n",
      "contrastive analysis   1.0\n",
      "\n",
      "translation can   0.02702702702702703\n",
      "\n",
      "Faber ,   1.0\n",
      "\n",
      "get ranked   0.14285714285714285\n",
      "\n",
      "basic OCR   0.07692307692307693\n",
      "\n",
      "of filtering   0.00089126559714795\n",
      "\n",
      "is responsible   0.0020325203252032522\n",
      "\n",
      "to fine   0.0013280212483399733\n",
      "\n",
      "was walking   0.012987012987012988\n",
      "\n",
      "in part   0.0018726591760299626\n",
      "\n",
      "a skilled   0.001226993865030675\n",
      "\n",
      "substantial resources   0.2\n",
      "\n",
      "have keyphrases   0.019230769230769232\n",
      "\n",
      "sent in   1.0\n",
      "\n",
      "reader -RRB-   0.1\n",
      "\n",
      "expertise ,   1.0\n",
      "\n",
      ", setting   0.0011229646266142617\n",
      "\n",
      "see is   0.05\n",
      "\n",
      "Law and   1.0\n",
      "\n",
      "research teams   0.023809523809523808\n",
      "\n",
      "-LRB- 1954   0.0027100271002710027\n",
      "\n",
      "been closely   0.014705882352941176\n",
      "\n",
      "Compare speech   1.0\n",
      "\n",
      "contained in   1.0\n",
      "\n",
      "a referring   0.001226993865030675\n",
      "\n",
      "distribution of   0.25\n",
      "\n",
      "small range   0.1111111111111111\n",
      "\n",
      "paper-to-computer text   1.0\n",
      "\n",
      "only way   0.02631578947368421\n",
      "\n",
      "of Eastern   0.00089126559714795\n",
      "\n",
      "standards .   0.4\n",
      "\n",
      "as some   0.003484320557491289\n",
      "\n",
      "single sentence   0.07142857142857142\n",
      "\n",
      "Aggregation :   1.0\n",
      "\n",
      "sources for   0.16666666666666666\n",
      "\n",
      "the latter   0.0006920415224913495\n",
      "\n",
      "particular ,   0.23076923076923078\n",
      "\n",
      "-RRB- the   0.0027100271002710027\n",
      "\n",
      "and persuasion   0.001445086705202312\n",
      "\n",
      "naive semantics   0.5\n",
      "\n",
      "depth of   0.3333333333333333\n",
      "\n",
      "Schroeder ,   1.0\n",
      "\n",
      "a person\\/persons   0.001226993865030675\n",
      "\n",
      "possible .   0.125\n",
      "\n",
      "thesis at   1.0\n",
      "\n",
      "East Asian   1.0\n",
      "\n",
      "others .   0.25\n",
      "\n",
      "the inter-texual   0.0006920415224913495\n",
      "\n",
      "domain or   0.05\n",
      "\n",
      "for sentence   0.0036101083032490976\n",
      "\n",
      "'s methodology   0.0196078431372549\n",
      "\n",
      "processing group   0.018518518518518517\n",
      "\n",
      "engine ,   0.16666666666666666\n",
      "\n",
      "using shallow   0.01694915254237288\n",
      "\n",
      "language ,   0.04054054054054054\n",
      "\n",
      "on large   0.0047169811320754715\n",
      "\n",
      "-RRB- Some   0.0027100271002710027\n",
      "\n",
      "cognitive operation   0.5\n",
      "\n",
      "-LRB- including   0.0027100271002710027\n",
      "\n",
      "a Fourier   0.001226993865030675\n",
      "\n",
      "likely to   0.4375\n",
      "\n",
      "accordance with   1.0\n",
      "\n",
      "extractive approach   0.14285714285714285\n",
      "\n",
      "that corresponded   0.0035460992907801418\n",
      "\n",
      "Santorini gives   1.0\n",
      "\n",
      "been shown   0.014705882352941176\n",
      "\n",
      "ATIS .   1.0\n",
      "\n",
      "In particular   0.02857142857142857\n",
      "\n",
      "learning -RRB-   0.023255813953488372\n",
      "\n",
      "a native   0.00245398773006135\n",
      "\n",
      "but weaker   0.014705882352941176\n",
      "\n",
      "of knowledge   0.0017825311942959\n",
      "\n",
      "avoids overfitting   1.0\n",
      "\n",
      "probably use   0.25\n",
      "\n",
      "supervised methods   0.125\n",
      "\n",
      "classes :   0.2\n",
      "\n",
      "correct summary   0.06666666666666667\n",
      "\n",
      "similarity score   0.1\n",
      "\n",
      "On what   0.16666666666666666\n",
      "\n",
      "answer reuse   0.03333333333333333\n",
      "\n",
      "humans when   0.08333333333333333\n",
      "\n",
      "language question-answering   0.006756756756756757\n",
      "\n",
      "umbrella term   1.0\n",
      "\n",
      "17 ambiguous   1.0\n",
      "\n",
      "from United   0.009615384615384616\n",
      "\n",
      "is generated   0.006097560975609756\n",
      "\n",
      "is broad   0.0020325203252032522\n",
      "\n",
      "the undercarriage   0.0006920415224913495\n",
      "\n",
      "that characterize   0.0035460992907801418\n",
      "\n",
      ", linguistic   0.0005614823133071309\n",
      "\n",
      "these environments   0.023809523809523808\n",
      "\n",
      "the food   0.0006920415224913495\n",
      "\n",
      "critical new   0.25\n",
      "\n",
      "character -RRB-   0.045454545454545456\n",
      "\n",
      "their answers   0.029411764705882353\n",
      "\n",
      "SYSTRAN for   1.0\n",
      "\n",
      "`` open   0.005291005291005291\n",
      "\n",
      "including mobile   0.07142857142857142\n",
      "\n",
      "are MARGIE   0.004149377593360996\n",
      "\n",
      "the microphone   0.0006920415224913495\n",
      "\n",
      "human speakers   0.021739130434782608\n",
      "\n",
      "limitation in   1.0\n",
      "\n",
      "two meanings   0.034482758620689655\n",
      "\n",
      "edge cases   0.3333333333333333\n",
      "\n",
      "machine-encoded text   1.0\n",
      "\n",
      "might vary   0.038461538461538464\n",
      "\n",
      "the extraction   0.002768166089965398\n",
      "\n",
      "intuitive sense   1.0\n",
      "\n",
      "be resolved   0.004219409282700422\n",
      "\n",
      "book -LRB-   0.25\n",
      "\n",
      "comprehension ,   0.14285714285714285\n",
      "\n",
      "be run   0.004219409282700422\n",
      "\n",
      "EUROPARL ,   1.0\n",
      "\n",
      "a way   0.006134969325153374\n",
      "\n",
      "we are   0.044444444444444446\n",
      "\n",
      "at level   0.014705882352941176\n",
      "\n",
      "to tag   0.0013280212483399733\n",
      "\n",
      "databases .   0.5\n",
      "\n",
      "to ignore   0.0013280212483399733\n",
      "\n",
      "specific strengths   0.047619047619047616\n",
      "\n",
      "with applications   0.00546448087431694\n",
      "\n",
      "structured documents   0.16666666666666666\n",
      "\n",
      "a keyboard   0.001226993865030675\n",
      "\n",
      "constraint ,   1.0\n",
      "\n",
      "bridging relationship   1.0\n",
      "\n",
      "syntactic .   0.07692307692307693\n",
      "\n",
      "or adjective   0.0045045045045045045\n",
      "\n",
      "now the   0.07692307692307693\n",
      "\n",
      "those running   0.045454545454545456\n",
      "\n",
      "from spelling   0.009615384615384616\n",
      "\n",
      "we use   0.022222222222222223\n",
      "\n",
      "ROUGE-1 scores   0.2\n",
      "\n",
      "normalization -LRB-   0.16666666666666666\n",
      "\n",
      "by both   0.005714285714285714\n",
      "\n",
      "other scientific   0.014285714285714285\n",
      "\n",
      "the shift-reduce   0.0006920415224913495\n",
      "\n",
      "captioning ,   1.0\n",
      "\n",
      "will cover   0.02857142857142857\n",
      "\n",
      "`` good   0.005291005291005291\n",
      "\n",
      "parsing or   0.07142857142857142\n",
      "\n",
      "Afghanistan or   1.0\n",
      "\n",
      "described above   0.5\n",
      "\n",
      "aim of   0.5\n",
      "\n",
      "single word   0.07142857142857142\n",
      "\n",
      "system generates   0.010752688172043012\n",
      "\n",
      "content question   0.08333333333333333\n",
      "\n",
      "reader to   0.1\n",
      "\n",
      "the acoustic   0.0006920415224913495\n",
      "\n",
      "make `   0.05\n",
      "\n",
      "as noun   0.003484320557491289\n",
      "\n",
      "the space   0.0020761245674740486\n",
      "\n",
      "are analyzed   0.004149377593360996\n",
      "\n",
      "and Ken   0.001445086705202312\n",
      "\n",
      "more general   0.031578947368421054\n",
      "\n",
      "produce numeric   0.045454545454545456\n",
      "\n",
      "transform ,   0.4\n",
      "\n",
      "'s job   0.0392156862745098\n",
      "\n",
      "order in   0.07142857142857142\n",
      "\n",
      "common .   0.08\n",
      "\n",
      "personnel .   1.0\n",
      "\n",
      "unwanted constructs   1.0\n",
      "\n",
      "sub-field of   1.0\n",
      "\n",
      "which do   0.007246376811594203\n",
      "\n",
      "Google .   0.5\n",
      "\n",
      "finite state   0.8\n",
      "\n",
      "the language   0.005536332179930796\n",
      "\n",
      "factors affect   0.3333333333333333\n",
      "\n",
      "much about   0.045454545454545456\n",
      "\n",
      "is largely   0.0020325203252032522\n",
      "\n",
      "one language   0.03076923076923077\n",
      "\n",
      "include versions   0.037037037037037035\n",
      "\n",
      "lowest level   1.0\n",
      "\n",
      "including morphemes   0.07142857142857142\n",
      "\n",
      "of yesterday   0.00267379679144385\n",
      "\n",
      "dealing with   1.0\n",
      "\n",
      "Given basic   0.07142857142857142\n",
      "\n",
      "of interest   0.00267379679144385\n",
      "\n",
      "history of   0.5\n",
      "\n",
      "time-scales -LRB-   1.0\n",
      "\n",
      "has increasingly   0.011904761904761904\n",
      "\n",
      "going backward   0.25\n",
      "\n",
      "-LRB- Cullingford   0.0027100271002710027\n",
      "\n",
      "finite set   0.2\n",
      "\n",
      "related tasks   0.2\n",
      "\n",
      "produced word   0.1111111111111111\n",
      "\n",
      "have humans   0.009615384615384616\n",
      "\n",
      "kinds of   1.0\n",
      "\n",
      "be phrased   0.004219409282700422\n",
      "\n",
      "procedure still   0.3333333333333333\n",
      "\n",
      "the name   0.001384083044982699\n",
      "\n",
      "organization of   0.4\n",
      "\n",
      "verbal unit   1.0\n",
      "\n",
      "analysis has   0.015384615384615385\n",
      "\n",
      "User Interface   0.5\n",
      "\n",
      "occurrence ,   0.5\n",
      "\n",
      "Re-encoding this   1.0\n",
      "\n",
      "; we   0.02127659574468085\n",
      "\n",
      "using ,   0.01694915254237288\n",
      "\n",
      "a more   0.0049079754601227\n",
      "\n",
      "into methods   0.01282051282051282\n",
      "\n",
      "of people   0.00089126559714795\n",
      "\n",
      "algebra word   0.5\n",
      "\n",
      "involves ``   0.1\n",
      "\n",
      ", search   0.0011229646266142617\n",
      "\n",
      "models were   0.038461538461538464\n",
      "\n",
      "gender ,   1.0\n",
      "\n",
      "categories in   0.1111111111111111\n",
      "\n",
      "subject .   0.25\n",
      "\n",
      "arm to   1.0\n",
      "\n",
      "In France   0.01904761904761905\n",
      "\n",
      "government and   0.3333333333333333\n",
      "\n",
      "transformations .   0.5\n",
      "\n",
      "humans possess   0.08333333333333333\n",
      "\n",
      "software is   0.07407407407407407\n",
      "\n",
      "a camera   0.001226993865030675\n",
      "\n",
      "ratings usually   0.1111111111111111\n",
      "\n",
      "offer the   1.0\n",
      "\n",
      "`` eat   0.005291005291005291\n",
      "\n",
      "of efforts   0.00089126559714795\n",
      "\n",
      "domain ontologies   0.1\n",
      "\n",
      "scanned can   0.3333333333333333\n",
      "\n",
      "D ,   1.0\n",
      "\n",
      "the types   0.001384083044982699\n",
      "\n",
      "some classification-related   0.012048192771084338\n",
      "\n",
      "better decisions   0.1111111111111111\n",
      "\n",
      "extraction as   0.06451612903225806\n",
      "\n",
      "Technologies that   1.0\n",
      "\n",
      "'' would   0.010309278350515464\n",
      "\n",
      "vary from   0.16666666666666666\n",
      "\n",
      "in errata   0.0018726591760299626\n",
      "\n",
      "are examples   0.012448132780082987\n",
      "\n",
      "also marked   0.014492753623188406\n",
      "\n",
      "decided a   0.3333333333333333\n",
      "\n",
      "'' might   0.010309278350515464\n",
      "\n",
      "to structured   0.0013280212483399733\n",
      "\n",
      "representations are   0.25\n",
      "\n",
      "-LRB- UC   0.0027100271002710027\n",
      "\n",
      "sufficient iteration   0.2\n",
      "\n",
      "that generate   0.0035460992907801418\n",
      "\n",
      "to include   0.009296148738379814\n",
      "\n",
      "memory of   0.5\n",
      "\n",
      "1930s .   1.0\n",
      "\n",
      "all governmental   0.023255813953488372\n",
      "\n",
      "Cuzco area   1.0\n",
      "\n",
      "sentence breaks   0.020833333333333332\n",
      "\n",
      "central ''   0.6666666666666666\n",
      "\n",
      "as Lisp   0.003484320557491289\n",
      "\n",
      "varied from   1.0\n",
      "\n",
      "with larger   0.00546448087431694\n",
      "\n",
      "publish a   1.0\n",
      "\n",
      "of their   0.0017825311942959\n",
      "\n",
      "the mental   0.0006920415224913495\n",
      "\n",
      "which various   0.007246376811594203\n",
      "\n",
      "Vice President   1.0\n",
      "\n",
      "recogniton vary   0.5\n",
      "\n",
      "usually are   0.03125\n",
      "\n",
      "rules that   0.09302325581395349\n",
      "\n",
      "overt morphological   1.0\n",
      "\n",
      "B ,   1.0\n",
      "\n",
      "relationship extraction   0.3333333333333333\n",
      "\n",
      "as sounds   0.003484320557491289\n",
      "\n",
      "which recursively   0.007246376811594203\n",
      "\n",
      "and Subjectivity   0.001445086705202312\n",
      "\n",
      "assertions ,   0.5\n",
      "\n",
      "for extracting   0.0036101083032490976\n",
      "\n",
      "Sentiment analysis   0.8333333333333334\n",
      "\n",
      ", content   0.0005614823133071309\n",
      "\n",
      "Human-machine interaction   1.0\n",
      "\n",
      "`` still   0.005291005291005291\n",
      "\n",
      "of numbers   0.0017825311942959\n",
      "\n",
      "to take   0.006640106241699867\n",
      "\n",
      "on finding   0.0047169811320754715\n",
      "\n",
      "adaptation .   0.6666666666666666\n",
      "\n",
      "that scans   0.0035460992907801418\n",
      "\n",
      "part-of-speech tags   0.06666666666666667\n",
      "\n",
      "service on   0.2\n",
      "\n",
      "of some   0.004456327985739751\n",
      "\n",
      "research .   0.09523809523809523\n",
      "\n",
      "Response based   1.0\n",
      "\n",
      "serve other   0.2\n",
      "\n",
      "detailed discussions   0.5\n",
      "\n",
      "computers and   0.1111111111111111\n",
      "\n",
      "converting the   0.5\n",
      "\n",
      "rank .   0.16666666666666666\n",
      "\n",
      "automate the   0.3333333333333333\n",
      "\n",
      "this ostensibly   0.01098901098901099\n",
      "\n",
      "Summarization of   0.25\n",
      "\n",
      "efficient parsers   0.3333333333333333\n",
      "\n",
      "Meaningful Use   1.0\n",
      "\n",
      "around the   0.375\n",
      "\n",
      "comprehensive knowledge   0.2\n",
      "\n",
      "requires each   0.0625\n",
      "\n",
      "sensible manner   1.0\n",
      "\n",
      "CoNLL shared   1.0\n",
      "\n",
      "although capabilities   0.16666666666666666\n",
      "\n",
      "evaluations .   0.16666666666666666\n",
      "\n",
      "English speaking   0.02702702702702703\n",
      "\n",
      "be retrained   0.004219409282700422\n",
      "\n",
      "consistently use   0.3333333333333333\n",
      "\n",
      "in other   0.009363295880149813\n",
      "\n",
      "sub-categories .   1.0\n",
      "\n",
      "approach which   0.05714285714285714\n",
      "\n",
      ", unlike   0.0005614823133071309\n",
      "\n",
      "is to   0.03861788617886179\n",
      "\n",
      "annotated -LRB-   0.5\n",
      "\n",
      "same topic   0.04\n",
      "\n",
      "<s> Accuracy   0.003843197540353574\n",
      "\n",
      "a sound   0.008588957055214725\n",
      "\n",
      "assumptions about   0.2\n",
      "\n",
      "<s> Bottom-up   0.0007686395080707148\n",
      "\n",
      ", cited   0.0005614823133071309\n",
      "\n",
      "as closed   0.003484320557491289\n",
      "\n",
      "translation Interlingual   0.02702702702702703\n",
      "\n",
      "The product   0.010416666666666666\n",
      "\n",
      "for Italian   0.0036101083032490976\n",
      "\n",
      "false positives   0.5\n",
      "\n",
      "and document   0.002890173410404624\n",
      "\n",
      "action should   0.2\n",
      "\n",
      "-- in   0.04\n",
      "\n",
      "databases into   0.125\n",
      "\n",
      "Quechua ,   1.0\n",
      "\n",
      "Research ,   0.125\n",
      "\n",
      "problem ,   0.09090909090909091\n",
      "\n",
      "of objects   0.00089126559714795\n",
      "\n",
      "voice user   0.07692307692307693\n",
      "\n",
      "handling such   0.5\n",
      "\n",
      "created based   0.14285714285714285\n",
      "\n",
      "segmentation is   0.2727272727272727\n",
      "\n",
      "and introducing   0.001445086705202312\n",
      "\n",
      "evaluation approach   0.018518518518518517\n",
      "\n",
      "of simple   0.0017825311942959\n",
      "\n",
      "MT -LRB-   0.2\n",
      "\n",
      "Contrary to   1.0\n",
      "\n",
      "together to   0.125\n",
      "\n",
      "reveal that   1.0\n",
      "\n",
      "will likely   0.05714285714285714\n",
      "\n",
      "`` who   0.005291005291005291\n",
      "\n",
      "to enumerate   0.0013280212483399733\n",
      "\n",
      "verb or   0.23076923076923078\n",
      "\n",
      "apply increasingly   0.2\n",
      "\n",
      "automatically learn   0.09523809523809523\n",
      "\n",
      "and placed   0.001445086705202312\n",
      "\n",
      "<s> ELIZA   0.0023059185242121443\n",
      "\n",
      "'' or   0.02577319587628866\n",
      "\n",
      "apple the   0.3333333333333333\n",
      "\n",
      "word accuracies   0.016666666666666666\n",
      "\n",
      "the assistance   0.0006920415224913495\n",
      "\n",
      "NLP ,   0.02127659574468085\n",
      "\n",
      "the dominance   0.0006920415224913495\n",
      "\n",
      "GRASSHOPPER algorithm   0.3333333333333333\n",
      "\n",
      "incorporate logical   1.0\n",
      "\n",
      "Systems -RRB-   0.08333333333333333\n",
      "\n",
      "Paul Drew   0.2\n",
      "\n",
      "that a   0.010638297872340425\n",
      "\n",
      "question marks   0.023809523809523808\n",
      "\n",
      "U.S. has   0.14285714285714285\n",
      "\n",
      "other features   0.014285714285714285\n",
      "\n",
      "language document   0.006756756756756757\n",
      "\n",
      "parser can   0.0625\n",
      "\n",
      "Brill 's   0.3333333333333333\n",
      "\n",
      "based recognition   0.018518518518518517\n",
      "\n",
      "The second   0.005208333333333333\n",
      "\n",
      "and languages   0.001445086705202312\n",
      "\n",
      "that used   0.0035460992907801418\n",
      "\n",
      "an implementation   0.007575757575757576\n",
      "\n",
      "technique referred   0.14285714285714285\n",
      "\n",
      "flight ''   0.5\n",
      "\n",
      "between them   0.05128205128205128\n",
      "\n",
      "Christmas fall   1.0\n",
      "\n",
      "as keeping   0.003484320557491289\n",
      "\n",
      "algorithm -LRB-   0.03571428571428571\n",
      "\n",
      "rates even   0.125\n",
      "\n",
      "easily when   0.1111111111111111\n",
      "\n",
      "drawn right-to-left   1.0\n",
      "\n",
      "good insight   0.07692307692307693\n",
      "\n",
      "research groups   0.023809523809523808\n",
      "\n",
      "the single   0.0006920415224913495\n",
      "\n",
      "summarization on   0.02\n",
      "\n",
      "Arabic in   0.25\n",
      "\n",
      "dictionary or   0.14285714285714285\n",
      "\n",
      "was installed   0.012987012987012988\n",
      "\n",
      "weapons release   1.0\n",
      "\n",
      "properties and   0.25\n",
      "\n",
      "that about   0.0035460992907801418\n",
      "\n",
      "by Frost   0.005714285714285714\n",
      "\n",
      "10 .   0.125\n",
      "\n",
      "the annual   0.0006920415224913495\n",
      "\n",
      "the typical   0.0006920415224913495\n",
      "\n",
      "a core   0.001226993865030675\n",
      "\n",
      "other pieces   0.014285714285714285\n",
      "\n",
      "developed in   0.23076923076923078\n",
      "\n",
      "was considered   0.012987012987012988\n",
      "\n",
      "the document   0.004152249134948097\n",
      "\n",
      "Company for   0.5\n",
      "\n",
      "approach of   0.02857142857142857\n",
      "\n",
      "N is   0.3333333333333333\n",
      "\n",
      ", instead   0.0005614823133071309\n",
      "\n",
      "queries on   0.3333333333333333\n",
      "\n",
      "for Larry   0.0036101083032490976\n",
      "\n",
      "assertions in   0.5\n",
      "\n",
      "of dependency   0.00089126559714795\n",
      "\n",
      "majority of   1.0\n",
      "\n",
      "and right   0.002890173410404624\n",
      "\n",
      "at an   0.014705882352941176\n",
      "\n",
      "The more   0.005208333333333333\n",
      "\n",
      "the fidelity   0.0006920415224913495\n",
      "\n",
      "vertices ,   0.1111111111111111\n",
      "\n",
      "domains .   0.25\n",
      "\n",
      "of classifying   0.00089126559714795\n",
      "\n",
      "specific summarization   0.047619047619047616\n",
      "\n",
      "setting ,   0.4\n",
      "\n",
      "and identify   0.002890173410404624\n",
      "\n",
      "primarily with   0.5\n",
      "\n",
      "Its main   0.5\n",
      "\n",
      "them ,   0.21052631578947367\n",
      "\n",
      "studies ,   0.5\n",
      "\n",
      "models for   0.23076923076923078\n",
      "\n",
      "generate form   0.05555555555555555\n",
      "\n",
      "pre-marked .   1.0\n",
      "\n",
      "when annotating   0.02857142857142857\n",
      "\n",
      "interim year   1.0\n",
      "\n",
      "as high   0.003484320557491289\n",
      "\n",
      "Center ,   1.0\n",
      "\n",
      ", no   0.0016844469399213925\n",
      "\n",
      "deal of   0.25\n",
      "\n",
      "assign targets   0.2\n",
      "\n",
      "different types   0.04081632653061224\n",
      "\n",
      "to extract   0.00398406374501992\n",
      "\n",
      "at Birkbeck   0.029411764705882353\n",
      "\n",
      "co-occur with   0.5\n",
      "\n",
      "the humanities   0.0006920415224913495\n",
      "\n",
      "? -RRB-   0.125\n",
      "\n",
      "seconds ,   1.0\n",
      "\n",
      "to it   0.0013280212483399733\n",
      "\n",
      "Turney 's   0.4444444444444444\n",
      "\n",
      "95 %   1.0\n",
      "\n",
      "Integration -LRB-   1.0\n",
      "\n",
      "is often   0.022357723577235773\n",
      "\n",
      "provider dictates   1.0\n",
      "\n",
      "Many machine   0.08333333333333333\n",
      "\n",
      "signal .   0.16666666666666666\n",
      "\n",
      "derived by   0.3333333333333333\n",
      "\n",
      "speech-recognition machine   0.3333333333333333\n",
      "\n",
      "what knowledge   0.03125\n",
      "\n",
      "Control -RRB-   1.0\n",
      "\n",
      "has increased   0.011904761904761904\n",
      "\n",
      "to found   0.0013280212483399733\n",
      "\n",
      "uses cosine   0.07142857142857142\n",
      "\n",
      "of off-line   0.00089126559714795\n",
      "\n",
      "long input   0.5\n",
      "\n",
      "the capital   0.001384083044982699\n",
      "\n",
      "quantities .   0.3333333333333333\n",
      "\n",
      "of vertices   0.00089126559714795\n",
      "\n",
      "at Brown   0.029411764705882353\n",
      "\n",
      "the tag   0.001384083044982699\n",
      "\n",
      "-LRB- b   0.0027100271002710027\n",
      "\n",
      "stock market   0.3333333333333333\n",
      "\n",
      "with diversity   0.00546448087431694\n",
      "\n",
      "qualities of   0.5\n",
      "\n",
      "the word   0.005536332179930796\n",
      "\n",
      "specification .   0.5\n",
      "\n",
      "`` On   0.005291005291005291\n",
      "\n",
      "is need   0.0020325203252032522\n",
      "\n",
      "An extrinsic   0.0625\n",
      "\n",
      "as researchers   0.003484320557491289\n",
      "\n",
      "-LRB- Adda   0.0027100271002710027\n",
      "\n",
      "providing customer   0.5\n",
      "\n",
      "is speaking   0.0020325203252032522\n",
      "\n",
      "or uttered   0.0045045045045045045\n",
      "\n",
      "technique chosen   0.14285714285714285\n",
      "\n",
      "use .   0.041666666666666664\n",
      "\n",
      "democracy .   1.0\n",
      "\n",
      "evaluation programs   0.018518518518518517\n",
      "\n",
      "base ,   0.5\n",
      "\n",
      "letters :   0.1\n",
      "\n",
      "like sentence   0.03571428571428571\n",
      "\n",
      "efficiently .   1.0\n",
      "\n",
      "be challenged   0.004219409282700422\n",
      "\n",
      "Advanced Fighter   0.2\n",
      "\n",
      "DeRose 1990   0.2\n",
      "\n",
      "significant taggers   0.1111111111111111\n",
      "\n",
      "<s> Algorithms   0.0015372790161414297\n",
      "\n",
      "many aspects   0.019230769230769232\n",
      "\n",
      "short time-scales   0.125\n",
      "\n",
      "Programming languages   0.6666666666666666\n",
      "\n",
      "`` learning   0.021164021164021163\n",
      "\n",
      "as multi-document   0.003484320557491289\n",
      "\n",
      "analysts This   0.5\n",
      "\n",
      "began selling   0.14285714285714285\n",
      "\n",
      "expansion of   0.3333333333333333\n",
      "\n",
      "phase is   1.0\n",
      "\n",
      "creates a   0.5\n",
      "\n",
      "so meaningless   0.03333333333333333\n",
      "\n",
      "column of   1.0\n",
      "\n",
      "a graph   0.0036809815950920245\n",
      "\n",
      "and phonemes   0.001445086705202312\n",
      "\n",
      "both LexRank   0.03225806451612903\n",
      "\n",
      "<s> Basically   0.0007686395080707148\n",
      "\n",
      "<s> Finally   0.0007686395080707148\n",
      "\n",
      "i.e. determining   0.05263157894736842\n",
      "\n",
      "they still   0.025\n",
      "\n",
      "its context   0.02857142857142857\n",
      "\n",
      "products .   0.25\n",
      "\n",
      "text classification   0.006289308176100629\n",
      "\n",
      "the Optophone   0.0006920415224913495\n",
      "\n",
      "valid summary   1.0\n",
      "\n",
      "becomes harder   0.25\n",
      "\n",
      "whereas when   0.3333333333333333\n",
      "\n",
      "that PageRank   0.0035460992907801418\n",
      "\n",
      "only rely   0.02631578947368421\n",
      "\n",
      "a bill   0.001226993865030675\n",
      "\n",
      "summary ,   0.14285714285714285\n",
      "\n",
      "humans can   0.08333333333333333\n",
      "\n",
      "<s> Decoding   0.0007686395080707148\n",
      "\n",
      "Voice Input   0.2\n",
      "\n",
      "mean of   0.5\n",
      "\n",
      "belong to   1.0\n",
      "\n",
      ", because   0.004491858506457047\n",
      "\n",
      "readable summary   0.3333333333333333\n",
      "\n",
      "subfields of   1.0\n",
      "\n",
      "mainly on   0.16666666666666666\n",
      "\n",
      "have ''   0.009615384615384616\n",
      "\n",
      "`` automatic   0.005291005291005291\n",
      "\n",
      "CSIS ,   0.5\n",
      "\n",
      "to ``   0.005312084993359893\n",
      "\n",
      "followed by   0.5\n",
      "\n",
      "any data   0.03225806451612903\n",
      "\n",
      "assumptions .   0.2\n",
      "\n",
      "robots ,   1.0\n",
      "\n",
      "internal representation   0.6\n",
      "\n",
      "odd looking   1.0\n",
      "\n",
      "leaders of   1.0\n",
      "\n",
      "direct and   0.16666666666666666\n",
      "\n",
      "of evaluation   0.004456327985739751\n",
      "\n",
      "Software OCR   0.5\n",
      "\n",
      "for some   0.018050541516245487\n",
      "\n",
      "complexity .   0.08333333333333333\n",
      "\n",
      "competitions devoted   1.0\n",
      "\n",
      "next four   0.14285714285714285\n",
      "\n",
      "data to   0.012987012987012988\n",
      "\n",
      "R. Harris   0.16666666666666666\n",
      "\n",
      "approaches presume   0.03571428571428571\n",
      "\n",
      "conversations such   0.3333333333333333\n",
      "\n",
      "reports ,   0.2\n",
      "\n",
      "Bolivar ,   1.0\n",
      "\n",
      "human-written texts   0.5\n",
      "\n",
      "Most of   0.5\n",
      "\n",
      "closely associate   0.2\n",
      "\n",
      "is on   0.0040650406504065045\n",
      "\n",
      "at TWA   0.014705882352941176\n",
      "\n",
      "article on   0.034482758620689655\n",
      "\n",
      "some parsing   0.012048192771084338\n",
      "\n",
      "as relations   0.003484320557491289\n",
      "\n",
      "-RRB- case   0.0027100271002710027\n",
      "\n",
      "given CFG   0.041666666666666664\n",
      "\n",
      "the Levenshtein   0.0006920415224913495\n",
      "\n",
      "feature which   0.07692307692307693\n",
      "\n",
      ", studying   0.0005614823133071309\n",
      "\n",
      "similar methods   0.037037037037037035\n",
      "\n",
      "the interim   0.0006920415224913495\n",
      "\n",
      "attempt to   1.0\n",
      "\n",
      "paper is   0.09090909090909091\n",
      "\n",
      "amount of   1.0\n",
      "\n",
      "of part   0.00089126559714795\n",
      "\n",
      "linguistic controversy   0.0625\n",
      "\n",
      "in French   0.0018726591760299626\n",
      "\n",
      "sentiment of   0.04\n",
      "\n",
      "consider sequences   0.25\n",
      "\n",
      "produced tones   0.1111111111111111\n",
      "\n",
      "implemented on   0.2\n",
      "\n",
      "Summarizers -LRB-   1.0\n",
      "\n",
      "form words   0.05\n",
      "\n",
      "using random   0.01694915254237288\n",
      "\n",
      "used OCR   0.008849557522123894\n",
      "\n",
      "that state   0.0035460992907801418\n",
      "\n",
      "further commercializing   0.125\n",
      "\n",
      "reason is   0.25\n",
      "\n",
      ", headlines   0.0005614823133071309\n",
      "\n",
      "evaluation is   0.07407407407407407\n",
      "\n",
      "we take   0.022222222222222223\n",
      "\n",
      "In any   0.01904761904761905\n",
      "\n",
      "aspect ,   0.5\n",
      "\n",
      "in contrast   0.0018726591760299626\n",
      "\n",
      "`` 12   0.010582010582010581\n",
      "\n",
      "about social   0.025\n",
      "\n",
      "+4 -RRB-   1.0\n",
      "\n",
      "learned model   0.2\n",
      "\n",
      "part-of-speech tag   0.06666666666666667\n",
      "\n",
      "Languages which   0.3333333333333333\n",
      "\n",
      "Other systems   0.14285714285714285\n",
      "\n",
      "door of   0.25\n",
      "\n",
      "algorithms differ   0.02857142857142857\n",
      "\n",
      "2 ,   0.2\n",
      "\n",
      "to interface   0.0013280212483399733\n",
      "\n",
      "of parameters   0.00089126559714795\n",
      "\n",
      "disabilities can   0.25\n",
      "\n",
      "CLAWS -LRB-   0.25\n",
      "\n",
      "the definition   0.0020761245674740486\n",
      "\n",
      "n't end   0.25\n",
      "\n",
      "on one   0.009433962264150943\n",
      "\n",
      "Electronic Medical   0.5\n",
      "\n",
      ", installed   0.0005614823133071309\n",
      "\n",
      "themselves .   0.25\n",
      "\n",
      "harder when   0.14285714285714285\n",
      "\n",
      "achieving fully   0.5\n",
      "\n",
      "even produce   0.037037037037037035\n",
      "\n",
      "as subtasks   0.003484320557491289\n",
      "\n",
      "`` deep   0.005291005291005291\n",
      "\n",
      "networks Neural   0.07142857142857142\n",
      "\n",
      "whose usage   0.3333333333333333\n",
      "\n",
      "used when   0.017699115044247787\n",
      "\n",
      "CLAWS pioneered   0.25\n",
      "\n",
      "into the   0.10256410256410256\n",
      "\n",
      ", The   0.0005614823133071309\n",
      "\n",
      "were workshops   0.024390243902439025\n",
      "\n",
      "English ,   0.16216216216216217\n",
      "\n",
      "read 23   0.14285714285714285\n",
      "\n",
      "after the   0.16666666666666666\n",
      "\n",
      "That is   1.0\n",
      "\n",
      "speech act   0.006578947368421052\n",
      "\n",
      "concatenated text   1.0\n",
      "\n",
      "a nice   0.00245398773006135\n",
      "\n",
      "did Christmas   0.2\n",
      "\n",
      "favor a   0.5\n",
      "\n",
      "are pre-determined   0.004149377593360996\n",
      "\n",
      "messages into   0.5\n",
      "\n",
      "translation :   0.02702702702702703\n",
      "\n",
      "a scaling   0.001226993865030675\n",
      "\n",
      "additional costs   0.16666666666666666\n",
      "\n",
      "count .   0.2\n",
      "\n",
      "specific person   0.047619047619047616\n",
      "\n",
      "programs .   0.2727272727272727\n",
      "\n",
      "linguistic competence   0.0625\n",
      "\n",
      "`` be   0.010582010582010581\n",
      "\n",
      "presented .   0.16666666666666666\n",
      "\n",
      "is extremely   0.0040650406504065045\n",
      "\n",
      "<s> Contrary   0.0015372790161414297\n",
      "\n",
      "for French   0.010830324909747292\n",
      "\n",
      "sharing one   1.0\n",
      "\n",
      "not invented   0.008928571428571428\n",
      "\n",
      "into linguistically   0.01282051282051282\n",
      "\n",
      "tasks include   0.03125\n",
      "\n",
      "difference was   0.25\n",
      "\n",
      "achieved with   0.2\n",
      "\n",
      "analysis can   0.03076923076923077\n",
      "\n",
      "linguistic formalism   0.0625\n",
      "\n",
      "direct real-world   0.16666666666666666\n",
      "\n",
      "English-like command   0.3333333333333333\n",
      "\n",
      "coverage ,   0.3333333333333333\n",
      "\n",
      "phenomenon may   0.2\n",
      "\n",
      "even if   0.1111111111111111\n",
      "\n",
      "of errors   0.00089126559714795\n",
      "\n",
      "8 %   1.0\n",
      "\n",
      "most suitable   0.017241379310344827\n",
      "\n",
      "the semantics   0.001384083044982699\n",
      "\n",
      "vertex would   0.3333333333333333\n",
      "\n",
      "tasks ;   0.03125\n",
      "\n",
      "what new   0.03125\n",
      "\n",
      "by programs   0.005714285714285714\n",
      "\n",
      "theory of   0.07692307692307693\n",
      "\n",
      "easily as   0.1111111111111111\n",
      "\n",
      "guesses '   1.0\n",
      "\n",
      "statistically-based speech   1.0\n",
      "\n",
      "Current machine   0.2\n",
      "\n",
      "changes which   1.0\n",
      "\n",
      "appear often   0.0625\n",
      "\n",
      "business letters   0.25\n",
      "\n",
      "co-founded Google   1.0\n",
      "\n",
      "later ,   0.5\n",
      "\n",
      "by analyzing   0.011428571428571429\n",
      "\n",
      "the time   0.004152249134948097\n",
      "\n",
      "exploits the   1.0\n",
      "\n",
      "for their   0.007220216606498195\n",
      "\n",
      "The software   0.005208333333333333\n",
      "\n",
      "it easily   0.008547008547008548\n",
      "\n",
      "quite different   0.375\n",
      "\n",
      ", English-like   0.0005614823133071309\n",
      "\n",
      "surprisingly difficult   0.3333333333333333\n",
      "\n",
      "a lot   0.0036809815950920245\n",
      "\n",
      "development cost   0.08333333333333333\n",
      "\n",
      "of word-frequency   0.00089126559714795\n",
      "\n",
      "human summaries   0.021739130434782608\n",
      "\n",
      "some labeled   0.012048192771084338\n",
      "\n",
      "on Hidden   0.0047169811320754715\n",
      "\n",
      "such formal   0.008130081300813009\n",
      "\n",
      "diversity as   0.25\n",
      "\n",
      "intrinsic evaluation   0.5\n",
      "\n",
      "storm ,   1.0\n",
      "\n",
      "relevant entities   0.14285714285714285\n",
      "\n",
      "of communication   0.0017825311942959\n",
      "\n",
      "retrained to   1.0\n",
      "\n",
      "as subject   0.003484320557491289\n",
      "\n",
      "sponsored evaluations   0.5\n",
      "\n",
      "sales data   0.3333333333333333\n",
      "\n",
      "needed without   0.047619047619047616\n",
      "\n",
      "machine language   0.0379746835443038\n",
      "\n",
      "- -RRB-   0.0625\n",
      "\n",
      "information request   0.021739130434782608\n",
      "\n",
      "payments .   1.0\n",
      "\n",
      "operated on   0.5\n",
      "\n",
      "human-written ones   0.5\n",
      "\n",
      ", identifying   0.0016844469399213925\n",
      "\n",
      "Transfer-based machine   1.0\n",
      "\n",
      "understanding can   0.030303030303030304\n",
      "\n",
      "The idea   0.010416666666666666\n",
      "\n",
      "input six   0.024390243902439025\n",
      "\n",
      "cause the   0.5\n",
      "\n",
      "to reliable   0.0013280212483399733\n",
      "\n",
      "in recognition   0.003745318352059925\n",
      "\n",
      "avoiding linguistic   0.5\n",
      "\n",
      "social work   0.07142857142857142\n",
      "\n",
      "define several   0.5\n",
      "\n",
      "; later   0.02127659574468085\n",
      "\n",
      "key area   0.3333333333333333\n",
      "\n",
      "finished writing   0.5\n",
      "\n",
      "shortened version   1.0\n",
      "\n",
      "enormous amount   1.0\n",
      "\n",
      "unsupervised and   0.125\n",
      "\n",
      "the 70   0.0006920415224913495\n",
      "\n",
      "the Apollo   0.0006920415224913495\n",
      "\n",
      "corresponding increase   0.16666666666666666\n",
      "\n",
      "of data   0.006238859180035651\n",
      "\n",
      "entropy -LRB-   0.2\n",
      "\n",
      "see context-free   0.05\n",
      "\n",
      "human .   0.06521739130434782\n",
      "\n",
      "Document summarization   0.25\n",
      "\n",
      "tag to   0.0625\n",
      "\n",
      "simulates the   1.0\n",
      "\n",
      "than whole   0.022222222222222223\n",
      "\n",
      "<s> Behind   0.0007686395080707148\n",
      "\n",
      "avoid confusion   1.0\n",
      "\n",
      "as described   0.006968641114982578\n",
      "\n",
      "best model   0.05555555555555555\n",
      "\n",
      "largely been   0.2\n",
      "\n",
      "informativeness of   0.6666666666666666\n",
      "\n",
      "of formalisms\\/languages   0.00089126559714795\n",
      "\n",
      "variance on   1.0\n",
      "\n",
      "Goldberg developed   0.5\n",
      "\n",
      "for triples   0.0036101083032490976\n",
      "\n",
      "Attribute grammars   1.0\n",
      "\n",
      "This device   0.015873015873015872\n",
      "\n",
      "construction of   0.6666666666666666\n",
      "\n",
      "would only   0.018867924528301886\n",
      "\n",
      "because translation   0.03333333333333333\n",
      "\n",
      "when processed   0.02857142857142857\n",
      "\n",
      "card OCR   0.25\n",
      "\n",
      "it must   0.008547008547008548\n",
      "\n",
      "sentence-end after   1.0\n",
      "\n",
      ", USMC   0.0005614823133071309\n",
      "\n",
      "been a   0.029411764705882353\n",
      "\n",
      "<s> Of   0.0007686395080707148\n",
      "\n",
      "canned text   0.5\n",
      "\n",
      "faster to   0.3333333333333333\n",
      "\n",
      "component sentences   0.2\n",
      "\n",
      "available .   0.17647058823529413\n",
      "\n",
      "that spontaneous   0.0035460992907801418\n",
      "\n",
      "LUNAR was   0.3333333333333333\n",
      "\n",
      "only because   0.02631578947368421\n",
      "\n",
      "Based on   1.0\n",
      "\n",
      "+ Cloud   0.16666666666666666\n",
      "\n",
      "determine ``   0.043478260869565216\n",
      "\n",
      "processing news   0.018518518518518517\n",
      "\n",
      "But the   0.16666666666666666\n",
      "\n",
      "short ,   0.125\n",
      "\n",
      "particular event   0.07692307692307693\n",
      "\n",
      "hand it   0.07142857142857142\n",
      "\n",
      "toolkit is   0.5\n",
      "\n",
      "path sentences   0.5\n",
      "\n",
      "keyboard .   0.3333333333333333\n",
      "\n",
      "Shepard ,   0.3333333333333333\n",
      "\n",
      "position and   0.25\n",
      "\n",
      "slower ,   1.0\n",
      "\n",
      "dependency grammar   0.2\n",
      "\n",
      "unigrams and   0.08333333333333333\n",
      "\n",
      "II -LRB-   0.5\n",
      "\n",
      "human-generated model   0.5\n",
      "\n",
      "can deal   0.0055248618784530384\n",
      "\n",
      "merge adjacent   1.0\n",
      "\n",
      "that there   0.0070921985815602835\n",
      "\n",
      "that much   0.0035460992907801418\n",
      "\n",
      "to proper   0.0013280212483399733\n",
      "\n",
      "use lexical   0.027777777777777776\n",
      "\n",
      "the cost   0.0006920415224913495\n",
      "\n",
      "see appraisal   0.05\n",
      "\n",
      "used an   0.008849557522123894\n",
      "\n",
      "the overall   0.0020761245674740486\n",
      "\n",
      "conversation ,   0.25\n",
      "\n",
      "responsible for   1.0\n",
      "\n",
      "will indicate   0.02857142857142857\n",
      "\n",
      "implementations of   1.0\n",
      "\n",
      "If there   0.1\n",
      "\n",
      "an approach   0.030303030303030304\n",
      "\n",
      "-RRB- securely   0.0027100271002710027\n",
      "\n",
      "technology also   0.045454545454545456\n",
      "\n",
      "faces a   1.0\n",
      "\n",
      "short summary   0.125\n",
      "\n",
      "answer to   0.16666666666666666\n",
      "\n",
      "This approach   0.031746031746031744\n",
      "\n",
      ", ASR   0.0005614823133071309\n",
      "\n",
      "2007 and   0.2\n",
      "\n",
      "corpus to   0.03225806451612903\n",
      "\n",
      "contains errors   0.2\n",
      "\n",
      "whether they   0.07692307692307693\n",
      "\n",
      "`` processing   0.010582010582010581\n",
      "\n",
      "the highest   0.0006920415224913495\n",
      "\n",
      "which range   0.007246376811594203\n",
      "\n",
      "assumptions such   0.2\n",
      "\n",
      "words commonly   0.009174311926605505\n",
      "\n",
      "usually separated   0.03125\n",
      "\n",
      "-LRB- see   0.032520325203252036\n",
      "\n",
      "text cohesion   0.006289308176100629\n",
      "\n",
      "Speaker Recognition   0.16666666666666666\n",
      "\n",
      "short paragraph   0.125\n",
      "\n",
      "syntax effectively   0.09090909090909091\n",
      "\n",
      "programmed with   0.5\n",
      "\n",
      "input and\\/or   0.024390243902439025\n",
      "\n",
      "adapted to   1.0\n",
      "\n",
      "identify keyphrases   0.08333333333333333\n",
      "\n",
      "<verb> ←   1.0\n",
      "\n",
      "a certain   0.001226993865030675\n",
      "\n",
      "is clear   0.0020325203252032522\n",
      "\n",
      "Speaker dependence   0.16666666666666666\n",
      "\n",
      "at the   0.22058823529411764\n",
      "\n",
      "to coherent   0.0013280212483399733\n",
      "\n",
      "sometimes ambiguous   0.07692307692307693\n",
      "\n",
      "rule-based algorithms   0.14285714285714285\n",
      "\n",
      "technology development   0.045454545454545456\n",
      "\n",
      "`` do   0.005291005291005291\n",
      "\n",
      "successively more   1.0\n",
      "\n",
      ", written   0.0005614823133071309\n",
      "\n",
      "run an   0.2\n",
      "\n",
      "Cook ,   1.0\n",
      "\n",
      ": Digitize   0.00980392156862745\n",
      "\n",
      "difficulty in   0.2857142857142857\n",
      "\n",
      "whom ?   0.5\n",
      "\n",
      "email address   0.5\n",
      "\n",
      "big a   0.5\n",
      "\n",
      "levels .   0.045454545454545456\n",
      "\n",
      "scale -LRB-   0.16666666666666666\n",
      "\n",
      "process broken   0.027777777777777776\n",
      "\n",
      "or positive   0.0045045045045045045\n",
      "\n",
      "Whether a   0.5\n",
      "\n",
      "Austrian emigre   1.0\n",
      "\n",
      "identify ambiguities   0.08333333333333333\n",
      "\n",
      "derivation and   0.25\n",
      "\n",
      "years in   0.047619047619047616\n",
      "\n",
      "his method   0.08333333333333333\n",
      "\n",
      "movie review   0.3333333333333333\n",
      "\n",
      "3 ,   0.2\n",
      "\n",
      "of pairs   0.0017825311942959\n",
      "\n",
      "about an   0.025\n",
      "\n",
      "versions needed   0.3333333333333333\n",
      "\n",
      "' could   0.05263157894736842\n",
      "\n",
      "Recognize if   1.0\n",
      "\n",
      "starting to   1.0\n",
      "\n",
      "improve readability   0.07692307692307693\n",
      "\n",
      "of edge   0.00089126559714795\n",
      "\n",
      "NLP and   0.02127659574468085\n",
      "\n",
      "subjectivity\\/objectivity identification   1.0\n",
      "\n",
      ", large   0.0005614823133071309\n",
      "\n",
      "ME -RRB-   0.5\n",
      "\n",
      "any previous   0.03225806451612903\n",
      "\n",
      "Administration ,   1.0\n",
      "\n",
      "some improvement   0.012048192771084338\n",
      "\n",
      "this area   0.03296703296703297\n",
      "\n",
      "later the   0.1\n",
      "\n",
      "grammars can   0.07142857142857142\n",
      "\n",
      "database industry   0.1\n",
      "\n",
      "then characterized   0.02857142857142857\n",
      "\n",
      "one sentence   0.03076923076923077\n",
      "\n",
      "germane to   1.0\n",
      "\n",
      "an English-like   0.007575757575757576\n",
      "\n",
      "but in   0.029411764705882353\n",
      "\n",
      "constrained ,   1.0\n",
      "\n",
      "larger text   0.0625\n",
      "\n",
      "program by   0.045454545454545456\n",
      "\n",
      "ME is   0.5\n",
      "\n",
      "2 --   0.2\n",
      "\n",
      "pragmatics of   0.3333333333333333\n",
      "\n",
      "of understanding   0.00089126559714795\n",
      "\n",
      "digital computers   0.14285714285714285\n",
      "\n",
      "hybrid approach   0.5\n",
      "\n",
      "fighter aircraft   0.5\n",
      "\n",
      "useful summary   0.07142857142857142\n",
      "\n",
      "could read   0.0625\n",
      "\n",
      "automatically The   0.047619047619047616\n",
      "\n",
      "known type   0.038461538461538464\n",
      "\n",
      "Rajman M.   1.0\n",
      "\n",
      "production when   0.3333333333333333\n",
      "\n",
      "by precision   0.005714285714285714\n",
      "\n",
      "human variability   0.021739130434782608\n",
      "\n",
      "not its   0.008928571428571428\n",
      "\n",
      "there is   0.35\n",
      "\n",
      "discourse is   0.08333333333333333\n",
      "\n",
      "understand simple   0.2857142857142857\n",
      "\n",
      "which ?   0.007246376811594203\n",
      "\n",
      "some invalid   0.012048192771084338\n",
      "\n",
      "Larry Page   0.5\n",
      "\n",
      "response Mobile   0.5\n",
      "\n",
      "translated ,   0.25\n",
      "\n",
      "Caldas-Coulthard ,   1.0\n",
      "\n",
      "additionally requires   1.0\n",
      "\n",
      "see computational   0.05\n",
      "\n",
      "<s> Major   0.0015372790161414297\n",
      "\n",
      "entities often   0.14285714285714285\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sophisticated NLG   0.14285714285714285\n",
      "\n",
      "of 2007   0.0017825311942959\n",
      "\n",
      "be effective   0.008438818565400843\n",
      "\n",
      "applications ,   0.16\n",
      "\n",
      "registry .   1.0\n",
      "\n",
      "a flight   0.001226993865030675\n",
      "\n",
      "of supervised   0.00089126559714795\n",
      "\n",
      "that of   0.028368794326241134\n",
      "\n",
      "and possibly   0.001445086705202312\n",
      "\n",
      "novel proposal   1.0\n",
      "\n",
      "block of   1.0\n",
      "\n",
      "than has   0.022222222222222223\n",
      "\n",
      "output in   0.038461538461538464\n",
      "\n",
      "and system   0.001445086705202312\n",
      "\n",
      "the terms   0.0006920415224913495\n",
      "\n",
      ", Edward   0.0005614823133071309\n",
      "\n",
      "numerous approaches   1.0\n",
      "\n",
      "shift positions   1.0\n",
      "\n",
      "aircraft platforms   0.14285714285714285\n",
      "\n",
      "the software   0.0020761245674740486\n",
      "\n",
      "quotations ,   1.0\n",
      "\n",
      "candidates ,   0.2\n",
      "\n",
      "the string   0.0006920415224913495\n",
      "\n",
      "As in   0.2222222222222222\n",
      "\n",
      "by creating   0.005714285714285714\n",
      "\n",
      "right -LRB-   0.1\n",
      "\n",
      "of contextual   0.00089126559714795\n",
      "\n",
      ", statistics   0.0011229646266142617\n",
      "\n",
      "not map   0.008928571428571428\n",
      "\n",
      "complex NLP   0.08333333333333333\n",
      "\n",
      ", relay   0.0005614823133071309\n",
      "\n",
      "resource such   0.2\n",
      "\n",
      "a 4   0.001226993865030675\n",
      "\n",
      "sociology ,   1.0\n",
      "\n",
      "a product   0.001226993865030675\n",
      "\n",
      "patent on   0.75\n",
      "\n",
      "then can   0.02857142857142857\n",
      "\n",
      "is -LRB-   0.0040650406504065045\n",
      "\n",
      "texts seems   0.058823529411764705\n",
      "\n",
      "-LRB- ending   0.0027100271002710027\n",
      "\n",
      "larger chunk   0.0625\n",
      "\n",
      "system would   0.021505376344086023\n",
      "\n",
      "now more   0.07692307692307693\n",
      "\n",
      "the details   0.0006920415224913495\n",
      "\n",
      "routed along   0.5\n",
      "\n",
      "which were   0.014492753623188406\n",
      "\n",
      "tagged ''   0.6666666666666666\n",
      "\n",
      "Therein lies   1.0\n",
      "\n",
      "what you   0.03125\n",
      "\n",
      "voices or   1.0\n",
      "\n",
      "complex sound   0.125\n",
      "\n",
      ", punctuation   0.0005614823133071309\n",
      "\n",
      "mouse driven   1.0\n",
      "\n",
      "difficulties in   0.5\n",
      "\n",
      "because NLP   0.03333333333333333\n",
      "\n",
      "far too   0.125\n",
      "\n",
      "equal to   1.0\n",
      "\n",
      "tackles each   1.0\n",
      "\n",
      "rarity and   1.0\n",
      "\n",
      ", size   0.0005614823133071309\n",
      "\n",
      "<s> Word   0.003843197540353574\n",
      "\n",
      "various features   0.05555555555555555\n",
      "\n",
      ", Robert   0.0016844469399213925\n",
      "\n",
      "broader and   1.0\n",
      "\n",
      "The only   0.010416666666666666\n",
      "\n",
      "usefully be   1.0\n",
      "\n",
      ", French   0.0005614823133071309\n",
      "\n",
      "problems with   0.058823529411764705\n",
      "\n",
      "output than   0.038461538461538464\n",
      "\n",
      "geological analysis   1.0\n",
      "\n",
      "designed for   0.14285714285714285\n",
      "\n",
      "Zellig Harris   1.0\n",
      "\n",
      "not use   0.017857142857142856\n",
      "\n",
      "um ''   1.0\n",
      "\n",
      "... About   0.5\n",
      "\n",
      "simple substitution   0.038461538461538464\n",
      "\n",
      "typically grouped   0.05555555555555555\n",
      "\n",
      "Apple Newton   1.0\n",
      "\n",
      "documents have   0.02631578947368421\n",
      "\n",
      "often using   0.022727272727272728\n",
      "\n",
      "= masculine   0.1111111111111111\n",
      "\n",
      "combined with   0.5\n",
      "\n",
      "ELIZA might   0.1111111111111111\n",
      "\n",
      "the largest   0.0006920415224913495\n",
      "\n",
      "AI than   0.3333333333333333\n",
      "\n",
      "though this   0.1\n",
      "\n",
      ", Bobrow   0.0005614823133071309\n",
      "\n",
      "strings of   1.0\n",
      "\n",
      "by analogy   0.005714285714285714\n",
      "\n",
      "testing .   0.2\n",
      "\n",
      "most research   0.017241379310344827\n",
      "\n",
      "automatic methodology   0.043478260869565216\n",
      "\n",
      "lexical exigencies   0.07692307692307693\n",
      "\n",
      "With the   0.2857142857142857\n",
      "\n",
      "or language   0.0045045045045045045\n",
      "\n",
      "the US   0.001384083044982699\n",
      "\n",
      "statistics -LRB-   0.125\n",
      "\n",
      "the typewritten   0.0006920415224913495\n",
      "\n",
      "speeds .   0.5\n",
      "\n",
      "method in   0.0625\n",
      "\n",
      "Kurzweil started   0.14285714285714285\n",
      "\n",
      "differ in   0.3333333333333333\n",
      "\n",
      "progress was   0.2857142857142857\n",
      "\n",
      "approach allows   0.02857142857142857\n",
      "\n",
      "NNS for   1.0\n",
      "\n",
      "sentence or   0.041666666666666664\n",
      "\n",
      "used a   0.02654867256637168\n",
      "\n",
      "per second   0.5\n",
      "\n",
      "The fact   0.005208333333333333\n",
      "\n",
      "that TextRank   0.0070921985815602835\n",
      "\n",
      "and far   0.002890173410404624\n",
      "\n",
      "were printed   0.024390243902439025\n",
      "\n",
      "Solving this   0.5\n",
      "\n",
      "structure with   0.08333333333333333\n",
      "\n",
      "analyses .   0.4\n",
      "\n",
      "answer ,   0.03333333333333333\n",
      "\n",
      "etc. ;   0.045454545454545456\n",
      "\n",
      ", does   0.0011229646266142617\n",
      "\n",
      "^ 2   0.3333333333333333\n",
      "\n",
      "thus returning   0.1\n",
      "\n",
      "professor at   1.0\n",
      "\n",
      "of accuracy   0.0017825311942959\n",
      "\n",
      "Pierce wrote   1.0\n",
      "\n",
      ", text   0.0016844469399213925\n",
      "\n",
      "electrical characteristics   1.0\n",
      "\n",
      "a robotic   0.001226993865030675\n",
      "\n",
      "<s> Dragon   0.0007686395080707148\n",
      "\n",
      "was demonstrated   0.012987012987012988\n",
      "\n",
      "with questions   0.01092896174863388\n",
      "\n",
      "like relevance   0.03571428571428571\n",
      "\n",
      "produce interpretable   0.045454545454545456\n",
      "\n",
      "outputting one   0.5\n",
      "\n",
      "with respect   0.03825136612021858\n",
      "\n",
      "two sequences   0.034482758620689655\n",
      "\n",
      "jokes -LRB-   1.0\n",
      "\n",
      "that the   0.08156028368794327\n",
      "\n",
      "that part-of-speech   0.0035460992907801418\n",
      "\n",
      "their routing   0.029411764705882353\n",
      "\n",
      "large percentage   0.043478260869565216\n",
      "\n",
      "Bois ,   1.0\n",
      "\n",
      "Emanuel Schegloff   0.5\n",
      "\n",
      "most can   0.017241379310344827\n",
      "\n",
      "specialist textbook   1.0\n",
      "\n",
      "called machine   0.05555555555555555\n",
      "\n",
      "caps -RRB-   1.0\n",
      "\n",
      "simply verbs   0.08333333333333333\n",
      "\n",
      "the Northern   0.001384083044982699\n",
      "\n",
      "to model   0.0013280212483399733\n",
      "\n",
      "equivalence is   0.5\n",
      "\n",
      "ICR software   0.3333333333333333\n",
      "\n",
      "considered or   0.1111111111111111\n",
      "\n",
      "retrieved .   1.0\n",
      "\n",
      "etc. ''   0.045454545454545456\n",
      "\n",
      "deemed most   0.5\n",
      "\n",
      "and assess   0.001445086705202312\n",
      "\n",
      "context have   0.030303030303030304\n",
      "\n",
      "and Tigrinya   0.001445086705202312\n",
      "\n",
      "one there   0.015384615384615385\n",
      "\n",
      "task is   0.14285714285714285\n",
      "\n",
      "was .   0.012987012987012988\n",
      "\n",
      "requires the   0.1875\n",
      "\n",
      "simple parsing   0.038461538461538464\n",
      "\n",
      "their suitability   0.029411764705882353\n",
      "\n",
      "built in   0.3333333333333333\n",
      "\n",
      "like syntax   0.03571428571428571\n",
      "\n",
      "the grammatical   0.0020761245674740486\n",
      "\n",
      "are much   0.008298755186721992\n",
      "\n",
      "the areas   0.001384083044982699\n",
      "\n",
      "set ''   0.05128205128205128\n",
      "\n",
      "to its   0.0013280212483399733\n",
      "\n",
      "adjective -LRB-   0.14285714285714285\n",
      "\n",
      "and mapping   0.001445086705202312\n",
      "\n",
      "walk ,   0.2\n",
      "\n",
      "ask for   0.25\n",
      "\n",
      "at different   0.014705882352941176\n",
      "\n",
      "logic ,   0.25\n",
      "\n",
      "sequential lines   1.0\n",
      "\n",
      ", correlation   0.0005614823133071309\n",
      "\n",
      ", 1978   0.0011229646266142617\n",
      "\n",
      "difficult task   0.03571428571428571\n",
      "\n",
      "which includes   0.014492753623188406\n",
      "\n",
      "clarification of   0.6666666666666666\n",
      "\n",
      "generate .   0.05555555555555555\n",
      "\n",
      ", stored   0.0005614823133071309\n",
      "\n",
      "contexts ,   0.2857142857142857\n",
      "\n",
      "not possible   0.008928571428571428\n",
      "\n",
      "TNO developed   1.0\n",
      "\n",
      "of arbitrary   0.00089126559714795\n",
      "\n",
      "criteria .   0.25\n",
      "\n",
      "possible task   0.041666666666666664\n",
      "\n",
      "co-articulation of   1.0\n",
      "\n",
      "computer vision   0.022727272727272728\n",
      "\n",
      "do we   0.038461538461538464\n",
      "\n",
      "vectors ,   0.3333333333333333\n",
      "\n",
      "is Hard   0.0020325203252032522\n",
      "\n",
      "definite on   1.0\n",
      "\n",
      "token is   0.5\n",
      "\n",
      "But also   0.16666666666666666\n",
      "\n",
      "D.S. 1998   1.0\n",
      "\n",
      "currently using   0.14285714285714285\n",
      "\n",
      "evaluation can   0.037037037037037035\n",
      "\n",
      "deciding where   0.16666666666666666\n",
      "\n",
      "them attractive   0.05263157894736842\n",
      "\n",
      "questions can   0.038461538461538464\n",
      "\n",
      "be approximately   0.004219409282700422\n",
      "\n",
      "step neural   0.06666666666666667\n",
      "\n",
      "more input   0.010526315789473684\n",
      "\n",
      "problem of   0.18181818181818182\n",
      "\n",
      "forecasts in   0.2\n",
      "\n",
      "character groups   0.045454545454545456\n",
      "\n",
      "linguistic research   0.0625\n",
      "\n",
      "between 1964   0.02564102564102564\n",
      "\n",
      ", Aletta   0.0005614823133071309\n",
      "\n",
      "any sentences   0.03225806451612903\n",
      "\n",
      "be sequences   0.004219409282700422\n",
      "\n",
      "difficult and   0.03571428571428571\n",
      "\n",
      "and common-sense   0.001445086705202312\n",
      "\n",
      "and pasted   0.001445086705202312\n",
      "\n",
      "complex recognition   0.041666666666666664\n",
      "\n",
      "Translations are   1.0\n",
      "\n",
      "score if   0.16666666666666666\n",
      "\n",
      "being expended   0.05555555555555555\n",
      "\n",
      "to digitize   0.0013280212483399733\n",
      "\n",
      "about any   0.025\n",
      "\n",
      "intensive as   1.0\n",
      "\n",
      "not Afghanistan   0.008928571428571428\n",
      "\n",
      "complicated statistical   0.3333333333333333\n",
      "\n",
      "Research Corporation   0.125\n",
      "\n",
      "grammar can   0.02702702702702703\n",
      "\n",
      ", Petrov   0.0005614823133071309\n",
      "\n",
      "legal and   0.3333333333333333\n",
      "\n",
      "synthesizer .   1.0\n",
      "\n",
      "Another research   0.07692307692307693\n",
      "\n",
      "the '   0.0006920415224913495\n",
      "\n",
      "other word   0.014285714285714285\n",
      "\n",
      "with neural   0.00546448087431694\n",
      "\n",
      "% of   0.20512820512820512\n",
      "\n",
      "hear sound   0.5\n",
      "\n",
      "roughly proportional   0.3333333333333333\n",
      "\n",
      "electronic conversion   0.5\n",
      "\n",
      "speech in   0.013157894736842105\n",
      "\n",
      "leaving the   1.0\n",
      "\n",
      "States and   0.14285714285714285\n",
      "\n",
      "Harris 1991   0.1111111111111111\n",
      "\n",
      "10 parsers   0.125\n",
      "\n",
      "cognitive psychology   0.5\n",
      "\n",
      "is described   0.0020325203252032522\n",
      "\n",
      "-LRB- VITO   0.0027100271002710027\n",
      "\n",
      "helped overall   0.3333333333333333\n",
      "\n",
      "opinions -RRB-   0.5\n",
      "\n",
      "embedded .   0.25\n",
      "\n",
      "bootstrap using   1.0\n",
      "\n",
      "making the   0.2857142857142857\n",
      "\n",
      "discussions .   0.3333333333333333\n",
      "\n",
      "generally more   0.18181818181818182\n",
      "\n",
      "Of particular   1.0\n",
      "\n",
      "descriptions ;   1.0\n",
      "\n",
      "-LRB- sometimes   0.0027100271002710027\n",
      "\n",
      "ones ,   0.3\n",
      "\n",
      "semantic analysis   0.09523809523809523\n",
      "\n",
      "high levels   0.16666666666666666\n",
      "\n",
      "are measured   0.004149377593360996\n",
      "\n",
      ", pruned   0.0005614823133071309\n",
      "\n",
      "maximal probability   1.0\n",
      "\n",
      "Forces Security   1.0\n",
      "\n",
      "time .   0.12121212121212122\n",
      "\n",
      "Issues While   0.5\n",
      "\n",
      "a huge   0.001226993865030675\n",
      "\n",
      "several seconds   0.045454545454545456\n",
      "\n",
      "routing bar   0.3333333333333333\n",
      "\n",
      "gained by   0.5\n",
      "\n",
      "blogs ,   0.5\n",
      "\n",
      "common nouns   0.08\n",
      "\n",
      "into punched   0.01282051282051282\n",
      "\n",
      "speed is   0.14285714285714285\n",
      "\n",
      "decade ,   0.3333333333333333\n",
      "\n",
      "run-time .   1.0\n",
      "\n",
      "games ,   1.0\n",
      "\n",
      ", and\\/or   0.0005614823133071309\n",
      "\n",
      "do predict   0.038461538461538464\n",
      "\n",
      "Interlingual machine   0.6666666666666666\n",
      "\n",
      "and achieves   0.001445086705202312\n",
      "\n",
      "a printed   0.001226993865030675\n",
      "\n",
      "algorithms ,   0.14285714285714285\n",
      "\n",
      "applies directly   0.14285714285714285\n",
      "\n",
      "to lower   0.0013280212483399733\n",
      "\n",
      "Carbonell ,   1.0\n",
      "\n",
      "Auto plant   1.0\n",
      "\n",
      "-RRB- or   0.01084010840108401\n",
      "\n",
      "Ken Church   1.0\n",
      "\n",
      "type of   0.5714285714285714\n",
      "\n",
      "Inc. in   0.5\n",
      "\n",
      "category registry   0.5\n",
      "\n",
      "testing is   0.2\n",
      "\n",
      ", TaleSpin   0.0005614823133071309\n",
      "\n",
      "appropriately ,   0.5\n",
      "\n",
      "medium -RRB-   0.3333333333333333\n",
      "\n",
      "complexity of   0.6666666666666666\n",
      "\n",
      "example above   0.012345679012345678\n",
      "\n",
      "summary and   0.047619047619047616\n",
      "\n",
      "discussed below   0.42857142857142855\n",
      "\n",
      "support vector   0.25\n",
      "\n",
      "necessary subtask   0.1\n",
      "\n",
      "Reading ''   0.5\n",
      "\n",
      "recall may   0.3333333333333333\n",
      "\n",
      "times in   0.2\n",
      "\n",
      "document before   0.027777777777777776\n",
      "\n",
      "discourse relationships   0.027777777777777776\n",
      "\n",
      "a dictionary   0.0036809815950920245\n",
      "\n",
      "Z ''   1.0\n",
      "\n",
      "this issue   0.01098901098901099\n",
      "\n",
      ", from   0.0005614823133071309\n",
      "\n",
      "English text   0.02702702702702703\n",
      "\n",
      "ōrātiōnis -RRB-   1.0\n",
      "\n",
      "answer temporal   0.03333333333333333\n",
      "\n",
      "run the   0.4\n",
      "\n",
      "typical machine-learning-based   0.1111111111111111\n",
      "\n",
      "It consists   0.02631578947368421\n",
      "\n",
      "The extrinsic   0.005208333333333333\n",
      "\n",
      "command interpreters   0.5\n",
      "\n",
      "Emanuel Goldberg   0.5\n",
      "\n",
      "summarization -LRB-   0.04\n",
      "\n",
      "an entire   0.007575757575757576\n",
      "\n",
      "to create   0.01195219123505976\n",
      "\n",
      "speech designed   0.006578947368421052\n",
      "\n",
      "identified is   0.2\n",
      "\n",
      "standards require   0.2\n",
      "\n",
      "where metrics   0.02857142857142857\n",
      "\n",
      "distinct from   0.42857142857142855\n",
      "\n",
      "critical or   0.25\n",
      "\n",
      "easy-to-use syntax   1.0\n",
      "\n",
      "for commercial   0.0036101083032490976\n",
      "\n",
      "-RRB- break   0.0027100271002710027\n",
      "\n",
      "John Heritage   0.125\n",
      "\n",
      "including images   0.07142857142857142\n",
      "\n",
      "context The   0.06060606060606061\n",
      "\n",
      "queries to   0.3333333333333333\n",
      "\n",
      "expression .   0.2\n",
      "\n",
      "or serving   0.0045045045045045045\n",
      "\n",
      "each choice   0.022222222222222223\n",
      "\n",
      "communication Pragmatics   0.2\n",
      "\n",
      "2PR \\/   1.0\n",
      "\n",
      "procedures ,   0.25\n",
      "\n",
      "achieves its   0.5\n",
      "\n",
      "<s> svg   0.0007686395080707148\n",
      "\n",
      "the attitude   0.0006920415224913495\n",
      "\n",
      "functions .   0.5\n",
      "\n",
      "get this   0.14285714285714285\n",
      "\n",
      "QA systems   0.2857142857142857\n",
      "\n",
      "US ports   0.14285714285714285\n",
      "\n",
      "steady accumulation   0.5\n",
      "\n",
      "higher degree   0.14285714285714285\n",
      "\n",
      "number of   0.8372093023255814\n",
      "\n",
      "it accepts   0.008547008547008548\n",
      "\n",
      "first evaluation   0.030303030303030304\n",
      "\n",
      "discontinuous ,   0.3333333333333333\n",
      "\n",
      "qualitative automatic   0.5\n",
      "\n",
      "marking up   0.5\n",
      "\n",
      "can effectively   0.0055248618784530384\n",
      "\n",
      "thought or   0.3333333333333333\n",
      "\n",
      "each for   0.022222222222222223\n",
      "\n",
      "<s> By   0.0007686395080707148\n",
      "\n",
      "can of   0.0055248618784530384\n",
      "\n",
      "Confusable Words   1.0\n",
      "\n",
      "the most   0.01314878892733564\n",
      "\n",
      "certain patterns   0.14285714285714285\n",
      "\n",
      "four steps   0.14285714285714285\n",
      "\n",
      "real-valued weights   0.6666666666666666\n",
      "\n",
      "After training   0.3333333333333333\n",
      "\n",
      "relevance theory   0.3333333333333333\n",
      "\n",
      "'' <s/>   0.041237113402061855\n",
      "\n",
      "at lower   0.014705882352941176\n",
      "\n",
      "text summarization   0.006289308176100629\n",
      "\n",
      "students at   0.6666666666666666\n",
      "\n",
      "'s Digest   0.058823529411764705\n",
      "\n",
      "Sync -RRB-   1.0\n",
      "\n",
      "first use   0.030303030303030304\n",
      "\n",
      "time window   0.030303030303030304\n",
      "\n",
      ", Marcus   0.0005614823133071309\n",
      "\n",
      "the first   0.010380622837370242\n",
      "\n",
      "`` Tell   0.005291005291005291\n",
      "\n",
      "-RRB- task-based   0.005420054200542005\n",
      "\n",
      "301 computer   1.0\n",
      "\n",
      "more data   0.021052631578947368\n",
      "\n",
      "they differ   0.025\n",
      "\n",
      "sciences ,   0.5\n",
      "\n",
      "by Pang   0.005714285714285714\n",
      "\n",
      "naturalness .   1.0\n",
      "\n",
      "genetic algorithm   1.0\n",
      "\n",
      "many forms   0.019230769230769232\n",
      "\n",
      "W. G.   0.5\n",
      "\n",
      "it seems   0.008547008547008548\n",
      "\n",
      "a learning   0.00245398773006135\n",
      "\n",
      "by keyphrase   0.005714285714285714\n",
      "\n",
      "method based   0.125\n",
      "\n",
      "DeRose and   0.2\n",
      "\n",
      "following manner   0.06666666666666667\n",
      "\n",
      "unknowns ,   1.0\n",
      "\n",
      "historical data   1.0\n",
      "\n",
      "-LRB- 2004   0.0027100271002710027\n",
      "\n",
      "tag sets   0.25\n",
      "\n",
      "use is   0.013888888888888888\n",
      "\n",
      "intervals like   1.0\n",
      "\n",
      "de l'assignation   0.5\n",
      "\n",
      "as Maximal   0.003484320557491289\n",
      "\n",
      "continued with   0.1111111111111111\n",
      "\n",
      ": Hidden   0.00980392156862745\n",
      "\n",
      "effectively learning   0.3333333333333333\n",
      "\n",
      "use training   0.027777777777777776\n",
      "\n",
      "TextRank and   0.14285714285714285\n",
      "\n",
      "a categorical   0.001226993865030675\n",
      "\n",
      "on sentence   0.0047169811320754715\n",
      "\n",
      "The Association   0.005208333333333333\n",
      "\n",
      "the expectancy   0.0006920415224913495\n",
      "\n",
      "funding has   0.125\n",
      "\n",
      "candidate ,   0.3333333333333333\n",
      "\n",
      "been built   0.014705882352941176\n",
      "\n",
      "text conversion   0.006289308176100629\n",
      "\n",
      "This can   0.015873015873015872\n",
      "\n",
      "text image   0.006289308176100629\n",
      "\n",
      "of problems   0.0017825311942959\n",
      "\n",
      "most widely   0.017241379310344827\n",
      "\n",
      "of 4   0.0017825311942959\n",
      "\n",
      "the Puma   0.0006920415224913495\n",
      "\n",
      "-LRB- Some   0.0027100271002710027\n",
      "\n",
      "It was   0.05263157894736842\n",
      "\n",
      "provides additional   0.5\n",
      "\n",
      "and was   0.001445086705202312\n",
      "\n",
      "and Lao   0.001445086705202312\n",
      "\n",
      "covariance Gaussians   0.5\n",
      "\n",
      "and Intelligent   0.001445086705202312\n",
      "\n",
      "of algorithms   0.00089126559714795\n",
      "\n",
      "generally lend   0.09090909090909091\n",
      "\n",
      "might use   0.07692307692307693\n",
      "\n",
      "vertex for   0.6666666666666666\n",
      "\n",
      "been opinionated   0.014705882352941176\n",
      "\n",
      "the collection   0.0006920415224913495\n",
      "\n",
      "source .   0.041666666666666664\n",
      "\n",
      "be performed   0.008438818565400843\n",
      "\n",
      "efforts based   0.14285714285714285\n",
      "\n",
      "a real   0.00245398773006135\n",
      "\n",
      "be asked   0.004219409282700422\n",
      "\n",
      ", affective   0.0005614823133071309\n",
      "\n",
      "as simple   0.006968641114982578\n",
      "\n",
      "of part-of-speech   0.0017825311942959\n",
      "\n",
      "while the   0.05\n",
      "\n",
      "person to   0.10526315789473684\n",
      "\n",
      "harder to   0.2857142857142857\n",
      "\n",
      "any arbitrary   0.06451612903225806\n",
      "\n",
      "As the   0.05555555555555555\n",
      "\n",
      ", relationship   0.0005614823133071309\n",
      "\n",
      "psycholinguistics ,   0.5\n",
      "\n",
      "in such   0.0056179775280898875\n",
      "\n",
      "making more   0.14285714285714285\n",
      "\n",
      "Intelligence Corporation   0.3333333333333333\n",
      "\n",
      "capital letters   0.3333333333333333\n",
      "\n",
      "recognition ''   0.01652892561983471\n",
      "\n",
      "would look   0.03773584905660377\n",
      "\n",
      "previous training   0.3333333333333333\n",
      "\n",
      "choice is   0.25\n",
      "\n",
      "portable .   0.3333333333333333\n",
      "\n",
      "Why it   0.14285714285714285\n",
      "\n",
      "-LRB- titled   0.0027100271002710027\n",
      "\n",
      "of entities   0.00089126559714795\n",
      "\n",
      "extensive research   0.3333333333333333\n",
      "\n",
      "system involves   0.010752688172043012\n",
      "\n",
      "of words   0.013368983957219251\n",
      "\n",
      "internal organization   0.2\n",
      "\n",
      "University introduced   0.1111111111111111\n",
      "\n",
      "to finding   0.0013280212483399733\n",
      "\n",
      "system used   0.010752688172043012\n",
      "\n",
      "literature are   1.0\n",
      "\n",
      "combined in   0.5\n",
      "\n",
      "aims to   0.6666666666666666\n",
      "\n",
      "had mentioned   0.07142857142857142\n",
      "\n",
      "and required   0.001445086705202312\n",
      "\n",
      "providing a   0.5\n",
      "\n",
      "Callaghan which   1.0\n",
      "\n",
      "sales receipts   0.3333333333333333\n",
      "\n",
      "the periods   0.0006920415224913495\n",
      "\n",
      "the talk   0.0006920415224913495\n",
      "\n",
      "an eyes-busy   0.007575757575757576\n",
      "\n",
      "of negative   0.00089126559714795\n",
      "\n",
      "and form   0.001445086705202312\n",
      "\n",
      "Chinese ,   0.2857142857142857\n",
      "\n",
      "somewhat shallow   0.5\n",
      "\n",
      "<s> LUNAR   0.0007686395080707148\n",
      "\n",
      "data -RRB-   0.03896103896103896\n",
      "\n",
      "<s> Also   0.0023059185242121443\n",
      "\n",
      ", Michael   0.0022459292532285235\n",
      "\n",
      "a significant   0.001226993865030675\n",
      "\n",
      "are generated   0.004149377593360996\n",
      "\n",
      "those human   0.045454545454545456\n",
      "\n",
      "score based   0.16666666666666666\n",
      "\n",
      "& Lehrberger   0.125\n",
      "\n",
      ", Carnegie   0.0005614823133071309\n",
      "\n",
      "proved negligibly   0.3333333333333333\n",
      "\n",
      "have much   0.009615384615384616\n",
      "\n",
      "Dependent ''   1.0\n",
      "\n",
      "correspond to   1.0\n",
      "\n",
      "progress in   0.2857142857142857\n",
      "\n",
      "consistently available   0.3333333333333333\n",
      "\n",
      "was applied   0.012987012987012988\n",
      "\n",
      "decimal point   1.0\n",
      "\n",
      "low agreement   0.3333333333333333\n",
      "\n",
      "garden-path sentences   1.0\n",
      "\n",
      "evaluating automatically   0.2\n",
      "\n",
      "may have   0.038461538461538464\n",
      "\n",
      "In contrast   0.047619047619047616\n",
      "\n",
      "relies on   1.0\n",
      "\n",
      "6 over   0.25\n",
      "\n",
      "Units -LRB-   1.0\n",
      "\n",
      "-RRB- leverages   0.0027100271002710027\n",
      "\n",
      "succession of   1.0\n",
      "\n",
      "tones that   1.0\n",
      "\n",
      "relationship between   0.16666666666666666\n",
      "\n",
      "than polarity   0.022222222222222223\n",
      "\n",
      ", yielding   0.0005614823133071309\n",
      "\n",
      "to publish   0.0013280212483399733\n",
      "\n",
      "improvement by   0.25\n",
      "\n",
      ", weather   0.0005614823133071309\n",
      "\n",
      "deep approach   0.14285714285714285\n",
      "\n",
      "explicit models   0.2\n",
      "\n",
      "adaptive document\\/text   0.3333333333333333\n",
      "\n",
      "Tokens are   1.0\n",
      "\n",
      "in Europe   0.003745318352059925\n",
      "\n",
      "different co-occurring   0.02040816326530612\n",
      "\n",
      "Jump to   1.0\n",
      "\n",
      "his ``   0.08333333333333333\n",
      "\n",
      "is ,   0.018292682926829267\n",
      "\n",
      "<s> Artificial   0.0007686395080707148\n",
      "\n",
      "theoretical underpinnings   0.3333333333333333\n",
      "\n",
      "are keyphrase   0.004149377593360996\n",
      "\n",
      "across their   0.2\n",
      "\n",
      "What should   0.09090909090909091\n",
      "\n",
      "clear that   0.25\n",
      "\n",
      "be weighted   0.004219409282700422\n",
      "\n",
      "as commercial   0.003484320557491289\n",
      "\n",
      "subjects with   1.0\n",
      "\n",
      "OCR products   0.02040816326530612\n",
      "\n",
      "learned on   0.2\n",
      "\n",
      "Closed-domain question   1.0\n",
      "\n",
      "on stochastic   0.0047169811320754715\n",
      "\n",
      "phonetic segments   0.5\n",
      "\n",
      "Jacob Rabinow   1.0\n",
      "\n",
      "Understanding Conferences   0.5\n",
      "\n",
      "found recognition   0.07142857142857142\n",
      "\n",
      "do .   0.038461538461538464\n",
      "\n",
      ", Harvey   0.0005614823133071309\n",
      "\n",
      ", probabilities   0.0005614823133071309\n",
      "\n",
      "will replace   0.02857142857142857\n",
      "\n",
      "precise ones   0.3333333333333333\n",
      "\n",
      "Some current   0.09523809523809523\n",
      "\n",
      "rank ,   0.16666666666666666\n",
      "\n",
      "commercial .   0.09090909090909091\n",
      "\n",
      "-LRB- especially   0.005420054200542005\n",
      "\n",
      "techniques can   0.043478260869565216\n",
      "\n",
      "; it   0.02127659574468085\n",
      "\n",
      "<s> See   0.0007686395080707148\n",
      "\n",
      "collections vary   0.25\n",
      "\n",
      "e.g. Chinese   0.017857142857142856\n",
      "\n",
      "keywords ,   0.5\n",
      "\n",
      "security process   1.0\n",
      "\n",
      "location ,   1.0\n",
      "\n",
      "sometimes ,   0.07692307692307693\n",
      "\n",
      "Current research   0.2\n",
      "\n",
      "of extractive   0.00089126559714795\n",
      "\n",
      "generated by   0.06666666666666667\n",
      "\n",
      "the hidden   0.0006920415224913495\n",
      "\n",
      "the geological   0.0006920415224913495\n",
      "\n",
      "new token   0.041666666666666664\n",
      "\n",
      "intended semantic   0.2\n",
      "\n",
      "to explicitly   0.0026560424966799467\n",
      "\n",
      "to customize   0.0026560424966799467\n",
      "\n",
      "the basics   0.0006920415224913495\n",
      "\n",
      "but article   0.014705882352941176\n",
      "\n",
      "sentence -RRB-   0.041666666666666664\n",
      "\n",
      "frequency -LRB-   0.5\n",
      "\n",
      "expansion .   0.3333333333333333\n",
      "\n",
      "final phase   0.1111111111111111\n",
      "\n",
      "actual forecast   0.2\n",
      "\n",
      "considerably from   1.0\n",
      "\n",
      "essential difference   1.0\n",
      "\n",
      "the expectations   0.0006920415224913495\n",
      "\n",
      "<s> Short   0.0007686395080707148\n",
      "\n",
      "to unsupervised   0.0026560424966799467\n",
      "\n",
      "Lakoff ,   1.0\n",
      "\n",
      "Jabberwacky .   1.0\n",
      "\n",
      "'s SPHINX   0.0196078431372549\n",
      "\n",
      "<s> -LRB-   0.014604150653343582\n",
      "\n",
      "on statistical   0.009433962264150943\n",
      "\n",
      "culture of   1.0\n",
      "\n",
      "classification of   0.058823529411764705\n",
      "\n",
      "are less   0.004149377593360996\n",
      "\n",
      "to translate   0.00398406374501992\n",
      "\n",
      "about 1,000,000   0.025\n",
      "\n",
      "only at   0.02631578947368421\n",
      "\n",
      "see Inter-rater   0.05\n",
      "\n",
      "committed into   1.0\n",
      "\n",
      "strength at   0.2\n",
      "\n",
      "views as   1.0\n",
      "\n",
      "playing in   1.0\n",
      "\n",
      "like Japanese   0.03571428571428571\n",
      "\n",
      "indirect left-recursion   1.0\n",
      "\n",
      "preferred computer-generated   1.0\n",
      "\n",
      "as information   0.003484320557491289\n",
      "\n",
      "an attractive   0.007575757575757576\n",
      "\n",
      "<s> Competing   0.0007686395080707148\n",
      "\n",
      ", opening   0.0005614823133071309\n",
      "\n",
      "milliseconds .   0.5\n",
      "\n",
      "are maximum   0.004149377593360996\n",
      "\n",
      "lexical functional   0.07692307692307693\n",
      "\n",
      "classify properly   0.5\n",
      "\n",
      "contains additional   0.1\n",
      "\n",
      "polarity and   0.125\n",
      "\n",
      "musical notations   1.0\n",
      "\n",
      "engine page   0.16666666666666666\n",
      "\n",
      "determine which   0.08695652173913043\n",
      "\n",
      "parsing concatenated   0.03571428571428571\n",
      "\n",
      "large set   0.043478260869565216\n",
      "\n",
      "dissertation .   0.3333333333333333\n",
      "\n",
      "`` look   0.005291005291005291\n",
      "\n",
      ", emoticons   0.0005614823133071309\n",
      "\n",
      "the derived   0.0006920415224913495\n",
      "\n",
      "notion of   0.75\n",
      "\n",
      ": Why   0.00980392156862745\n",
      "\n",
      "contains no   0.1\n",
      "\n",
      "appropriate number   0.25\n",
      "\n",
      "Vito Technology   1.0\n",
      "\n",
      "has not   0.023809523809523808\n",
      "\n",
      "within the   0.16666666666666666\n",
      "\n",
      "Cohesion and   1.0\n",
      "\n",
      "examples produces   0.041666666666666664\n",
      "\n",
      "ranging from   1.0\n",
      "\n",
      "by Makoto   0.005714285714285714\n",
      "\n",
      "this genre   0.01098901098901099\n",
      "\n",
      "locate the   1.0\n",
      "\n",
      "or topics   0.0045045045045045045\n",
      "\n",
      "remains the   0.25\n",
      "\n",
      "says phrases   1.0\n",
      "\n",
      "scripts ,   0.3333333333333333\n",
      "\n",
      "reporting on   0.3333333333333333\n",
      "\n",
      "Results have   1.0\n",
      "\n",
      "feature\\/aspect-based sentiment   1.0\n",
      "\n",
      "du discors   1.0\n",
      "\n",
      "from speech   0.009615384615384616\n",
      "\n",
      "the sequences   0.0006920415224913495\n",
      "\n",
      "probabilistic decisions   0.2857142857142857\n",
      "\n",
      "all perform   0.023255813953488372\n",
      "\n",
      "of pilot   0.00089126559714795\n",
      "\n",
      "part of   0.8148148148148148\n",
      "\n",
      "for training   0.010830324909747292\n",
      "\n",
      "for evaluating   0.010830324909747292\n",
      "\n",
      "to consult   0.0013280212483399733\n",
      "\n",
      "in which   0.0149812734082397\n",
      "\n",
      "correlate best   0.3333333333333333\n",
      "\n",
      "pro or   1.0\n",
      "\n",
      "to summarization   0.0026560424966799467\n",
      "\n",
      "As businesses   0.05555555555555555\n",
      "\n",
      "language model   0.006756756756756757\n",
      "\n",
      "l'assignation des   1.0\n",
      "\n",
      ", linear-time   0.0005614823133071309\n",
      "\n",
      "in e-communities   0.0018726591760299626\n",
      "\n",
      "collecting a   1.0\n",
      "\n",
      "extremes ,   1.0\n",
      "\n",
      "effort ,   0.25\n",
      "\n",
      "deep parsing   0.14285714285714285\n",
      "\n",
      ", stochastic   0.0005614823133071309\n",
      "\n",
      "worldwide view   1.0\n",
      "\n",
      "specially designed   1.0\n",
      "\n",
      "computer based   0.022727272727272728\n",
      "\n",
      "from first   0.009615384615384616\n",
      "\n",
      "<s> Large-scale   0.0007686395080707148\n",
      "\n",
      "whole .   0.1111111111111111\n",
      "\n",
      "audio ,   1.0\n",
      "\n",
      ", discourse   0.0005614823133071309\n",
      "\n",
      "industry .   0.3333333333333333\n",
      "\n",
      "Harris ,   0.1111111111111111\n",
      "\n",
      "There is   0.2727272727272727\n",
      "\n",
      "on programer   0.0047169811320754715\n",
      "\n",
      "and Janet   0.001445086705202312\n",
      "\n",
      "that transcended   0.0035460992907801418\n",
      "\n",
      "`` breadth   0.005291005291005291\n",
      "\n",
      "blogs and   0.5\n",
      "\n",
      "<s> Unsourced   0.0007686395080707148\n",
      "\n",
      "mining of   0.2\n",
      "\n",
      "Critical discourse   0.5\n",
      "\n",
      "league over   1.0\n",
      "\n",
      "article :   0.4482758620689655\n",
      "\n",
      "global '   0.3333333333333333\n",
      "\n",
      "see wide   0.05\n",
      "\n",
      ": lessons   0.00980392156862745\n",
      "\n",
      "selects the   0.5\n",
      "\n",
      "processing :   0.018518518518518517\n",
      "\n",
      "role in   0.25\n",
      "\n",
      "to densely   0.0013280212483399733\n",
      "\n",
      "language to   0.02702702702702703\n",
      "\n",
      "posed in   0.6666666666666666\n",
      "\n",
      "available and   0.058823529411764705\n",
      "\n",
      "vector .   0.3333333333333333\n",
      "\n",
      "waves are   0.14285714285714285\n",
      "\n",
      "achieved by   0.2\n",
      "\n",
      "conditions .   0.2\n",
      "\n",
      "errors -LRB-   0.4\n",
      "\n",
      "in ASR   0.003745318352059925\n",
      "\n",
      "Back-End or   1.0\n",
      "\n",
      "out other   0.07142857142857142\n",
      "\n",
      "Language ,   0.08333333333333333\n",
      "\n",
      "<s> There   0.006917755572636433\n",
      "\n",
      "of Speaker   0.00089126559714795\n",
      "\n",
      "it proved   0.008547008547008548\n",
      "\n",
      "and sentences   0.002890173410404624\n",
      "\n",
      "and -RRB-   0.001445086705202312\n",
      "\n",
      "determining the   0.6666666666666666\n",
      "\n",
      "real human   0.1111111111111111\n",
      "\n",
      "consider a   0.25\n",
      "\n",
      "the Wall   0.001384083044982699\n",
      "\n",
      "Aerospace -LRB-   0.5\n",
      "\n",
      "and combine   0.001445086705202312\n",
      "\n",
      "A series   0.02\n",
      "\n",
      "basics and   1.0\n",
      "\n",
      "disruptive to   1.0\n",
      "\n",
      "the feature\\/aspect-based   0.0006920415224913495\n",
      "\n",
      "for identifying   0.0036101083032490976\n",
      "\n",
      "Training air   0.5\n",
      "\n",
      "Realisation :   1.0\n",
      "\n",
      "though automating   0.1\n",
      "\n",
      "with only   0.00546448087431694\n",
      "\n",
      "it about   0.008547008547008548\n",
      "\n",
      "requires one   0.0625\n",
      "\n",
      "the technology   0.0006920415224913495\n",
      "\n",
      "analysis Variation   0.015384615384615385\n",
      "\n",
      "translation tasks   0.013513513513513514\n",
      "\n",
      "<s> Modern   0.0007686395080707148\n",
      "\n",
      "systems included   0.008928571428571428\n",
      "\n",
      "inter-texual ones   0.5\n",
      "\n",
      "clear imaging   0.25\n",
      "\n",
      "UC -RRB-   0.5\n",
      "\n",
      ", 1975   0.0005614823133071309\n",
      "\n",
      "MAHS =   1.0\n",
      "\n",
      "Turn around   1.0\n",
      "\n",
      "teach that   1.0\n",
      "\n",
      "heuristic to   0.3333333333333333\n",
      "\n",
      "Initial results   1.0\n",
      "\n",
      "word and   0.016666666666666666\n",
      "\n",
      "best application   0.05555555555555555\n",
      "\n",
      "be as   0.012658227848101266\n",
      "\n",
      "In common   0.009523809523809525\n",
      "\n",
      "your system   0.5\n",
      "\n",
      "consumed from   1.0\n",
      "\n",
      "when a   0.11428571428571428\n",
      "\n",
      "<s> Isolated   0.0007686395080707148\n",
      "\n",
      "the emotional   0.001384083044982699\n",
      "\n",
      "prove impossible   1.0\n",
      "\n",
      "<s> Digitized   0.0007686395080707148\n",
      "\n",
      "relevance or   0.3333333333333333\n",
      "\n",
      "unique and   1.0\n",
      "\n",
      "The NIST   0.005208333333333333\n",
      "\n",
      "among humans   0.125\n",
      "\n",
      "the schematic   0.0006920415224913495\n",
      "\n",
      ", Brazil   0.0005614823133071309\n",
      "\n",
      "on .   0.018867924528301886\n",
      "\n",
      "parties du   1.0\n",
      "\n",
      "Monroe and   1.0\n",
      "\n",
      "An increasing   0.0625\n",
      "\n",
      "simple demonstrations   0.038461538461538464\n",
      "\n",
      "the EHR   0.0006920415224913495\n",
      "\n",
      "does not   0.5\n",
      "\n",
      "ATC -RRB-   0.2\n",
      "\n",
      "typically the   0.05555555555555555\n",
      "\n",
      "an easier   0.007575757575757576\n",
      "\n",
      "`` semi-supervised   0.005291005291005291\n",
      "\n",
      "2500 articles   1.0\n",
      "\n",
      "following words   0.06666666666666667\n",
      "\n",
      "which showed   0.007246376811594203\n",
      "\n",
      ", document   0.0005614823133071309\n",
      "\n",
      "the content   0.0020761245674740486\n",
      "\n",
      "clearly visible   0.3333333333333333\n",
      "\n",
      "quite high   0.125\n",
      "\n",
      "search corpus   0.09090909090909091\n",
      "\n",
      "real difference   0.1111111111111111\n",
      "\n",
      "the cosine   0.0006920415224913495\n",
      "\n",
      "a dissertation   0.001226993865030675\n",
      "\n",
      "approaches have   0.07142857142857142\n",
      "\n",
      "A subtask   0.02\n",
      "\n",
      ", explanation   0.0005614823133071309\n",
      "\n",
      "dramatically reduced   1.0\n",
      "\n",
      "Each sample   0.16666666666666666\n",
      "\n",
      "other disciplines   0.014285714285714285\n",
      "\n",
      "not used   0.017857142857142856\n",
      "\n",
      "news domain   0.23076923076923078\n",
      "\n",
      "values to   0.125\n",
      "\n",
      ": Stemming   0.00980392156862745\n",
      "\n",
      "attained .   1.0\n",
      "\n",
      "assessing whether   1.0\n",
      "\n",
      "-RRB- Transcription   0.0027100271002710027\n",
      "\n",
      "gained surprising   0.5\n",
      "\n",
      "used by   0.07964601769911504\n",
      "\n",
      "sequences of   0.3333333333333333\n",
      "\n",
      "other domains   0.014285714285714285\n",
      "\n",
      "one can   0.015384615384615385\n",
      "\n",
      "metamodel and   1.0\n",
      "\n",
      "also refer   0.014492753623188406\n",
      "\n",
      "a reasonable   0.00245398773006135\n",
      "\n",
      "Brenton D.   1.0\n",
      "\n",
      "information can   0.021739130434782608\n",
      "\n",
      "have taken   0.009615384615384616\n",
      "\n",
      "merges highly   1.0\n",
      "\n",
      "nautical term   0.5\n",
      "\n",
      "Harold Garfinkel   1.0\n",
      "\n",
      "devoted in   0.2\n",
      "\n",
      ", false   0.0005614823133071309\n",
      "\n",
      "power The   0.25\n",
      "\n",
      "walking patterns   0.3333333333333333\n",
      "\n",
      "a system   0.012269938650306749\n",
      "\n",
      "or dimensions   0.0045045045045045045\n",
      "\n",
      "answering deals   0.16666666666666666\n",
      "\n",
      "mental representations   0.3333333333333333\n",
      "\n",
      "and retrieving   0.001445086705202312\n",
      "\n",
      "possible semantics   0.041666666666666664\n",
      "\n",
      "OCR machines   0.02040816326530612\n",
      "\n",
      "essentially perfectly   0.125\n",
      "\n",
      "More recently   0.1111111111111111\n",
      "\n",
      "The model   0.005208333333333333\n",
      "\n",
      "billion words   1.0\n",
      "\n",
      "within documents   0.05555555555555555\n",
      "\n",
      "error-prone and   1.0\n",
      "\n",
      "video ,   0.2\n",
      "\n",
      "Robotics Speech-to-text   1.0\n",
      "\n",
      "noun reading   0.07142857142857142\n",
      "\n",
      "simulation is   0.3333333333333333\n",
      "\n",
      "output ,   0.038461538461538464\n",
      "\n",
      "The Unicode   0.005208333333333333\n",
      "\n",
      "out in   0.14285714285714285\n",
      "\n",
      "in use   0.003745318352059925\n",
      "\n",
      "into battle   0.01282051282051282\n",
      "\n",
      "sentence position   0.041666666666666664\n",
      "\n",
      "includes mainly   0.14285714285714285\n",
      "\n",
      "printed by   0.08333333333333333\n",
      "\n",
      "begin and   0.3333333333333333\n",
      "\n",
      "classifier that   0.14285714285714285\n",
      "\n",
      "semantic lexicons   0.047619047619047616\n",
      "\n",
      "window of   1.0\n",
      "\n",
      "Command Success   0.5\n",
      "\n",
      "barmaid ''   0.3333333333333333\n",
      "\n",
      "those two   0.045454545454545456\n",
      "\n",
      "by Environment   0.005714285714285714\n",
      "\n",
      "for single   0.0036101083032490976\n",
      "\n",
      "paper data   0.09090909090909091\n",
      "\n",
      "Force for   0.5\n",
      "\n",
      "Symbian and   1.0\n",
      "\n",
      "state transducer   0.14285714285714285\n",
      "\n",
      "a rules   0.001226993865030675\n",
      "\n",
      "corresponding to   0.3333333333333333\n",
      "\n",
      "past the   0.3333333333333333\n",
      "\n",
      "the overriding   0.0006920415224913495\n",
      "\n",
      "misspelled words   1.0\n",
      "\n",
      "to physicians   0.0013280212483399733\n",
      "\n",
      "are already   0.004149377593360996\n",
      "\n",
      "media has   0.16666666666666666\n",
      "\n",
      "are two   0.008298755186721992\n",
      "\n",
      ", its   0.0005614823133071309\n",
      "\n",
      "state -RRB-   0.07142857142857142\n",
      "\n",
      "also granted   0.014492753623188406\n",
      "\n",
      "weak ,   1.0\n",
      "\n",
      "include an   0.07407407407407407\n",
      "\n",
      "speaker ,   0.05555555555555555\n",
      "\n",
      "systems explore   0.008928571428571428\n",
      "\n",
      "specific letter   0.047619047619047616\n",
      "\n",
      "narrative text   1.0\n",
      "\n",
      "The reader   0.005208333333333333\n",
      "\n",
      "the financial   0.0006920415224913495\n",
      "\n",
      "conceptual dependency   0.5\n",
      "\n",
      "<s> That   0.0023059185242121443\n",
      "\n",
      "as machine   0.003484320557491289\n",
      "\n",
      "many programmers   0.019230769230769232\n",
      "\n",
      "target-language-independent representation   1.0\n",
      "\n",
      "Products ,   0.5\n",
      "\n",
      "most likely   0.05172413793103448\n",
      "\n",
      "to start   0.0026560424966799467\n",
      "\n",
      "<s> Topics   0.0007686395080707148\n",
      "\n",
      "thanks to   1.0\n",
      "\n",
      "the textual   0.0006920415224913495\n",
      "\n",
      "that most   0.0035460992907801418\n",
      "\n",
      "usually in   0.09375\n",
      "\n",
      "closed-domain might   1.0\n",
      "\n",
      "analyst is   1.0\n",
      "\n",
      "become well   0.25\n",
      "\n",
      "Nuance Communications   0.6666666666666666\n",
      "\n",
      "are then   0.004149377593360996\n",
      "\n",
      "`` black   0.005291005291005291\n",
      "\n",
      "installed defective   0.3333333333333333\n",
      "\n",
      "-RRB- that   0.005420054200542005\n",
      "\n",
      "same problem   0.04\n",
      "\n",
      "different ones   0.02040816326530612\n",
      "\n",
      "character .   0.045454545454545456\n",
      "\n",
      "the boundaries   0.0020761245674740486\n",
      "\n",
      "natural and   0.02666666666666667\n",
      "\n",
      "As well   0.05555555555555555\n",
      "\n",
      "camp with   0.5\n",
      "\n",
      "to produce   0.013280212483399735\n",
      "\n",
      "avoiding some   0.5\n",
      "\n",
      "computer input   0.022727272727272728\n",
      "\n",
      "word sequences   0.016666666666666666\n",
      "\n",
      "<s> Winograd   0.0007686395080707148\n",
      "\n",
      "the 1970s   0.0006920415224913495\n",
      "\n",
      "purpose of   0.2\n",
      "\n",
      "spelled `   1.0\n",
      "\n",
      "both use   0.03225806451612903\n",
      "\n",
      "combining it   0.25\n",
      "\n",
      "' is   0.05263157894736842\n",
      "\n",
      "many similar   0.019230769230769232\n",
      "\n",
      "for plural   0.0036101083032490976\n",
      "\n",
      "& Hollenbach   0.125\n",
      "\n",
      "supervised machine   0.0625\n",
      "\n",
      "summary sentences   0.023809523809523808\n",
      "\n",
      "create a   0.4117647058823529\n",
      "\n",
      "opinion in   0.4\n",
      "\n",
      "the equivalent   0.0006920415224913495\n",
      "\n",
      "Jonathan Potter   1.0\n",
      "\n",
      "first choice   0.030303030303030304\n",
      "\n",
      "page ,   0.42857142857142855\n",
      "\n",
      "system comprising   0.010752688172043012\n",
      "\n",
      "where successively   0.02857142857142857\n",
      "\n",
      "be modified   0.004219409282700422\n",
      "\n",
      "speech -LRB-   0.02631578947368421\n",
      "\n",
      "judge fluency   0.25\n",
      "\n",
      "right ,   0.1\n",
      "\n",
      "alphabet are   0.3333333333333333\n",
      "\n",
      "an arbitrarily   0.007575757575757576\n",
      "\n",
      "studies of   0.25\n",
      "\n",
      "is likely   0.006097560975609756\n",
      "\n",
      "would like   0.03773584905660377\n",
      "\n",
      "conducted the   0.2\n",
      "\n",
      "in general   0.009363295880149813\n",
      "\n",
      "continuous recognition   0.16666666666666666\n",
      "\n",
      "and count   0.001445086705202312\n",
      "\n",
      "progress and   0.14285714285714285\n",
      "\n",
      "picture above   0.25\n",
      "\n",
      "both research   0.03225806451612903\n",
      "\n",
      "techniques merely   0.043478260869565216\n",
      "\n",
      "may also   0.019230769230769232\n",
      "\n",
      "recent developments   0.125\n",
      "\n",
      "not new   0.008928571428571428\n",
      "\n",
      "children 's   0.5\n",
      "\n",
      "evaluated in   0.14285714285714285\n",
      "\n",
      "abstracts or   0.5\n",
      "\n",
      "negative sentiment   0.125\n",
      "\n",
      "characters themselves   0.0625\n",
      "\n",
      "legends and   1.0\n",
      "\n",
      "where particular   0.02857142857142857\n",
      "\n",
      "for this   0.018050541516245487\n",
      "\n",
      "notably to   0.3333333333333333\n",
      "\n",
      "<s> Jump   0.0007686395080707148\n",
      "\n",
      "carefully design   1.0\n",
      "\n",
      "communication radios   0.2\n",
      "\n",
      "and easily   0.001445086705202312\n",
      "\n",
      "analysis :   0.06153846153846154\n",
      "\n",
      "and making   0.002890173410404624\n",
      "\n",
      "a relaxed   0.001226993865030675\n",
      "\n",
      "made up   0.0625\n",
      "\n",
      "count of   0.4\n",
      "\n",
      "been made   0.014705882352941176\n",
      "\n",
      "In 1929   0.009523809523809525\n",
      "\n",
      "who is   0.2\n",
      "\n",
      "with 17   0.00546448087431694\n",
      "\n",
      "assignment .   0.5\n",
      "\n",
      "smoothly with   0.5\n",
      "\n",
      "accurate even   0.14285714285714285\n",
      "\n",
      "many artificial   0.019230769230769232\n",
      "\n",
      "or 4-gram   0.0045045045045045045\n",
      "\n",
      ", DeRose   0.0005614823133071309\n",
      "\n",
      "the expected   0.001384083044982699\n",
      "\n",
      "the CKY   0.0006920415224913495\n",
      "\n",
      "word error   0.016666666666666666\n",
      "\n",
      "the Parliament   0.0006920415224913495\n",
      "\n",
      "Some speech   0.047619047619047616\n",
      "\n",
      "explanation ,   1.0\n",
      "\n",
      "Brill tagger   0.3333333333333333\n",
      "\n",
      "use ,   0.05555555555555555\n",
      "\n",
      ", leading   0.0005614823133071309\n",
      "\n",
      "Gail Jefferson   1.0\n",
      "\n",
      "an F-score   0.007575757575757576\n",
      "\n",
      "spaces of   0.2\n",
      "\n",
      "-LRB- so   0.005420054200542005\n",
      "\n",
      "linear transform   0.14285714285714285\n",
      "\n",
      "approach used   0.02857142857142857\n",
      "\n",
      "suitable department   0.25\n",
      "\n",
      ", pronunciation   0.0005614823133071309\n",
      "\n",
      "-LRB- one   0.0027100271002710027\n",
      "\n",
      "Tagging Guidelines   1.0\n",
      "\n",
      "and time-consuming   0.001445086705202312\n",
      "\n",
      "to paper-intensive   0.0013280212483399733\n",
      "\n",
      "of taking   0.00089126559714795\n",
      "\n",
      "about the   0.2\n",
      "\n",
      "that part   0.0035460992907801418\n",
      "\n",
      "might ask   0.038461538461538464\n",
      "\n",
      "the issue   0.002768166089965398\n",
      "\n",
      "approximation was   0.16666666666666666\n",
      "\n",
      "has the   0.023809523809523808\n",
      "\n",
      "canned phrases   0.5\n",
      "\n",
      "NLG output   0.047619047619047616\n",
      "\n",
      "agglutinative languages   1.0\n",
      "\n",
      "Foucault became   0.3333333333333333\n",
      "\n",
      "larger summarization   0.0625\n",
      "\n",
      "morphemes and   0.3333333333333333\n",
      "\n",
      "MLLT -RRB-   1.0\n",
      "\n",
      "parameters related   0.25\n",
      "\n",
      "detected ,   0.5\n",
      "\n",
      ", various   0.0005614823133071309\n",
      "\n",
      "pre-defined by   0.5\n",
      "\n",
      "summary tackles   0.023809523809523808\n",
      "\n",
      "major influence   0.08333333333333333\n",
      "\n",
      "these systems   0.11904761904761904\n",
      "\n",
      "and social   0.004335260115606936\n",
      "\n",
      "limited in   0.1\n",
      "\n",
      "two steps   0.034482758620689655\n",
      "\n",
      "are content   0.004149377593360996\n",
      "\n",
      "more times   0.010526315789473684\n",
      "\n",
      "using either   0.01694915254237288\n",
      "\n",
      "content -LRB-   0.08333333333333333\n",
      "\n",
      "a basic   0.00245398773006135\n",
      "\n",
      "Types of   1.0\n",
      "\n",
      "generate weather   0.05555555555555555\n",
      "\n",
      "that Piron   0.0035460992907801418\n",
      "\n",
      "in another   0.00749063670411985\n",
      "\n",
      "discussion of   0.5\n",
      "\n",
      "sentences -RRB-   0.02631578947368421\n",
      "\n",
      "R. Howarth   0.16666666666666666\n",
      "\n",
      ", largely   0.0005614823133071309\n",
      "\n",
      "decisions --   0.1\n",
      "\n",
      "after ,   0.08333333333333333\n",
      "\n",
      "standard table   0.07142857142857142\n",
      "\n",
      "that might   0.0070921985815602835\n",
      "\n",
      "entirely and   0.5\n",
      "\n",
      "a linguistic   0.00245398773006135\n",
      "\n",
      "the ambiguous   0.001384083044982699\n",
      "\n",
      "or paragraphs   0.009009009009009009\n",
      "\n",
      "computers -RRB-   0.1111111111111111\n",
      "\n",
      "retrieval results   0.14285714285714285\n",
      "\n",
      ", these   0.0011229646266142617\n",
      "\n",
      "little any   0.3333333333333333\n",
      "\n",
      "found .   0.07142857142857142\n",
      "\n",
      "orally speaking   1.0\n",
      "\n",
      "measure one   0.09090909090909091\n",
      "\n",
      "longer sentences   1.0\n",
      "\n",
      "slot represents   1.0\n",
      "\n",
      "time step   0.030303030303030304\n",
      "\n",
      "as discussions   0.003484320557491289\n",
      "\n",
      "further clues   0.125\n",
      "\n",
      "grouped into   0.5\n",
      "\n",
      "spoke the   1.0\n",
      "\n",
      ", 4   0.0005614823133071309\n",
      "\n",
      "are confirmed   0.004149377593360996\n",
      "\n",
      "characteristics of   0.5\n",
      "\n",
      ": Content   0.00980392156862745\n",
      "\n",
      "with some   0.02185792349726776\n",
      "\n",
      "there as   0.025\n",
      "\n",
      "machine processes   0.012658227848101266\n",
      "\n",
      "simultaneously with   0.5\n",
      "\n",
      "address -   0.25\n",
      "\n",
      "study language   0.25\n",
      "\n",
      "than precision   0.022222222222222223\n",
      "\n",
      "time factor   0.030303030303030304\n",
      "\n",
      "products in   0.25\n",
      "\n",
      "same column   0.04\n",
      "\n",
      "a relic   0.001226993865030675\n",
      "\n",
      "with low   0.00546448087431694\n",
      "\n",
      "see and   0.05\n",
      "\n",
      "Specifically ,   1.0\n",
      "\n",
      "quantities of   0.6666666666666666\n",
      "\n",
      "limited number   0.2\n",
      "\n",
      "modeling of   0.14285714285714285\n",
      "\n",
      "of estimating   0.00089126559714795\n",
      "\n",
      "information about   0.043478260869565216\n",
      "\n",
      "commercial systems   0.09090909090909091\n",
      "\n",
      "abbreviation ,   0.5\n",
      "\n",
      "items .   0.5\n",
      "\n",
      "-LRB- transcription   0.0027100271002710027\n",
      "\n",
      "and Pang   0.001445086705202312\n",
      "\n",
      "disambiguation ,   0.1\n",
      "\n",
      ", Margaret   0.0005614823133071309\n",
      "\n",
      "Some notably   0.047619047619047616\n",
      "\n",
      "contextual or   0.5\n",
      "\n",
      "only of   0.02631578947368421\n",
      "\n",
      "understanding or   0.030303030303030304\n",
      "\n",
      "editing the   0.5\n",
      "\n",
      "data ,   0.12987012987012986\n",
      "\n",
      "a podcast   0.001226993865030675\n",
      "\n",
      "result in   0.09090909090909091\n",
      "\n",
      "summaries is   0.06976744186046512\n",
      "\n",
      "simpler questions   0.3333333333333333\n",
      "\n",
      "number on   0.023255813953488372\n",
      "\n",
      "most authoritative   0.017241379310344827\n",
      "\n",
      "entropy model   0.2\n",
      "\n",
      "Willig ,   1.0\n",
      "\n",
      "describe the   0.3333333333333333\n",
      "\n",
      "arranged hierarchically   1.0\n",
      "\n",
      "of international   0.00089126559714795\n",
      "\n",
      "schematic organization   1.0\n",
      "\n",
      "expressed with   0.16666666666666666\n",
      "\n",
      "either an   0.1\n",
      "\n",
      "recognize text   0.1111111111111111\n",
      "\n",
      "stability in   1.0\n",
      "\n",
      "similar measure   0.037037037037037035\n",
      "\n",
      "phrase begin   0.1\n",
      "\n",
      "of cepstral   0.00089126559714795\n",
      "\n",
      "In many   0.01904761904761905\n",
      "\n",
      "interfaces such   0.5\n",
      "\n",
      "all written   0.06976744186046512\n",
      "\n",
      "that larger   0.0035460992907801418\n",
      "\n",
      "of top-down   0.0017825311942959\n",
      "\n",
      "getting into   0.25\n",
      "\n",
      "many person-years   0.019230769230769232\n",
      "\n",
      "strong and   0.25\n",
      "\n",
      "bilingual text   0.5\n",
      "\n",
      "can identify   0.0055248618784530384\n",
      "\n",
      ", conjunction   0.0005614823133071309\n",
      "\n",
      "includes both   0.14285714285714285\n",
      "\n",
      "Deese ,   1.0\n",
      "\n",
      "appends the   1.0\n",
      "\n",
      "and report   0.001445086705202312\n",
      "\n",
      "house through   0.5\n",
      "\n",
      "businesses look   0.5\n",
      "\n",
      "provides for   0.5\n",
      "\n",
      "'s intrinsic   0.0196078431372549\n",
      "\n",
      "summary might   0.023809523809523808\n",
      "\n",
      "nice '   0.25\n",
      "\n",
      "person 's   0.21052631578947367\n",
      "\n",
      "world .   0.13333333333333333\n",
      "\n",
      "objective document   0.2\n",
      "\n",
      "ideas in   0.5\n",
      "\n",
      "De Guzman   1.0\n",
      "\n",
      "section of   0.16666666666666666\n",
      "\n",
      "in predicate   0.0018726591760299626\n",
      "\n",
      "binary judgement   0.25\n",
      "\n",
      "been taken   0.014705882352941176\n",
      "\n",
      "other aspects   0.014285714285714285\n",
      "\n",
      "help in   0.1111111111111111\n",
      "\n",
      "universal language   0.3333333333333333\n",
      "\n",
      "recognize speech   0.1111111111111111\n",
      "\n",
      "and commercial   0.001445086705202312\n",
      "\n",
      "skew ,   1.0\n",
      "\n",
      "represent analog   0.1111111111111111\n",
      "\n",
      "English prose   0.02702702702702703\n",
      "\n",
      "involves both   0.1\n",
      "\n",
      "naturally occurring   0.5\n",
      "\n",
      "answering The   0.08333333333333333\n",
      "\n",
      "also require   0.014492753623188406\n",
      "\n",
      "is steered   0.0020325203252032522\n",
      "\n",
      "are averaged   0.004149377593360996\n",
      "\n",
      "Bell Telephone   1.0\n",
      "\n",
      "informal exchange   0.5\n",
      "\n",
      ", Gender   0.0005614823133071309\n",
      "\n",
      "based therapy   0.018518518518518517\n",
      "\n",
      "features are   0.11538461538461539\n",
      "\n",
      "elements ,   0.25\n",
      "\n",
      "the ROUGE-1   0.0006920415224913495\n",
      "\n",
      "Guidelines for   0.5\n",
      "\n",
      "the UC   0.0006920415224913495\n",
      "\n",
      "In part-of-speech   0.009523809523809525\n",
      "\n",
      "ambiguity of   0.125\n",
      "\n",
      "values for   0.125\n",
      "\n",
      "interactions between   1.0\n",
      "\n",
      "More up   0.1111111111111111\n",
      "\n",
      "'s Stilstudien   0.0196078431372549\n",
      "\n",
      "from ,   0.009615384615384616\n",
      "\n",
      "the industry   0.0006920415224913495\n",
      "\n",
      "and memory   0.001445086705202312\n",
      "\n",
      "were then   0.024390243902439025\n",
      "\n",
      "NLP using   0.02127659574468085\n",
      "\n",
      "limit to   0.25\n",
      "\n",
      "of printed   0.0017825311942959\n",
      "\n",
      "we ultimately   0.022222222222222223\n",
      "\n",
      "must appear   0.07142857142857142\n",
      "\n",
      "CyberEmotions project   1.0\n",
      "\n",
      "as semantic   0.003484320557491289\n",
      "\n",
      "coherent and   0.2\n",
      "\n",
      "Main article   1.0\n",
      "\n",
      "or classified   0.0045045045045045045\n",
      "\n",
      "where formal   0.02857142857142857\n",
      "\n",
      "recent book   0.125\n",
      "\n",
      "on both   0.0047169811320754715\n",
      "\n",
      ", see   0.0011229646266142617\n",
      "\n",
      ", matching   0.0005614823133071309\n",
      "\n",
      ", Why   0.0005614823133071309\n",
      "\n",
      "design and   0.25\n",
      "\n",
      "application has   0.07142857142857142\n",
      "\n",
      "choices Designing   0.2\n",
      "\n",
      "we need   0.13333333333333333\n",
      "\n",
      "developing new   0.25\n",
      "\n",
      "variability ,   1.0\n",
      "\n",
      "cases where   0.16666666666666666\n",
      "\n",
      ", sociolinguistics   0.0005614823133071309\n",
      "\n",
      "quantitative approaches   0.25\n",
      "\n",
      "the ALPAC   0.001384083044982699\n",
      "\n",
      "but could   0.014705882352941176\n",
      "\n",
      "a part   0.00245398773006135\n",
      "\n",
      "be robust   0.004219409282700422\n",
      "\n",
      "1989 -RRB-   0.5\n",
      "\n",
      "reader .   0.2\n",
      "\n",
      "processing and   0.018518518518518517\n",
      "\n",
      "The CyberEmotions   0.005208333333333333\n",
      "\n",
      "group developed   0.25\n",
      "\n",
      "descriptive rather   0.3333333333333333\n",
      "\n",
      "RAE -RRB-   1.0\n",
      "\n",
      "grammar which   0.05405405405405406\n",
      "\n",
      "-RRB- tagger   0.0027100271002710027\n",
      "\n",
      "writing systems   0.2222222222222222\n",
      "\n",
      "often allows   0.022727272727272728\n",
      "\n",
      "may happen   0.019230769230769232\n",
      "\n",
      "to other   0.0013280212483399733\n",
      "\n",
      "draft is   0.5\n",
      "\n",
      "Tannen ,   1.0\n",
      "\n",
      "the way   0.002768166089965398\n",
      "\n",
      "glue text   1.0\n",
      "\n",
      "linguistics concerned   0.05\n",
      "\n",
      "marks are   0.25\n",
      "\n",
      "it off   0.008547008547008548\n",
      "\n",
      "a slide   0.001226993865030675\n",
      "\n",
      "Agency -LRB-   0.5\n",
      "\n",
      "The English   0.005208333333333333\n",
      "\n",
      "whole discourses   0.1111111111111111\n",
      "\n",
      "Design choices   1.0\n",
      "\n",
      "phonetic segmentation   0.5\n",
      "\n",
      "and 1970s   0.001445086705202312\n",
      "\n",
      "without significant   0.07692307692307693\n",
      "\n",
      "ink -LRB-   1.0\n",
      "\n",
      "collect call   1.0\n",
      "\n",
      "useful review   0.07142857142857142\n",
      "\n",
      "found most   0.07142857142857142\n",
      "\n",
      "includes making   0.14285714285714285\n",
      "\n",
      "of patterns   0.00089126559714795\n",
      "\n",
      "be -RRB-   0.004219409282700422\n",
      "\n",
      "and human-generated   0.001445086705202312\n",
      "\n",
      "and very   0.001445086705202312\n",
      "\n",
      "'s estimate   0.0196078431372549\n",
      "\n",
      ", education   0.0005614823133071309\n",
      "\n",
      "the gradual   0.0006920415224913495\n",
      "\n",
      "NLG is   0.09523809523809523\n",
      "\n",
      "not been   0.017857142857142856\n",
      "\n",
      "to multi-document   0.0013280212483399733\n",
      "\n",
      "and potential   0.001445086705202312\n",
      "\n",
      "not always   0.008928571428571428\n",
      "\n",
      "complex NLG   0.041666666666666664\n",
      "\n",
      "and proper   0.001445086705202312\n",
      "\n",
      "textual representation   0.2\n",
      "\n",
      "in sentiment   0.0018726591760299626\n",
      "\n",
      "a training   0.001226993865030675\n",
      "\n",
      "then run   0.02857142857142857\n",
      "\n",
      "which parts   0.007246376811594203\n",
      "\n",
      "way we   0.08333333333333333\n",
      "\n",
      "decomposition into   1.0\n",
      "\n",
      "you 've   0.15384615384615385\n",
      "\n",
      "and controlling   0.001445086705202312\n",
      "\n",
      "modeling ,   0.14285714285714285\n",
      "\n",
      "distribution that   0.5\n",
      "\n",
      "the size   0.001384083044982699\n",
      "\n",
      "be available   0.004219409282700422\n",
      "\n",
      "use multiple   0.013888888888888888\n",
      "\n",
      "often addressed   0.022727272727272728\n",
      "\n",
      "for generating   0.0036101083032490976\n",
      "\n",
      "integrated into   0.3333333333333333\n",
      "\n",
      "within Tipster   0.05555555555555555\n",
      "\n",
      "the earliest   0.0006920415224913495\n",
      "\n",
      "samples per   0.5\n",
      "\n",
      "for help   0.0036101083032490976\n",
      "\n",
      "human thought   0.021739130434782608\n",
      "\n",
      "opposed to   1.0\n",
      "\n",
      "dataset -RRB-   1.0\n",
      "\n",
      "in ``   0.0056179775280898875\n",
      "\n",
      "Sentence breaking   0.2\n",
      "\n",
      "creating systems   0.14285714285714285\n",
      "\n",
      "to doctors   0.0013280212483399733\n",
      "\n",
      "in helicopters   0.003745318352059925\n",
      "\n",
      "are outside   0.004149377593360996\n",
      "\n",
      "blocks to   0.25\n",
      "\n",
      "acoustic signal   0.16666666666666666\n",
      "\n",
      "earlier some   0.25\n",
      "\n",
      "material .   0.5\n",
      "\n",
      "Bayes ,   0.3333333333333333\n",
      "\n",
      "should represent   0.10526315789473684\n",
      "\n",
      "Speech recogniton   0.03225806451612903\n",
      "\n",
      "option .   1.0\n",
      "\n",
      ", shop   0.0005614823133071309\n",
      "\n",
      "the large   0.0006920415224913495\n",
      "\n",
      "= accusative   0.1111111111111111\n",
      "\n",
      "1990s there   0.3333333333333333\n",
      "\n",
      "domain of   0.1\n",
      "\n",
      "terms ,   0.07692307692307693\n",
      "\n",
      "a useful   0.001226993865030675\n",
      "\n",
      "<s> As   0.010760953112990008\n",
      "\n",
      "those patterns   0.045454545454545456\n",
      "\n",
      "if there   0.07142857142857142\n",
      "\n",
      "etc. ,   0.045454545454545456\n",
      "\n",
      "are implemented   0.004149377593360996\n",
      "\n",
      "Algorithm -RRB-   1.0\n",
      "\n",
      "patterns ,   0.2\n",
      "\n",
      "its lexicon   0.02857142857142857\n",
      "\n",
      "test example   0.1\n",
      "\n",
      ", abstractive   0.0005614823133071309\n",
      "\n",
      "<s> Compare   0.0007686395080707148\n",
      "\n",
      "the discourse   0.0020761245674740486\n",
      "\n",
      "feedback on   0.5\n",
      "\n",
      "built a   0.3333333333333333\n",
      "\n",
      "University ,   0.1111111111111111\n",
      "\n",
      "confused with   1.0\n",
      "\n",
      "analysis was   0.03076923076923077\n",
      "\n",
      "of nouns   0.00089126559714795\n",
      "\n",
      "thus be   0.1\n",
      "\n",
      "The essential   0.005208333333333333\n",
      "\n",
      "you must   0.07692307692307693\n",
      "\n",
      "-LRB- U.S.   0.005420054200542005\n",
      "\n",
      "is becoming   0.0020325203252032522\n",
      "\n",
      "semantics of   0.07142857142857142\n",
      "\n",
      "A machine   0.02\n",
      "\n",
      "data and   0.025974025974025976\n",
      "\n",
      ", Dr.   0.0005614823133071309\n",
      "\n",
      "abstract synopsis   1.0\n",
      "\n",
      "humans often   0.08333333333333333\n",
      "\n",
      "portable to   0.3333333333333333\n",
      "\n",
      "these techniques   0.023809523809523808\n",
      "\n",
      "1950 ,   1.0\n",
      "\n",
      "based engine   0.018518518518518517\n",
      "\n",
      ", according   0.0005614823133071309\n",
      "\n",
      "forms than   0.16666666666666666\n",
      "\n",
      ", also   0.002807411566535654\n",
      "\n",
      "The FAA   0.005208333333333333\n",
      "\n",
      "computationally feasible   0.5\n",
      "\n",
      "use natural   0.013888888888888888\n",
      "\n",
      "is an   0.02032520325203252\n",
      "\n",
      "checking that   1.0\n",
      "\n",
      "language is   0.033783783783783786\n",
      "\n",
      "France ,   0.5\n",
      "\n",
      "concept -LRB-   0.25\n",
      "\n",
      "Future of   0.5\n",
      "\n",
      "programs sponsored   0.09090909090909091\n",
      "\n",
      "abbreviation MT   0.5\n",
      "\n",
      "ways in   0.125\n",
      "\n",
      "that pollen   0.0035460992907801418\n",
      "\n",
      "affect OCR   0.3333333333333333\n",
      "\n",
      "capitalized ,   0.6666666666666666\n",
      "\n",
      "orange in   1.0\n",
      "\n",
      "articles or   0.25\n",
      "\n",
      "considers an   0.5\n",
      "\n",
      "It follows   0.02631578947368421\n",
      "\n",
      "actioning it   1.0\n",
      "\n",
      "approaches :   0.14285714285714285\n",
      "\n",
      "can indeed   0.0055248618784530384\n",
      "\n",
      "of machine   0.0071301247771836\n",
      "\n",
      "People with   1.0\n",
      "\n",
      "and human   0.001445086705202312\n",
      "\n",
      "individual phones   0.08333333333333333\n",
      "\n",
      "must first   0.07142857142857142\n",
      "\n",
      "mark word   0.3333333333333333\n",
      "\n",
      "tagging could   0.04\n",
      "\n",
      "comparison ,   0.3333333333333333\n",
      "\n",
      "essentially identical   0.125\n",
      "\n",
      "a generic   0.001226993865030675\n",
      "\n",
      ", relatively   0.0005614823133071309\n",
      "\n",
      "then it   0.05714285714285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this ,   0.04395604395604396\n",
      "\n",
      "and exclamation   0.001445086705202312\n",
      "\n",
      "have error   0.009615384615384616\n",
      "\n",
      "conventional computer   1.0\n",
      "\n",
      "effect of   0.5\n",
      "\n",
      "-- computer   0.04\n",
      "\n",
      "two senses   0.034482758620689655\n",
      "\n",
      "and metrics   0.001445086705202312\n",
      "\n",
      "into ``   0.01282051282051282\n",
      "\n",
      "c -RRB-   1.0\n",
      "\n",
      "accuracy and   0.03225806451612903\n",
      "\n",
      "address this   0.25\n",
      "\n",
      "psychology Response   0.25\n",
      "\n",
      "the WYSIWYM   0.0006920415224913495\n",
      "\n",
      "Chinese have   0.14285714285714285\n",
      "\n",
      "syntax ,   0.45454545454545453\n",
      "\n",
      "improved their   0.25\n",
      "\n",
      "for each   0.02527075812274368\n",
      "\n",
      "that humans   0.0070921985815602835\n",
      "\n",
      "to specify   0.0013280212483399733\n",
      "\n",
      "have assessed   0.009615384615384616\n",
      "\n",
      "text as   0.006289308176100629\n",
      "\n",
      "specific domain   0.14285714285714285\n",
      "\n",
      "own right   0.16666666666666666\n",
      "\n",
      "meet President   0.25\n",
      "\n",
      "WordNet .   0.5\n",
      "\n",
      "was made   0.012987012987012988\n",
      "\n",
      "deep are   0.14285714285714285\n",
      "\n",
      "words such   0.01834862385321101\n",
      "\n",
      "points out   0.5\n",
      "\n",
      "these databases   0.023809523809523808\n",
      "\n",
      "a computer   0.018404907975460124\n",
      "\n",
      "new wave   0.041666666666666664\n",
      "\n",
      "no significant   0.07692307692307693\n",
      "\n",
      "resolution ,   0.25\n",
      "\n",
      "can be   0.5027624309392266\n",
      "\n",
      "cases are   0.05555555555555555\n",
      "\n",
      "led by   0.3333333333333333\n",
      "\n",
      "parsing aims   0.03571428571428571\n",
      "\n",
      "markers over   0.3333333333333333\n",
      "\n",
      "known as   0.38461538461538464\n",
      "\n",
      "appear consecutively   0.0625\n",
      "\n",
      "exceeded the   1.0\n",
      "\n",
      "software started   0.037037037037037035\n",
      "\n",
      "scientific fields   0.5\n",
      "\n",
      "technologies to   0.25\n",
      "\n",
      "reliably --   1.0\n",
      "\n",
      "classification for   0.11764705882352941\n",
      "\n",
      "in context   0.00749063670411985\n",
      "\n",
      "use by   0.027777777777777776\n",
      "\n",
      "eigenvector centrality   0.5\n",
      "\n",
      "to compare   0.005312084993359893\n",
      "\n",
      "they relate   0.025\n",
      "\n",
      "considerable commercial   0.2\n",
      "\n",
      "-LRB- selecting   0.0027100271002710027\n",
      "\n",
      "lexical analysis   0.07692307692307693\n",
      "\n",
      "1935 Tauschek   1.0\n",
      "\n",
      "use simple   0.013888888888888888\n",
      "\n",
      "the SPOTLIGHT   0.0006920415224913495\n",
      "\n",
      "documents might   0.02631578947368421\n",
      "\n",
      "all .   0.023255813953488372\n",
      "\n",
      "nodes based   0.14285714285714285\n",
      "\n",
      "health and   1.0\n",
      "\n",
      "expressivity of   1.0\n",
      "\n",
      "to market   0.0013280212483399733\n",
      "\n",
      "a reference   0.00245398773006135\n",
      "\n",
      "did cause   0.2\n",
      "\n",
      "Speech Writing   0.03225806451612903\n",
      "\n",
      "Mobile telephony   0.3333333333333333\n",
      "\n",
      "subsystem for   1.0\n",
      "\n",
      "the issues   0.0006920415224913495\n",
      "\n",
      "started to   0.25\n",
      "\n",
      "John Pierce   0.125\n",
      "\n",
      "while abstraction   0.05\n",
      "\n",
      ", taking   0.0005614823133071309\n",
      "\n",
      "measured with   0.16666666666666666\n",
      "\n",
      "-LRB- parsed   0.0027100271002710027\n",
      "\n",
      "knowledge on   0.037037037037037035\n",
      "\n",
      ", ID   0.0005614823133071309\n",
      "\n",
      "country ,   0.25\n",
      "\n",
      "are highly   0.004149377593360996\n",
      "\n",
      "answer may   0.03333333333333333\n",
      "\n",
      "-LRB- ōrātiōnis   0.0027100271002710027\n",
      "\n",
      "output with   0.038461538461538464\n",
      "\n",
      "paper legal   0.09090909090909091\n",
      "\n",
      "comparative depths   1.0\n",
      "\n",
      "parser are   0.0625\n",
      "\n",
      "1983 ,   1.0\n",
      "\n",
      "in fighter   0.0056179775280898875\n",
      "\n",
      "<s> Extracted   0.0007686395080707148\n",
      "\n",
      "challenge in   1.0\n",
      "\n",
      "human review   0.021739130434782608\n",
      "\n",
      "based speech   0.018518518518518517\n",
      "\n",
      "words into   0.03669724770642202\n",
      "\n",
      "Human Aided   0.2\n",
      "\n",
      "IE -RRB-   0.6666666666666666\n",
      "\n",
      "progress -   0.14285714285714285\n",
      "\n",
      "a neural   0.001226993865030675\n",
      "\n",
      "text is   0.025157232704402517\n",
      "\n",
      "verb ,   0.38461538461538464\n",
      "\n",
      "organization documents   0.2\n",
      "\n",
      "the functioning   0.0006920415224913495\n",
      "\n",
      "natural languages   0.12\n",
      "\n",
      "is performed   0.0040650406504065045\n",
      "\n",
      "corpora of   0.09090909090909091\n",
      "\n",
      "grouped with   0.5\n",
      "\n",
      "routing -LRB-   0.3333333333333333\n",
      "\n",
      "above techniques   0.07692307692307693\n",
      "\n",
      "pollen levels   0.6923076923076923\n",
      "\n",
      "various natural   0.05555555555555555\n",
      "\n",
      "results in   0.047619047619047616\n",
      "\n",
      "Text segmentation   0.16666666666666666\n",
      "\n",
      "vary considerably   0.16666666666666666\n",
      "\n",
      "distortions -LRB-   1.0\n",
      "\n",
      "each sentence   0.022222222222222223\n",
      "\n",
      "singular forms   0.25\n",
      "\n",
      "into one   0.02564102564102564\n",
      "\n",
      "the informativeness   0.0006920415224913495\n",
      "\n",
      "-LRB- on   0.005420054200542005\n",
      "\n",
      ", communicative   0.0005614823133071309\n",
      "\n",
      "<s> Keyphrases   0.0007686395080707148\n",
      "\n",
      "been annotated   0.014705882352941176\n",
      "\n",
      "Other issues   0.14285714285714285\n",
      "\n",
      "Corpus ,   0.0625\n",
      "\n",
      "disfluences -LRB-   1.0\n",
      "\n",
      "expression which   0.1\n",
      "\n",
      "and enterprise   0.001445086705202312\n",
      "\n",
      "of hand-printed   0.0017825311942959\n",
      "\n",
      "as each   0.003484320557491289\n",
      "\n",
      "to 90   0.0013280212483399733\n",
      "\n",
      "are free   0.004149377593360996\n",
      "\n",
      "defined by   0.16666666666666666\n",
      "\n",
      "data on   0.012987012987012988\n",
      "\n",
      "sentiment strength   0.04\n",
      "\n",
      "word blend   0.016666666666666666\n",
      "\n",
      "severe in   1.0\n",
      "\n",
      "and his   0.001445086705202312\n",
      "\n",
      "to new   0.005312084993359893\n",
      "\n",
      "2007 -RRB-   0.2\n",
      "\n",
      "even articles   0.037037037037037035\n",
      "\n",
      "text are   0.006289308176100629\n",
      "\n",
      "form multi-word   0.05\n",
      "\n",
      "described here   0.16666666666666666\n",
      "\n",
      "text corresponds   0.006289308176100629\n",
      "\n",
      "essentially two   0.125\n",
      "\n",
      "a discussion   0.001226993865030675\n",
      "\n",
      "Lao ,   1.0\n",
      "\n",
      "no distinction   0.07692307692307693\n",
      "\n",
      "comprehensive hand-crafted   0.2\n",
      "\n",
      "needs to   0.4\n",
      "\n",
      "is considered   0.0040650406504065045\n",
      "\n",
      "produce textual   0.045454545454545456\n",
      "\n",
      "qualitative manner   0.5\n",
      "\n",
      "features indicating   0.038461538461538464\n",
      "\n",
      "devised to   0.5\n",
      "\n",
      "token generation   0.25\n",
      "\n",
      "identification is   0.2\n",
      "\n",
      "use in   0.013888888888888888\n",
      "\n",
      "language constructs   0.006756756756756757\n",
      "\n",
      "all been   0.023255813953488372\n",
      "\n",
      "post -   1.0\n",
      "\n",
      "Hendrix formed   1.0\n",
      "\n",
      "this product   0.01098901098901099\n",
      "\n",
      "mentions -LRB-   0.3333333333333333\n",
      "\n",
      "tag set   0.3125\n",
      "\n",
      ", graphic   0.0005614823133071309\n",
      "\n",
      "new methods   0.041666666666666664\n",
      "\n",
      "naval battle   0.3333333333333333\n",
      "\n",
      "dissertation -LRB-   0.3333333333333333\n",
      "\n",
      "My head   1.0\n",
      "\n",
      "1982 Gary   0.3333333333333333\n",
      "\n",
      "everyday life   1.0\n",
      "\n",
      "ending at   1.0\n",
      "\n",
      "a toy   0.00245398773006135\n",
      "\n",
      "<s> ATNs   0.0007686395080707148\n",
      "\n",
      "for database   0.0036101083032490976\n",
      "\n",
      "R. ,   0.3333333333333333\n",
      "\n",
      "evaluation process   0.018518518518518517\n",
      "\n",
      "in trying   0.0018726591760299626\n",
      "\n",
      "developed to   0.038461538461538464\n",
      "\n",
      "interface for   0.25\n",
      "\n",
      "'s input   0.0196078431372549\n",
      "\n",
      "although not   0.16666666666666666\n",
      "\n",
      "dictionary-based machine   1.0\n",
      "\n",
      "organized notations   1.0\n",
      "\n",
      "experience is   0.5\n",
      "\n",
      "text databases   0.006289308176100629\n",
      "\n",
      "different angle   0.02040816326530612\n",
      "\n",
      "documents more   0.02631578947368421\n",
      "\n",
      "world -LRB-   0.06666666666666667\n",
      "\n",
      "program ,   0.045454545454545456\n",
      "\n",
      "recursion in   1.0\n",
      "\n",
      "systems of   0.05357142857142857\n",
      "\n",
      "neural networks   0.5333333333333333\n",
      "\n",
      "do not   0.5\n",
      "\n",
      "work by   0.08333333333333333\n",
      "\n",
      "sophisticated measures   0.14285714285714285\n",
      "\n",
      "understanding ,   0.09090909090909091\n",
      "\n",
      "morphological distinctions   0.3333333333333333\n",
      "\n",
      ", comprehend   0.0005614823133071309\n",
      "\n",
      "Also ,   1.0\n",
      "\n",
      "was developed   0.012987012987012988\n",
      "\n",
      "directly to   0.4\n",
      "\n",
      "example type   0.012345679012345678\n",
      "\n",
      "product was   0.14285714285714285\n",
      "\n",
      "the AVRADA   0.0006920415224913495\n",
      "\n",
      "but BLEU   0.014705882352941176\n",
      "\n",
      "names that   0.2857142857142857\n",
      "\n",
      "-LRB- Lehnert   0.005420054200542005\n",
      "\n",
      "Hirschman 1998   0.5\n",
      "\n",
      "Accuracy rates   0.2857142857142857\n",
      "\n",
      "sixty Russian   1.0\n",
      "\n",
      ", based   0.0011229646266142617\n",
      "\n",
      "into words   0.038461538461538464\n",
      "\n",
      "analyses of   0.2\n",
      "\n",
      "to recognize   0.00796812749003984\n",
      "\n",
      "tries to   1.0\n",
      "\n",
      "is distinct   0.0020325203252032522\n",
      "\n",
      "restricted vocabularies   0.25\n",
      "\n",
      "a multileveled   0.001226993865030675\n",
      "\n",
      "while Carnegie   0.05\n",
      "\n",
      "ELIZA gained   0.1111111111111111\n",
      "\n",
      "coupons returned   1.0\n",
      "\n",
      "less time   0.08333333333333333\n",
      "\n",
      "GPO -RRB-   1.0\n",
      "\n",
      "also similar   0.014492753623188406\n",
      "\n",
      "is more   0.006097560975609756\n",
      "\n",
      "a deep   0.001226993865030675\n",
      "\n",
      "same as   0.08\n",
      "\n",
      "online opinion   0.125\n",
      "\n",
      "the importance   0.001384083044982699\n",
      "\n",
      "word separators   0.016666666666666666\n",
      "\n",
      "Corporation -LRB-   0.5\n",
      "\n",
      "containing the   0.375\n",
      "\n",
      ", Jay   0.0005614823133071309\n",
      "\n",
      "sentences Grass   0.013157894736842105\n",
      "\n",
      "a plural   0.001226993865030675\n",
      "\n",
      "for Reading   0.0036101083032490976\n",
      "\n",
      "into play   0.01282051282051282\n",
      "\n",
      "fixed schemata   0.5\n",
      "\n",
      "2 ''   0.2\n",
      "\n",
      "emerge that   1.0\n",
      "\n",
      "'ve seen   0.5\n",
      "\n",
      "much easier   0.045454545454545456\n",
      "\n",
      "language into   0.006756756756756757\n",
      "\n",
      "for substantial   0.0036101083032490976\n",
      "\n",
      "Early versions   0.5\n",
      "\n",
      "the longest   0.0006920415224913495\n",
      "\n",
      "a field   0.0036809815950920245\n",
      "\n",
      "adjacent instances   0.16666666666666666\n",
      "\n",
      "advanced pattern   0.2\n",
      "\n",
      "tested the   0.5\n",
      "\n",
      "perspective in   0.25\n",
      "\n",
      "Standardization in   1.0\n",
      "\n",
      "speech-recognition engine   0.6666666666666666\n",
      "\n",
      "has improved   0.011904761904761904\n",
      "\n",
      "of sounds   0.00089126559714795\n",
      "\n",
      "and linguistics   0.002890173410404624\n",
      "\n",
      "historically used   0.5\n",
      "\n",
      "implicitly determines   1.0\n",
      "\n",
      "the characters   0.0006920415224913495\n",
      "\n",
      "`` What   0.015873015873015872\n",
      "\n",
      "those used   0.13636363636363635\n",
      "\n",
      "first word   0.030303030303030304\n",
      "\n",
      "Unix operating   0.5\n",
      "\n",
      "part-of-speech tagger   0.06666666666666667\n",
      "\n",
      "little interference   0.3333333333333333\n",
      "\n",
      "process Flow   0.027777777777777776\n",
      "\n",
      ", preposition   0.0005614823133071309\n",
      "\n",
      "often inaccurate   0.022727272727272728\n",
      "\n",
      "datum is   1.0\n",
      "\n",
      "<s> Words   0.0015372790161414297\n",
      "\n",
      "some machine   0.012048192771084338\n",
      "\n",
      "answering .   0.16666666666666666\n",
      "\n",
      ": Produce   0.00980392156862745\n",
      "\n",
      "standard written   0.07142857142857142\n",
      "\n",
      "light on   0.3333333333333333\n",
      "\n",
      "automatically created   0.047619047619047616\n",
      "\n",
      "systems applications   0.008928571428571428\n",
      "\n",
      "involves preliminary   0.1\n",
      "\n",
      "knowledge specific   0.037037037037037035\n",
      "\n",
      "what information   0.03125\n",
      "\n",
      "the start   0.002768166089965398\n",
      "\n",
      "a meaningful   0.00245398773006135\n",
      "\n",
      "Black 1991   0.5\n",
      "\n",
      "published his   0.14285714285714285\n",
      "\n",
      "processing to   0.018518518518518517\n",
      "\n",
      "in Statistical   0.0018726591760299626\n",
      "\n",
      "paragraphs .   0.25\n",
      "\n",
      "words .   0.14678899082568808\n",
      "\n",
      "← barmaid   1.0\n",
      "\n",
      "Ensemble methods   1.0\n",
      "\n",
      "Conference Technolangue\\/Easy   0.5\n",
      "\n",
      "parsers .   0.07692307692307693\n",
      "\n",
      "the future   0.001384083044982699\n",
      "\n",
      "known keyphrase   0.038461538461538464\n",
      "\n",
      ", ^   0.0011229646266142617\n",
      "\n",
      "common cases   0.04\n",
      "\n",
      "genre and   0.5\n",
      "\n",
      "rate these   0.09090909090909091\n",
      "\n",
      "that represents   0.0035460992907801418\n",
      "\n",
      "<s> Attribute   0.0007686395080707148\n",
      "\n",
      "candidate can   0.3333333333333333\n",
      "\n",
      "commonly referred   0.125\n",
      "\n",
      "probability -RRB-   0.2857142857142857\n",
      "\n",
      "Once the   0.2\n",
      "\n",
      "approaches Automatic   0.03571428571428571\n",
      "\n",
      "Automatically translate   1.0\n",
      "\n",
      "hyphenation .   1.0\n",
      "\n",
      "then used   0.02857142857142857\n",
      "\n",
      "speech processing   0.006578947368421052\n",
      "\n",
      "Hirschman L.   0.5\n",
      "\n",
      "resource management   0.4\n",
      "\n",
      "into sentences   0.01282051282051282\n",
      "\n",
      "are typically   0.012448132780082987\n",
      "\n",
      "any number   0.03225806451612903\n",
      "\n",
      "individual users   0.08333333333333333\n",
      "\n",
      "match between   0.16666666666666666\n",
      "\n",
      ", Nikolas   0.0005614823133071309\n",
      "\n",
      "would probably   0.018867924528301886\n",
      "\n",
      "problems colloquially   0.11764705882352941\n",
      "\n",
      "environment where   0.16666666666666666\n",
      "\n",
      "Shallow parsing   0.5\n",
      "\n",
      "a fast-evolving   0.001226993865030675\n",
      "\n",
      "the CCD   0.0006920415224913495\n",
      "\n",
      "chosen publications   0.2\n",
      "\n",
      "summary used   0.023809523809523808\n",
      "\n",
      "judgement ,   0.3333333333333333\n",
      "\n",
      "but sometimes   0.014705882352941176\n",
      "\n",
      "and here   0.001445086705202312\n",
      "\n",
      "cross-lingual -RRB-   0.5\n",
      "\n",
      "is using   0.0040650406504065045\n",
      "\n",
      "scale .   0.16666666666666666\n",
      "\n",
      "typically involved   0.05555555555555555\n",
      "\n",
      "- passage   0.0625\n",
      "\n",
      "article quoting   0.034482758620689655\n",
      "\n",
      "regular expressions   1.0\n",
      "\n",
      "article contains   0.034482758620689655\n",
      "\n",
      "context -LRB-   0.06060606060606061\n",
      "\n",
      "words or   0.06422018348623854\n",
      "\n",
      "than that   0.044444444444444446\n",
      "\n",
      "during handwriting   0.1\n",
      "\n",
      "multiple languages   0.07692307692307693\n",
      "\n",
      "is seen   0.0020325203252032522\n",
      "\n",
      "is little   0.0020325203252032522\n",
      "\n",
      "note is   1.0\n",
      "\n",
      "news articles   0.23076923076923078\n",
      "\n",
      "of triple   0.00089126559714795\n",
      "\n",
      "In about   0.009523809523809525\n",
      "\n",
      "own expert   0.16666666666666666\n",
      "\n",
      "existing hand-written   0.2\n",
      "\n",
      ", Sandra   0.0005614823133071309\n",
      "\n",
      "some fundamental   0.012048192771084338\n",
      "\n",
      "sound into   0.05\n",
      "\n",
      "less standardised   0.08333333333333333\n",
      "\n",
      "Word Error   0.14285714285714285\n",
      "\n",
      "as humans   0.003484320557491289\n",
      "\n",
      "serial numbers   1.0\n",
      "\n",
      "a standard   0.00245398773006135\n",
      "\n",
      "faster computers   0.3333333333333333\n",
      "\n",
      ", Robyn   0.0005614823133071309\n",
      "\n",
      "equipment would   0.3333333333333333\n",
      "\n",
      "quoted in   1.0\n",
      "\n",
      "Wide Web   1.0\n",
      "\n",
      "The set   0.005208333333333333\n",
      "\n",
      "Frost ,   1.0\n",
      "\n",
      "knowledge system   0.037037037037037035\n",
      "\n",
      "probabilities of   0.2727272727272727\n",
      "\n",
      "-LRB- MMI   0.0027100271002710027\n",
      "\n",
      "identifiers .   1.0\n",
      "\n",
      "with human-made   0.00546448087431694\n",
      "\n",
      "& Online   0.125\n",
      "\n",
      "a first   0.00245398773006135\n",
      "\n",
      "characterizes its   1.0\n",
      "\n",
      "speech is   0.006578947368421052\n",
      "\n",
      "the burden   0.0006920415224913495\n",
      "\n",
      "of traditional   0.00089126559714795\n",
      "\n",
      "qualitatively The   1.0\n",
      "\n",
      "The late   0.005208333333333333\n",
      "\n",
      "simple natural   0.038461538461538464\n",
      "\n",
      "features ,   0.038461538461538464\n",
      "\n",
      "A restricted   0.02\n",
      "\n",
      "and ontology   0.001445086705202312\n",
      "\n",
      "like this   0.03571428571428571\n",
      "\n",
      "various ways   0.1111111111111111\n",
      "\n",
      "fashion ,   1.0\n",
      "\n",
      ", will   0.0011229646266142617\n",
      "\n",
      "possess -LRB-   1.0\n",
      "\n",
      "transducers with   1.0\n",
      "\n",
      "metrics .   0.1111111111111111\n",
      "\n",
      "suitability for   0.5\n",
      "\n",
      "what the   0.125\n",
      "\n",
      "level we   0.05\n",
      "\n",
      "information theory   0.021739130434782608\n",
      "\n",
      "approach for   0.02857142857142857\n",
      "\n",
      "much smaller   0.045454545454545456\n",
      "\n",
      "base or   0.25\n",
      "\n",
      "vs. ``   0.16666666666666666\n",
      "\n",
      "as artificial   0.003484320557491289\n",
      "\n",
      "translation may   0.013513513513513514\n",
      "\n",
      "structures of   0.2\n",
      "\n",
      "whether -LRB-   0.07692307692307693\n",
      "\n",
      "as discussed   0.003484320557491289\n",
      "\n",
      "approximates the   0.5\n",
      "\n",
      "compactly ,   1.0\n",
      "\n",
      "The improvement   0.005208333333333333\n",
      "\n",
      "algorithms to   0.08571428571428572\n",
      "\n",
      "' at   0.05263157894736842\n",
      "\n",
      "hand-written rules   0.8571428571428571\n",
      "\n",
      "linguist working   0.5\n",
      "\n",
      "entry -LRB-   0.25\n",
      "\n",
      "parameters for   0.5\n",
      "\n",
      "no evident   0.07692307692307693\n",
      "\n",
      "or poetry   0.0045045045045045045\n",
      "\n",
      ", extracting   0.0005614823133071309\n",
      "\n",
      ", cultural   0.0005614823133071309\n",
      "\n",
      "and SpeechTEK   0.001445086705202312\n",
      "\n",
      "soft ,   0.5\n",
      "\n",
      "publications .   1.0\n",
      "\n",
      "Although humans   0.125\n",
      "\n",
      "Sydney Lamb   1.0\n",
      "\n",
      "will not   0.11428571428571428\n",
      "\n",
      "main verb   0.125\n",
      "\n",
      "Thai do   0.5\n",
      "\n",
      "<s> DARPA   0.0007686395080707148\n",
      "\n",
      "this example   0.01098901098901099\n",
      "\n",
      "LinguaSys ,   1.0\n",
      "\n",
      "analysis .   0.09230769230769231\n",
      "\n",
      "was greatly   0.012987012987012988\n",
      "\n",
      "grammars -RRB-   0.14285714285714285\n",
      "\n",
      "he talking   0.14285714285714285\n",
      "\n",
      "A popular   0.02\n",
      "\n",
      "given formal   0.041666666666666664\n",
      "\n",
      "that merely   0.0035460992907801418\n",
      "\n",
      "Naturally Speaking   1.0\n",
      "\n",
      "organization ,   0.2\n",
      "\n",
      "exhibited good   1.0\n",
      "\n",
      "fastens -LRB-   1.0\n",
      "\n",
      "task requiring   0.023809523809523808\n",
      "\n",
      "others were   0.08333333333333333\n",
      "\n",
      "improved computer   0.25\n",
      "\n",
      "is specifically   0.0020325203252032522\n",
      "\n",
      "speech interface   0.006578947368421052\n",
      "\n",
      "materials .   0.5\n",
      "\n",
      "times ,   0.2\n",
      "\n",
      "Subjectivity ''   1.0\n",
      "\n",
      "Meehan ,   1.0\n",
      "\n",
      "translation Machine   0.013513513513513514\n",
      "\n",
      "<s> Apart   0.0007686395080707148\n",
      "\n",
      "usually have   0.03125\n",
      "\n",
      "by an   0.011428571428571429\n",
      "\n",
      "analyzed with   0.2\n",
      "\n",
      ": Given   0.09803921568627451\n",
      "\n",
      "and manage   0.001445086705202312\n",
      "\n",
      "recognizes the   1.0\n",
      "\n",
      "learning algorithm   0.11627906976744186\n",
      "\n",
      "more common   0.010526315789473684\n",
      "\n",
      "less likely   0.16666666666666666\n",
      "\n",
      "1950s included   0.25\n",
      "\n",
      "likely source   0.0625\n",
      "\n",
      "currently focus   0.14285714285714285\n",
      "\n",
      "<s> Additional   0.0007686395080707148\n",
      "\n",
      "groups ,   0.2\n",
      "\n",
      "Gaussians ,   1.0\n",
      "\n",
      "distortion ,   1.0\n",
      "\n",
      "<s> Edges   0.0015372790161414297\n",
      "\n",
      "concepts between   0.2\n",
      "\n",
      "can select   0.0055248618784530384\n",
      "\n",
      "100 %   0.6666666666666666\n",
      "\n",
      "fall between   0.25\n",
      "\n",
      "coefficients ,   0.25\n",
      "\n",
      "fairly simple   0.25\n",
      "\n",
      "word vector   0.016666666666666666\n",
      "\n",
      "The sailor   0.005208333333333333\n",
      "\n",
      "excerpt containing   1.0\n",
      "\n",
      "generally amenable   0.09090909090909091\n",
      "\n",
      ": Transfer-based   0.00980392156862745\n",
      "\n",
      "and Markov   0.001445086705202312\n",
      "\n",
      "using logical   0.01694915254237288\n",
      "\n",
      "in USA   0.0018726591760299626\n",
      "\n",
      "question answering   0.21428571428571427\n",
      "\n",
      "it helps   0.008547008547008548\n",
      "\n",
      "Each level   0.16666666666666666\n",
      "\n",
      "would also   0.018867924528301886\n",
      "\n",
      "democratizing publishing   0.5\n",
      "\n",
      "perspective .   0.25\n",
      "\n",
      "and must   0.001445086705202312\n",
      "\n",
      "more effectively   0.010526315789473684\n",
      "\n",
      "the error   0.0006920415224913495\n",
      "\n",
      "is farther   0.0020325203252032522\n",
      "\n",
      "a tonal   0.001226993865030675\n",
      "\n",
      "may appear   0.019230769230769232\n",
      "\n",
      ", V.J.   0.0005614823133071309\n",
      "\n",
      "QA computer   0.047619047619047616\n",
      "\n",
      "gold standard   0.8333333333333334\n",
      "\n",
      "a translation   0.00245398773006135\n",
      "\n",
      "improve information   0.07692307692307693\n",
      "\n",
      "an individual   0.007575757575757576\n",
      "\n",
      "Computer Problem   0.16666666666666666\n",
      "\n",
      "applied to   0.7333333333333333\n",
      "\n",
      "developed the   0.15384615384615385\n",
      "\n",
      "software Annotate   0.037037037037037035\n",
      "\n",
      "feature is   0.07692307692307693\n",
      "\n",
      "graphs and   1.0\n",
      "\n",
      "of logical   0.00089126559714795\n",
      "\n",
      "major OCR   0.16666666666666666\n",
      "\n",
      "'s intent   0.0196078431372549\n",
      "\n",
      "Programming methods   0.3333333333333333\n",
      "\n",
      "-RRB- can   0.008130081300813009\n",
      "\n",
      "reviews to   0.16666666666666666\n",
      "\n",
      "disseminate it   1.0\n",
      "\n",
      "document reader   0.027777777777777776\n",
      "\n",
      "as in   0.027874564459930314\n",
      "\n",
      "perception of   0.5\n",
      "\n",
      "consist of   1.0\n",
      "\n",
      "stemming -RRB-   0.5\n",
      "\n",
      ", regardless   0.0016844469399213925\n",
      "\n",
      "Why does   0.2857142857142857\n",
      "\n",
      "an understanding   0.015151515151515152\n",
      "\n",
      "field is   0.037037037037037035\n",
      "\n",
      "standard expression   0.07142857142857142\n",
      "\n",
      "Germany .   0.5\n",
      "\n",
      ", training   0.0005614823133071309\n",
      "\n",
      "cited the   1.0\n",
      "\n",
      "co-occur at   0.5\n",
      "\n",
      "<s> Often   0.0023059185242121443\n",
      "\n",
      "will give   0.02857142857142857\n",
      "\n",
      "to classify   0.0013280212483399733\n",
      "\n",
      "attempts have   0.16666666666666666\n",
      "\n",
      "or Web-based   0.0045045045045045045\n",
      "\n",
      "and occurs   0.001445086705202312\n",
      "\n",
      "used during   0.008849557522123894\n",
      "\n",
      "whether it   0.07692307692307693\n",
      "\n",
      "and use   0.004335260115606936\n",
      "\n",
      "used the   0.008849557522123894\n",
      "\n",
      "obtained .   0.14285714285714285\n",
      "\n",
      "the Austrian   0.0006920415224913495\n",
      "\n",
      "learn about   0.07692307692307693\n",
      "\n",
      "translation components   0.013513513513513514\n",
      "\n",
      "conveyed via   1.0\n",
      "\n",
      "follows that   0.5\n",
      "\n",
      "some context   0.012048192771084338\n",
      "\n",
      "shared concepts   0.5\n",
      "\n",
      "sound signal   0.05\n",
      "\n",
      "use considers   0.013888888888888888\n",
      "\n",
      "So an   0.3333333333333333\n",
      "\n",
      "looks ,   0.25\n",
      "\n",
      "perform as   0.09090909090909091\n",
      "\n",
      "he developed   0.14285714285714285\n",
      "\n",
      "<s> Whether   0.0015372790161414297\n",
      "\n",
      "equivalent to   0.2\n",
      "\n",
      "reasoning schemes   0.14285714285714285\n",
      "\n",
      "spaces .   0.2\n",
      "\n",
      "use `   0.013888888888888888\n",
      "\n",
      "is easier   0.0040650406504065045\n",
      "\n",
      "reviews respectively   0.16666666666666666\n",
      "\n",
      "not necessary   0.008928571428571428\n",
      "\n",
      "internalize the   1.0\n",
      "\n",
      "interface Home   0.25\n",
      "\n",
      "as references   0.003484320557491289\n",
      "\n",
      "<s> Thus   0.009223674096848577\n",
      "\n",
      "systems can   0.026785714285714284\n",
      "\n",
      "the last   0.0020761245674740486\n",
      "\n",
      "Current difficulties   0.2\n",
      "\n",
      "blend smoothly   0.6666666666666666\n",
      "\n",
      "data be   0.012987012987012988\n",
      "\n",
      "automatically generated   0.14285714285714285\n",
      "\n",
      "sufficiently well   1.0\n",
      "\n",
      "language as   0.006756756756756757\n",
      "\n",
      "Tagger ,   1.0\n",
      "\n",
      "letters or   0.1\n",
      "\n",
      "to low   0.0013280212483399733\n",
      "\n",
      "whether a   0.15384615384615385\n",
      "\n",
      "published a   0.2857142857142857\n",
      "\n",
      "environment in   0.16666666666666666\n",
      "\n",
      "level 6   0.05\n",
      "\n",
      "bigrams ,   1.0\n",
      "\n",
      "how big   0.034482758620689655\n",
      "\n",
      "this in   0.01098901098901099\n",
      "\n",
      "much through   0.045454545454545456\n",
      "\n",
      "Recall-Oriented Understudy   1.0\n",
      "\n",
      "more than   0.042105263157894736\n",
      "\n",
      "some of   0.1566265060240964\n",
      "\n",
      "in universities   0.0018726591760299626\n",
      "\n",
      "the ACL   0.0006920415224913495\n",
      "\n",
      "unigrams placed   0.08333333333333333\n",
      "\n",
      "Recognition ''   0.375\n",
      "\n",
      "name -LRB-   0.2\n",
      "\n",
      "that is   0.05673758865248227\n",
      "\n",
      "waves that   0.14285714285714285\n",
      "\n",
      "Latin-script ,   1.0\n",
      "\n",
      "in differing   0.0018726591760299626\n",
      "\n",
      "people ,   0.0625\n",
      "\n",
      "was based   0.012987012987012988\n",
      "\n",
      "all the   0.13953488372093023\n",
      "\n",
      "texts .   0.17647058823529413\n",
      "\n",
      "texts or   0.058823529411764705\n",
      "\n",
      "As an   0.1111111111111111\n",
      "\n",
      "clean hand-printed   0.5\n",
      "\n",
      "evaluation requires   0.018518518518518517\n",
      "\n",
      "-LRB- p.   0.0027100271002710027\n",
      "\n",
      "-LRB- discourse   0.0027100271002710027\n",
      "\n",
      "lexical similarity   0.07692307692307693\n",
      "\n",
      "only Wikipedia   0.02631578947368421\n",
      "\n",
      "research may   0.023809523809523808\n",
      "\n",
      "speech can   0.013157894736842105\n",
      "\n",
      "editor ,   1.0\n",
      "\n",
      "used together   0.008849557522123894\n",
      "\n",
      "automated language   0.14285714285714285\n",
      "\n",
      "Amplitude -LRB-   1.0\n",
      "\n",
      "problems .   0.17647058823529413\n",
      "\n",
      ", Case   0.0005614823133071309\n",
      "\n",
      "building a   1.0\n",
      "\n",
      ", P   0.0005614823133071309\n",
      "\n",
      "the conceptual   0.0006920415224913495\n",
      "\n",
      ": navigation   0.00980392156862745\n",
      "\n",
      "generate examples   0.05555555555555555\n",
      "\n",
      ", Oklahoma   0.0005614823133071309\n",
      "\n",
      "the Cuzco   0.0006920415224913495\n",
      "\n",
      "are three   0.004149377593360996\n",
      "\n",
      "displayed as   0.5\n",
      "\n",
      "in natural   0.013108614232209739\n",
      "\n",
      "Such models   0.25\n",
      "\n",
      "extracting and   0.2\n",
      "\n",
      "simply guessed   0.08333333333333333\n",
      "\n",
      "A linguist   0.02\n",
      "\n",
      "address of   0.25\n",
      "\n",
      "least to   0.2\n",
      "\n",
      "-LRB- usually   0.005420054200542005\n",
      "\n",
      "a sub-field   0.001226993865030675\n",
      "\n",
      "of them   0.0017825311942959\n",
      "\n",
      "relevant summaries   0.14285714285714285\n",
      "\n",
      "<s> First   0.0007686395080707148\n",
      "\n",
      "referred to   1.0\n",
      "\n",
      "done using   0.09090909090909091\n",
      "\n",
      "first mechanized   0.030303030303030304\n",
      "\n",
      "physician ,   1.0\n",
      "\n",
      "continue to   1.0\n",
      "\n",
      "usually thought   0.03125\n",
      "\n",
      "work at   0.041666666666666664\n",
      "\n",
      "<s> Early   0.0015372790161414297\n",
      "\n",
      "success in   0.2\n",
      "\n",
      "In 1982   0.009523809523809525\n",
      "\n",
      "software .   0.037037037037037035\n",
      "\n",
      "dialogue with   0.5\n",
      "\n",
      "3 %   0.2\n",
      "\n",
      "or Auto   0.0045045045045045045\n",
      "\n",
      "demonstrations ,   1.0\n",
      "\n",
      "pyramid showing   1.0\n",
      "\n",
      "Rose ,   1.0\n",
      "\n",
      "state-of-the-art in   0.5\n",
      "\n",
      ", has   0.0005614823133071309\n",
      "\n",
      "kick '   1.0\n",
      "\n",
      ", highly-specialized   0.0005614823133071309\n",
      "\n",
      "capital of   0.6666666666666666\n",
      "\n",
      "details of   0.5\n",
      "\n",
      "with known   0.01092896174863388\n",
      "\n",
      "of 21   0.00089126559714795\n",
      "\n",
      "for 1-July-2005   0.0036101083032490976\n",
      "\n",
      "experts of   1.0\n",
      "\n",
      "degrees of   0.5\n",
      "\n",
      "and create   0.002890173410404624\n",
      "\n",
      "the Annual   0.0006920415224913495\n",
      "\n",
      "usually perform   0.03125\n",
      "\n",
      "context-free grammars   0.36363636363636365\n",
      "\n",
      "logical inference   0.16666666666666666\n",
      "\n",
      "that were   0.014184397163120567\n",
      "\n",
      "ideas ,   0.25\n",
      "\n",
      "version of   0.6666666666666666\n",
      "\n",
      "the next   0.004152249134948097\n",
      "\n",
      "MT performs   0.2\n",
      "\n",
      "their own   0.029411764705882353\n",
      "\n",
      "sound input   0.05\n",
      "\n",
      "within three   0.1111111111111111\n",
      "\n",
      "from several   0.009615384615384616\n",
      "\n",
      "largely because   0.2\n",
      "\n",
      "-LRB- OCR   0.0027100271002710027\n",
      "\n",
      "went to   0.4\n",
      "\n",
      "has gone   0.011904761904761904\n",
      "\n",
      "The notion   0.010416666666666666\n",
      "\n",
      "specific theoretical   0.047619047619047616\n",
      "\n",
      "controversy is   1.0\n",
      "\n",
      "1914 ,   1.0\n",
      "\n",
      "Canada to   0.16666666666666666\n",
      "\n",
      "more subjective   0.010526315789473684\n",
      "\n",
      "applications can   0.04\n",
      "\n",
      "extraction module   0.03225806451612903\n",
      "\n",
      "Pang showed   0.3333333333333333\n",
      "\n",
      "job ,   0.5\n",
      "\n",
      "regions for   0.5\n",
      "\n",
      "Constraint Grammar   1.0\n",
      "\n",
      "be manually   0.004219409282700422\n",
      "\n",
      "official languages   1.0\n",
      "\n",
      "typically a   0.05555555555555555\n",
      "\n",
      "successful .   0.1111111111111111\n",
      "\n",
      "Terry Winograd   1.0\n",
      "\n",
      "require a   0.22727272727272727\n",
      "\n",
      "Once examples   0.2\n",
      "\n",
      "MMI -RRB-   1.0\n",
      "\n",
      "the earlier   0.0006920415224913495\n",
      "\n",
      "numbers ,   0.2857142857142857\n",
      "\n",
      "toolkit -RRB-   0.5\n",
      "\n",
      "another linguistic   0.07692307692307693\n",
      "\n",
      "might co-occur   0.038461538461538464\n",
      "\n",
      "text ,   0.18867924528301888\n",
      "\n",
      "service .   0.2\n",
      "\n",
      "by any   0.005714285714285714\n",
      "\n",
      "domains ,   0.125\n",
      "\n",
      "He then   0.125\n",
      "\n",
      "Hopper ,   1.0\n",
      "\n",
      "improved the   0.25\n",
      "\n",
      "be apparent   0.004219409282700422\n",
      "\n",
      "by hand   0.03428571428571429\n",
      "\n",
      "the vertices   0.0006920415224913495\n",
      "\n",
      "measures how   0.3333333333333333\n",
      "\n",
      "in software   0.0018726591760299626\n",
      "\n",
      "way that   0.125\n",
      "\n",
      "sentences weighted   0.013157894736842105\n",
      "\n",
      "in each   0.0018726591760299626\n",
      "\n",
      "training ;   0.03571428571428571\n",
      "\n",
      "methods In   0.022727272727272728\n",
      "\n",
      "informative enough   0.5\n",
      "\n",
      "<s> Advanced   0.0023059185242121443\n",
      "\n",
      "Like the   0.5\n",
      "\n",
      "OCR Document   0.02040816326530612\n",
      "\n",
      "grammatical contexts   0.09090909090909091\n",
      "\n",
      "inflected languages   1.0\n",
      "\n",
      "practically available   1.0\n",
      "\n",
      "left recursive   0.16666666666666666\n",
      "\n",
      "linguistics Cognitive   0.05\n",
      "\n",
      "year .   0.5\n",
      "\n",
      "post-secondary look   1.0\n",
      "\n",
      ". -RRB-   0.0062402496099844\n",
      "\n",
      "<s> Evaluation   0.003843197540353574\n",
      "\n",
      "correlation is   0.5\n",
      "\n",
      "its users   0.02857142857142857\n",
      "\n",
      "a fashion   0.001226993865030675\n",
      "\n",
      "comparison uses   0.3333333333333333\n",
      "\n",
      "program were   0.045454545454545456\n",
      "\n",
      "to carry   0.0013280212483399733\n",
      "\n",
      "Coreference resolution   1.0\n",
      "\n",
      "was a   0.03896103896103896\n",
      "\n",
      "Continuous speech   1.0\n",
      "\n",
      "algorithms use   0.02857142857142857\n",
      "\n",
      "as could   0.003484320557491289\n",
      "\n",
      "'' for   0.005154639175257732\n",
      "\n",
      "solution can   1.0\n",
      "\n",
      "knowledge .   0.037037037037037035\n",
      "\n",
      "analyze the   0.25\n",
      "\n",
      "to express   0.0013280212483399733\n",
      "\n",
      "PC history   0.25\n",
      "\n",
      "-LRB- QA   0.0027100271002710027\n",
      "\n",
      ", so   0.00673778775968557\n",
      "\n",
      "extensively used   1.0\n",
      "\n",
      "repetitive .   0.5\n",
      "\n",
      "between closely   0.02564102564102564\n",
      "\n",
      "% -RRB-   0.02564102564102564\n",
      "\n",
      "statistical distribution   0.030303030303030304\n",
      "\n",
      "T to   0.16666666666666666\n",
      "\n",
      "many in   0.019230769230769232\n",
      "\n",
      "expensive and   0.14285714285714285\n",
      "\n",
      "strength of   0.6\n",
      "\n",
      "research necessary   0.023809523809523808\n",
      "\n",
      "sentenced separated   1.0\n",
      "\n",
      "such statistical   0.008130081300813009\n",
      "\n",
      "semantic from   0.047619047619047616\n",
      "\n",
      "' .   0.10526315789473684\n",
      "\n",
      "of internal   0.00089126559714795\n",
      "\n",
      "other purposes   0.014285714285714285\n",
      "\n",
      "funding for   0.25\n",
      "\n",
      "often used   0.022727272727272728\n",
      "\n",
      "In 1955   0.009523809523809525\n",
      "\n",
      "resulting from   0.25\n",
      "\n",
      "pattern .   0.16666666666666666\n",
      "\n",
      "sample corpus   0.3333333333333333\n",
      "\n",
      "industry ,   0.3333333333333333\n",
      "\n",
      "after testing   0.08333333333333333\n",
      "\n",
      "documents obtained   0.02631578947368421\n",
      "\n",
      "overfitting and   0.5\n",
      "\n",
      "by these   0.005714285714285714\n",
      "\n",
      "automatically tuned   0.047619047619047616\n",
      "\n",
      "discriminative training   1.0\n",
      "\n",
      "evaluation procedures   0.018518518518518517\n",
      "\n",
      "but other   0.014705882352941176\n",
      "\n",
      "in fact   0.0018726591760299626\n",
      "\n",
      ", other   0.0005614823133071309\n",
      "\n",
      "cost related   0.5\n",
      "\n",
      "Sublanguage analysis   1.0\n",
      "\n",
      "taggers for   0.14285714285714285\n",
      "\n",
      "common use   0.08\n",
      "\n",
      "a corporation   0.001226993865030675\n",
      "\n",
      "usually has   0.03125\n",
      "\n",
      "use splicing   0.013888888888888888\n",
      "\n",
      "Success Rate   1.0\n",
      "\n",
      "nodes in   0.14285714285714285\n",
      "\n",
      "may blend   0.019230769230769232\n",
      "\n",
      "terminology ,   1.0\n",
      "\n",
      "Systems with   0.08333333333333333\n",
      "\n",
      "Models .   0.3333333333333333\n",
      "\n",
      "identification pattern   0.2\n",
      "\n",
      "well-defined problem   1.0\n",
      "\n",
      "like that   0.03571428571428571\n",
      "\n",
      "application may   0.07142857142857142\n",
      "\n",
      "be directed   0.004219409282700422\n",
      "\n",
      "Relevance -LRB-   1.0\n",
      "\n",
      "Schools commonly   1.0\n",
      "\n",
      "to data   0.0026560424966799467\n",
      "\n",
      "If the   0.4\n",
      "\n",
      "rules through   0.023255813953488372\n",
      "\n",
      "ROUGE -LRB-   0.2\n",
      "\n",
      "example is   0.012345679012345678\n",
      "\n",
      "is worth   0.0040650406504065045\n",
      "\n",
      "which should   0.007246376811594203\n",
      "\n",
      "covers tasks   0.25\n",
      "\n",
      "in evaluation   0.0018726591760299626\n",
      "\n",
      "solve a   0.25\n",
      "\n",
      "result ,   0.2727272727272727\n",
      "\n",
      "benefits :   0.5\n",
      "\n",
      "generate polynomial-size   0.05555555555555555\n",
      "\n",
      "performance mainly   0.05555555555555555\n",
      "\n",
      "Full of   1.0\n",
      "\n",
      "database of   0.2\n",
      "\n",
      "make it   0.1\n",
      "\n",
      "common way   0.08\n",
      "\n",
      "medium levels   0.3333333333333333\n",
      "\n",
      "Mention must   1.0\n",
      "\n",
      "analysis Genre   0.015384615384615385\n",
      "\n",
      "database tables   0.1\n",
      "\n",
      "<s> Paul   0.0007686395080707148\n",
      "\n",
      "results when   0.09523809523809523\n",
      "\n",
      "researchers need   0.1\n",
      "\n",
      "chosen domain   0.2\n",
      "\n",
      "HMMs involve   0.125\n",
      "\n",
      "Harrison P.   1.0\n",
      "\n",
      "ambiguity than   0.125\n",
      "\n",
      "PageRank\\/TextRank on   1.0\n",
      "\n",
      "size and   0.3333333333333333\n",
      "\n",
      "high at   0.05555555555555555\n",
      "\n",
      "meet larger   0.25\n",
      "\n",
      "usually not   0.03125\n",
      "\n",
      "of summaries   0.0035650623885918\n",
      "\n",
      "practice of   0.5\n",
      "\n",
      "references .   0.25\n",
      "\n",
      "try to   1.0\n",
      "\n",
      "language in   0.006756756756756757\n",
      "\n",
      "recognition accuracy   0.05785123966942149\n",
      "\n",
      "-LRB- Recall-Oriented   0.005420054200542005\n",
      "\n",
      "using OCR   0.05084745762711865\n",
      "\n",
      "icon -RRB-   1.0\n",
      "\n",
      "known summaries   0.038461538461538464\n",
      "\n",
      "document retrieval   0.027777777777777776\n",
      "\n",
      "S. ,   1.0\n",
      "\n",
      "frequencies -LRB-   0.5\n",
      "\n",
      "`` corpora   0.005291005291005291\n",
      "\n",
      "handwriting ,   0.5\n",
      "\n",
      "printed characters   0.08333333333333333\n",
      "\n",
      "his book   0.08333333333333333\n",
      "\n",
      "how the   0.034482758620689655\n",
      "\n",
      "as models   0.003484320557491289\n",
      "\n",
      "currently in   0.14285714285714285\n",
      "\n",
      "reading and   0.25\n",
      "\n",
      "in picture   0.0018726591760299626\n",
      "\n",
      "validated and   1.0\n",
      "\n",
      "of years   0.00089126559714795\n",
      "\n",
      "Future research   0.5\n",
      "\n",
      "1985 ,   1.0\n",
      "\n",
      "serving a   1.0\n",
      "\n",
      "examples in   0.041666666666666664\n",
      "\n",
      "adapt to   1.0\n",
      "\n",
      "itself as   0.2\n",
      "\n",
      "variously defined   1.0\n",
      "\n",
      "speech naturally   0.006578947368421052\n",
      "\n",
      "Harris et   0.1111111111111111\n",
      "\n",
      "translate spoken   0.16666666666666666\n",
      "\n",
      "success and   0.2\n",
      "\n",
      "has already   0.011904761904761904\n",
      "\n",
      "worked by   0.2\n",
      "\n",
      "80 %   1.0\n",
      "\n",
      "pre-existing keyphrases   0.5\n",
      "\n",
      "-RRB- Critical   0.0027100271002710027\n",
      "\n",
      "consonants ,   0.3333333333333333\n",
      "\n",
      "is where   0.0040650406504065045\n",
      "\n",
      "revolution in   1.0\n",
      "\n",
      "in testing   0.0018726591760299626\n",
      "\n",
      "NLP -RRB-   0.0851063829787234\n",
      "\n",
      "Larry R.   0.5\n",
      "\n",
      "decision-support aids   1.0\n",
      "\n",
      "GRACE d'évaluation   1.0\n",
      "\n",
      "remains to   0.25\n",
      "\n",
      "additional features   0.16666666666666666\n",
      "\n",
      "stems from   0.5\n",
      "\n",
      "vagueness of   1.0\n",
      "\n",
      "e.g. from   0.017857142857142856\n",
      "\n",
      "where each   0.02857142857142857\n",
      "\n",
      "cursive script   0.4\n",
      "\n",
      "currently used   0.14285714285714285\n",
      "\n",
      "of cases   0.00089126559714795\n",
      "\n",
      "McDonald -LRB-   1.0\n",
      "\n",
      "noun phrases   0.07142857142857142\n",
      "\n",
      "of digital   0.00089126559714795\n",
      "\n",
      "have proposed   0.009615384615384616\n",
      "\n",
      "when deployed   0.02857142857142857\n",
      "\n",
      "one distinguishes   0.015384615384615385\n",
      "\n",
      "e.g. vocabulary   0.017857142857142856\n",
      "\n",
      "to ,   0.0026560424966799467\n",
      "\n",
      "A. Woods   0.2\n",
      "\n",
      "problem may   0.022727272727272728\n",
      "\n",
      "2010 and   0.3333333333333333\n",
      "\n",
      "devoted to   0.6\n",
      "\n",
      "and Rubin   0.001445086705202312\n",
      "\n",
      "When used   0.14285714285714285\n",
      "\n",
      "conducted with   0.2\n",
      "\n",
      "still largely   0.06666666666666667\n",
      "\n",
      "internal semantic   0.2\n",
      "\n",
      "parsing for   0.03571428571428571\n",
      "\n",
      "test document   0.1\n",
      "\n",
      "areas ,   0.16666666666666666\n",
      "\n",
      "were compared   0.04878048780487805\n",
      "\n",
      "into French   0.02564102564102564\n",
      "\n",
      "and patented   0.001445086705202312\n",
      "\n",
      "where much   0.02857142857142857\n",
      "\n",
      "and thus   0.004335260115606936\n",
      "\n",
      "review of   0.3333333333333333\n",
      "\n",
      "<s> Moreover   0.0030745580322828594\n",
      "\n",
      "concern .   1.0\n",
      "\n",
      "Europe ,   0.6\n",
      "\n",
      "or other   0.009009009009009009\n",
      "\n",
      "and classifying   0.001445086705202312\n",
      "\n",
      "other native   0.014285714285714285\n",
      "\n",
      "wide use   0.25\n",
      "\n",
      "feeling that   1.0\n",
      "\n",
      "retrieval and   0.2857142857142857\n",
      "\n",
      "EMR -LRB-   0.3333333333333333\n",
      "\n",
      "commonly serve   0.125\n",
      "\n",
      "OnStar ,   1.0\n",
      "\n",
      "mainland Scotland   1.0\n",
      "\n",
      "several qualities   0.045454545454545456\n",
      "\n",
      "Smartphones .   1.0\n",
      "\n",
      "a QA   0.0049079754601227\n",
      "\n",
      "of London   0.00089126559714795\n",
      "\n",
      "and possessives   0.001445086705202312\n",
      "\n",
      "Increase as   1.0\n",
      "\n",
      "more widely   0.010526315789473684\n",
      "\n",
      "from some   0.009615384615384616\n",
      "\n",
      "occur ,   0.2\n",
      "\n",
      "the identification   0.001384083044982699\n",
      "\n",
      "a finite   0.00245398773006135\n",
      "\n",
      "output simply   0.038461538461538464\n",
      "\n",
      "broken in   0.2\n",
      "\n",
      "complex sounds   0.041666666666666664\n",
      "\n",
      "slide represent   1.0\n",
      "\n",
      "Such systems   0.125\n",
      "\n",
      "parsers for   0.15384615384615385\n",
      "\n",
      "disappear .   1.0\n",
      "\n",
      "a summary   0.0098159509202454\n",
      "\n",
      "of research   0.0071301247771836\n",
      "\n",
      "of Speech   0.00089126559714795\n",
      "\n",
      "that contain   0.010638297872340425\n",
      "\n",
      "that integrated   0.0035460992907801418\n",
      "\n",
      "with part-of-speech   0.00546448087431694\n",
      "\n",
      "Computed every   1.0\n",
      "\n",
      "2009 -RRB-   0.3333333333333333\n",
      "\n",
      "representative of   1.0\n",
      "\n",
      "initial sounds   0.3333333333333333\n",
      "\n",
      "other approaches   0.014285714285714285\n",
      "\n",
      "life ?   0.25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter preselects   0.5\n",
      "\n",
      "broadcast news   1.0\n",
      "\n",
      "The hidden   0.005208333333333333\n",
      "\n",
      "more generally   0.010526315789473684\n",
      "\n",
      "<s> Hulth   0.0023059185242121443\n",
      "\n",
      "be assumed   0.004219409282700422\n",
      "\n",
      "analysis tasks   0.015384615384615385\n",
      "\n",
      "her judgement   0.5\n",
      "\n",
      "who utilize   0.1\n",
      "\n",
      "some writing   0.012048192771084338\n",
      "\n",
      "of images   0.00089126559714795\n",
      "\n",
      "to support   0.0026560424966799467\n",
      "\n",
      "`` sailor   0.010582010582010581\n",
      "\n",
      "for top-down   0.0036101083032490976\n",
      "\n",
      "characterize keyphrases   0.5\n",
      "\n",
      "Art Graesser   1.0\n",
      "\n",
      "count T   0.2\n",
      "\n",
      "National Giro   0.3333333333333333\n",
      "\n",
      "create features   0.058823529411764705\n",
      "\n",
      "analyzed using   0.2\n",
      "\n",
      "Open source   1.0\n",
      "\n",
      "reduction ,   0.5\n",
      "\n",
      "Envelopes may   1.0\n",
      "\n",
      "that consider   0.0035460992907801418\n",
      "\n",
      "and abstraction   0.002890173410404624\n",
      "\n",
      "and there   0.005780346820809248\n",
      "\n",
      "behavior even   0.5\n",
      "\n",
      "by deep   0.005714285714285714\n",
      "\n",
      "then given   0.02857142857142857\n",
      "\n",
      "computer automated   0.022727272727272728\n",
      "\n",
      "is one   0.012195121951219513\n",
      "\n",
      "is similar   0.0040650406504065045\n",
      "\n",
      "question classifier   0.023809523809523808\n",
      "\n",
      "are vulnerable   0.004149377593360996\n",
      "\n",
      "a common   0.00245398773006135\n",
      "\n",
      "more like   0.010526315789473684\n",
      "\n",
      "theory in   0.07692307692307693\n",
      "\n",
      "phrases .   0.3125\n",
      "\n",
      "Birkbeck College   1.0\n",
      "\n",
      "summers of   1.0\n",
      "\n",
      "Reader 's   1.0\n",
      "\n",
      "phrases with   0.0625\n",
      "\n",
      "<s> Rules   0.0007686395080707148\n",
      "\n",
      "generated is   0.06666666666666667\n",
      "\n",
      "University of   0.3333333333333333\n",
      "\n",
      "effects of   1.0\n",
      "\n",
      "This reader   0.015873015873015872\n",
      "\n",
      "US Veterans   0.14285714285714285\n",
      "\n",
      "analytical artificial   0.5\n",
      "\n",
      "<s> Examples   0.0023059185242121443\n",
      "\n",
      "TextRank uses   0.14285714285714285\n",
      "\n",
      "of dividing   0.00267379679144385\n",
      "\n",
      "DARPA -RRB-   0.25\n",
      "\n",
      "stationary signal   0.2857142857142857\n",
      "\n",
      "deterministic decisions   0.25\n",
      "\n",
      "backgrounds ,   1.0\n",
      "\n",
      "even so   0.037037037037037035\n",
      "\n",
      "to book   0.0013280212483399733\n",
      "\n",
      "its component   0.02857142857142857\n",
      "\n",
      "an attribute   0.007575757575757576\n",
      "\n",
      "were question   0.024390243902439025\n",
      "\n",
      "its utility   0.02857142857142857\n",
      "\n",
      "Text simplification   0.16666666666666666\n",
      "\n",
      "Corpus developed   0.0625\n",
      "\n",
      "each such   0.022222222222222223\n",
      "\n",
      "and perspective   0.001445086705202312\n",
      "\n",
      "Speaking ''   1.0\n",
      "\n",
      "chart parsing   1.0\n",
      "\n",
      "limited application   0.1\n",
      "\n",
      "The difficulty   0.015625\n",
      "\n",
      "'s work   0.0196078431372549\n",
      "\n",
      "phrased in   1.0\n",
      "\n",
      "utterance can   0.3333333333333333\n",
      "\n",
      "by its   0.005714285714285714\n",
      "\n",
      "systems typically   0.008928571428571428\n",
      "\n",
      "and cognition   0.001445086705202312\n",
      "\n",
      "In short   0.009523809523809525\n",
      "\n",
      "can improve   0.0055248618784530384\n",
      "\n",
      "edges with   0.14285714285714285\n",
      "\n",
      "speech-to-text processing   0.5\n",
      "\n",
      "say whether   0.14285714285714285\n",
      "\n",
      "is checking   0.0020325203252032522\n",
      "\n",
      "non-trivial ,   0.5\n",
      "\n",
      "using CSIS   0.01694915254237288\n",
      "\n",
      "The 26   0.005208333333333333\n",
      "\n",
      "tagger on   0.1111111111111111\n",
      "\n",
      "computers .   0.2222222222222222\n",
      "\n",
      "usually do   0.03125\n",
      "\n",
      "It converted   0.02631578947368421\n",
      "\n",
      "journal ``   0.3333333333333333\n",
      "\n",
      "on simple   0.0047169811320754715\n",
      "\n",
      "formed the   0.2\n",
      "\n",
      "controversial .   1.0\n",
      "\n",
      "it began   0.008547008547008548\n",
      "\n",
      ", outputting   0.0005614823133071309\n",
      "\n",
      "as corresponding   0.003484320557491289\n",
      "\n",
      "keyphrase system   0.05263157894736842\n",
      "\n",
      "of good   0.00089126559714795\n",
      "\n",
      "languages words   0.02\n",
      "\n",
      "linguistics that   0.1\n",
      "\n",
      "Models In   0.3333333333333333\n",
      "\n",
      "experimented with   1.0\n",
      "\n",
      "be recognized   0.008438818565400843\n",
      "\n",
      "also because   0.014492753623188406\n",
      "\n",
      "verify the   1.0\n",
      "\n",
      "be an   0.004219409282700422\n",
      "\n",
      "difficult process   0.03571428571428571\n",
      "\n",
      "a filter   0.001226993865030675\n",
      "\n",
      "AT&T libraries   1.0\n",
      "\n",
      "XML documents   1.0\n",
      "\n",
      "-RRB- vs.   0.0027100271002710027\n",
      "\n",
      "and intra-texual   0.001445086705202312\n",
      "\n",
      ", text-to-speech   0.0011229646266142617\n",
      "\n",
      "-RRB- while   0.0027100271002710027\n",
      "\n",
      "<s> Using   0.0015372790161414297\n",
      "\n",
      "phrasing the   1.0\n",
      "\n",
      "probable answer   1.0\n",
      "\n",
      "his wingmen   0.08333333333333333\n",
      "\n",
      "-RRB- refer   0.0027100271002710027\n",
      "\n",
      "deep systems   0.14285714285714285\n",
      "\n",
      "-RRB- into   0.005420054200542005\n",
      "\n",
      "on how   0.009433962264150943\n",
      "\n",
      "across most   0.6\n",
      "\n",
      "space is   0.2\n",
      "\n",
      "calculator or   0.5\n",
      "\n",
      "technology .   0.09090909090909091\n",
      "\n",
      "sequence alignment   0.125\n",
      "\n",
      "words in   0.09174311926605505\n",
      "\n",
      "'s usually   0.0196078431372549\n",
      "\n",
      "sentence in   0.041666666666666664\n",
      "\n",
      "the draft   0.0006920415224913495\n",
      "\n",
      "gold-standard against   1.0\n",
      "\n",
      "<s> because   0.0007686395080707148\n",
      "\n",
      "simply based   0.08333333333333333\n",
      "\n",
      "SBD -RRB-   1.0\n",
      "\n",
      "indicating important   1.0\n",
      "\n",
      "OnlineOCR With   0.3333333333333333\n",
      "\n",
      "given text   0.041666666666666664\n",
      "\n",
      "but have   0.029411764705882353\n",
      "\n",
      "think of   0.3333333333333333\n",
      "\n",
      "especially because   0.06666666666666667\n",
      "\n",
      "e.g. Syntactic   0.017857142857142856\n",
      "\n",
      "-LRB- Black   0.0027100271002710027\n",
      "\n",
      "main ideas   0.125\n",
      "\n",
      "candidates can   0.2\n",
      "\n",
      ", internet   0.0005614823133071309\n",
      "\n",
      "often as   0.045454545454545456\n",
      "\n",
      "the speech-enabled   0.0006920415224913495\n",
      "\n",
      "of fusion   0.00089126559714795\n",
      "\n",
      ", generating   0.0005614823133071309\n",
      "\n",
      "mathematical rules   0.5\n",
      "\n",
      "innumerable studies   1.0\n",
      "\n",
      "John McCarthy   0.125\n",
      "\n",
      "of possible   0.00267379679144385\n",
      "\n",
      "of hours   0.00089126559714795\n",
      "\n",
      "linguistic nuances   0.0625\n",
      "\n",
      "the generated   0.001384083044982699\n",
      "\n",
      "grammatical relationships   0.09090909090909091\n",
      "\n",
      "use an   0.013888888888888888\n",
      "\n",
      "approached keyphrase   0.5\n",
      "\n",
      "whole phrases   0.1111111111111111\n",
      "\n",
      "most later   0.017241379310344827\n",
      "\n",
      "any pauses   0.03225806451612903\n",
      "\n",
      "and broadband   0.001445086705202312\n",
      "\n",
      "<s> We   0.005380476556495004\n",
      "\n",
      "person-years of   1.0\n",
      "\n",
      "Interlingual Main   0.3333333333333333\n",
      "\n",
      "increased and   0.2\n",
      "\n",
      "word pronunciations   0.016666666666666666\n",
      "\n",
      "which they   0.014492753623188406\n",
      "\n",
      "is preferable   0.0020325203252032522\n",
      "\n",
      "sentence transformations   0.020833333333333332\n",
      "\n",
      "sound waves   0.05\n",
      "\n",
      "<s> Although   0.005380476556495004\n",
      "\n",
      "-LRB- Harris   0.005420054200542005\n",
      "\n",
      "moved across   1.0\n",
      "\n",
      "noun in   0.07142857142857142\n",
      "\n",
      "Kurzweil Applied   0.14285714285714285\n",
      "\n",
      "The experiment   0.005208333333333333\n",
      "\n",
      "substitution of   1.0\n",
      "\n",
      "copy the   1.0\n",
      "\n",
      "The lowest   0.005208333333333333\n",
      "\n",
      "a substantial   0.001226993865030675\n",
      "\n",
      ", communication   0.0005614823133071309\n",
      "\n",
      "for reasons   0.0036101083032490976\n",
      "\n",
      "Development Activity   1.0\n",
      "\n",
      "keyphrases that   0.08571428571428572\n",
      "\n",
      ", E   0.0005614823133071309\n",
      "\n",
      "in any   0.0018726591760299626\n",
      "\n",
      ", volume   0.0005614823133071309\n",
      "\n",
      "show the   1.0\n",
      "\n",
      "code of   0.14285714285714285\n",
      "\n",
      "large collections   0.043478260869565216\n",
      "\n",
      "consumer ,   1.0\n",
      "\n",
      "Hafiz ,   1.0\n",
      "\n",
      "methods can   0.022727272727272728\n",
      "\n",
      "came from   0.5\n",
      "\n",
      "words must   0.009174311926605505\n",
      "\n",
      "or even   0.02252252252252252\n",
      "\n",
      "be keyphrases   0.004219409282700422\n",
      "\n",
      "a trend   0.001226993865030675\n",
      "\n",
      "a real-time   0.001226993865030675\n",
      "\n",
      "to accurately   0.0013280212483399733\n",
      "\n",
      "Please improve   0.3333333333333333\n",
      "\n",
      "having the   0.2\n",
      "\n",
      "discrete terms   0.3333333333333333\n",
      "\n",
      "Institute -LRB-   1.0\n",
      "\n",
      "basis for   0.3333333333333333\n",
      "\n",
      "Kolodner .   1.0\n",
      "\n",
      "construct an   0.3333333333333333\n",
      "\n",
      "to internal   0.0013280212483399733\n",
      "\n",
      "programs that   0.09090909090909091\n",
      "\n",
      "of valuable   0.00089126559714795\n",
      "\n",
      "corpus ,   0.06451612903225806\n",
      "\n",
      "approximately divided   0.5\n",
      "\n",
      "work is   0.125\n",
      "\n",
      "adjacent words   0.3333333333333333\n",
      "\n",
      "theory for   0.07692307692307693\n",
      "\n",
      "features of   0.15384615384615385\n",
      "\n",
      "analysis could   0.015384615384615385\n",
      "\n",
      "ushered in   1.0\n",
      "\n",
      "In natural   0.009523809523809525\n",
      "\n",
      "and news   0.001445086705202312\n",
      "\n",
      "in NLG   0.0056179775280898875\n",
      "\n",
      "Coulthard ,   1.0\n",
      "\n",
      "Other tasks   0.14285714285714285\n",
      "\n",
      "substantially .   1.0\n",
      "\n",
      "articulated theory   1.0\n",
      "\n",
      "and after   0.004335260115606936\n",
      "\n",
      "recognition of   0.0743801652892562\n",
      "\n",
      "to rewrite   0.0013280212483399733\n",
      "\n",
      "on an   0.014150943396226415\n",
      "\n",
      "to adjust\\/correct   0.0013280212483399733\n",
      "\n",
      "obtained by   0.5714285714285714\n",
      "\n",
      "On others   0.16666666666666666\n",
      "\n",
      "creating a   0.2857142857142857\n",
      "\n",
      "sound that   0.05\n",
      "\n",
      "be output   0.004219409282700422\n",
      "\n",
      "robustness against   0.5\n",
      "\n",
      "US baseball   0.14285714285714285\n",
      "\n",
      "that closely   0.0035460992907801418\n",
      "\n",
      "When punctuation   0.14285714285714285\n",
      "\n",
      "metrics correlate   0.1111111111111111\n",
      "\n",
      "Paroubek P.   1.0\n",
      "\n",
      ", however   0.006176305446378439\n",
      "\n",
      "past-tense verb   1.0\n",
      "\n",
      "asked and   0.3333333333333333\n",
      "\n",
      "purely statistical   1.0\n",
      "\n",
      "interaction ,   0.125\n",
      "\n",
      "text into   0.0440251572327044\n",
      "\n",
      "algorithm is   0.17857142857142858\n",
      "\n",
      "comparison of   0.3333333333333333\n",
      "\n",
      "Advanced applications   0.2\n",
      "\n",
      "discourse and   0.1111111111111111\n",
      "\n",
      "long research   0.5\n",
      "\n",
      "with Japanese   0.00546448087431694\n",
      "\n",
      "13 ,   0.5\n",
      "\n",
      "lexical segment   0.07692307692307693\n",
      "\n",
      "best single   0.05555555555555555\n",
      "\n",
      "an array   0.007575757575757576\n",
      "\n",
      "as early   0.003484320557491289\n",
      "\n",
      "POS categories   0.07692307692307693\n",
      "\n",
      "summarization involves   0.02\n",
      "\n",
      "Much effort   0.3333333333333333\n",
      "\n",
      "the subjectivity   0.0006920415224913495\n",
      "\n",
      "data sets   0.03896103896103896\n",
      "\n",
      "on text   0.0047169811320754715\n",
      "\n",
      "-LRB- such   0.02168021680216802\n",
      "\n",
      "Single Word   1.0\n",
      "\n",
      "of two   0.0017825311942959\n",
      "\n",
      "be deployed   0.004219409282700422\n",
      "\n",
      "wanted to   1.0\n",
      "\n",
      "<s> Language   0.0007686395080707148\n",
      "\n",
      "is constructed   0.0040650406504065045\n",
      "\n",
      "a component   0.00245398773006135\n",
      "\n",
      "are created   0.012448132780082987\n",
      "\n",
      ", moves   0.0005614823133071309\n",
      "\n",
      "depends greatly   0.125\n",
      "\n",
      "such application   0.008130081300813009\n",
      "\n",
      "good approximation   0.07692307692307693\n",
      "\n",
      "query relevant   0.6666666666666666\n",
      "\n",
      "process ,   0.027777777777777776\n",
      "\n",
      "For this   0.04918032786885246\n",
      "\n",
      "first statistical   0.06060606060606061\n",
      "\n",
      "system and   0.03225806451612903\n",
      "\n",
      "and Web   0.001445086705202312\n",
      "\n",
      "that aid   0.0035460992907801418\n",
      "\n",
      "'' which   0.005154639175257732\n",
      "\n",
      ", 1979   0.0005614823133071309\n",
      "\n",
      "7 %   0.14285714285714285\n",
      "\n",
      "might want   0.038461538461538464\n",
      "\n",
      "low-resolution ,   1.0\n",
      "\n",
      "these are   0.047619047619047616\n",
      "\n",
      "The earliest   0.005208333333333333\n",
      "\n",
      "of 2009   0.00089126559714795\n",
      "\n",
      "require exponential   0.045454545454545456\n",
      "\n",
      "infer where   1.0\n",
      "\n",
      "a journal   0.001226993865030675\n",
      "\n",
      "healthcare is   1.0\n",
      "\n",
      "taken to   0.3333333333333333\n",
      "\n",
      "solved in   0.2\n",
      "\n",
      "the 100   0.0006920415224913495\n",
      "\n",
      "<s> Sound   0.0015372790161414297\n",
      "\n",
      "Australia .   1.0\n",
      "\n",
      "are rarely   0.004149377593360996\n",
      "\n",
      "ask him   0.25\n",
      "\n",
      "document classification   0.05555555555555555\n",
      "\n",
      "track of   1.0\n",
      "\n",
      "be .   0.004219409282700422\n",
      "\n",
      "off as   0.5\n",
      "\n",
      "substantial ambiguity   0.2\n",
      "\n",
      "emails -RRB-   0.5\n",
      "\n",
      "president of   1.0\n",
      "\n",
      "highly and   0.1111111111111111\n",
      "\n",
      "and curves   0.001445086705202312\n",
      "\n",
      "the role   0.001384083044982699\n",
      "\n",
      "and analysis   0.001445086705202312\n",
      "\n",
      "stationary distribution   0.2857142857142857\n",
      "\n",
      "little inflectional   0.3333333333333333\n",
      "\n",
      "many examples   0.019230769230769232\n",
      "\n",
      "dozens of   1.0\n",
      "\n",
      "very rudimentary   0.024390243902439025\n",
      "\n",
      "this type   0.03296703296703297\n",
      "\n",
      "Trained linguists   1.0\n",
      "\n",
      "developing Q&A   0.25\n",
      "\n",
      "by standard   0.005714285714285714\n",
      "\n",
      "real ATC   0.1111111111111111\n",
      "\n",
      "them out   0.05263157894736842\n",
      "\n",
      "systems have   0.044642857142857144\n",
      "\n",
      "-RRB- recognize   0.0027100271002710027\n",
      "\n",
      "important distinction   0.125\n",
      "\n",
      "looking at   0.2\n",
      "\n",
      "model would   0.1\n",
      "\n",
      "condition that   1.0\n",
      "\n",
      "delimiter .   1.0\n",
      "\n",
      "displays .   1.0\n",
      "\n",
      "NLP comes   0.02127659574468085\n",
      "\n",
      "True\\/False is   1.0\n",
      "\n",
      "therefore to   0.2\n",
      "\n",
      "to corpus   0.0013280212483399733\n",
      "\n",
      "of similarity   0.00089126559714795\n",
      "\n",
      "elaborate theories   1.0\n",
      "\n",
      "-LRB- i.e.   0.02981029810298103\n",
      "\n",
      "be represented   0.008438818565400843\n",
      "\n",
      "or the   0.04054054054054054\n",
      "\n",
      "quantity of   0.3333333333333333\n",
      "\n",
      ", support   0.0005614823133071309\n",
      "\n",
      "nice properties   0.25\n",
      "\n",
      ": control   0.00980392156862745\n",
      "\n",
      "A semantic   0.02\n",
      "\n",
      "tasks ,   0.125\n",
      "\n",
      "Mr. is   0.5\n",
      "\n",
      "information of   0.021739130434782608\n",
      "\n",
      "data will   0.012987012987012988\n",
      "\n",
      "more commonly   0.021052631578947368\n",
      "\n",
      "put the   0.25\n",
      "\n",
      "Character Recognition   1.0\n",
      "\n",
      "dynamics and   0.5\n",
      "\n",
      "online expression   0.125\n",
      "\n",
      "characters .   0.125\n",
      "\n",
      "the big   0.0006920415224913495\n",
      "\n",
      "which itself   0.007246376811594203\n",
      "\n",
      "many applications   0.038461538461538464\n",
      "\n",
      "the Vocabulary   0.0006920415224913495\n",
      "\n",
      "shallow-transfer machine   1.0\n",
      "\n",
      "application domain   0.07142857142857142\n",
      "\n",
      "<s> User   0.0007686395080707148\n",
      "\n",
      "of producing   0.00089126559714795\n",
      "\n",
      "where the   0.37142857142857144\n",
      "\n",
      "sentence -LRB-   0.020833333333333332\n",
      "\n",
      "<s> Question   0.003843197540353574\n",
      "\n",
      "human judge   0.021739130434782608\n",
      "\n",
      "on context   0.0047169811320754715\n",
      "\n",
      "`` political   0.005291005291005291\n",
      "\n",
      "OCR Since   0.02040816326530612\n",
      "\n",
      "the analysis   0.002768166089965398\n",
      "\n",
      "a pre-existing   0.001226993865030675\n",
      "\n",
      "translations ,   0.5\n",
      "\n",
      "etc. --   0.045454545454545456\n",
      "\n",
      "the algorithm   0.0006920415224913495\n",
      "\n",
      "image consisting   0.3333333333333333\n",
      "\n",
      "Arabic -RRB-   0.25\n",
      "\n",
      "of building   0.00089126559714795\n",
      "\n",
      "could just   0.0625\n",
      "\n",
      "phonemes of   0.16666666666666666\n",
      "\n",
      "some linguistic   0.012048192771084338\n",
      "\n",
      "of surrounding   0.00089126559714795\n",
      "\n",
      "these summaries   0.047619047619047616\n",
      "\n",
      "important parts   0.0625\n",
      "\n",
      "software that   0.037037037037037035\n",
      "\n",
      "<s> About   0.0007686395080707148\n",
      "\n",
      "sets ;   0.09090909090909091\n",
      "\n",
      "called a   0.05555555555555555\n",
      "\n",
      "in Northern   0.0018726591760299626\n",
      "\n",
      "<s> Sentence   0.0023059185242121443\n",
      "\n",
      "advantage that   0.2\n",
      "\n",
      "Major tasks   0.5\n",
      "\n",
      "dedicated OCR   0.3333333333333333\n",
      "\n",
      "and recursive-descent   0.001445086705202312\n",
      "\n",
      "to focus   0.0013280212483399733\n",
      "\n",
      "simply ranks   0.08333333333333333\n",
      "\n",
      "sound really   0.05\n",
      "\n",
      "social interaction   0.07142857142857142\n",
      "\n",
      "noun ,   0.42857142857142855\n",
      "\n",
      "processing The   0.018518518518518517\n",
      "\n",
      "demonstrates the   1.0\n",
      "\n",
      "different grammatical   0.02040816326530612\n",
      "\n",
      "distance to   0.3333333333333333\n",
      "\n",
      "An 8   0.0625\n",
      "\n",
      "successive words   0.5\n",
      "\n",
      "goal -RRB-   0.14285714285714285\n",
      "\n",
      "decorrelating the   1.0\n",
      "\n",
      "class of   0.75\n",
      "\n",
      "other NLP   0.014285714285714285\n",
      "\n",
      "also manual   0.014492753623188406\n",
      "\n",
      "meaning from   0.043478260869565216\n",
      "\n",
      "techniques ,   0.08695652173913043\n",
      "\n",
      "for measuring   0.0036101083032490976\n",
      "\n",
      "Yehoshua Bar-Hillel   1.0\n",
      "\n",
      "manually or   0.25\n",
      "\n",
      "answer candidate   0.03333333333333333\n",
      "\n",
      "last year   0.2\n",
      "\n",
      "methodologies .   1.0\n",
      "\n",
      "keyphrases attached   0.02857142857142857\n",
      "\n",
      "shift-reduce algorithm   1.0\n",
      "\n",
      "DCD library   1.0\n",
      "\n",
      "possible improvement   0.041666666666666664\n",
      "\n",
      "training data   0.35714285714285715\n",
      "\n",
      "are SHRDLU   0.004149377593360996\n",
      "\n",
      "broken into   0.6\n",
      "\n",
      "under a   0.2\n",
      "\n",
      "Automatic translation   0.1111111111111111\n",
      "\n",
      "pertain strongly   1.0\n",
      "\n",
      "DARPA Speech   0.25\n",
      "\n",
      "high .   0.05555555555555555\n",
      "\n",
      "In speech   0.009523809523809525\n",
      "\n",
      "table ''   0.14285714285714285\n",
      "\n",
      "Cynthia Hardy   1.0\n",
      "\n",
      "if indeed   0.03571428571428571\n",
      "\n",
      "1949 RCA   0.5\n",
      "\n",
      "stock .   0.6666666666666666\n",
      "\n",
      "one font   0.015384615384615385\n",
      "\n",
      "paraphrases -LRB-   1.0\n",
      "\n",
      "Wikipedia 's   0.5\n",
      "\n",
      "`` Army   0.005291005291005291\n",
      "\n",
      "; nor   0.02127659574468085\n",
      "\n",
      "Automated Summarizers   0.5\n",
      "\n",
      "as the   0.09407665505226481\n",
      "\n",
      "meets the   0.5\n",
      "\n",
      "part-of-speech categories   0.06666666666666667\n",
      "\n",
      "of unigrams   0.0017825311942959\n",
      "\n",
      "significant increases   0.1111111111111111\n",
      "\n",
      "a basis   0.00245398773006135\n",
      "\n",
      "since they   0.1\n",
      "\n",
      "10msec section   0.5\n",
      "\n",
      "parser generates   0.0625\n",
      "\n",
      "cover .   1.0\n",
      "\n",
      "heteroscedastic linear   1.0\n",
      "\n",
      "traffic controllers   1.0\n",
      "\n",
      "Processing -RRB-   0.25\n",
      "\n",
      "statistical models   0.21212121212121213\n",
      "\n",
      "a classifier   0.001226993865030675\n",
      "\n",
      "voice and   0.07692307692307693\n",
      "\n",
      "in popular   0.0018726591760299626\n",
      "\n",
      "state a   0.07142857142857142\n",
      "\n",
      "algorithms which   0.02857142857142857\n",
      "\n",
      "stress and   0.5\n",
      "\n",
      "applications seek   0.04\n",
      "\n",
      "Lifeline as   1.0\n",
      "\n",
      "statistical inference   0.06060606060606061\n",
      "\n",
      "guessing wrong   1.0\n",
      "\n",
      "algorithms used   0.02857142857142857\n",
      "\n",
      "The following   0.020833333333333332\n",
      "\n",
      "patent for   0.25\n",
      "\n",
      "be around   0.004219409282700422\n",
      "\n",
      "one observation   0.015384615384615385\n",
      "\n",
      ", Walter   0.0005614823133071309\n",
      "\n",
      "units --   0.14285714285714285\n",
      "\n",
      "ATC training   0.4\n",
      "\n",
      "latent semantic   1.0\n",
      "\n",
      "unsupervised keyphrase   0.125\n",
      "\n",
      "et al.   1.0\n",
      "\n",
      "Margaret Wetherell   1.0\n",
      "\n",
      "addition to   0.5\n",
      "\n",
      "summaries can   0.046511627906976744\n",
      "\n",
      "unlabeled data   1.0\n",
      "\n",
      "a process   0.0049079754601227\n",
      "\n",
      "Query expansion   1.0\n",
      "\n",
      "assumption -LRB-   0.5\n",
      "\n",
      "discourse in   0.05555555555555555\n",
      "\n",
      "to choose   0.0013280212483399733\n",
      "\n",
      "technology devised   0.045454545454545456\n",
      "\n",
      "manipulate the   0.3333333333333333\n",
      "\n",
      "rules ,   0.11627906976744186\n",
      "\n",
      "Sentence boundary   0.2\n",
      "\n",
      "centroid ''   0.5\n",
      "\n",
      "that involves   0.0035460992907801418\n",
      "\n",
      "sometimes confused   0.07692307692307693\n",
      "\n",
      "PCFGs -LRB-   1.0\n",
      "\n",
      "a company   0.001226993865030675\n",
      "\n",
      "than one   0.06666666666666667\n",
      "\n",
      "explicitly mention   0.25\n",
      "\n",
      "the term   0.0034602076124567475\n",
      "\n",
      "common tag   0.04\n",
      "\n",
      ", while   0.007860752386299831\n",
      "\n",
      "with sentences   0.00546448087431694\n",
      "\n",
      "robotic arm   1.0\n",
      "\n",
      "commonly associated   0.125\n",
      "\n",
      "as ``   0.04878048780487805\n",
      "\n",
      "'s idea   0.0196078431372549\n",
      "\n",
      "Web pages   0.2222222222222222\n",
      "\n",
      "document is   0.027777777777777776\n",
      "\n",
      "sometimes be   0.07692307692307693\n",
      "\n",
      "re-encode the   1.0\n",
      "\n",
      "comprehension .   0.42857142857142855\n",
      "\n",
      "fighter environment   0.16666666666666666\n",
      "\n",
      "specialised expertise   0.5\n",
      "\n",
      "despite the   0.3333333333333333\n",
      "\n",
      "-RRB- with   0.008130081300813009\n",
      "\n",
      ", they   0.004491858506457047\n",
      "\n",
      "trivial ,   0.25\n",
      "\n",
      "with payments   0.00546448087431694\n",
      "\n",
      "the 93-95   0.0006920415224913495\n",
      "\n",
      "optimized for   1.0\n",
      "\n",
      "at University   0.014705882352941176\n",
      "\n",
      "NLG may   0.047619047619047616\n",
      "\n",
      "electronic medical   0.5\n",
      "\n",
      "and can   0.011560693641618497\n",
      "\n",
      "usually the   0.03125\n",
      "\n",
      "often contains   0.022727272727272728\n",
      "\n",
      "social media   0.2857142857142857\n",
      "\n",
      "the programs   0.0006920415224913495\n",
      "\n",
      "Sager ,   0.5\n",
      "\n",
      "U.S. Patent   0.42857142857142855\n",
      "\n",
      "1975 -RRB-   1.0\n",
      "\n",
      ", even   0.0039303761931499155\n",
      "\n",
      "These two   0.058823529411764705\n",
      "\n",
      "Hence the   0.5\n",
      "\n",
      "Retrieval Conference   1.0\n",
      "\n",
      "takes into   0.3333333333333333\n",
      "\n",
      "knowledge frequently   0.037037037037037035\n",
      "\n",
      "in 1949   0.0018726591760299626\n",
      "\n",
      "font .   0.6666666666666666\n",
      "\n",
      "similarity or   0.1\n",
      "\n",
      "spend much   1.0\n",
      "\n",
      "Maximal Marginal   1.0\n",
      "\n",
      "like PDF   0.03571428571428571\n",
      "\n",
      "<s> Google   0.0007686395080707148\n",
      "\n",
      "memory Political   0.5\n",
      "\n",
      "relevant .   0.14285714285714285\n",
      "\n",
      "entering the   0.5\n",
      "\n",
      "understanding machine   0.030303030303030304\n",
      "\n",
      "prevent incorrect   1.0\n",
      "\n",
      "cache language   1.0\n",
      "\n",
      "questions or   0.038461538461538464\n",
      "\n",
      "signal or   0.16666666666666666\n",
      "\n",
      "culminating in   1.0\n",
      "\n",
      "'s polarity   0.0196078431372549\n",
      "\n",
      "by highly   0.005714285714285714\n",
      "\n",
      "the reverse   0.0006920415224913495\n",
      "\n",
      "<s> Two   0.005380476556495004\n",
      "\n",
      "Chilton ,   1.0\n",
      "\n",
      "processing natural   0.018518518518518517\n",
      "\n",
      "mean word   0.5\n",
      "\n",
      "developed CLAWS   0.038461538461538464\n",
      "\n",
      "related information   0.06666666666666667\n",
      "\n",
      "like HTML   0.03571428571428571\n",
      "\n",
      "on integrating   0.0047169811320754715\n",
      "\n",
      "to discriminate   0.0026560424966799467\n",
      "\n",
      ", imagery   0.0005614823133071309\n",
      "\n",
      "to learn   0.00796812749003984\n",
      "\n",
      "<s> Working   0.0007686395080707148\n",
      "\n",
      "enough for   0.2\n",
      "\n",
      "Several research   0.3333333333333333\n",
      "\n",
      "proposed keyphrases   0.2222222222222222\n",
      "\n",
      ", SAM   0.0005614823133071309\n",
      "\n",
      "priorities .   1.0\n",
      "\n",
      "to school-age   0.0013280212483399733\n",
      "\n",
      "multi-platforms such   1.0\n",
      "\n",
      "and smaller   0.001445086705202312\n",
      "\n",
      "<s> Both   0.0015372790161414297\n",
      "\n",
      "but those   0.014705882352941176\n",
      "\n",
      "flow together   1.0\n",
      "\n",
      "Lander Automatic   0.5\n",
      "\n",
      "create odd   0.058823529411764705\n",
      "\n",
      "rules can   0.06976744186046512\n",
      "\n",
      "APEXC machine   1.0\n",
      "\n",
      "makes the   0.25\n",
      "\n",
      "-LRB- correct   0.0027100271002710027\n",
      "\n",
      "T. 1991   1.0\n",
      "\n",
      "captured by   1.0\n",
      "\n",
      "and ELIZA   0.002890173410404624\n",
      "\n",
      "why certain   0.14285714285714285\n",
      "\n",
      "<s> CLAWS   0.0015372790161414297\n",
      "\n",
      "John 's   0.25\n",
      "\n",
      ", within   0.0005614823133071309\n",
      "\n",
      "the essence   0.001384083044982699\n",
      "\n",
      "but we   0.014705882352941176\n",
      "\n",
      "movie reviews   0.3333333333333333\n",
      "\n",
      "as Penn   0.003484320557491289\n",
      "\n",
      ", employs   0.0005614823133071309\n",
      "\n",
      "understanding systems   0.030303030303030304\n",
      "\n",
      "More powerful   0.1111111111111111\n",
      "\n",
      "including :   0.14285714285714285\n",
      "\n",
      "<s> Example-based   0.0007686395080707148\n",
      "\n",
      "1970 -LRB-   0.3333333333333333\n",
      "\n",
      "or keyphrases   0.0045045045045045045\n",
      "\n",
      "particularly the   0.2\n",
      "\n",
      "is then   0.01016260162601626\n",
      "\n",
      "software finding   0.037037037037037035\n",
      "\n",
      "as 1946   0.003484320557491289\n",
      "\n",
      "the semantic   0.001384083044982699\n",
      "\n",
      "that merges   0.0035460992907801418\n",
      "\n",
      "to assign   0.00398406374501992\n",
      "\n",
      "documents .   0.13157894736842105\n",
      "\n",
      "artificial intelligence   0.6363636363636364\n",
      "\n",
      "1952 .   0.5\n",
      "\n",
      "provided significant   0.2\n",
      "\n",
      "invented examples   0.5\n",
      "\n",
      "'s house   0.0392156862745098\n",
      "\n",
      "to enhance   0.0013280212483399733\n",
      "\n",
      ", NAACL   0.0005614823133071309\n",
      "\n",
      "evidence of   0.5\n",
      "\n",
      "Segmentation ,   1.0\n",
      "\n",
      "it may   0.017094017094017096\n",
      "\n",
      "as either   0.003484320557491289\n",
      "\n",
      "morphemes -LRB-   0.3333333333333333\n",
      "\n",
      "the spectrum   0.0006920415224913495\n",
      "\n",
      "to test   0.0026560424966799467\n",
      "\n",
      "writing -RRB-   0.1111111111111111\n",
      "\n",
      "of disassembling   0.00089126559714795\n",
      "\n",
      "centrality .   0.5\n",
      "\n",
      "customisation by   1.0\n",
      "\n",
      "only cares   0.02631578947368421\n",
      "\n",
      "had not   0.07142857142857142\n",
      "\n",
      "that had   0.0035460992907801418\n",
      "\n",
      "later part-of-speech   0.1\n",
      "\n",
      "two sentences   0.06896551724137931\n",
      "\n",
      "cases on   0.05555555555555555\n",
      "\n",
      "the provider   0.001384083044982699\n",
      "\n",
      "lexical segmentation   0.07692307692307693\n",
      "\n",
      "cursive text   0.2\n",
      "\n",
      "combination hidden   0.2\n",
      "\n",
      "Both acoustic   0.3333333333333333\n",
      "\n",
      "-LRB- Dec.   0.0027100271002710027\n",
      "\n",
      "names of   0.14285714285714285\n",
      "\n",
      "capabilities were   0.2\n",
      "\n",
      "mechanisms of   0.5\n",
      "\n",
      "interaction .   0.25\n",
      "\n",
      "additional evidence   0.16666666666666666\n",
      "\n",
      "David Nunan   0.25\n",
      "\n",
      "of applications   0.00267379679144385\n",
      "\n",
      "as those   0.017421602787456445\n",
      "\n",
      "complex endeavors   0.041666666666666664\n",
      "\n",
      "of intelligence   0.00089126559714795\n",
      "\n",
      "articles ,   0.125\n",
      "\n",
      "when it   0.02857142857142857\n",
      "\n",
      "characteristics .   0.5\n",
      "\n",
      "of reasons   0.00089126559714795\n",
      "\n",
      "express sentiment   0.2\n",
      "\n",
      "a recall-based   0.001226993865030675\n",
      "\n",
      "was declared   0.012987012987012988\n",
      "\n",
      "in overall   0.0018726591760299626\n",
      "\n",
      "OCR in   0.04081632653061224\n",
      "\n",
      "similar kind   0.037037037037037035\n",
      "\n",
      "facts about   1.0\n",
      "\n",
      "see it   0.05\n",
      "\n",
      "analyzed for   0.2\n",
      "\n",
      "intelligence systems   0.125\n",
      "\n",
      "human kind   0.021739130434782608\n",
      "\n",
      "Georgetown experiment   1.0\n",
      "\n",
      "and derive   0.001445086705202312\n",
      "\n",
      "the Pyramid   0.0006920415224913495\n",
      "\n",
      "in of   0.0018726591760299626\n",
      "\n",
      "language use   0.02702702702702703\n",
      "\n",
      "others ,   0.08333333333333333\n",
      "\n",
      "hand-printed documents   0.25\n",
      "\n",
      "For other   0.01639344262295082\n",
      "\n",
      "correct part   0.2\n",
      "\n",
      "context data   0.030303030303030304\n",
      "\n",
      "classifier module   0.14285714285714285\n",
      "\n",
      "what kinds   0.03125\n",
      "\n",
      "hear this   0.5\n",
      "\n",
      "also programs   0.014492753623188406\n",
      "\n",
      "discourse studies   0.027777777777777776\n",
      "\n",
      ", artificial   0.0011229646266142617\n",
      "\n",
      "Some unsupervised   0.047619047619047616\n",
      "\n",
      "cluster of   1.0\n",
      "\n",
      "`` Who   0.010582010582010581\n",
      "\n",
      "or transfer-based   0.0045045045045045045\n",
      "\n",
      "place in   0.5\n",
      "\n",
      "regard .   0.2\n",
      "\n",
      "Vocalizations vary   1.0\n",
      "\n",
      "happy .   1.0\n",
      "\n",
      "parse computationally   0.1111111111111111\n",
      "\n",
      "an interest   0.007575757575757576\n",
      "\n",
      "connects to   1.0\n",
      "\n",
      "invalid constructs   1.0\n",
      "\n",
      "and ask   0.001445086705202312\n",
      "\n",
      "or query   0.0045045045045045045\n",
      "\n",
      ", cursive   0.0005614823133071309\n",
      "\n",
      "questions asking   0.038461538461538464\n",
      "\n",
      "sources are   0.16666666666666666\n",
      "\n",
      "source for   0.041666666666666664\n",
      "\n",
      "In 1993   0.009523809523809525\n",
      "\n",
      "are still   0.016597510373443983\n",
      "\n",
      "language will   0.006756756756756757\n",
      "\n",
      ", therefore   0.0016844469399213925\n",
      "\n",
      "nested one   1.0\n",
      "\n",
      "cues help   1.0\n",
      "\n",
      "as computational   0.003484320557491289\n",
      "\n",
      "This rubric   0.015873015873015872\n",
      "\n",
      "Cleave and   1.0\n",
      "\n",
      "45 %   1.0\n",
      "\n",
      "if in   0.07142857142857142\n",
      "\n",
      "on lower   0.0047169811320754715\n",
      "\n",
      "Standard Annex   0.5\n",
      "\n",
      "which usually   0.007246376811594203\n",
      "\n",
      "experiment -LRB-   0.2\n",
      "\n",
      "relevance assessment   0.3333333333333333\n",
      "\n",
      "Microsoft Voice   0.5\n",
      "\n",
      "It had   0.02631578947368421\n",
      "\n",
      "training on   0.03571428571428571\n",
      "\n",
      "communication studies   0.2\n",
      "\n",
      "A document   0.02\n",
      "\n",
      "languages are   0.02\n",
      "\n",
      "Recent applications   0.3333333333333333\n",
      "\n",
      "five-star scale   1.0\n",
      "\n",
      "were published   0.024390243902439025\n",
      "\n",
      "hand ,   0.5\n",
      "\n",
      "British National   0.3333333333333333\n",
      "\n",
      "happens when   1.0\n",
      "\n",
      "query these   0.3333333333333333\n",
      "\n",
      ", Cleave   0.0005614823133071309\n",
      "\n",
      "on personal   0.0047169811320754715\n",
      "\n",
      "the envelope   0.0006920415224913495\n",
      "\n",
      "Much of   0.3333333333333333\n",
      "\n",
      "end up   0.25\n",
      "\n",
      "the art   0.001384083044982699\n",
      "\n",
      "overriding issue   1.0\n",
      "\n",
      "<s> Just   0.0007686395080707148\n",
      "\n",
      "the helicopter   0.0020761245674740486\n",
      "\n",
      "tools starts   0.16666666666666666\n",
      "\n",
      "toward actions   1.0\n",
      "\n",
      "text can   0.006289308176100629\n",
      "\n",
      "speaker can   0.05555555555555555\n",
      "\n",
      "Stephen H.   1.0\n",
      "\n",
      "two distinct   0.034482758620689655\n",
      "\n",
      "Analysis of   0.2\n",
      "\n",
      "printed pages   0.08333333333333333\n",
      "\n",
      "exponential time   0.5\n",
      "\n",
      "to cope   0.0013280212483399733\n",
      "\n",
      "than metrics   0.022222222222222223\n",
      "\n",
      "and larger   0.002890173410404624\n",
      "\n",
      "publication devoted   0.3333333333333333\n",
      "\n",
      "the concept   0.001384083044982699\n",
      "\n",
      "of mobile   0.00089126559714795\n",
      "\n",
      "documents is   0.02631578947368421\n",
      "\n",
      "A speaker   0.04\n",
      "\n",
      "trends of   1.0\n",
      "\n",
      "were later   0.024390243902439025\n",
      "\n",
      "Duchess was   1.0\n",
      "\n",
      "<s> Internet   0.0007686395080707148\n",
      "\n",
      "system might   0.010752688172043012\n",
      "\n",
      "explicitly present   0.25\n",
      "\n",
      "Thus the   0.08333333333333333\n",
      "\n",
      "Creating referring   0.5\n",
      "\n",
      "highly interactive   0.1111111111111111\n",
      "\n",
      "language are   0.006756756756756757\n",
      "\n",
      "ongoing issue   0.5\n",
      "\n",
      "is searched   0.0020325203252032522\n",
      "\n",
      "momentum for   1.0\n",
      "\n",
      "New Orleans   1.0\n",
      "\n",
      "Recall measures   0.3333333333333333\n",
      "\n",
      "ISO\\/TC37 and   1.0\n",
      "\n",
      "from MUC   0.009615384615384616\n",
      "\n",
      "study ,   0.25\n",
      "\n",
      "row ,   1.0\n",
      "\n",
      "different left   0.02040816326530612\n",
      "\n",
      "core database   0.5\n",
      "\n",
      "fonts ,   0.3333333333333333\n",
      "\n",
      "Army ,   0.25\n",
      "\n",
      "of life   0.00089126559714795\n",
      "\n",
      "focused on   0.9090909090909091\n",
      "\n",
      "the table   0.001384083044982699\n",
      "\n",
      "translator need   0.14285714285714285\n",
      "\n",
      "domain tends   0.05\n",
      "\n",
      "subsequent application   0.5\n",
      "\n",
      "popular is   0.1111111111111111\n",
      "\n",
      "typically agree   0.05555555555555555\n",
      "\n",
      "similar clues   0.037037037037037035\n",
      "\n",
      "the above   0.001384083044982699\n",
      "\n",
      "transcended the   1.0\n",
      "\n",
      "any feedback   0.03225806451612903\n",
      "\n",
      "nasality ,   1.0\n",
      "\n",
      "Word error   0.14285714285714285\n",
      "\n",
      "are BASEBALL   0.004149377593360996\n",
      "\n",
      "system can   0.010752688172043012\n",
      "\n",
      "up of   0.045454545454545456\n",
      "\n",
      "LexRank deals   0.08333333333333333\n",
      "\n",
      "still quite   0.06666666666666667\n",
      "\n",
      "contractions ,   0.5\n",
      "\n",
      "the evaluators   0.0006920415224913495\n",
      "\n",
      "such a   0.04878048780487805\n",
      "\n",
      "<s> Text   0.0015372790161414297\n",
      "\n",
      "the Penn   0.005536332179930796\n",
      "\n",
      ", Louise   0.0005614823133071309\n",
      "\n",
      ", despite   0.0005614823133071309\n",
      "\n",
      "commonly taught   0.125\n",
      "\n",
      "anything ,   1.0\n",
      "\n",
      "Cary Grant   1.0\n",
      "\n",
      "have limited   0.009615384615384616\n",
      "\n",
      "would correspond   0.018867924528301886\n",
      "\n",
      "or structures   0.0045045045045045045\n",
      "\n",
      "after applying   0.08333333333333333\n",
      "\n",
      "learned is   0.2\n",
      "\n",
      "or sometimes   0.0045045045045045045\n",
      "\n",
      "commercial efforts   0.18181818181818182\n",
      "\n",
      "grammatical structure   0.09090909090909091\n",
      "\n",
      "parsers in   0.07692307692307693\n",
      "\n",
      "both algorithms   0.03225806451612903\n",
      "\n",
      "It refers   0.02631578947368421\n",
      "\n",
      "method can   0.0625\n",
      "\n",
      "time-consuming and   0.3333333333333333\n",
      "\n",
      "highlighting candidate   1.0\n",
      "\n",
      "neural network   0.3333333333333333\n",
      "\n",
      "linguistics -LRB-   0.05\n",
      "\n",
      "are made   0.012448132780082987\n",
      "\n",
      "IMR during   0.5\n",
      "\n",
      "condensation operations   1.0\n",
      "\n",
      "pilots in   0.5\n",
      "\n",
      "errors in   0.2\n",
      "\n",
      "the words   0.004152249134948097\n",
      "\n",
      "socio-psychological characteristics   1.0\n",
      "\n",
      "between sentences   0.05128205128205128\n",
      "\n",
      "simulation of   0.3333333333333333\n",
      "\n",
      "seem completely   0.5\n",
      "\n",
      "made feasible   0.0625\n",
      "\n",
      ", Jef   0.0005614823133071309\n",
      "\n",
      "highly redundant   0.1111111111111111\n",
      "\n",
      "`` I   0.005291005291005291\n",
      "\n",
      "methods of   0.045454545454545456\n",
      "\n",
      "automatically evaluating   0.047619047619047616\n",
      "\n",
      "categories could   0.1111111111111111\n",
      "\n",
      "algorithm like   0.03571428571428571\n",
      "\n",
      "LOB Corpus   1.0\n",
      "\n",
      "at hand   0.014705882352941176\n",
      "\n",
      "can even   0.0055248618784530384\n",
      "\n",
      "Latin pars   0.25\n",
      "\n",
      "semantic information   0.09523809523809523\n",
      "\n",
      "the main   0.001384083044982699\n",
      "\n",
      "greatly on   0.14285714285714285\n",
      "\n",
      "would be   0.16981132075471697\n",
      "\n",
      "sociolinguistics ,   0.5\n",
      "\n",
      "dynamically create   0.5\n",
      "\n",
      "Ncmsan ,   1.0\n",
      "\n",
      "paragraph boundaries   0.3333333333333333\n",
      "\n",
      "elementary sounds   1.0\n",
      "\n",
      "may chose   0.019230769230769232\n",
      "\n",
      "weighted to   0.3333333333333333\n",
      "\n",
      "suffer .   1.0\n",
      "\n",
      "success of   0.6\n",
      "\n",
      "to .   0.00398406374501992\n",
      "\n",
      "places and   0.5\n",
      "\n",
      "Psycholinguists prefer   1.0\n",
      "\n",
      "in speech   0.013108614232209739\n",
      "\n",
      "choices What   0.4\n",
      "\n",
      "meaning and   0.043478260869565216\n",
      "\n",
      "on discourse   0.0047169811320754715\n",
      "\n",
      "robust against   0.25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nouns   0.0006920415224913495\n",
      "\n",
      ", some   0.0050533408197641775\n",
      "\n",
      "or millions   0.0045045045045045045\n",
      "\n",
      "high level   0.16666666666666666\n",
      "\n",
      "curves ,   1.0\n",
      "\n",
      "being considered   0.1111111111111111\n",
      "\n",
      "to impersonate   0.0013280212483399733\n",
      "\n",
      "has given   0.011904761904761904\n",
      "\n",
      "vendors began   0.25\n",
      "\n",
      "concerned with   0.8\n",
      "\n",
      "Technology Center   0.3333333333333333\n",
      "\n",
      "Gismo ''   0.5\n",
      "\n",
      "how phrases   0.034482758620689655\n",
      "\n",
      "reviewed and   1.0\n",
      "\n",
      "Anaphor resolution   1.0\n",
      "\n",
      "simple pro   0.038461538461538464\n",
      "\n",
      "each document   0.022222222222222223\n",
      "\n",
      "larger corpus   0.125\n",
      "\n",
      "resources it   0.16666666666666666\n",
      "\n",
      "omni-font OCR   1.0\n",
      "\n",
      "Semantic Orientation   0.3333333333333333\n",
      "\n",
      "for them   0.007220216606498195\n",
      "\n",
      "taggers can   0.14285714285714285\n",
      "\n",
      "`` Turn   0.005291005291005291\n",
      "\n",
      "in document   0.003745318352059925\n",
      "\n",
      "nodes represents   0.14285714285714285\n",
      "\n",
      "people would   0.0625\n",
      "\n",
      "context-free approximation   0.09090909090909091\n",
      "\n",
      "different method   0.02040816326530612\n",
      "\n",
      "fully up   0.16666666666666666\n",
      "\n",
      "understanding of   0.15151515151515152\n",
      "\n",
      "A useful   0.02\n",
      "\n",
      "used speech   0.008849557522123894\n",
      "\n",
      "first primitive   0.030303030303030304\n",
      "\n",
      "evaluation Depending   0.018518518518518517\n",
      "\n",
      "and became   0.001445086705202312\n",
      "\n",
      "documents ,   0.23684210526315788\n",
      "\n",
      "what is   0.09375\n",
      "\n",
      ", called   0.0005614823133071309\n",
      "\n",
      "validity and   1.0\n",
      "\n",
      "<s> Some   0.012298232129131437\n",
      "\n",
      "space complexity   0.2\n",
      "\n",
      "Process .   1.0\n",
      "\n",
      "-LRB- 3rd   0.0027100271002710027\n",
      "\n",
      "or to   0.009009009009009009\n",
      "\n",
      "are multiple   0.004149377593360996\n",
      "\n",
      ", Cynthia   0.0005614823133071309\n",
      "\n",
      "the quality   0.0034602076124567475\n",
      "\n",
      "present special   0.16666666666666666\n",
      "\n",
      "BioCreative Message   1.0\n",
      "\n",
      "`` sounds   0.005291005291005291\n",
      "\n",
      "that funding   0.0035460992907801418\n",
      "\n",
      "EMR -RRB-   0.3333333333333333\n",
      "\n",
      "term ,   0.05555555555555555\n",
      "\n",
      "direction is   0.3333333333333333\n",
      "\n",
      "systems to   0.008928571428571428\n",
      "\n",
      "were realized   0.024390243902439025\n",
      "\n",
      "like to   0.07142857142857142\n",
      "\n",
      "deciding on   0.16666666666666666\n",
      "\n",
      "Computers can   1.0\n",
      "\n",
      "modern systems   0.2\n",
      "\n",
      "-LRB- extrinsic   0.0027100271002710027\n",
      "\n",
      "as with   0.006968641114982578\n",
      "\n",
      "many consecutive   0.019230769230769232\n",
      "\n",
      "Processing -LRB-   0.75\n",
      "\n",
      "web pages   0.125\n",
      "\n",
      "are very   0.016597510373443983\n",
      "\n",
      "spoken natural   0.07142857142857142\n",
      "\n",
      "'s subscription   0.0196078431372549\n",
      "\n",
      "which words   0.014492753623188406\n",
      "\n",
      "create texts   0.058823529411764705\n",
      "\n",
      "model temporal   0.03333333333333333\n",
      "\n",
      "HTK toolkit   0.5\n",
      "\n",
      "has focused   0.047619047619047616\n",
      "\n",
      "example generic   0.012345679012345678\n",
      "\n",
      "original scanned   0.07692307692307693\n",
      "\n",
      "to ensure   0.0013280212483399733\n",
      "\n",
      "or future   0.0045045045045045045\n",
      "\n",
      "to prepare   0.0013280212483399733\n",
      "\n",
      "can express   0.022099447513812154\n",
      "\n",
      "are systems   0.012448132780082987\n",
      "\n",
      "made between   0.0625\n",
      "\n",
      "specific voice   0.047619047619047616\n",
      "\n",
      "very common   0.04878048780487805\n",
      "\n",
      "onto its   1.0\n",
      "\n",
      "tagging include   0.04\n",
      "\n",
      "The poor   0.005208333333333333\n",
      "\n",
      "will never   0.02857142857142857\n",
      "\n",
      "algorithms is   0.02857142857142857\n",
      "\n",
      "list of   0.7272727272727273\n",
      "\n",
      "OCR software   0.08163265306122448\n",
      "\n",
      "variant of   1.0\n",
      "\n",
      "intonation ,   1.0\n",
      "\n",
      "computer -LRB-   0.022727272727272728\n",
      "\n",
      "which generates   0.007246376811594203\n",
      "\n",
      "machine to   0.012658227848101266\n",
      "\n",
      "techniques from   0.043478260869565216\n",
      "\n",
      "on recognition   0.0047169811320754715\n",
      "\n",
      "The genetic   0.005208333333333333\n",
      "\n",
      "ISRI -RRB-   1.0\n",
      "\n",
      "Puma helicopter   1.0\n",
      "\n",
      "brain .   0.3333333333333333\n",
      "\n",
      "need at   0.047619047619047616\n",
      "\n",
      "which accepts   0.007246376811594203\n",
      "\n",
      "and translation   0.004335260115606936\n",
      "\n",
      "a predefined   0.001226993865030675\n",
      "\n",
      "evaluations ,   0.16666666666666666\n",
      "\n",
      "comes from   0.4\n",
      "\n",
      "the 2011   0.0006920415224913495\n",
      "\n",
      "states -RRB-   0.25\n",
      "\n",
      "event ,   0.6666666666666666\n",
      "\n",
      "are concerned   0.004149377593360996\n",
      "\n",
      "sets -LRB-   0.09090909090909091\n",
      "\n",
      "taggers .   0.14285714285714285\n",
      "\n",
      "them .   0.10526315789473684\n",
      "\n",
      "of to   0.00089126559714795\n",
      "\n",
      "decisions based   0.2\n",
      "\n",
      "vertices are   0.1111111111111111\n",
      "\n",
      "b -RRB-   1.0\n",
      "\n",
      "from our   0.009615384615384616\n",
      "\n",
      "of immunology   0.00089126559714795\n",
      "\n",
      "<s> Morphological   0.0007686395080707148\n",
      "\n",
      "issue for   0.125\n",
      "\n",
      "use it   0.027777777777777776\n",
      "\n",
      "journals -LRB-   0.5\n",
      "\n",
      "our knowledge   0.2\n",
      "\n",
      "identification of   0.4\n",
      "\n",
      "Lisp hence   1.0\n",
      "\n",
      "-RRB- is   0.02981029810298103\n",
      "\n",
      "NAACL ,   1.0\n",
      "\n",
      "learning Beginning   0.023255813953488372\n",
      "\n",
      "for document   0.0036101083032490976\n",
      "\n",
      "<s> WebOCR   0.0015372790161414297\n",
      "\n",
      "personal computing   0.25\n",
      "\n",
      "helicopters ,   0.5\n",
      "\n",
      "keyphrases will   0.02857142857142857\n",
      "\n",
      "reduction of   0.5\n",
      "\n",
      "system exhibited   0.010752688172043012\n",
      "\n",
      "to humans   0.0013280212483399733\n",
      "\n",
      "a topic   0.001226993865030675\n",
      "\n",
      "and unexpected   0.001445086705202312\n",
      "\n",
      "<s> Typical   0.0015372790161414297\n",
      "\n",
      "semantic representation   0.047619047619047616\n",
      "\n",
      "by Kurzweil   0.005714285714285714\n",
      "\n",
      "and rich   0.001445086705202312\n",
      "\n",
      "or phrase   0.0045045045045045045\n",
      "\n",
      "as language   0.003484320557491289\n",
      "\n",
      "other scripts   0.014285714285714285\n",
      "\n",
      "substantial amount   0.2\n",
      "\n",
      "published but   0.14285714285714285\n",
      "\n",
      "Norman ,   0.5\n",
      "\n",
      "HMMs ,   0.125\n",
      "\n",
      "Perspectives The   1.0\n",
      "\n",
      "this makes   0.01098901098901099\n",
      "\n",
      "President Bush   0.5\n",
      "\n",
      "of artifacts   0.00089126559714795\n",
      "\n",
      "language might   0.006756756756756757\n",
      "\n",
      "are accepted   0.004149377593360996\n",
      "\n",
      "world applications   0.06666666666666667\n",
      "\n",
      "AI-complete ''   0.6666666666666666\n",
      "\n",
      "school-age children   1.0\n",
      "\n",
      "a potentially   0.001226993865030675\n",
      "\n",
      "thus beyond   0.1\n",
      "\n",
      "turns -RRB-   0.3333333333333333\n",
      "\n",
      "words relate   0.009174311926605505\n",
      "\n",
      "the ''   0.0006920415224913495\n",
      "\n",
      "<s> Essentially   0.0007686395080707148\n",
      "\n",
      "abbreviations .   0.2\n",
      "\n",
      "level ;   0.1\n",
      "\n",
      "<s> Applications   0.0015372790161414297\n",
      "\n",
      "actual data   0.2\n",
      "\n",
      "then common   0.02857142857142857\n",
      "\n",
      "final keyphrase   0.1111111111111111\n",
      "\n",
      "into meaningful   0.02564102564102564\n",
      "\n",
      "taking only   0.2\n",
      "\n",
      "very early   0.024390243902439025\n",
      "\n",
      "the major   0.001384083044982699\n",
      "\n",
      "other text   0.02857142857142857\n",
      "\n",
      "would output   0.018867924528301886\n",
      "\n",
      "may generate   0.019230769230769232\n",
      "\n",
      "shipment of   1.0\n",
      "\n",
      "Hindle D.   1.0\n",
      "\n",
      "boundaries in   0.09090909090909091\n",
      "\n",
      "checked each   0.5\n",
      "\n",
      "step --   0.13333333333333333\n",
      "\n",
      "them automatically   0.05263157894736842\n",
      "\n",
      "a date   0.001226993865030675\n",
      "\n",
      "of 500,000   0.00089126559714795\n",
      "\n",
      "Corpus Research   0.0625\n",
      "\n",
      "write `   1.0\n",
      "\n",
      "side effect   1.0\n",
      "\n",
      ", each   0.003368893879842785\n",
      "\n",
      "mentioned by   0.16666666666666666\n",
      "\n",
      "Separate a   0.5\n",
      "\n",
      "can both   0.0055248618784530384\n",
      "\n",
      "of campaigns   0.00089126559714795\n",
      "\n",
      "Asia Online   1.0\n",
      "\n",
      "`` Dog   0.005291005291005291\n",
      "\n",
      "or existing   0.0045045045045045045\n",
      "\n",
      "integrated information   0.3333333333333333\n",
      "\n",
      "-RRB- Court   0.0027100271002710027\n",
      "\n",
      "grammatical gender   0.09090909090909091\n",
      "\n",
      "radios ,   1.0\n",
      "\n",
      "which kind   0.007246376811594203\n",
      "\n",
      "one that   0.015384615384615385\n",
      "\n",
      "used about   0.008849557522123894\n",
      "\n",
      "document\\/text genre   0.5\n",
      "\n",
      "be his   0.004219409282700422\n",
      "\n",
      "especially inflectional   0.06666666666666667\n",
      "\n",
      "users and   0.1111111111111111\n",
      "\n",
      "synopsis like   1.0\n",
      "\n",
      "machine-learning-based implementation   1.0\n",
      "\n",
      "Two of   0.2857142857142857\n",
      "\n",
      "automatic evaluation   0.13043478260869565\n",
      "\n",
      "harder it   0.14285714285714285\n",
      "\n",
      "CLAWS ,   0.5\n",
      "\n",
      "sounds .   0.06666666666666667\n",
      "\n",
      "Janet Holmes   0.5\n",
      "\n",
      "issue is   0.125\n",
      "\n",
      "The authors   0.015625\n",
      "\n",
      "using sentence   0.01694915254237288\n",
      "\n",
      "human meteorologist   0.021739130434782608\n",
      "\n",
      "fairly trivial   0.25\n",
      "\n",
      "cases -RRB-   0.05555555555555555\n",
      "\n",
      "In 1987   0.009523809523809525\n",
      "\n",
      "in multiscript   0.0018726591760299626\n",
      "\n",
      "opinion expressed   0.2\n",
      "\n",
      "letter that   0.16666666666666666\n",
      "\n",
      "lacks pre-existing   1.0\n",
      "\n",
      "the DUC   0.0006920415224913495\n",
      "\n",
      "answer -LRB-   0.03333333333333333\n",
      "\n",
      "conversion of   0.6666666666666666\n",
      "\n",
      "and for   0.001445086705202312\n",
      "\n",
      "and practice   0.001445086705202312\n",
      "\n",
      "merely assigning   0.5\n",
      "\n",
      "enabling technologies   1.0\n",
      "\n",
      "Malcolm Coulthard   1.0\n",
      "\n",
      "found that   0.35714285714285715\n",
      "\n",
      "a dog   0.001226993865030675\n",
      "\n",
      "post-process the   1.0\n",
      "\n",
      "word processors   0.016666666666666666\n",
      "\n",
      "unstructured text   1.0\n",
      "\n",
      "and if   0.001445086705202312\n",
      "\n",
      "words --   0.009174311926605505\n",
      "\n",
      "a distinction   0.001226993865030675\n",
      "\n",
      "inventor Jacob   1.0\n",
      "\n",
      "representation into   0.05263157894736842\n",
      "\n",
      "addition might   0.16666666666666666\n",
      "\n",
      "knowledge sources   0.037037037037037035\n",
      "\n",
      "training techniques   0.03571428571428571\n",
      "\n",
      "reliability -RRB-   0.5\n",
      "\n",
      "following issues   0.06666666666666667\n",
      "\n",
      "output from   0.038461538461538464\n",
      "\n",
      "those it   0.045454545454545456\n",
      "\n",
      "<s> NLP   0.0007686395080707148\n",
      "\n",
      "other places   0.014285714285714285\n",
      "\n",
      "the past   0.001384083044982699\n",
      "\n",
      "ARNS system   1.0\n",
      "\n",
      "period may   0.5\n",
      "\n",
      "10 %   0.25\n",
      "\n",
      "failed to   1.0\n",
      "\n",
      "unfortunately ,   1.0\n",
      "\n",
      "by larger   0.005714285714285714\n",
      "\n",
      "that investigates   0.0035460992907801418\n",
      "\n",
      "a nautical   0.001226993865030675\n",
      "\n",
      "embedded system   0.25\n",
      "\n",
      "feature or   0.07692307692307693\n",
      "\n",
      ", web   0.0005614823133071309\n",
      "\n",
      "functioning of   0.3333333333333333\n",
      "\n",
      "because analyzing   0.03333333333333333\n",
      "\n",
      "style ,   0.5\n",
      "\n",
      "measure a   0.09090909090909091\n",
      "\n",
      "Another project   0.07692307692307693\n",
      "\n",
      "approaches differ   0.03571428571428571\n",
      "\n",
      "important sentences   0.125\n",
      "\n",
      "-LRB- EMR   0.0027100271002710027\n",
      "\n",
      "considerable interest   0.2\n",
      "\n",
      "for 5   0.0036101083032490976\n",
      "\n",
      "nodes for   0.14285714285714285\n",
      "\n",
      "disagree that   0.3333333333333333\n",
      "\n",
      "ranked by   0.2\n",
      "\n",
      "into more   0.02564102564102564\n",
      "\n",
      "the F35   0.0006920415224913495\n",
      "\n",
      "wrong fairly   1.0\n",
      "\n",
      "clarify a   1.0\n",
      "\n",
      "blocks ,   0.25\n",
      "\n",
      "machine learning   0.24050632911392406\n",
      "\n",
      "asking why   0.5\n",
      "\n",
      "later users   0.1\n",
      "\n",
      "progress is   0.14285714285714285\n",
      "\n",
      "formal representations   0.2222222222222222\n",
      "\n",
      "end .   0.125\n",
      "\n",
      "disturbed by   1.0\n",
      "\n",
      "'' -   0.010309278350515464\n",
      "\n",
      "to pauses   0.0013280212483399733\n",
      "\n",
      "Some writing   0.047619047619047616\n",
      "\n",
      "the door   0.0006920415224913495\n",
      "\n",
      "for computers   0.0036101083032490976\n",
      "\n",
      "relevant text   0.14285714285714285\n",
      "\n",
      "have included   0.009615384615384616\n",
      "\n",
      ", ranging   0.0011229646266142617\n",
      "\n",
      "Robert Wilensky   0.25\n",
      "\n",
      "the target   0.006228373702422145\n",
      "\n",
      "are summaries   0.004149377593360996\n",
      "\n",
      "a 3   0.001226993865030675\n",
      "\n",
      "a rudimentary   0.001226993865030675\n",
      "\n",
      "In 1994   0.009523809523809525\n",
      "\n",
      "Methods such   0.25\n",
      "\n",
      "<s> Multilingual   0.0007686395080707148\n",
      "\n",
      "Alternatively ,   1.0\n",
      "\n",
      "several classifiers   0.045454545454545456\n",
      "\n",
      "<s> Due   0.0007686395080707148\n",
      "\n",
      "often mentioned   0.022727272727272728\n",
      "\n",
      "to derive   0.0013280212483399733\n",
      "\n",
      "software tools   0.037037037037037035\n",
      "\n",
      "with medium   0.00546448087431694\n",
      "\n",
      "recommending ''   1.0\n",
      "\n",
      "assess how   0.6666666666666666\n",
      "\n",
      "length ,   0.25\n",
      "\n",
      "reliable hits   0.25\n",
      "\n",
      "the Turing   0.0006920415224913495\n",
      "\n",
      "pointed out   1.0\n",
      "\n",
      "features might   0.038461538461538464\n",
      "\n",
      "together the   0.125\n",
      "\n",
      "relate to   1.0\n",
      "\n",
      "year later   0.16666666666666666\n",
      "\n",
      "their stationary   0.029411764705882353\n",
      "\n",
      "recognition for   0.008264462809917356\n",
      "\n",
      "MT companies   0.2\n",
      "\n",
      "Variation analysis   1.0\n",
      "\n",
      "and Callaghan   0.001445086705202312\n",
      "\n",
      "singular common   0.25\n",
      "\n",
      "a model   0.001226993865030675\n",
      "\n",
      "which led   0.007246376811594203\n",
      "\n",
      "would somehow   0.018867924528301886\n",
      "\n",
      "emergence of   1.0\n",
      "\n",
      "produced like   0.1111111111111111\n",
      "\n",
      "accordingly .   1.0\n",
      "\n",
      "was reading   0.012987012987012988\n",
      "\n",
      "applications .   0.16\n",
      "\n",
      "grammar ,   0.10810810810810811\n",
      "\n",
      "systems remains   0.008928571428571428\n",
      "\n",
      "and Japanese   0.001445086705202312\n",
      "\n",
      "for breathing   0.0036101083032490976\n",
      "\n",
      "Peru .   0.5\n",
      "\n",
      "Examples include   0.3333333333333333\n",
      "\n",
      "even human   0.037037037037037035\n",
      "\n",
      "This problem   0.06349206349206349\n",
      "\n",
      "speech segmentation   0.03289473684210526\n",
      "\n",
      "rule should   0.3333333333333333\n",
      "\n",
      "languages was   0.02\n",
      "\n",
      "limit the   0.5\n",
      "\n",
      "SATZ architecture   1.0\n",
      "\n",
      "the presentation   0.0006920415224913495\n",
      "\n",
      "common for   0.08\n",
      "\n",
      ", room   0.0005614823133071309\n",
      "\n",
      "sentences in   0.10526315789473684\n",
      "\n",
      "estimated probability   1.0\n",
      "\n",
      "evaluated to   0.2857142857142857\n",
      "\n",
      "scholars -LRB-   0.5\n",
      "\n",
      "the pragmatics   0.0006920415224913495\n",
      "\n",
      "especially to   0.06666666666666667\n",
      "\n",
      "-RRB- represents   0.0027100271002710027\n",
      "\n",
      "international ATC   0.5\n",
      "\n",
      "reasoning mechanisms   0.14285714285714285\n",
      "\n",
      "telephone speech   0.5\n",
      "\n",
      "problems of   0.058823529411764705\n",
      "\n",
      "in conference   0.0018726591760299626\n",
      "\n",
      "possibly linked   0.5\n",
      "\n",
      "essentially calculates   0.125\n",
      "\n",
      "periods in   0.3333333333333333\n",
      "\n",
      "focus and   0.14285714285714285\n",
      "\n",
      "isolated NLP   0.2\n",
      "\n",
      "databases as   0.125\n",
      "\n",
      "some summarization   0.012048192771084338\n",
      "\n",
      "have also   0.009615384615384616\n",
      "\n",
      "to involved   0.0013280212483399733\n",
      "\n",
      "not easily   0.026785714285714284\n",
      "\n",
      "a suitable   0.0036809815950920245\n",
      "\n",
      "syntactic structure   0.07692307692307693\n",
      "\n",
      "which ,   0.007246376811594203\n",
      "\n",
      "understanding to   0.06060606060606061\n",
      "\n",
      "or real   0.0045045045045045045\n",
      "\n",
      "compounded by   1.0\n",
      "\n",
      "very optimistic   0.024390243902439025\n",
      "\n",
      "still be   0.06666666666666667\n",
      "\n",
      "forms ,   0.16666666666666666\n",
      "\n",
      "prone to   1.0\n",
      "\n",
      "discussed involve   0.14285714285714285\n",
      "\n",
      "Shipibo Paragraph   0.5\n",
      "\n",
      "for comparison   0.0036101083032490976\n",
      "\n",
      "to ease   0.0013280212483399733\n",
      "\n",
      "language analysis   0.006756756756756757\n",
      "\n",
      "the ARCHILES   0.0006920415224913495\n",
      "\n",
      "diversity :   0.25\n",
      "\n",
      "and geospatial   0.001445086705202312\n",
      "\n",
      "Gustav Tauschek   1.0\n",
      "\n",
      "the availability   0.0006920415224913495\n",
      "\n",
      "performed more   0.1\n",
      "\n",
      "decisions .   0.1\n",
      "\n",
      "provide any   0.16666666666666666\n",
      "\n",
      "hard and   0.16666666666666666\n",
      "\n",
      "The phenomenon   0.005208333333333333\n",
      "\n",
      "some statistical   0.012048192771084338\n",
      "\n",
      "Navy ,   1.0\n",
      "\n",
      "to identify   0.006640106241699867\n",
      "\n",
      "first and   0.030303030303030304\n",
      "\n",
      "Lehnart .   1.0\n",
      "\n",
      "spite of   1.0\n",
      "\n",
      "simple data   0.038461538461538464\n",
      "\n",
      "speech that   0.006578947368421052\n",
      "\n",
      "producing natural   0.3333333333333333\n",
      "\n",
      "classifier so   0.14285714285714285\n",
      "\n",
      "Pollen counts   1.0\n",
      "\n",
      "user-specified fraction   0.5\n",
      "\n",
      "diagonal covariance   1.0\n",
      "\n",
      "restricted ``   0.25\n",
      "\n",
      "to train   0.0013280212483399733\n",
      "\n",
      "a corresponding   0.001226993865030675\n",
      "\n",
      "speech ,   0.07236842105263158\n",
      "\n",
      "company to   0.3333333333333333\n",
      "\n",
      "assistant providing   1.0\n",
      "\n",
      "developed transformational   0.038461538461538464\n",
      "\n",
      "as statistical   0.003484320557491289\n",
      "\n",
      "given corpus   0.041666666666666664\n",
      "\n",
      "in addition   0.0056179775280898875\n",
      "\n",
      "found no   0.07142857142857142\n",
      "\n",
      "About 47   0.5\n",
      "\n",
      "Richard Kittredge   1.0\n",
      "\n",
      "translating Quechua   0.25\n",
      "\n",
      "that determines   0.0070921985815602835\n",
      "\n",
      "in performance   0.0018726591760299626\n",
      "\n",
      "The system   0.03125\n",
      "\n",
      "context --   0.030303030303030304\n",
      "\n",
      "programer 's   1.0\n",
      "\n",
      "giving the   0.5\n",
      "\n",
      ", sufficiently   0.0005614823133071309\n",
      "\n",
      "with fixed   0.00546448087431694\n",
      "\n",
      "used on   0.008849557522123894\n",
      "\n",
      "not using   0.008928571428571428\n",
      "\n",
      "an associated   0.007575757575757576\n",
      "\n",
      "feedback .   0.5\n",
      "\n",
      "to HMMs   0.0013280212483399733\n",
      "\n",
      "idea but   0.14285714285714285\n",
      "\n",
      "Learning Some   1.0\n",
      "\n",
      "with keyphrases   0.00546448087431694\n",
      "\n",
      "Chomskyan theories   1.0\n",
      "\n",
      "computers have   0.1111111111111111\n",
      "\n",
      "translation capabilities   0.013513513513513514\n",
      "\n",
      "grammar -LRB-   0.02702702702702703\n",
      "\n",
      "would identify   0.018867924528301886\n",
      "\n",
      "Recent research   0.6666666666666666\n",
      "\n",
      "points of   0.5\n",
      "\n",
      "<s> Maximum   0.0015372790161414297\n",
      "\n",
      "phrase ,   0.1\n",
      "\n",
      "relationship with   0.16666666666666666\n",
      "\n",
      "it aims   0.008547008547008548\n",
      "\n",
      "also experimented   0.014492753623188406\n",
      "\n",
      ", have   0.0011229646266142617\n",
      "\n",
      "directly comparable   0.2\n",
      "\n",
      "transformational grammar   1.0\n",
      "\n",
      "using precision   0.01694915254237288\n",
      "\n",
      "and actual   0.001445086705202312\n",
      "\n",
      "appropriately spelled   0.5\n",
      "\n",
      "two possibilities   0.034482758620689655\n",
      "\n",
      "positive or   0.2857142857142857\n",
      "\n",
      "frame ;   0.5\n",
      "\n",
      "differences themselves   0.3333333333333333\n",
      "\n",
      "often required   0.022727272727272728\n",
      "\n",
      "different problem   0.02040816326530612\n",
      "\n",
      "recognition equipment   0.008264462809917356\n",
      "\n",
      "platform for   0.5\n",
      "\n",
      "affect is   0.3333333333333333\n",
      "\n",
      "incremental improvements   1.0\n",
      "\n",
      ", Larry   0.0005614823133071309\n",
      "\n",
      "they consider   0.025\n",
      "\n",
      "from large   0.009615384615384616\n",
      "\n",
      "is unusual   0.0020325203252032522\n",
      "\n",
      "Performance The   1.0\n",
      "\n",
      "a demonstration   0.0036809815950920245\n",
      "\n",
      "text .   0.16981132075471697\n",
      "\n",
      "CWA -RRB-   1.0\n",
      "\n",
      "Alan Turing   1.0\n",
      "\n",
      "important points   0.0625\n",
      "\n",
      "Paul Gee   0.2\n",
      "\n",
      "Kurzweil and   0.14285714285714285\n",
      "\n",
      "and subsequent   0.001445086705202312\n",
      "\n",
      "workday to   1.0\n",
      "\n",
      "Parsers may   0.5\n",
      "\n",
      "that human   0.0070921985815602835\n",
      "\n",
      "lexicon required   0.1111111111111111\n",
      "\n",
      "was hand-written   0.012987012987012988\n",
      "\n",
      "especially those   0.2\n",
      "\n",
      "of nodes   0.0035650623885918\n",
      "\n",
      "the special   0.0006920415224913495\n",
      "\n",
      "statement ,   1.0\n",
      "\n",
      "discourse begin   0.027777777777777776\n",
      "\n",
      "world ,   0.06666666666666667\n",
      "\n",
      "Zacharov -RRB-   1.0\n",
      "\n",
      "sets in   0.09090909090909091\n",
      "\n",
      "resort to   1.0\n",
      "\n",
      "differ ,   0.3333333333333333\n",
      "\n",
      "automated semantic   0.14285714285714285\n",
      "\n",
      "graphics --   1.0\n",
      "\n",
      "Tablet PC   1.0\n",
      "\n",
      "of this   0.00980392156862745\n",
      "\n",
      "as smart   0.003484320557491289\n",
      "\n",
      "1950s ,   0.5\n",
      "\n",
      "cursive handwriting   0.2\n",
      "\n",
      "= singular   0.1111111111111111\n",
      "\n",
      "could often   0.0625\n",
      "\n",
      "be filtered   0.012658227848101266\n",
      "\n",
      "the opposite   0.001384083044982699\n",
      "\n",
      "or component   0.0045045045045045045\n",
      "\n",
      "are often   0.016597510373443983\n",
      "\n",
      "ARCHILES technique   1.0\n",
      "\n",
      ", D.   0.0005614823133071309\n",
      "\n",
      "on dictionary   0.0047169811320754715\n",
      "\n",
      "multiple times   0.07692307692307693\n",
      "\n",
      "Some SR   0.047619047619047616\n",
      "\n",
      "to meet   0.005312084993359893\n",
      "\n",
      "English phrase   0.02702702702702703\n",
      "\n",
      "to by   0.0026560424966799467\n",
      "\n",
      "such an   0.016260162601626018\n",
      "\n",
      "meaning which   0.043478260869565216\n",
      "\n",
      "the real   0.0020761245674740486\n",
      "\n",
      "express all   0.2\n",
      "\n",
      "first -LRB-   0.030303030303030304\n",
      "\n",
      "authors provide   0.2\n",
      "\n",
      "corpora that   0.09090909090909091\n",
      "\n",
      "i.e. it   0.05263157894736842\n",
      "\n",
      "highly by   0.1111111111111111\n",
      "\n",
      "early 1990s   0.1\n",
      "\n",
      "demonstrate .   1.0\n",
      "\n",
      ", developed   0.0005614823133071309\n",
      "\n",
      "many instances   0.019230769230769232\n",
      "\n",
      "Bhatia ,   1.0\n",
      "\n",
      "accomplished in   1.0\n",
      "\n",
      "markers ,   0.3333333333333333\n",
      "\n",
      "algorithm -RRB-   0.03571428571428571\n",
      "\n",
      "the segmentation   0.0006920415224913495\n",
      "\n",
      "emotions in   1.0\n",
      "\n",
      "EAGLi for   1.0\n",
      "\n",
      "critical tasks   0.25\n",
      "\n",
      "include straightforward   0.037037037037037035\n",
      "\n",
      "recognized words   0.16666666666666666\n",
      "\n",
      "used through   0.008849557522123894\n",
      "\n",
      "analysis is   0.015384615384615385\n",
      "\n",
      "glossary words   0.5\n",
      "\n",
      "how useful   0.034482758620689655\n",
      "\n",
      "isolated speech   0.4\n",
      "\n",
      "being referred   0.05555555555555555\n",
      "\n",
      "As mentioned   0.16666666666666666\n",
      "\n",
      "the Penpoint   0.0006920415224913495\n",
      "\n",
      "of Roger   0.00089126559714795\n",
      "\n",
      "-LRB- and   0.013550135501355014\n",
      "\n",
      "Commanders and   1.0\n",
      "\n",
      "years later   0.14285714285714285\n",
      "\n",
      "The edges   0.005208333333333333\n",
      "\n",
      ", notably   0.0005614823133071309\n",
      "\n",
      "also been   0.057971014492753624\n",
      "\n",
      "students ,   0.3333333333333333\n",
      "\n",
      "human intervention   0.021739130434782608\n",
      "\n",
      "the advantage   0.0006920415224913495\n",
      "\n",
      "technology providers   0.045454545454545456\n",
      "\n",
      "simplified the   0.5\n",
      "\n",
      "machines to   0.25\n",
      "\n",
      "paragraphs ,   0.25\n",
      "\n",
      "several sub-problems   0.045454545454545456\n",
      "\n",
      "different groups   0.02040816326530612\n",
      "\n",
      "extent -RRB-   0.25\n",
      "\n",
      "to travel   0.0013280212483399733\n",
      "\n",
      "will contain   0.02857142857142857\n",
      "\n",
      "in .   0.0018726591760299626\n",
      "\n",
      "for verification   0.0036101083032490976\n",
      "\n",
      "a ``   0.007361963190184049\n",
      "\n",
      "to detect   0.0013280212483399733\n",
      "\n",
      "information appear   0.021739130434782608\n",
      "\n",
      "the mechanism   0.0006920415224913495\n",
      "\n",
      "Fundamentals of   1.0\n",
      "\n",
      "their ratings   0.029411764705882353\n",
      "\n",
      "or as   0.009009009009009009\n",
      "\n",
      "recognition systems   0.08264462809917356\n",
      "\n",
      "1954 involved   0.3333333333333333\n",
      "\n",
      "Maximum entropy   0.6666666666666666\n",
      "\n",
      "Lancaster-Oslo-Bergen Corpus   1.0\n",
      "\n",
      "for use   0.007220216606498195\n",
      "\n",
      "between dynamically   0.02564102564102564\n",
      "\n",
      "'s blocks   0.0196078431372549\n",
      "\n",
      "topic -RRB-   0.125\n",
      "\n",
      ", international   0.0005614823133071309\n",
      "\n",
      "or five   0.0045045045045045045\n",
      "\n",
      "artificial processes   0.18181818181818182\n",
      "\n",
      "select whole   0.16666666666666666\n",
      "\n",
      "attached to   0.5\n",
      "\n",
      "English is   0.02702702702702703\n",
      "\n",
      "We also   0.14285714285714285\n",
      "\n",
      "account how   0.3333333333333333\n",
      "\n",
      "it has   0.03418803418803419\n",
      "\n",
      "reasons .   0.5\n",
      "\n",
      "and in   0.010115606936416185\n",
      "\n",
      "output -RRB-   0.038461538461538464\n",
      "\n",
      "surrounding vowels   0.2\n",
      "\n",
      "the optical   0.0006920415224913495\n",
      "\n",
      "user profile   0.07142857142857142\n",
      "\n",
      "<s> Translation   0.0007686395080707148\n",
      "\n",
      "`` have   0.005291005291005291\n",
      "\n",
      "promising line   1.0\n",
      "\n",
      ", Discontinuous   0.0005614823133071309\n",
      "\n",
      "in using   0.0056179775280898875\n",
      "\n",
      "Statistical NLP   0.2222222222222222\n",
      "\n",
      "The best   0.005208333333333333\n",
      "\n",
      "last decade   0.4\n",
      "\n",
      "science of   0.1\n",
      "\n",
      "World ,   0.14285714285714285\n",
      "\n",
      "Putting words   1.0\n",
      "\n",
      "reading is   0.125\n",
      "\n",
      "statistical decision-making   0.030303030303030304\n",
      "\n",
      "both ``   0.06451612903225806\n",
      "\n",
      "SRI International   1.0\n",
      "\n",
      "decided that   0.3333333333333333\n",
      "\n",
      "include contractions   0.037037037037037035\n",
      "\n",
      "directed .   1.0\n",
      "\n",
      "is concerned   0.0040650406504065045\n",
      "\n",
      "Despite the   1.0\n",
      "\n",
      "recognizing and   0.2\n",
      "\n",
      "communication -LRB-   0.4\n",
      "\n",
      "in smaller   0.0018726591760299626\n",
      "\n",
      "speaker deliberately   0.05555555555555555\n",
      "\n",
      "AI-complete problem   0.3333333333333333\n",
      "\n",
      "from IBM   0.009615384615384616\n",
      "\n",
      "representation of   0.10526315789473684\n",
      "\n",
      "representation -LRB-   0.10526315789473684\n",
      "\n",
      "a noun   0.007361963190184049\n",
      "\n",
      "remain high   1.0\n",
      "\n",
      "to discover   0.0013280212483399733\n",
      "\n",
      "search -LRB-   0.09090909090909091\n",
      "\n",
      "improving output   1.0\n",
      "\n",
      "Xuedong Huang   1.0\n",
      "\n",
      "van Leeuwen   0.5\n",
      "\n",
      "including linguistics   0.14285714285714285\n",
      "\n",
      "since 1971   0.1\n",
      "\n",
      "most successful   0.034482758620689655\n",
      "\n",
      "both learn   0.03225806451612903\n",
      "\n",
      "Blind In   0.5\n",
      "\n",
      "searching -LRB-   0.3333333333333333\n",
      "\n",
      "tied to   1.0\n",
      "\n",
      "of code   0.00089126559714795\n",
      "\n",
      "hand or   0.14285714285714285\n",
      "\n",
      "NLP ranking   0.02127659574468085\n",
      "\n",
      "finding non-existent   0.2\n",
      "\n",
      ", annotation   0.0005614823133071309\n",
      "\n",
      "with hand-written   0.00546448087431694\n",
      "\n",
      "fulfill expectations   0.5\n",
      "\n",
      "domain -LRB-   0.05\n",
      "\n",
      "analysis and   0.03076923076923077\n",
      "\n",
      "a semantic   0.001226993865030675\n",
      "\n",
      "Approaches which   0.3333333333333333\n",
      "\n",
      "it into   0.042735042735042736\n",
      "\n",
      "for continuous   0.0036101083032490976\n",
      "\n",
      "'' about   0.005154639175257732\n",
      "\n",
      "PageRank on   0.16666666666666666\n",
      "\n",
      "resolution :   0.25\n",
      "\n",
      "a relative   0.001226993865030675\n",
      "\n",
      "mining .   0.2\n",
      "\n",
      "in 1971   0.0018726591760299626\n",
      "\n",
      "entirety ,   1.0\n",
      "\n",
      "multiple possible   0.15384615384615385\n",
      "\n",
      "adjective ;   0.14285714285714285\n",
      "\n",
      "some extent   0.012048192771084338\n",
      "\n",
      "`` Customized   0.005291005291005291\n",
      "\n",
      "implications of   1.0\n",
      "\n",
      "a group   0.001226993865030675\n",
      "\n",
      "quantitative one   0.25\n",
      "\n",
      "highlighted ,   1.0\n",
      "\n",
      "formal or   0.1111111111111111\n",
      "\n",
      "methods based   0.022727272727272728\n",
      "\n",
      "properties .   0.25\n",
      "\n",
      "interpreter ,   0.5\n",
      "\n",
      "these algorithms   0.023809523809523808\n",
      "\n",
      "acquire basic   1.0\n",
      "\n",
      "morphosyntactic descriptor   1.0\n",
      "\n",
      "subdivided into   1.0\n",
      "\n",
      "TF-IDF vectors   1.0\n",
      "\n",
      "a limited   0.00245398773006135\n",
      "\n",
      "<s> Efficient   0.0007686395080707148\n",
      "\n",
      "A summary   0.02\n",
      "\n",
      "but these   0.014705882352941176\n",
      "\n",
      "are capable   0.008298755186721992\n",
      "\n",
      "and when   0.001445086705202312\n",
      "\n",
      "levels ,   0.045454545454545456\n",
      "\n",
      "into account   0.038461538461538464\n",
      "\n",
      ", typically   0.0016844469399213925\n",
      "\n",
      "and length   0.001445086705202312\n",
      "\n",
      "keyphrases formed   0.02857142857142857\n",
      "\n",
      "programs have   0.09090909090909091\n",
      "\n",
      "on Audio   0.0047169811320754715\n",
      "\n",
      "and without   0.002890173410404624\n",
      "\n",
      "end ,   0.125\n",
      "\n",
      "a criterion   0.001226993865030675\n",
      "\n",
      "each lexical   0.022222222222222223\n",
      "\n",
      "through a   0.25\n",
      "\n",
      "logical deduction   0.16666666666666666\n",
      "\n",
      "purposes -LRB-   0.25\n",
      "\n",
      "by resorting   0.005714285714285714\n",
      "\n",
      "complex task   0.041666666666666664\n",
      "\n",
      "in visible   0.0018726591760299626\n",
      "\n",
      "available -LRB-   0.058823529411764705\n",
      "\n",
      "In 1978   0.009523809523809525\n",
      "\n",
      "subsequent concepts   0.5\n",
      "\n",
      "artifacts ,   1.0\n",
      "\n",
      "with language   0.00546448087431694\n",
      "\n",
      "and DCD   0.001445086705202312\n",
      "\n",
      "text documents   0.006289308176100629\n",
      "\n",
      "verifying certain   1.0\n",
      "\n",
      "into machine   0.01282051282051282\n",
      "\n",
      "serve as   0.8\n",
      "\n",
      "some time   0.024096385542168676\n",
      "\n",
      "work .   0.08333333333333333\n",
      "\n",
      "syntax are   0.09090909090909091\n",
      "\n",
      "been hand-annotated   0.029411764705882353\n",
      "\n",
      "the design   0.001384083044982699\n",
      "\n",
      "relative position   0.3333333333333333\n",
      "\n",
      "Digest and   0.3333333333333333\n",
      "\n",
      "'' aimed   0.005154639175257732\n",
      "\n",
      "the isolation   0.0006920415224913495\n",
      "\n",
      "A large   0.02\n",
      "\n",
      "have all   0.009615384615384616\n",
      "\n",
      "about as   0.025\n",
      "\n",
      "Jones Street   1.0\n",
      "\n",
      "is now   0.006097560975609756\n",
      "\n",
      "the author   0.0020761245674740486\n",
      "\n",
      "controller would   0.25\n",
      "\n",
      "up in   0.09090909090909091\n",
      "\n",
      "word processing   0.016666666666666666\n",
      "\n",
      "detail .   0.5\n",
      "\n",
      "right context   0.1\n",
      "\n",
      "on upper   0.0047169811320754715\n",
      "\n",
      "lower level   0.4\n",
      "\n",
      "interpreted as   1.0\n",
      "\n",
      "politics ,   1.0\n",
      "\n",
      "signal to   0.16666666666666666\n",
      "\n",
      "component .   0.2\n",
      "\n",
      "Intelligent Character   0.3333333333333333\n",
      "\n",
      "tool .   0.5\n",
      "\n",
      "written including   0.038461538461538464\n",
      "\n",
      "<s> Inclusive   0.0007686395080707148\n",
      "\n",
      "logic -RRB-   0.25\n",
      "\n",
      "to parsers   0.0013280212483399733\n",
      "\n",
      "echoes ,   1.0\n",
      "\n",
      "as often   0.003484320557491289\n",
      "\n",
      "editing and   0.5\n",
      "\n",
      "<s> Extrinsic   0.0015372790161414297\n",
      "\n",
      "or may   0.009009009009009009\n",
      "\n",
      ", hence   0.0005614823133071309\n",
      "\n",
      "Advanced Research   0.2\n",
      "\n",
      "Some ISO   0.047619047619047616\n",
      "\n",
      "advent of   1.0\n",
      "\n",
      ", Adriana   0.0005614823133071309\n",
      "\n",
      "transform -RRB-   0.2\n",
      "\n",
      "reliability ,   0.5\n",
      "\n",
      "normally requires   0.5\n",
      "\n",
      "ratings .   0.1111111111111111\n",
      "\n",
      "obvious at   1.0\n",
      "\n",
      "by Junqua   0.005714285714285714\n",
      "\n",
      "It sometimes   0.02631578947368421\n",
      "\n",
      "right-to-left ,   1.0\n",
      "\n",
      "`` universal   0.010582010582010581\n",
      "\n",
      "Customized OCR   1.0\n",
      "\n",
      "approaches to   0.17857142857142858\n",
      "\n",
      ", NNS   0.0005614823133071309\n",
      "\n",
      "applications fall   0.04\n",
      "\n",
      "discriminate because   0.3333333333333333\n",
      "\n",
      ": extraction   0.00980392156862745\n",
      "\n",
      "-RRB- Bhatia   0.0027100271002710027\n",
      "\n",
      "book applies   0.125\n",
      "\n",
      "how it   0.06896551724137931\n",
      "\n",
      "parsers are   0.15384615384615385\n",
      "\n",
      "linear representation   0.14285714285714285\n",
      "\n",
      "MUC and   1.0\n",
      "\n",
      "record of   1.0\n",
      "\n",
      "phonetically different   1.0\n",
      "\n",
      "another problem   0.15384615384615385\n",
      "\n",
      "agree about   0.3333333333333333\n",
      "\n",
      "processing tools   0.018518518518518517\n",
      "\n",
      "instances ,   0.3333333333333333\n",
      "\n",
      "a large   0.0098159509202454\n",
      "\n",
      "classifiers make   0.5\n",
      "\n",
      "for words   0.0036101083032490976\n",
      "\n",
      "required for   0.14285714285714285\n",
      "\n",
      "Roger Fowler   0.25\n",
      "\n",
      "2009 to   0.3333333333333333\n",
      "\n",
      "The profile   0.005208333333333333\n",
      "\n",
      "keeping a   0.5\n",
      "\n",
      "the CoNLL   0.0006920415224913495\n",
      "\n",
      ", René   0.0005614823133071309\n",
      "\n",
      "technology are   0.045454545454545456\n",
      "\n",
      "optimize some   1.0\n",
      "\n",
      "disagree on   0.3333333333333333\n",
      "\n",
      "H. Levinsohn   0.5\n",
      "\n",
      "characters using   0.0625\n",
      "\n",
      "known what   0.038461538461538464\n",
      "\n",
      "a Standard   0.001226993865030675\n",
      "\n",
      "startlingly human-like   1.0\n",
      "\n",
      "a short-time   0.001226993865030675\n",
      "\n",
      "you can   0.15384615384615385\n",
      "\n",
      "focus to   0.14285714285714285\n",
      "\n",
      "particular method   0.07692307692307693\n",
      "\n",
      "the waves   0.0006920415224913495\n",
      "\n",
      "This unreferenced   0.015873015873015872\n",
      "\n",
      "on such   0.0047169811320754715\n",
      "\n",
      "words appear   0.009174311926605505\n",
      "\n",
      "similarity .   0.1\n",
      "\n",
      "a negative   0.001226993865030675\n",
      "\n",
      "input is   0.024390243902439025\n",
      "\n",
      "of omni-font   0.00089126559714795\n",
      "\n",
      "universal ''   0.3333333333333333\n",
      "\n",
      "increases in   1.0\n",
      "\n",
      "so on   0.16666666666666666\n",
      "\n",
      "representation and   0.10526315789473684\n",
      "\n",
      "to summarise   0.00398406374501992\n",
      "\n",
      "sales reports   0.3333333333333333\n",
      "\n",
      "They combine   0.3333333333333333\n",
      "\n",
      "to get   0.005312084993359893\n",
      "\n",
      "movie together   0.3333333333333333\n",
      "\n",
      "same method   0.04\n",
      "\n",
      "as mentioned   0.003484320557491289\n",
      "\n",
      "text accordingly   0.006289308176100629\n",
      "\n",
      "<s> TextRank   0.0023059185242121443\n",
      "\n",
      "natural summaries   0.013333333333333334\n",
      "\n",
      "a facemask   0.001226993865030675\n",
      "\n",
      "became less   0.2\n",
      "\n",
      "included -LRB-   0.125\n",
      "\n",
      "of parsing   0.0017825311942959\n",
      "\n",
      "a knowledge   0.001226993865030675\n",
      "\n",
      "value ,   0.3333333333333333\n",
      "\n",
      "the dynamic   0.0006920415224913495\n",
      "\n",
      "paying attention   1.0\n",
      "\n",
      "Extracted sentences   1.0\n",
      "\n",
      "construct over   0.3333333333333333\n",
      "\n",
      "be achieved   0.02109704641350211\n",
      "\n",
      "Sentence segmentation   0.4\n",
      "\n",
      "20 %   1.0\n",
      "\n",
      "the news   0.001384083044982699\n",
      "\n",
      "automatically answering   0.047619047619047616\n",
      "\n",
      "between successive   0.02564102564102564\n",
      "\n",
      "translation is   0.013513513513513514\n",
      "\n",
      "languages of   0.02\n",
      "\n",
      "abstraction can   0.25\n",
      "\n",
      "characters for   0.0625\n",
      "\n",
      "What learning   0.09090909090909091\n",
      "\n",
      "with ,   0.00546448087431694\n",
      "\n",
      "Text Retrieval   0.16666666666666666\n",
      "\n",
      "specific domains   0.047619047619047616\n",
      "\n",
      "G ,   1.0\n",
      "\n",
      "are largely   0.004149377593360996\n",
      "\n",
      "to machine   0.00398406374501992\n",
      "\n",
      "evaluated by   0.14285714285714285\n",
      "\n",
      "linear combination   0.14285714285714285\n",
      "\n",
      "higher level   0.14285714285714285\n",
      "\n",
      "Star Trek   1.0\n",
      "\n",
      "duplicate typewritten   0.5\n",
      "\n",
      "different parts   0.04081632653061224\n",
      "\n",
      "special image   0.2\n",
      "\n",
      "years long   0.047619047619047616\n",
      "\n",
      "of standard   0.00089126559714795\n",
      "\n",
      ", for   0.012352610892756879\n",
      "\n",
      "stage using   0.2\n",
      "\n",
      "capitalized .   0.3333333333333333\n",
      "\n",
      "tagging -LRB-   0.04\n",
      "\n",
      "a radiology   0.001226993865030675\n",
      "\n",
      "input sales   0.024390243902439025\n",
      "\n",
      "which found   0.014492753623188406\n",
      "\n",
      "In 1971   0.009523809523809525\n",
      "\n",
      "The examples   0.005208333333333333\n",
      "\n",
      "test and   0.2\n",
      "\n",
      "expert that   1.0\n",
      "\n",
      "question types   0.023809523809523808\n",
      "\n",
      ", paper   0.0005614823133071309\n",
      "\n",
      "features describing   0.038461538461538464\n",
      "\n",
      "updated textbook   1.0\n",
      "\n",
      "algebra .   0.5\n",
      "\n",
      "different tongues   0.02040816326530612\n",
      "\n",
      "of answer   0.00089126559714795\n",
      "\n",
      "or phrases   0.009009009009009009\n",
      "\n",
      "describing each   0.25\n",
      "\n",
      "spoken words   0.14285714285714285\n",
      "\n",
      "answer highlighted   0.03333333333333333\n",
      "\n",
      "turn requires   0.16666666666666666\n",
      "\n",
      "while verbs   0.05\n",
      "\n",
      "topics .   0.14285714285714285\n",
      "\n",
      "The ideal   0.005208333333333333\n",
      "\n",
      "as needed   0.003484320557491289\n",
      "\n",
      "weights equal   0.2\n",
      "\n",
      "angry ,   0.5\n",
      "\n",
      "<s> People   0.0007686395080707148\n",
      "\n",
      "in non-Western   0.0018726591760299626\n",
      "\n",
      "to contain   0.0013280212483399733\n",
      "\n",
      "dictionary can   0.14285714285714285\n",
      "\n",
      "more or   0.031578947368421054\n",
      "\n",
      "to tell   0.0013280212483399733\n",
      "\n",
      "example The   0.012345679012345678\n",
      "\n",
      "letters .   0.4\n",
      "\n",
      "classification ,   0.058823529411764705\n",
      "\n",
      "are limited   0.004149377593360996\n",
      "\n",
      "are designed   0.004149377593360996\n",
      "\n",
      "entries for   0.5\n",
      "\n",
      "Moreover ,   1.0\n",
      "\n",
      "that machine   0.010638297872340425\n",
      "\n",
      "minute ,   1.0\n",
      "\n",
      "of NLP   0.004456327985739751\n",
      "\n",
      "on casual   0.0047169811320754715\n",
      "\n",
      "in polynomial   0.0018726591760299626\n",
      "\n",
      "looks at   0.25\n",
      "\n",
      "judgement often   0.3333333333333333\n",
      "\n",
      "us with   0.5\n",
      "\n",
      "with Nuance   0.00546448087431694\n",
      "\n",
      "being the   0.05555555555555555\n",
      "\n",
      "the desired   0.002768166089965398\n",
      "\n",
      "model and   0.03333333333333333\n",
      "\n",
      "adverb ,   1.0\n",
      "\n",
      "or identical   0.0045045045045045045\n",
      "\n",
      "step ,   0.13333333333333333\n",
      "\n",
      ", flexibility   0.0005614823133071309\n",
      "\n",
      "causes a   1.0\n",
      "\n",
      "completion of   1.0\n",
      "\n",
      "knowledge about   0.1111111111111111\n",
      "\n",
      "are able   0.012448132780082987\n",
      "\n",
      "achieving high   0.5\n",
      "\n",
      "a fully   0.001226993865030675\n",
      "\n",
      "personalised business   1.0\n",
      "\n",
      "meanings ,   0.25\n",
      "\n",
      "their chosen   0.029411764705882353\n",
      "\n",
      "usually rated   0.03125\n",
      "\n",
      ", T   0.0005614823133071309\n",
      "\n",
      "<s> Starting   0.0007686395080707148\n",
      "\n",
      "been changed   0.014705882352941176\n",
      "\n",
      "way :   0.041666666666666664\n",
      "\n",
      "spoken text   0.07142857142857142\n",
      "\n",
      "a string   0.00245398773006135\n",
      "\n",
      "linguistic discourse   0.0625\n",
      "\n",
      "to mental   0.0013280212483399733\n",
      "\n",
      "a hidden   0.001226993865030675\n",
      "\n",
      "breaking ,   0.5\n",
      "\n",
      "with high   0.01092896174863388\n",
      "\n",
      "with specific   0.00546448087431694\n",
      "\n",
      "Penpoint OS   1.0\n",
      "\n",
      "popular in   0.1111111111111111\n",
      "\n",
      "extractive methods   0.14285714285714285\n",
      "\n",
      ": Dynamic   0.00980392156862745\n",
      "\n",
      "important Web   0.0625\n",
      "\n",
      "right kind   0.1\n",
      "\n",
      "distinct sentences   0.14285714285714285\n",
      "\n",
      "rescore lattices   1.0\n",
      "\n",
      "what type   0.03125\n",
      "\n",
      "A somewhat   0.02\n",
      "\n",
      "extractor might   0.5\n",
      "\n",
      "their spoken   0.029411764705882353\n",
      "\n",
      "can simplify   0.0055248618784530384\n",
      "\n",
      "users with   0.1111111111111111\n",
      "\n",
      "research attempts   0.047619047619047616\n",
      "\n",
      "necessary therefore   0.1\n",
      "\n",
      "we want   0.044444444444444446\n",
      "\n",
      "wrote The   0.16666666666666666\n",
      "\n",
      "Human judgement   0.2\n",
      "\n",
      "Howarth ,   1.0\n",
      "\n",
      "moon missions   1.0\n",
      "\n",
      "syntax is   0.09090909090909091\n",
      "\n",
      "expect answers   0.3333333333333333\n",
      "\n",
      ", Zellig   0.0011229646266142617\n",
      "\n",
      "document such   0.027777777777777776\n",
      "\n",
      "p. 32   1.0\n",
      "\n",
      "Tell me   1.0\n",
      "\n",
      "and Cary   0.001445086705202312\n",
      "\n",
      "recognition from   0.01652892561983471\n",
      "\n",
      "to names   0.0013280212483399733\n",
      "\n",
      "an objective   0.007575757575757576\n",
      "\n",
      "subtasks that   0.5\n",
      "\n",
      "the corresponding   0.001384083044982699\n",
      "\n",
      "determine both   0.043478260869565216\n",
      "\n",
      "21 taggers   1.0\n",
      "\n",
      "about to   0.025\n",
      "\n",
      "meaningful units   0.125\n",
      "\n",
      "identified the   0.2\n",
      "\n",
      "in-principle obstacles   1.0\n",
      "\n",
      "Journal corpus   0.3333333333333333\n",
      "\n",
      "hours .   0.5\n",
      "\n",
      "and get   0.001445086705202312\n",
      "\n",
      "relic of   1.0\n",
      "\n",
      ", handling   0.0011229646266142617\n",
      "\n",
      "<s> English   0.0007686395080707148\n",
      "\n",
      "comparing the   0.5\n",
      "\n",
      "follows a   0.5\n",
      "\n",
      "non -   1.0\n",
      "\n",
      "Evaluation of   0.1111111111111111\n",
      "\n",
      "is coherent   0.0020325203252032522\n",
      "\n",
      "focuses on   1.0\n",
      "\n",
      "-RRB- Acoustical   0.0027100271002710027\n",
      "\n",
      "English of   0.02702702702702703\n",
      "\n",
      "so most   0.03333333333333333\n",
      "\n",
      "directly from   0.2\n",
      "\n",
      "Corporation and   0.25\n",
      "\n",
      "10 -RRB-   0.125\n",
      "\n",
      "the unigrams   0.001384083044982699\n",
      "\n",
      ", propositions   0.0011229646266142617\n",
      "\n",
      "custom speech   0.5\n",
      "\n",
      "recognition -LRB-   0.049586776859504134\n",
      "\n",
      "statistics of   0.125\n",
      "\n",
      "computed with   0.5\n",
      "\n",
      "coding of   1.0\n",
      "\n",
      ", after   0.0005614823133071309\n",
      "\n",
      "translation Example-based   0.013513513513513514\n",
      "\n",
      "industry currently   0.3333333333333333\n",
      "\n",
      "of heuristics   0.00089126559714795\n",
      "\n",
      "﻿Natural language   1.0\n",
      "\n",
      "written ,   0.038461538461538464\n",
      "\n",
      "that OCR   0.0035460992907801418\n",
      "\n",
      "statistical quantity   0.030303030303030304\n",
      "\n",
      "alignment software   0.5\n",
      "\n",
      "travel .   1.0\n",
      "\n",
      "`` Natural   0.005291005291005291\n",
      "\n",
      "seminal paper   1.0\n",
      "\n",
      ": whereas   0.00980392156862745\n",
      "\n",
      "or Latin   0.0045045045045045045\n",
      "\n",
      "difference is   0.25\n",
      "\n",
      "voice than   0.07692307692307693\n",
      "\n",
      "management environments   0.14285714285714285\n",
      "\n",
      "number should   0.023255813953488372\n",
      "\n",
      "2008 -RRB-   1.0\n",
      "\n",
      "mechanical or   1.0\n",
      "\n",
      "thousands of   0.6666666666666666\n",
      "\n",
      "Medical Language   0.5\n",
      "\n",
      "the position   0.0006920415224913495\n",
      "\n",
      "retail sales   1.0\n",
      "\n",
      "; This   0.02127659574468085\n",
      "\n",
      "characterized in   0.25\n",
      "\n",
      "threshold is   0.25\n",
      "\n",
      "words -LRB-   0.027522935779816515\n",
      "\n",
      "input ,   0.07317073170731707\n",
      "\n",
      "static shape   1.0\n",
      "\n",
      "each observed   0.022222222222222223\n",
      "\n",
      "different ways   0.02040816326530612\n",
      "\n",
      "are informative   0.004149377593360996\n",
      "\n",
      "formalism which   1.0\n",
      "\n",
      "human in   0.021739130434782608\n",
      "\n",
      "the opportunity   0.0006920415224913495\n",
      "\n",
      "working from   0.14285714285714285\n",
      "\n",
      "greatly improved   0.14285714285714285\n",
      "\n",
      "defined to   0.16666666666666666\n",
      "\n",
      "using algorithms   0.01694915254237288\n",
      "\n",
      "probabilistic context-free   0.14285714285714285\n",
      "\n",
      ", electrical   0.0005614823133071309\n",
      "\n",
      "English .   0.13513513513513514\n",
      "\n",
      "text segmentation   0.0440251572327044\n",
      "\n",
      "placement of   1.0\n",
      "\n",
      "contrast -RRB-   0.125\n",
      "\n",
      "one element   0.015384615384615385\n",
      "\n",
      "the picture   0.001384083044982699\n",
      "\n",
      "Language as   0.08333333333333333\n",
      "\n",
      "terms that   0.07692307692307693\n",
      "\n",
      "essay scoring   1.0\n",
      "\n",
      "semantic model   0.047619047619047616\n",
      "\n",
      "units ;   0.14285714285714285\n",
      "\n",
      "Helicopters The   1.0\n",
      "\n",
      "network is   0.16666666666666666\n",
      "\n",
      "with other   0.00546448087431694\n",
      "\n",
      "Science ,   0.5\n",
      "\n",
      "necessary for   0.3\n",
      "\n",
      "but most   0.029411764705882353\n",
      "\n",
      "that without   0.0035460992907801418\n",
      "\n",
      "generating the   0.2\n",
      "\n",
      "Other areas   0.14285714285714285\n",
      "\n",
      "many -LRB-   0.019230769230769232\n",
      "\n",
      "better understanding   0.1111111111111111\n",
      "\n",
      "the Standard   0.0006920415224913495\n",
      "\n",
      "Online ,   0.5\n",
      "\n",
      "October 2007   1.0\n",
      "\n",
      "and wrote   0.001445086705202312\n",
      "\n",
      "such representation   0.008130081300813009\n",
      "\n",
      "then end   0.02857142857142857\n",
      "\n",
      "complexity ,   0.16666666666666666\n",
      "\n",
      "particular case   0.07692307692307693\n",
      "\n",
      "<s> Few   0.0007686395080707148\n",
      "\n",
      "look at   0.4\n",
      "\n",
      "'' set   0.005154639175257732\n",
      "\n",
      "a bunch   0.001226993865030675\n",
      "\n",
      "reading comprehension   0.25\n",
      "\n",
      "licensed on   1.0\n",
      "\n",
      "involve various   0.16666666666666666\n",
      "\n",
      "data mining   0.025974025974025976\n",
      "\n",
      "ranked with   0.2\n",
      "\n",
      "<s> For   0.043812451960030745\n",
      "\n",
      "Processor is   1.0\n",
      "\n",
      "or fuse   0.0045045045045045045\n",
      "\n",
      "model for   0.06666666666666667\n",
      "\n",
      "Home automation   1.0\n",
      "\n",
      "sounds of   0.13333333333333333\n",
      "\n",
      "output that   0.07692307692307693\n",
      "\n",
      "Applications include   0.5\n",
      "\n",
      "proceedings into   1.0\n",
      "\n",
      "medium or   0.3333333333333333\n",
      "\n",
      "expected .   0.14285714285714285\n",
      "\n",
      "smaller ones   0.14285714285714285\n",
      "\n",
      "architecture Regardless   0.5\n",
      "\n",
      "discourse ,   0.08333333333333333\n",
      "\n",
      "will approach   0.02857142857142857\n",
      "\n",
      "though other   0.1\n",
      "\n",
      "d'Albe developed   1.0\n",
      "\n",
      "<s> Realisation   0.0007686395080707148\n",
      "\n",
      "Automatic summarization   0.2222222222222222\n",
      "\n",
      "to erroneous   0.0013280212483399733\n",
      "\n",
      "systems are   0.11607142857142858\n",
      "\n",
      "transcribe such   1.0\n",
      "\n",
      "How many   0.14285714285714285\n",
      "\n",
      "contains all   0.1\n",
      "\n",
      "<s> Solutions   0.0007686395080707148\n",
      "\n",
      "motion during   1.0\n",
      "\n",
      "be produced   0.004219409282700422\n",
      "\n",
      "or Continuous   0.0045045045045045045\n",
      "\n",
      "formal language   0.2222222222222222\n",
      "\n",
      "human-made summaries   0.5\n",
      "\n",
      "eat ''   1.0\n",
      "\n",
      "knowledge of   0.14814814814814814\n",
      "\n",
      "Important journals   1.0\n",
      "\n",
      "commanding an   1.0\n",
      "\n",
      "very likely   0.024390243902439025\n",
      "\n",
      "In general   0.02857142857142857\n",
      "\n",
      "important part   0.0625\n",
      "\n",
      "-LRB- CSIS   0.0027100271002710027\n",
      "\n",
      "require extensive   0.09090909090909091\n",
      "\n",
      "favor accuracy   0.5\n",
      "\n",
      "discourse analyst   0.027777777777777776\n",
      "\n",
      "sometimes referred   0.23076923076923078\n",
      "\n",
      "people for   0.0625\n",
      "\n",
      "grammar to   0.02702702702702703\n",
      "\n",
      "overall task   0.16666666666666666\n",
      "\n",
      "basic technology   0.07692307692307693\n",
      "\n",
      "<s> Generally   0.003843197540353574\n",
      "\n",
      "this is   0.0989010989010989\n",
      "\n",
      "Effective natural   1.0\n",
      "\n",
      "in different   0.0056179775280898875\n",
      "\n",
      "prior attempts   0.3333333333333333\n",
      "\n",
      "methods were   0.045454545454545456\n",
      "\n",
      "-RRB- --   0.0027100271002710027\n",
      "\n",
      "claim that   1.0\n",
      "\n",
      "matching -RRB-   0.2\n",
      "\n",
      "on pilot   0.0047169811320754715\n",
      "\n",
      "5000 or   1.0\n",
      "\n",
      "actual text   0.2\n",
      "\n",
      "large variety   0.043478260869565216\n",
      "\n",
      "The recently   0.005208333333333333\n",
      "\n",
      "different possible   0.02040816326530612\n",
      "\n",
      "timing for   1.0\n",
      "\n",
      "and statistical   0.004335260115606936\n",
      "\n",
      "to change   0.0013280212483399733\n",
      "\n",
      "not absolutely   0.008928571428571428\n",
      "\n",
      "as interactivity   0.003484320557491289\n",
      "\n",
      "`` recommending   0.005291005291005291\n",
      "\n",
      "How are   0.2857142857142857\n",
      "\n",
      "news ,   0.07692307692307693\n",
      "\n",
      "apply the   0.2\n",
      "\n",
      "software ,   0.037037037037037035\n",
      "\n",
      "and answers   0.001445086705202312\n",
      "\n",
      "needed .   0.09523809523809523\n",
      "\n",
      "Agency in   0.5\n",
      "\n",
      "images of   0.3333333333333333\n",
      "\n",
      "grammar .   0.10810810810810811\n",
      "\n",
      "would expect   0.018867924528301886\n",
      "\n",
      "intelligent character   1.0\n",
      "\n",
      "of domain   0.00089126559714795\n",
      "\n",
      "supplying more   1.0\n",
      "\n",
      "can understand   0.0055248618784530384\n",
      "\n",
      "sailor →   0.2\n",
      "\n",
      "the machine-learning   0.0006920415224913495\n",
      "\n",
      "Deep approaches   1.0\n",
      "\n",
      "a difficult   0.001226993865030675\n",
      "\n",
      "controller tasks   0.25\n",
      "\n",
      "of symbols   0.00089126559714795\n",
      "\n",
      "<s> Use   0.0007686395080707148\n",
      "\n",
      "formalisms such   0.5\n",
      "\n",
      "things .   0.3333333333333333\n",
      "\n",
      "nuances and   1.0\n",
      "\n",
      "HMM based   0.3333333333333333\n",
      "\n",
      "answers are   0.08333333333333333\n",
      "\n",
      "periods can   0.3333333333333333\n",
      "\n",
      "paste relevant   1.0\n",
      "\n",
      "about machine   0.025\n",
      "\n",
      "several variables   0.045454545454545456\n",
      "\n",
      "are exceptions   0.004149377593360996\n",
      "\n",
      "working to   0.14285714285714285\n",
      "\n",
      "could usefully   0.0625\n",
      "\n",
      "on broad   0.0047169811320754715\n",
      "\n",
      "more informative   0.010526315789473684\n",
      "\n",
      "Other taggers   0.14285714285714285\n",
      "\n",
      "chance of   1.0\n",
      "\n",
      "model summaries   0.06666666666666667\n",
      "\n",
      "of related   0.00267379679144385\n",
      "\n",
      "problem in   0.09090909090909091\n",
      "\n",
      "if word   0.03571428571428571\n",
      "\n",
      "would .   0.018867924528301886\n",
      "\n",
      "& Critical   0.125\n",
      "\n",
      "focus on   0.5714285714285714\n",
      "\n",
      "from which   0.028846153846153848\n",
      "\n",
      "typewritten messages   0.2\n",
      "\n",
      "a rightmost   0.00245398773006135\n",
      "\n",
      "; these   0.0425531914893617\n",
      "\n",
      "lightweight ontologies   1.0\n",
      "\n",
      "-LRB- MLLR   0.0027100271002710027\n",
      "\n",
      "as maximum   0.003484320557491289\n",
      "\n",
      "tract length   1.0\n",
      "\n",
      "not initially   0.008928571428571428\n",
      "\n",
      "was LILOG   0.012987012987012988\n",
      "\n",
      "abstractive method   0.16666666666666666\n",
      "\n",
      "Knowing this   1.0\n",
      "\n",
      ", automatic   0.0016844469399213925\n",
      "\n",
      "speech to   0.019736842105263157\n",
      "\n",
      "larger group   0.0625\n",
      "\n",
      "by Su   0.005714285714285714\n",
      "\n",
      "what sound   0.03125\n",
      "\n",
      "is identifying   0.0020325203252032522\n",
      "\n",
      "and Dale   0.001445086705202312\n",
      "\n",
      "analysis ,   0.1076923076923077\n",
      "\n",
      "ICR make   0.3333333333333333\n",
      "\n",
      "coherence .   0.3333333333333333\n",
      "\n",
      "closely related   0.4\n",
      "\n",
      "then applied   0.05714285714285714\n",
      "\n",
      "with highest   0.01092896174863388\n",
      "\n",
      "you would   0.07692307692307693\n",
      "\n",
      "readers processed   0.5\n",
      "\n",
      "Summarization -RRB-   0.5\n",
      "\n",
      "<s> Intra-texual   0.0007686395080707148\n",
      "\n",
      "and weaknesses   0.001445086705202312\n",
      "\n",
      "of rocks   0.00089126559714795\n",
      "\n",
      "understanding :   0.030303030303030304\n",
      "\n",
      "of annotated   0.00089126559714795\n",
      "\n",
      "subtypes of   1.0\n",
      "\n",
      "summary 's   0.047619047619047616\n",
      "\n",
      "and model   0.001445086705202312\n",
      "\n",
      "require rapid   0.045454545454545456\n",
      "\n",
      "have increased   0.028846153846153848\n",
      "\n",
      "automated sentiment   0.14285714285714285\n",
      "\n",
      "and indirect   0.001445086705202312\n",
      "\n",
      "graph -RRB-   0.07692307692307693\n",
      "\n",
      "while logic   0.05\n",
      "\n",
      "said with   1.0\n",
      "\n",
      "Bush 's   0.5\n",
      "\n",
      "involves deciding   0.1\n",
      "\n",
      "opened ,   1.0\n",
      "\n",
      "which give   0.007246376811594203\n",
      "\n",
      "from has   0.009615384615384616\n",
      "\n",
      "top T   0.4\n",
      "\n",
      "an image   0.007575757575757576\n",
      "\n",
      "Corpus -RRB-   0.1875\n",
      "\n",
      "the known   0.0034602076124567475\n",
      "\n",
      "would then   0.018867924528301886\n",
      "\n",
      "similarities in   0.5\n",
      "\n",
      "is shown   0.0020325203252032522\n",
      "\n",
      "retrieval or   0.14285714285714285\n",
      "\n",
      "conference headed   0.5\n",
      "\n",
      "of system-generated   0.00089126559714795\n",
      "\n",
      "from multiple   0.009615384615384616\n",
      "\n",
      "which many   0.007246376811594203\n",
      "\n",
      "and negative   0.002890173410404624\n",
      "\n",
      "on extractive   0.0047169811320754715\n",
      "\n",
      "physicians who   1.0\n",
      "\n",
      "enable the   1.0\n",
      "\n",
      "or turns-at-talk   0.0045045045045045045\n",
      "\n",
      "Extract subjective   1.0\n",
      "\n",
      "representation system   0.05263157894736842\n",
      "\n",
      "state of   0.35714285714285715\n",
      "\n",
      "life experience   0.25\n",
      "\n",
      "is especially   0.0040650406504065045\n",
      "\n",
      "-LRB- CSR   0.005420054200542005\n",
      "\n",
      "tests .   0.25\n",
      "\n",
      "Drum printer   1.0\n",
      "\n",
      "the segment   0.0006920415224913495\n",
      "\n",
      ": Many   0.00980392156862745\n",
      "\n",
      "overall system   0.16666666666666666\n",
      "\n",
      "a machine   0.008588957055214725\n",
      "\n",
      "possibilities .   0.2\n",
      "\n",
      "to encourage   0.0013280212483399733\n",
      "\n",
      "text -LRB-   0.03773584905660377\n",
      "\n",
      "only relief   0.02631578947368421\n",
      "\n",
      "the addressee   0.0006920415224913495\n",
      "\n",
      "requirements .   0.5\n",
      "\n",
      "-LRB- speed   0.0027100271002710027\n",
      "\n",
      "and shorter   0.001445086705202312\n",
      "\n",
      "features that   0.07692307692307693\n",
      "\n",
      "often possible   0.022727272727272728\n",
      "\n",
      "and morphology   0.001445086705202312\n",
      "\n",
      "the right   0.0020761245674740486\n",
      "\n",
      "recognition programs   0.008264462809917356\n",
      "\n",
      "both its   0.03225806451612903\n",
      "\n",
      "-- between   0.04\n",
      "\n",
      "social networks   0.21428571428571427\n",
      "\n",
      "has received   0.011904761904761904\n",
      "\n",
      "find a   0.15384615384615385\n",
      "\n",
      "for various   0.0036101083032490976\n",
      "\n",
      "measured can   0.16666666666666666\n",
      "\n",
      "may result   0.019230769230769232\n",
      "\n",
      "more precise   0.010526315789473684\n",
      "\n",
      "the volume   0.0006920415224913495\n",
      "\n",
      "the relationships   0.0006920415224913495\n",
      "\n",
      "one typically   0.015384615384615385\n",
      "\n",
      "vs. objective   0.08333333333333333\n",
      "\n",
      "applies those   0.14285714285714285\n",
      "\n",
      "separate it   0.2\n",
      "\n",
      ", going   0.0005614823133071309\n",
      "\n",
      "Aviation Authorities   1.0\n",
      "\n",
      "new text   0.08333333333333333\n",
      "\n",
      "vs. glass-box   0.08333333333333333\n",
      "\n",
      "input characters   0.024390243902439025\n",
      "\n",
      "form logical   0.05\n",
      "\n",
      "earlier term   0.25\n",
      "\n",
      "manage their   1.0\n",
      "\n",
      "put together   0.25\n",
      "\n",
      "<s> POS-tagging   0.0007686395080707148\n",
      "\n",
      "are at   0.008298755186721992\n",
      "\n",
      "is whether   0.0020325203252032522\n",
      "\n",
      "as PC   0.003484320557491289\n",
      "\n",
      "relationships .   0.16666666666666666\n",
      "\n",
      "they helped   0.025\n",
      "\n",
      "domains such   0.125\n",
      "\n",
      "reasoning approach   0.14285714285714285\n",
      "\n",
      "potential of   0.2857142857142857\n",
      "\n",
      "various types   0.1111111111111111\n",
      "\n",
      "<s> Unlike   0.0007686395080707148\n",
      "\n",
      "Syphon -LRB-   1.0\n",
      "\n",
      "periods or   0.3333333333333333\n",
      "\n",
      "'s opinions   0.0196078431372549\n",
      "\n",
      "Case =   1.0\n",
      "\n",
      "issued to   1.0\n",
      "\n",
      "manual annotation   0.5\n",
      "\n",
      "like a   0.07142857142857142\n",
      "\n",
      "MAHT and   1.0\n",
      "\n",
      "of chatterbots   0.00089126559714795\n",
      "\n",
      "green fire   1.0\n",
      "\n",
      "disassembling and   1.0\n",
      "\n",
      "its understanding   0.02857142857142857\n",
      "\n",
      "<s> Extraction   0.0015372790161414297\n",
      "\n",
      "the training   0.002768166089965398\n",
      "\n",
      "SHRDLU for   0.16666666666666666\n",
      "\n",
      ", needed   0.0005614823133071309\n",
      "\n",
      "See machine   0.16666666666666666\n",
      "\n",
      "sailor !   0.2\n",
      "\n",
      "intrinsic properties   0.25\n",
      "\n",
      "a limit   0.001226993865030675\n",
      "\n",
      "reduced set   0.25\n",
      "\n",
      "47 %   1.0\n",
      "\n",
      "standard random   0.07142857142857142\n",
      "\n",
      "and paste   0.001445086705202312\n",
      "\n",
      "has now   0.011904761904761904\n",
      "\n",
      "certain sequences   0.14285714285714285\n",
      "\n",
      "developed into   0.038461538461538464\n",
      "\n",
      "<s> Several   0.0023059185242121443\n",
      "\n",
      "parsing can   0.07142857142857142\n",
      "\n",
      "have questioned   0.009615384615384616\n",
      "\n",
      "Journal -RRB-   0.3333333333333333\n",
      "\n",
      "-LRB- RAE   0.0027100271002710027\n",
      "\n",
      "Jurafsky and   1.0\n",
      "\n",
      "result -LRB-   0.09090909090909091\n",
      "\n",
      "degree of   0.5\n",
      "\n",
      "questions -LRB-   0.038461538461538464\n",
      "\n",
      "fragments that   1.0\n",
      "\n",
      "an arithmetic   0.007575757575757576\n",
      "\n",
      "meaning but   0.043478260869565216\n",
      "\n",
      "vocal tract   1.0\n",
      "\n",
      "have resulted   0.009615384615384616\n",
      "\n",
      "Morpholympics compared   1.0\n",
      "\n",
      "A similar   0.02\n",
      "\n",
      "written language   0.11538461538461539\n",
      "\n",
      "under construction   0.2\n",
      "\n",
      "give the   0.5\n",
      "\n",
      "is closer   0.0020325203252032522\n",
      "\n",
      "named entity   0.2857142857142857\n",
      "\n",
      "likely following   0.0625\n",
      "\n",
      "are also   0.03319502074688797\n",
      "\n",
      "subjectivity used   0.5\n",
      "\n",
      "desktop OCR   1.0\n",
      "\n",
      "made indifferent   0.0625\n",
      "\n",
      "and funding   0.001445086705202312\n",
      "\n",
      "a voice   0.001226993865030675\n",
      "\n",
      "Gary Hendrix   1.0\n",
      "\n",
      "mobile processor   0.5\n",
      "\n",
      "not become   0.008928571428571428\n",
      "\n",
      "unsupervised ''   0.125\n",
      "\n",
      "letter ,   0.16666666666666666\n",
      "\n",
      "Standard Oil   0.5\n",
      "\n",
      "the polarity   0.0006920415224913495\n",
      "\n",
      "and correctly-developed   0.001445086705202312\n",
      "\n",
      "needs additional   0.1\n",
      "\n",
      "hoping to   1.0\n",
      "\n",
      "and know   0.001445086705202312\n",
      "\n",
      "are usually   0.012448132780082987\n",
      "\n",
      "<s> Shallow   0.0015372790161414297\n",
      "\n",
      "situation .   0.5\n",
      "\n",
      "recommendation ''   1.0\n",
      "\n",
      "signing off   1.0\n",
      "\n",
      "platform to   0.5\n",
      "\n",
      "perform automated   0.09090909090909091\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that use   0.0070921985815602835\n",
      "\n",
      "cell phone   1.0\n",
      "\n",
      "by which   0.005714285714285714\n",
      "\n",
      "it was   0.02564102564102564\n",
      "\n",
      "before -RRB-   0.3333333333333333\n",
      "\n",
      "or places   0.0045045045045045045\n",
      "\n",
      "fair gold-standard   1.0\n",
      "\n",
      "if you   0.07142857142857142\n",
      "\n",
      "between positive   0.02564102564102564\n",
      "\n",
      "Environment Canada   1.0\n",
      "\n",
      "the tagging   0.001384083044982699\n",
      "\n",
      "bigram ,   1.0\n",
      "\n",
      "superseded by   1.0\n",
      "\n",
      "vice versa   1.0\n",
      "\n",
      "single PC   0.07142857142857142\n",
      "\n",
      "classifier and   0.14285714285714285\n",
      "\n",
      "in an   0.0149812734082397\n",
      "\n",
      "Levinsohn ,   1.0\n",
      "\n",
      "in garden   0.0018726591760299626\n",
      "\n",
      ": Sample   0.00980392156862745\n",
      "\n",
      "answers -RRB-   0.08333333333333333\n",
      "\n",
      "accurate by   0.14285714285714285\n",
      "\n",
      "the English-French   0.0006920415224913495\n",
      "\n",
      "meaningful relationships   0.125\n",
      "\n",
      "Relationship extraction   1.0\n",
      "\n",
      ", maybe   0.0005614823133071309\n",
      "\n",
      "questions about   0.15384615384615385\n",
      "\n",
      "connected regions   0.2\n",
      "\n",
      "and signing   0.001445086705202312\n",
      "\n",
      "lines and   0.3333333333333333\n",
      "\n",
      "no matter   0.07692307692307693\n",
      "\n",
      "Reinvestment Act   1.0\n",
      "\n",
      "are needed   0.004149377593360996\n",
      "\n",
      "been undertaken   0.014705882352941176\n",
      "\n",
      "much additional   0.045454545454545456\n",
      "\n",
      "linguistic typology   0.0625\n",
      "\n",
      "only succeeding   0.02631578947368421\n",
      "\n",
      "extraction algorithm   0.03225806451612903\n",
      "\n",
      "a leftmost   0.00245398773006135\n",
      "\n",
      "of systems   0.0017825311942959\n",
      "\n",
      "phonetic-based categories   1.0\n",
      "\n",
      "unigrams ,   0.25\n",
      "\n",
      ", impressive   0.0005614823133071309\n",
      "\n",
      "trigrams without   0.5\n",
      "\n",
      "actual measurement   0.2\n",
      "\n",
      "languages concepts   0.02\n",
      "\n",
      "improvement of   0.5\n",
      "\n",
      "context-free ,   0.09090909090909091\n",
      "\n",
      "<s> How   0.0030745580322828594\n",
      "\n",
      "approach using   0.02857142857142857\n",
      "\n",
      "take as   0.1\n",
      "\n",
      "Instead of   1.0\n",
      "\n",
      "have a   0.125\n",
      "\n",
      "150 examples   0.5\n",
      "\n",
      "any learning   0.03225806451612903\n",
      "\n",
      "a succession   0.001226993865030675\n",
      "\n",
      "active area   0.5\n",
      "\n",
      "necessarily portable   0.5\n",
      "\n",
      "and aircraft   0.001445086705202312\n",
      "\n",
      "graph can   0.07692307692307693\n",
      "\n",
      "words to   0.009174311926605505\n",
      "\n",
      "script used   0.25\n",
      "\n",
      "separated out   0.3333333333333333\n",
      "\n",
      "text comprehension   0.006289308176100629\n",
      "\n",
      "questions have   0.038461538461538464\n",
      "\n",
      "discourses and   0.5\n",
      "\n",
      "procedure lies   0.3333333333333333\n",
      "\n",
      "their training   0.029411764705882353\n",
      "\n",
      "coverage .   0.3333333333333333\n",
      "\n",
      "2002 evaluation   0.5\n",
      "\n",
      "or text   0.009009009009009009\n",
      "\n",
      "constituents such   0.5\n",
      "\n",
      "that ``   0.02127659574468085\n",
      "\n",
      "American Bible   0.2\n",
      "\n",
      "the interlingua   0.0006920415224913495\n",
      "\n",
      "IR -RRB-   0.3333333333333333\n",
      "\n",
      "operation .   0.5\n",
      "\n",
      "as their   0.006968641114982578\n",
      "\n",
      "average distance   0.5\n",
      "\n",
      "to video   0.0013280212483399733\n",
      "\n",
      "you say   0.07692307692307693\n",
      "\n",
      "annotation process   0.25\n",
      "\n",
      "classifier ,   0.14285714285714285\n",
      "\n",
      "sentences .   0.10526315789473684\n",
      "\n",
      "History The   0.5\n",
      "\n",
      "pages ,   0.42857142857142855\n",
      "\n",
      "of cursive   0.00089126559714795\n",
      "\n",
      "ELIZA was   0.1111111111111111\n",
      "\n",
      "Lemke ,   1.0\n",
      "\n",
      "'' appears   0.005154639175257732\n",
      "\n",
      "One example   0.07692307692307693\n",
      "\n",
      "even several   0.037037037037037035\n",
      "\n",
      "choice between   0.125\n",
      "\n",
      "form filling   0.05\n",
      "\n",
      "when summarizing   0.02857142857142857\n",
      "\n",
      "also help   0.014492753623188406\n",
      "\n",
      "a subtopic   0.001226993865030675\n",
      "\n",
      "tasks typically   0.03125\n",
      "\n",
      "NLG to   0.14285714285714285\n",
      "\n",
      "discards any   1.0\n",
      "\n",
      "a canonical   0.001226993865030675\n",
      "\n",
      "the entities   0.0006920415224913495\n",
      "\n",
      "the 2006   0.0006920415224913495\n",
      "\n",
      "while LexRank   0.1\n",
      "\n",
      ", Sept.   0.0005614823133071309\n",
      "\n",
      "Adam Jaworski   1.0\n",
      "\n",
      "the work   0.001384083044982699\n",
      "\n",
      "Documents ''   1.0\n",
      "\n",
      "kind appears   0.09090909090909091\n",
      "\n",
      "of action   0.00089126559714795\n",
      "\n",
      "properties ,   0.25\n",
      "\n",
      "made in   0.125\n",
      "\n",
      "`` Japanese   0.005291005291005291\n",
      "\n",
      "news conference   0.07692307692307693\n",
      "\n",
      "http:\\/\\/arxiv.org\\/abs\\/1104.2086 -RRB-   1.0\n",
      "\n",
      "the notion   0.001384083044982699\n",
      "\n",
      "but may   0.029411764705882353\n",
      "\n",
      "introduced the   1.0\n",
      "\n",
      "read characters   0.14285714285714285\n",
      "\n",
      "rainbow form   1.0\n",
      "\n",
      "meaningful symbols   0.125\n",
      "\n",
      "abstractive summarization   0.3333333333333333\n",
      "\n",
      "same general   0.04\n",
      "\n",
      "gets around   0.5\n",
      "\n",
      "other cockpit   0.014285714285714285\n",
      "\n",
      "textual summaries   0.2\n",
      "\n",
      "the scope   0.001384083044982699\n",
      "\n",
      "the Brown   0.005536332179930796\n",
      "\n",
      "strong is   0.25\n",
      "\n",
      "on different   0.0047169811320754715\n",
      "\n",
      "by whom   0.005714285714285714\n",
      "\n",
      "-LRB- SBD   0.0027100271002710027\n",
      "\n",
      "between discourse   0.1282051282051282\n",
      "\n",
      "Since then   0.2\n",
      "\n",
      "language during   0.006756756756756757\n",
      "\n",
      "a team   0.001226993865030675\n",
      "\n",
      "<s> These   0.012298232129131437\n",
      "\n",
      "image ,   0.3333333333333333\n",
      "\n",
      "<s> Beatrice   0.0007686395080707148\n",
      "\n",
      "many years   0.019230769230769232\n",
      "\n",
      "by human   0.017142857142857144\n",
      "\n",
      "on functional   0.0047169811320754715\n",
      "\n",
      "Annotate the   1.0\n",
      "\n",
      "for people   0.007220216606498195\n",
      "\n",
      ", sociology   0.0005614823133071309\n",
      "\n",
      "refer to   1.0\n",
      "\n",
      "to move   0.0013280212483399733\n",
      "\n",
      "was entertaining   0.012987012987012988\n",
      "\n",
      "the eigenvector   0.0006920415224913495\n",
      "\n",
      "grammatical constituents   0.09090909090909091\n",
      "\n",
      "uttered ;   0.3333333333333333\n",
      "\n",
      "to do   0.00398406374501992\n",
      "\n",
      "that have   0.02127659574468085\n",
      "\n",
      "ratings on   0.1111111111111111\n",
      "\n",
      "F-16 VISTA   0.5\n",
      "\n",
      "Sound Graph   0.3333333333333333\n",
      "\n",
      ": Translations   0.00980392156862745\n",
      "\n",
      "upon which   1.0\n",
      "\n",
      "a general   0.0036809815950920245\n",
      "\n",
      "and etc.   0.001445086705202312\n",
      "\n",
      "VOLSUNGA .   1.0\n",
      "\n",
      "of work   0.00089126559714795\n",
      "\n",
      "-LRB- monetary   0.0027100271002710027\n",
      "\n",
      "Halliday ,   1.0\n",
      "\n",
      "may pick   0.019230769230769232\n",
      "\n",
      "the sampling   0.0006920415224913495\n",
      "\n",
      "as well   0.04878048780487805\n",
      "\n",
      "-LRB- MCE   0.0027100271002710027\n",
      "\n",
      "on what   0.009433962264150943\n",
      "\n",
      "morphology -LRB-   0.14285714285714285\n",
      "\n",
      "in psycholinguistics   0.0018726591760299626\n",
      "\n",
      "element of   1.0\n",
      "\n",
      "used being   0.008849557522123894\n",
      "\n",
      "However even   0.02702702702702703\n",
      "\n",
      "Regardless of   1.0\n",
      "\n",
      "be given   0.004219409282700422\n",
      "\n",
      "spectrum using   1.0\n",
      "\n",
      "particularly difficult   0.2\n",
      "\n",
      "programs often   0.09090909090909091\n",
      "\n",
      "be any   0.004219409282700422\n",
      "\n",
      "include automatic   0.037037037037037035\n",
      "\n",
      "the random   0.0006920415224913495\n",
      "\n",
      "-RRB- -   0.0027100271002710027\n",
      "\n",
      "and FAA   0.001445086705202312\n",
      "\n",
      "to predicting   0.0013280212483399733\n",
      "\n",
      "made of   0.1875\n",
      "\n",
      "have problems   0.009615384615384616\n",
      "\n",
      "program can   0.045454545454545456\n",
      "\n",
      "concerning coherence   1.0\n",
      "\n",
      "typically around   0.05555555555555555\n",
      "\n",
      "languages .   0.16\n",
      "\n",
      "`` entities   0.005291005291005291\n",
      "\n",
      "estimate the   0.5\n",
      "\n",
      "mining refers   0.2\n",
      "\n",
      "by Lawrence   0.005714285714285714\n",
      "\n",
      "-RRB- ``   0.0027100271002710027\n",
      "\n",
      "speech feature   0.006578947368421052\n",
      "\n",
      "which consists   0.007246376811594203\n",
      "\n",
      "there was   0.075\n",
      "\n",
      "The sub-committee   0.005208333333333333\n",
      "\n",
      "errors per   0.2\n",
      "\n",
      "considered .   0.1111111111111111\n",
      "\n",
      "is subject   0.0020325203252032522\n",
      "\n",
      "communicative event   0.3333333333333333\n",
      "\n",
      "been devised   0.014705882352941176\n",
      "\n",
      ", ratings   0.0005614823133071309\n",
      "\n",
      "soon developed   0.3333333333333333\n",
      "\n",
      "\\/ F-16   0.3333333333333333\n",
      "\n",
      "-RRB- <s/>   0.037940379403794036\n",
      "\n",
      "intervening punctuation   1.0\n",
      "\n",
      "meanings of   0.25\n",
      "\n",
      "The context   0.005208333333333333\n",
      "\n",
      "phenomenon is   0.2\n",
      "\n",
      "sentence of   0.020833333333333332\n",
      "\n",
      "statistical techniques   0.06060606060606061\n",
      "\n",
      "counting cases   1.0\n",
      "\n",
      "forecasts used   0.2\n",
      "\n",
      "texts of   0.11764705882352941\n",
      "\n",
      "of Chinese   0.00089126559714795\n",
      "\n",
      "and obtained   0.001445086705202312\n",
      "\n",
      "Lee Pike   1.0\n",
      "\n",
      "% ;   0.02564102564102564\n",
      "\n",
      "entire banking   0.3333333333333333\n",
      "\n",
      "would both   0.018867924528301886\n",
      "\n",
      "noise levels   0.125\n",
      "\n",
      "-LRB- DeRose   0.0027100271002710027\n",
      "\n",
      "extracted summaries   1.0\n",
      "\n",
      "<s> consider   0.0007686395080707148\n",
      "\n",
      "and Arabic   0.002890173410404624\n",
      "\n",
      "generally used   0.09090909090909091\n",
      "\n",
      "of our   0.00089126559714795\n",
      "\n",
      "is typical   0.0020325203252032522\n",
      "\n",
      "-LRB- Realtime   0.0027100271002710027\n",
      "\n",
      "of possibilities   0.00089126559714795\n",
      "\n",
      "on developing   0.0047169811320754715\n",
      "\n",
      "declaration of   1.0\n",
      "\n",
      "intermediary ,   0.3333333333333333\n",
      "\n",
      "Overall organization   1.0\n",
      "\n",
      "10 digits   0.125\n",
      "\n",
      "for voice   0.0036101083032490976\n",
      "\n",
      "short textual   0.125\n",
      "\n",
      "dry up   1.0\n",
      "\n",
      "keyphrase containing   0.05263157894736842\n",
      "\n",
      "the completion   0.0006920415224913495\n",
      "\n",
      "-LRB- 1995   0.0027100271002710027\n",
      "\n",
      "to better   0.00398406374501992\n",
      "\n",
      "expected for   0.14285714285714285\n",
      "\n",
      "markers .   0.3333333333333333\n",
      "\n",
      "of hand   0.00089126559714795\n",
      "\n",
      "an ellipsis   0.007575757575757576\n",
      "\n",
      "minimum classification   0.5\n",
      "\n",
      ", processing   0.0005614823133071309\n",
      "\n",
      "parsing a   0.03571428571428571\n",
      "\n",
      "is particularly   0.0040650406504065045\n",
      "\n",
      "children ,   0.5\n",
      "\n",
      "also pioneered   0.014492753623188406\n",
      "\n",
      "on unsupervised   0.0047169811320754715\n",
      "\n",
      "voice file   0.07692307692307693\n",
      "\n",
      "deployed in   0.5\n",
      "\n",
      "Text Segmentation   0.16666666666666666\n",
      "\n",
      "analyze all   0.25\n",
      "\n",
      "years .   0.19047619047619047\n",
      "\n",
      "discourses ,   0.5\n",
      "\n",
      "require the   0.18181818181818182\n",
      "\n",
      "space .   0.2\n",
      "\n",
      "Use of   0.5\n",
      "\n",
      "been attained   0.014705882352941176\n",
      "\n",
      "Error Rate   0.5\n",
      "\n",
      "question and   0.023809523809523808\n",
      "\n",
      "among the   0.125\n",
      "\n",
      "gives examples   0.5\n",
      "\n",
      "Court reporting   1.0\n",
      "\n",
      "of domains   0.00089126559714795\n",
      "\n",
      "are variously   0.004149377593360996\n",
      "\n",
      "interference between   1.0\n",
      "\n",
      "and\\/or producing   0.3333333333333333\n",
      "\n",
      "read aloud   0.14285714285714285\n",
      "\n",
      "extent of   0.25\n",
      "\n",
      "are given   0.012448132780082987\n",
      "\n",
      "research is   0.047619047619047616\n",
      "\n",
      "in Germany   0.003745318352059925\n",
      "\n",
      "manipulate .   0.3333333333333333\n",
      "\n",
      "in Star   0.0018726591760299626\n",
      "\n",
      "many are   0.019230769230769232\n",
      "\n",
      "at SRI   0.014705882352941176\n",
      "\n",
      "task usually   0.023809523809523808\n",
      "\n",
      "advances in   1.0\n",
      "\n",
      "that ten   0.0035460992907801418\n",
      "\n",
      "that serve   0.0035460992907801418\n",
      "\n",
      "simple extraction   0.038461538461538464\n",
      "\n",
      "on complex   0.0047169811320754715\n",
      "\n",
      "e.g. Constraints   0.017857142857142856\n",
      "\n",
      "parses -LRB-   0.5\n",
      "\n",
      "dialogue in   0.5\n",
      "\n",
      "grammars ,   0.14285714285714285\n",
      "\n",
      "did Joe   0.2\n",
      "\n",
      "retrieving information   1.0\n",
      "\n",
      "before or   0.16666666666666666\n",
      "\n",
      "on Speech   0.0047169811320754715\n",
      "\n",
      "the answers   0.0006920415224913495\n",
      "\n",
      "the magazine   0.0006920415224913495\n",
      "\n",
      ": Rule-based   0.00980392156862745\n",
      "\n",
      "Keyphrases have   1.0\n",
      "\n",
      "to which   0.006640106241699867\n",
      "\n",
      "<s> Adda   0.0007686395080707148\n",
      "\n",
      "required many   0.14285714285714285\n",
      "\n",
      "the generation   0.0006920415224913495\n",
      "\n",
      ", recognizing   0.0005614823133071309\n",
      "\n",
      "German and   0.25\n",
      "\n",
      "Man bites   0.5\n",
      "\n",
      "ask the   0.5\n",
      "\n",
      "saw the   1.0\n",
      "\n",
      "line in   0.3333333333333333\n",
      "\n",
      "filtered by   0.3333333333333333\n",
      "\n",
      "or stochastic   0.0045045045045045045\n",
      "\n",
      "for simple   0.0036101083032490976\n",
      "\n",
      "- \\/   0.0625\n",
      "\n",
      "have produced   0.009615384615384616\n",
      "\n",
      "and of   0.001445086705202312\n",
      "\n",
      "genres of   1.0\n",
      "\n",
      "in artificial   0.0018726591760299626\n",
      "\n",
      "finished product   0.5\n",
      "\n",
      "-LRB- HAMS   0.0027100271002710027\n",
      "\n",
      "\\* ,   0.5\n",
      "\n",
      "interactive clarification   0.25\n",
      "\n",
      "Constraints may   0.3333333333333333\n",
      "\n",
      "Recovery and   1.0\n",
      "\n",
      "of constraints   0.00089126559714795\n",
      "\n",
      "fairly non-trivial   0.25\n",
      "\n",
      ", Janet   0.0005614823133071309\n",
      "\n",
      "boundary information   0.16666666666666666\n",
      "\n",
      "Depending on   1.0\n",
      "\n",
      "processing techniques   0.037037037037037035\n",
      "\n",
      "had similar   0.07142857142857142\n",
      "\n",
      "-- thus   0.04\n",
      "\n",
      "create edges   0.058823529411764705\n",
      "\n",
      "a learner   0.001226993865030675\n",
      "\n",
      "unusual in   1.0\n",
      "\n",
      "the Medical   0.0006920415224913495\n",
      "\n",
      "can decide   0.0055248618784530384\n",
      "\n",
      "Models are   0.3333333333333333\n",
      "\n",
      "indeed that   0.3333333333333333\n",
      "\n",
      "of physics   0.00089126559714795\n",
      "\n",
      "open-access journal   1.0\n",
      "\n",
      "again statistically   1.0\n",
      "\n",
      "target handover   0.09090909090909091\n",
      "\n",
      "them in   0.05263157894736842\n",
      "\n",
      "Another reason   0.07692307692307693\n",
      "\n",
      "all lower   0.023255813953488372\n",
      "\n",
      "for machine   0.010830324909747292\n",
      "\n",
      "from data   0.019230769230769232\n",
      "\n",
      "'s 1990   0.0196078431372549\n",
      "\n",
      "reads it   0.5\n",
      "\n",
      "or shifted   0.0045045045045045045\n",
      "\n",
      "whether each   0.07692307692307693\n",
      "\n",
      "the individual   0.001384083044982699\n",
      "\n",
      "a reliance   0.001226993865030675\n",
      "\n",
      "which simply   0.007246376811594203\n",
      "\n",
      "speaker adaptation   0.1111111111111111\n",
      "\n",
      "HMMs -RRB-   0.25\n",
      "\n",
      "outputs of   1.0\n",
      "\n",
      "'' tag   0.005154639175257732\n",
      "\n",
      "linguistics and   0.05\n",
      "\n",
      "<s> Document   0.0015372790161414297\n",
      "\n",
      "occurrence of   0.5\n",
      "\n",
      "real-world applications   0.16666666666666666\n",
      "\n",
      "of global   0.00089126559714795\n",
      "\n",
      "Grant ever   1.0\n",
      "\n",
      "is computed   0.0020325203252032522\n",
      "\n",
      "implemented ,   0.2\n",
      "\n",
      ", closed-domain   0.0005614823133071309\n",
      "\n",
      "classification .   0.11764705882352941\n",
      "\n",
      "resolved :   1.0\n",
      "\n",
      "goal of   0.2857142857142857\n",
      "\n",
      "Liberman M.   1.0\n",
      "\n",
      "KEA -LRB-   1.0\n",
      "\n",
      "We then   0.14285714285714285\n",
      "\n",
      "'s instructions   0.0196078431372549\n",
      "\n",
      "singular ,   0.25\n",
      "\n",
      "the broken   0.0006920415224913495\n",
      "\n",
      "a quantitative   0.00245398773006135\n",
      "\n",
      "measures try   0.16666666666666666\n",
      "\n",
      "and linguistic   0.001445086705202312\n",
      "\n",
      "are :   0.008298755186721992\n",
      "\n",
      "to answer   0.00398406374501992\n",
      "\n",
      "significant increase   0.1111111111111111\n",
      "\n",
      "be repeated   0.004219409282700422\n",
      "\n",
      "often ambiguous   0.022727272727272728\n",
      "\n",
      "Aletta Norval   1.0\n",
      "\n",
      "his PhD   0.08333333333333333\n",
      "\n",
      "proposed photographing   0.1111111111111111\n",
      "\n",
      "financial and   0.25\n",
      "\n",
      "The simplest   0.005208333333333333\n",
      "\n",
      "technology that   0.045454545454545456\n",
      "\n",
      "errors or   0.2\n",
      "\n",
      "VISTA -RRB-   1.0\n",
      "\n",
      "produce consonants   0.045454545454545456\n",
      "\n",
      "been created   0.029411764705882353\n",
      "\n",
      "<s> Later   0.0007686395080707148\n",
      "\n",
      "<s> Leading   0.0007686395080707148\n",
      "\n",
      "<s> Statistical   0.0023059185242121443\n",
      "\n",
      "than procedural   0.022222222222222223\n",
      "\n",
      "we construct   0.022222222222222223\n",
      "\n",
      "large portion   0.043478260869565216\n",
      "\n",
      "Phrases ,   1.0\n",
      "\n",
      ", anthropology   0.0005614823133071309\n",
      "\n",
      "statistical NLP   0.06060606060606061\n",
      "\n",
      "is working   0.0040650406504065045\n",
      "\n",
      "Inter-rater reliability   1.0\n",
      "\n",
      "-LRB- various   0.0027100271002710027\n",
      "\n",
      "example the   0.012345679012345678\n",
      "\n",
      ", means   0.0005614823133071309\n",
      "\n",
      "a user-specified   0.001226993865030675\n",
      "\n",
      "with specialised   0.00546448087431694\n",
      "\n",
      "best ,   0.05555555555555555\n",
      "\n",
      "from a   0.11538461538461539\n",
      "\n",
      "is apple   0.0020325203252032522\n",
      "\n",
      "ostensibly simple   1.0\n",
      "\n",
      "part because   0.037037037037037035\n",
      "\n",
      "To decode   0.1111111111111111\n",
      "\n",
      "is needed   0.0020325203252032522\n",
      "\n",
      "not spend   0.008928571428571428\n",
      "\n",
      "preposition ,   1.0\n",
      "\n",
      "decide to   0.25\n",
      "\n",
      ", thus   0.0011229646266142617\n",
      "\n",
      "capabilities ,   0.2\n",
      "\n",
      "accessibility ,   1.0\n",
      "\n",
      "at varying   0.014705882352941176\n",
      "\n",
      "<s> Therein   0.0007686395080707148\n",
      "\n",
      "<s> Open   0.0007686395080707148\n",
      "\n",
      "he or   0.14285714285714285\n",
      "\n",
      "heavily inflected   1.0\n",
      "\n",
      "phrase appears   0.1\n",
      "\n",
      "Sparkle campaign   1.0\n",
      "\n",
      "be necessary   0.008438818565400843\n",
      "\n",
      "dialogues between   1.0\n",
      "\n",
      "takes as   0.3333333333333333\n",
      "\n",
      "addition ,   0.3333333333333333\n",
      "\n",
      "tools usually   0.16666666666666666\n",
      "\n",
      "Digital Syphon   1.0\n",
      "\n",
      "which proposed   0.007246376811594203\n",
      "\n",
      "start symbol   0.2857142857142857\n",
      "\n",
      "depending on   0.75\n",
      "\n",
      "weighted by   0.3333333333333333\n",
      "\n",
      "products ,   0.25\n",
      "\n",
      "domain and   0.05\n",
      "\n",
      "`` random   0.005291005291005291\n",
      "\n",
      "the social   0.0020761245674740486\n",
      "\n",
      "discriminant analysis   1.0\n",
      "\n",
      "de Beaugrande   0.5\n",
      "\n",
      "home ''   1.0\n",
      "\n",
      "installed at   0.6666666666666666\n",
      "\n",
      "is difficult   0.008130081300813009\n",
      "\n",
      "exchange of   1.0\n",
      "\n",
      "to construct   0.0013280212483399733\n",
      "\n",
      "increase recognition   0.25\n",
      "\n",
      "-RRB- coefficients   0.0027100271002710027\n",
      "\n",
      "translation Statistical   0.013513513513513514\n",
      "\n",
      "keyphrases from   0.02857142857142857\n",
      "\n",
      "getting enough   0.25\n",
      "\n",
      "to query   0.0013280212483399733\n",
      "\n",
      "top of   0.2\n",
      "\n",
      "extrapolate that   1.0\n",
      "\n",
      "you want   0.07692307692307693\n",
      "\n",
      "summarise conditions   0.3333333333333333\n",
      "\n",
      "complicated because   0.3333333333333333\n",
      "\n",
      "<s> Many   0.008455034588777863\n",
      "\n",
      "English :   0.02702702702702703\n",
      "\n",
      "were very   0.04878048780487805\n",
      "\n",
      "known cases   0.038461538461538464\n",
      "\n",
      "computer extracting   0.022727272727272728\n",
      "\n",
      "likely another   0.0625\n",
      "\n",
      "facemask ,   1.0\n",
      "\n",
      "as natural   0.003484320557491289\n",
      "\n",
      "besides words   1.0\n",
      "\n",
      "ambiguities one   0.25\n",
      "\n",
      "judge ,   0.25\n",
      "\n",
      "to maintain   0.0013280212483399733\n",
      "\n",
      "generators .   0.5\n",
      "\n",
      "-LRB- with   0.008130081300813009\n",
      "\n",
      "and English   0.001445086705202312\n",
      "\n",
      "standard can   0.07142857142857142\n",
      "\n",
      "of its   0.0071301247771836\n",
      "\n",
      "`` Mr.   0.005291005291005291\n",
      "\n",
      "cases -LRB-   0.05555555555555555\n",
      "\n",
      "unigrams to   0.08333333333333333\n",
      "\n",
      "were easy   0.024390243902439025\n",
      "\n",
      ", How   0.0005614823133071309\n",
      "\n",
      "Produce a   1.0\n",
      "\n",
      "non-linear transformations   1.0\n",
      "\n",
      "<s> vs.   0.0015372790161414297\n",
      "\n",
      "wishes to   1.0\n",
      "\n",
      "so the   0.23333333333333334\n",
      "\n",
      "our life   0.2\n",
      "\n",
      "best with   0.05555555555555555\n",
      "\n",
      "the reader   0.002768166089965398\n",
      "\n",
      "capitalize names   1.0\n",
      "\n",
      "collection sizes   0.2\n",
      "\n",
      "data has   0.012987012987012988\n",
      "\n",
      ", pronoun   0.0005614823133071309\n",
      "\n",
      "Political discourse   1.0\n",
      "\n",
      ", dimensions   0.0005614823133071309\n",
      "\n",
      "other words   0.02857142857142857\n",
      "\n",
      "semantics or   0.14285714285714285\n",
      "\n",
      "for many   0.007220216606498195\n",
      "\n",
      "researchers undertake   0.1\n",
      "\n",
      "to examples   0.0013280212483399733\n",
      "\n",
      "terminate a   1.0\n",
      "\n",
      "all where   0.023255813953488372\n",
      "\n",
      "web blogs   0.125\n",
      "\n",
      "Jaworski ,   1.0\n",
      "\n",
      "the statistics   0.0006920415224913495\n",
      "\n",
      "Morse Code   1.0\n",
      "\n",
      "how people   0.034482758620689655\n",
      "\n",
      "about basic   0.025\n",
      "\n",
      "speaker-dependent system   1.0\n",
      "\n",
      "expensive task   0.14285714285714285\n",
      "\n",
      "for air   0.0036101083032490976\n",
      "\n",
      "reasoning for   0.14285714285714285\n",
      "\n",
      "parsing accuracy   0.03571428571428571\n",
      "\n",
      "computer forecasts   0.022727272727272728\n",
      "\n",
      "Stemming Text   1.0\n",
      "\n",
      "content present   0.08333333333333333\n",
      "\n",
      "solved .   0.2\n",
      "\n",
      "be poorly   0.004219409282700422\n",
      "\n",
      "in 1993   0.0018726591760299626\n",
      "\n",
      "one feasibility   0.015384615384615385\n",
      "\n",
      "emotional state   0.25\n",
      "\n",
      "be unrealistically   0.004219409282700422\n",
      "\n",
      "approach to   0.17142857142857143\n",
      "\n",
      "of charge   0.00089126559714795\n",
      "\n",
      "trivial -RRB-   0.25\n",
      "\n",
      "not included   0.008928571428571428\n",
      "\n",
      "printed page   0.08333333333333333\n",
      "\n",
      "A random   0.02\n",
      "\n",
      "pioneered at   0.3333333333333333\n",
      "\n",
      "computer code   0.022727272727272728\n",
      "\n",
      "grammar formalisms   0.02702702702702703\n",
      "\n",
      "collaborated to   1.0\n",
      "\n",
      "which creates   0.007246376811594203\n",
      "\n",
      "is actually   0.0040650406504065045\n",
      "\n",
      "Another term   0.07692307692307693\n",
      "\n",
      "by question   0.005714285714285714\n",
      "\n",
      "variety of   1.0\n",
      "\n",
      "by part   0.005714285714285714\n",
      "\n",
      "letters blend   0.1\n",
      "\n",
      "a cell   0.00245398773006135\n",
      "\n",
      "ASR .   0.16666666666666666\n",
      "\n",
      "simple keyword   0.038461538461538464\n",
      "\n",
      "effort should   0.25\n",
      "\n",
      "Politics -LRB-   1.0\n",
      "\n",
      "user interfaces   0.14285714285714285\n",
      "\n",
      "most sense   0.017241379310344827\n",
      "\n",
      "Graesser ,   1.0\n",
      "\n",
      "messages .   0.5\n",
      "\n",
      "LexRank uses   0.08333333333333333\n",
      "\n",
      "transcriptions -LRB-   0.5\n",
      "\n",
      "still to   0.06666666666666667\n",
      "\n",
      "is still   0.008130081300813009\n",
      "\n",
      "-LRB- orange   0.0027100271002710027\n",
      "\n",
      "and ushered   0.001445086705202312\n",
      "\n",
      "-LRB- Style   0.0027100271002710027\n",
      "\n",
      "numbers represent   0.14285714285714285\n",
      "\n",
      "and the   0.059248554913294796\n",
      "\n",
      "themselves simply   0.25\n",
      "\n",
      "to know   0.0013280212483399733\n",
      "\n",
      "dependence vs.   1.0\n",
      "\n",
      "<s> Are   0.0007686395080707148\n",
      "\n",
      "of shared   0.00089126559714795\n",
      "\n",
      "context in   0.030303030303030304\n",
      "\n",
      "the entire   0.0006920415224913495\n",
      "\n",
      "capture speech   0.5\n",
      "\n",
      "Spoken Language   1.0\n",
      "\n",
      "tagging has   0.04\n",
      "\n",
      "statistics readily   0.125\n",
      "\n",
      "<s> However   0.02843966179861645\n",
      "\n",
      "much harder   0.045454545454545456\n",
      "\n",
      "commands .   0.4\n",
      "\n",
      "English has   0.05405405405405406\n",
      "\n",
      "Nuance Voice   0.3333333333333333\n",
      "\n",
      "be NP-complete   0.004219409282700422\n",
      "\n",
      "learned .   0.2\n",
      "\n",
      "environments .   1.0\n",
      "\n",
      "division rather   0.5\n",
      "\n",
      "account context   0.3333333333333333\n",
      "\n",
      "Transcription -LRB-   1.0\n",
      "\n",
      "speech recognizers   0.006578947368421052\n",
      "\n",
      "human-readable address   1.0\n",
      "\n",
      "carry out   1.0\n",
      "\n",
      "same string   0.04\n",
      "\n",
      "In this   0.047619047619047616\n",
      "\n",
      "roughness ,   1.0\n",
      "\n",
      "syntactic parser   0.07692307692307693\n",
      "\n",
      "importance .   0.16666666666666666\n",
      "\n",
      "product became   0.14285714285714285\n",
      "\n",
      "language output   0.006756756756756757\n",
      "\n",
      "developed at   0.07692307692307693\n",
      "\n",
      "the interactions   0.0006920415224913495\n",
      "\n",
      "symbol .   0.5\n",
      "\n",
      "final letter   0.1111111111111111\n",
      "\n",
      "recognition-related project   1.0\n",
      "\n",
      "who co-founded   0.1\n",
      "\n",
      "Extraction and   0.3333333333333333\n",
      "\n",
      "need for   0.14285714285714285\n",
      "\n",
      "the probabilities   0.002768166089965398\n",
      "\n",
      "digital dictation   0.14285714285714285\n",
      "\n",
      "now we   0.07692307692307693\n",
      "\n",
      "<s> Discursive   0.0007686395080707148\n",
      "\n",
      "classifying the   0.2\n",
      "\n",
      "as input   0.006968641114982578\n",
      "\n",
      "well-known application   1.0\n",
      "\n",
      "and text   0.005780346820809248\n",
      "\n",
      "-RRB- have   0.005420054200542005\n",
      "\n",
      "similar application   0.037037037037037035\n",
      "\n",
      "magazine 's   1.0\n",
      "\n",
      "waves can   0.14285714285714285\n",
      "\n",
      "hidden parts   0.125\n",
      "\n",
      "grown .   1.0\n",
      "\n",
      "the .   0.0006920415224913495\n",
      "\n",
      "journals include   0.5\n",
      "\n",
      "Commercial research   0.5\n",
      "\n",
      "do so   0.038461538461538464\n",
      "\n",
      "ranking process   0.14285714285714285\n",
      "\n",
      "Information Science   0.2\n",
      "\n",
      "searching and   0.3333333333333333\n",
      "\n",
      "much slower   0.09090909090909091\n",
      "\n",
      "not President   0.008928571428571428\n",
      "\n",
      "real-world information   0.16666666666666666\n",
      "\n",
      "called ``   0.2777777777777778\n",
      "\n",
      "3 +4   0.2\n",
      "\n",
      "classification :   0.058823529411764705\n",
      "\n",
      "precursor to   1.0\n",
      "\n",
      "-LRB- Campaigns   0.0027100271002710027\n",
      "\n",
      "the so-called   0.0006920415224913495\n",
      "\n",
      "alone may   0.25\n",
      "\n",
      "discourse analysis   0.2222222222222222\n",
      "\n",
      "several modules   0.045454545454545456\n",
      "\n",
      "two ?   0.034482758620689655\n",
      "\n",
      "<s> He   0.005380476556495004\n",
      "\n",
      "but not   0.058823529411764705\n",
      "\n",
      "scoring Truecasing   0.5\n",
      "\n",
      "significant complexity   0.1111111111111111\n",
      "\n",
      "more descriptive   0.010526315789473684\n",
      "\n",
      "software produces   0.037037037037037035\n",
      "\n",
      "together into   0.125\n",
      "\n",
      "explicit formalization   0.2\n",
      "\n",
      "`` the   0.026455026455026454\n",
      "\n",
      "Wilson ,   1.0\n",
      "\n",
      "smoothly or   0.5\n",
      "\n",
      "about 95   0.025\n",
      "\n",
      "models ...   0.038461538461538464\n",
      "\n",
      "use so-called   0.013888888888888888\n",
      "\n",
      "Pang who   0.3333333333333333\n",
      "\n",
      "one reference   0.015384615384615385\n",
      "\n",
      "behavior of   0.5\n",
      "\n",
      "grammars .   0.14285714285714285\n",
      "\n",
      "all official   0.023255813953488372\n",
      "\n",
      "computerization of   1.0\n",
      "\n",
      "distorted ,   0.5\n",
      "\n",
      "rather to   0.0625\n",
      "\n",
      "the only   0.0006920415224913495\n",
      "\n",
      "The apple   0.010416666666666666\n",
      "\n",
      "vision .   1.0\n",
      "\n",
      "text linguistics   0.006289308176100629\n",
      "\n",
      "<s> Systems   0.006149116064565719\n",
      "\n",
      "-RRB- Marc   0.0027100271002710027\n",
      "\n",
      "Computer Products   0.3333333333333333\n",
      "\n",
      "use directly   0.013888888888888888\n",
      "\n",
      "at Cognitive   0.014705882352941176\n",
      "\n",
      "; for   0.0425531914893617\n",
      "\n",
      "with rules   0.00546448087431694\n",
      "\n",
      "original sound   0.07692307692307693\n",
      "\n",
      "'' that   0.020618556701030927\n",
      "\n",
      "Contains Confusable   1.0\n",
      "\n",
      "and computationally   0.001445086705202312\n",
      "\n",
      "ATNs used   0.3333333333333333\n",
      "\n",
      "as voicemail   0.003484320557491289\n",
      "\n",
      "background knowledge   0.3333333333333333\n",
      "\n",
      "speech recognition-related   0.006578947368421052\n",
      "\n",
      "is it   0.0020325203252032522\n",
      "\n",
      "helicopter environment   0.5\n",
      "\n",
      "1998 The   0.25\n",
      "\n",
      "verification .   1.0\n",
      "\n",
      "Dijk ,   1.0\n",
      "\n",
      "Intelligent Machines   0.3333333333333333\n",
      "\n",
      "the impossibility   0.0006920415224913495\n",
      "\n",
      "gone into   1.0\n",
      "\n",
      "they superimpose   0.025\n",
      "\n",
      "Eugene Charniak   1.0\n",
      "\n",
      "is strong   0.0020325203252032522\n",
      "\n",
      "encouraged researchers   1.0\n",
      "\n",
      "first few   0.030303030303030304\n",
      "\n",
      "and even   0.008670520231213872\n",
      "\n",
      "greatly with   0.14285714285714285\n",
      "\n",
      "be expected   0.012658227848101266\n",
      "\n",
      "require subjects   0.045454545454545456\n",
      "\n",
      "procedural information   1.0\n",
      "\n",
      "medical data   0.3333333333333333\n",
      "\n",
      "analyses to   0.2\n",
      "\n",
      "-RRB- languages   0.0027100271002710027\n",
      "\n",
      "two waves   0.034482758620689655\n",
      "\n",
      "Civil Aviation   1.0\n",
      "\n",
      "together ?   0.125\n",
      "\n",
      "Theo van   1.0\n",
      "\n",
      "<s> Subsequently   0.0007686395080707148\n",
      "\n",
      "is in   0.006097560975609756\n",
      "\n",
      "that apply   0.0035460992907801418\n",
      "\n",
      "systems now   0.008928571428571428\n",
      "\n",
      "real-world data   0.3333333333333333\n",
      "\n",
      "rule-based machine-translation   0.14285714285714285\n",
      "\n",
      "with -LRB-   0.00546448087431694\n",
      "\n",
      "machine reading   0.012658227848101266\n",
      "\n",
      ", Digital   0.0005614823133071309\n",
      "\n",
      "overall topics   0.16666666666666666\n",
      "\n",
      "source and   0.041666666666666664\n",
      "\n",
      "likely related   0.0625\n",
      "\n",
      "primitive computer-type   1.0\n",
      "\n",
      "automate about   0.3333333333333333\n",
      "\n",
      "Statistical machine   0.2222222222222222\n",
      "\n",
      "terms of   0.5384615384615384\n",
      "\n",
      "interoperability between   1.0\n",
      "\n",
      "find left-most   0.07692307692307693\n",
      "\n",
      "help speakers   0.1111111111111111\n",
      "\n",
      "knowledge bases   0.037037037037037035\n",
      "\n",
      "of analyzing   0.00089126559714795\n",
      "\n",
      "-LRB- at   0.0027100271002710027\n",
      "\n",
      "be viewed   0.016877637130801686\n",
      "\n",
      "online databases   0.125\n",
      "\n",
      "that alone   0.0035460992907801418\n",
      "\n",
      "was done   0.012987012987012988\n",
      "\n",
      "SWER -RRB-   1.0\n",
      "\n",
      "the mission   0.0006920415224913495\n",
      "\n",
      "word British   0.016666666666666666\n",
      "\n",
      ", contractions   0.0005614823133071309\n",
      "\n",
      "using their   0.01694915254237288\n",
      "\n",
      "output quality   0.038461538461538464\n",
      "\n",
      "1980s saw   0.1111111111111111\n",
      "\n",
      "Ohio Bell   1.0\n",
      "\n",
      "manner .   0.75\n",
      "\n",
      "manually assigned   0.25\n",
      "\n",
      "became part   0.2\n",
      "\n",
      "robust to   0.25\n",
      "\n",
      "other are   0.014285714285714285\n",
      "\n",
      "up differently   0.045454545454545456\n",
      "\n",
      "a reduced   0.001226993865030675\n",
      "\n",
      "section requires   0.3333333333333333\n",
      "\n",
      "that person   0.0035460992907801418\n",
      "\n",
      "Beaugrande ,   1.0\n",
      "\n",
      "of democracy   0.00089126559714795\n",
      "\n",
      "perform adaptive   0.09090909090909091\n",
      "\n",
      "`` training   0.005291005291005291\n",
      "\n",
      "then generated   0.02857142857142857\n",
      "\n",
      "form .   0.1\n",
      "\n",
      "parsers which   0.07692307692307693\n",
      "\n",
      "nonexistent in   1.0\n",
      "\n",
      "presentation of   1.0\n",
      "\n",
      "identify the   0.5\n",
      "\n",
      "the inferior   0.0006920415224913495\n",
      "\n",
      ", associating   0.0005614823133071309\n",
      "\n",
      "NLG ;   0.047619047619047616\n",
      "\n",
      "which of   0.007246376811594203\n",
      "\n",
      "on word   0.0047169811320754715\n",
      "\n",
      "attaching real-valued   1.0\n",
      "\n",
      "measure than   0.09090909090909091\n",
      "\n",
      "initial ,   0.3333333333333333\n",
      "\n",
      "USMC ,   1.0\n",
      "\n",
      "Information Subsumption   0.2\n",
      "\n",
      "is 8000   0.0020325203252032522\n",
      "\n",
      "predict performance   0.16666666666666666\n",
      "\n",
      ", ELIZA   0.0011229646266142617\n",
      "\n",
      "the use\\/mention   0.0006920415224913495\n",
      "\n",
      "Big wave   1.0\n",
      "\n",
      "necessary .   0.1\n",
      "\n",
      "word that   0.03333333333333333\n",
      "\n",
      "sounds ,   0.13333333333333333\n",
      "\n",
      "product or   0.14285714285714285\n",
      "\n",
      "the dialog   0.0006920415224913495\n",
      "\n",
      "other we   0.014285714285714285\n",
      "\n",
      "an enormous   0.007575757575757576\n",
      "\n",
      "software and   0.037037037037037035\n",
      "\n",
      "broken English   0.2\n",
      "\n",
      "low precision   0.3333333333333333\n",
      "\n",
      "\\* ''   0.25\n",
      "\n",
      "module that   0.3333333333333333\n",
      "\n",
      "the edges   0.001384083044982699\n",
      "\n",
      "sizes of   0.6666666666666666\n",
      "\n",
      "1984 .   1.0\n",
      "\n",
      "temporal and   0.5\n",
      "\n",
      "information Popular   0.021739130434782608\n",
      "\n",
      "earlier Brown   0.25\n",
      "\n",
      "most parts   0.05172413793103448\n",
      "\n",
      "original .   0.07692307692307693\n",
      "\n",
      "of interaction   0.00089126559714795\n",
      "\n",
      "repeatedly reviewed   1.0\n",
      "\n",
      "different languages   0.02040816326530612\n",
      "\n",
      "taggers are   0.14285714285714285\n",
      "\n",
      "life .   0.25\n",
      "\n",
      "`` Intelligent   0.005291005291005291\n",
      "\n",
      "emotional communication   0.25\n",
      "\n",
      "untrained on   1.0\n",
      "\n",
      "small set   0.1111111111111111\n",
      "\n",
      "evaluation campaign   0.018518518518518517\n",
      "\n",
      "Records -LRB-   1.0\n",
      "\n",
      "the Web   0.001384083044982699\n",
      "\n",
      "<s> Future   0.0007686395080707148\n",
      "\n",
      "reached .   0.5\n",
      "\n",
      "difficulty is   0.14285714285714285\n",
      "\n",
      "vocabulary size   0.125\n",
      "\n",
      "is brought   0.0020325203252032522\n",
      "\n",
      "'' can   0.02577319587628866\n",
      "\n",
      "focusing on   1.0\n",
      "\n",
      "maybe to   1.0\n",
      "\n",
      "missions .   1.0\n",
      "\n",
      "generated from   0.13333333333333333\n",
      "\n",
      "Some examples   0.047619047619047616\n",
      "\n",
      "or `   0.0045045045045045045\n",
      "\n",
      "followed perhaps   0.25\n",
      "\n",
      "<s> DeRose   0.0015372790161414297\n",
      "\n",
      "and isolated   0.001445086705202312\n",
      "\n",
      "the degree   0.0006920415224913495\n",
      "\n",
      "in 1965   0.0018726591760299626\n",
      "\n",
      "HTK book   0.5\n",
      "\n",
      "visit .   0.5\n",
      "\n",
      "word context   0.016666666666666666\n",
      "\n",
      "either a   0.2\n",
      "\n",
      "Act of   1.0\n",
      "\n",
      ", common   0.0005614823133071309\n",
      "\n",
      "records .   0.5\n",
      "\n",
      "search Sentence   0.09090909090909091\n",
      "\n",
      "`` Why   0.015873015873015872\n",
      "\n",
      "shared tasks   0.5\n",
      "\n",
      "which use   0.007246376811594203\n",
      "\n",
      "addressed the   0.5\n",
      "\n",
      "and Language   0.005780346820809248\n",
      "\n",
      "of semantic   0.004456327985739751\n",
      "\n",
      "this would   0.01098901098901099\n",
      "\n",
      "levels first   0.045454545454545456\n",
      "\n",
      "above ,   0.3076923076923077\n",
      "\n",
      "States .   0.2857142857142857\n",
      "\n",
      "'s software   0.0196078431372549\n",
      "\n",
      "human-generated summaries   0.5\n",
      "\n",
      "important memorandum   0.0625\n",
      "\n",
      "affects the   1.0\n",
      "\n",
      "classes Different   0.2\n",
      "\n",
      "usually done   0.0625\n",
      "\n",
      "example through   0.012345679012345678\n",
      "\n",
      "or grammatical   0.0045045045045045045\n",
      "\n",
      "on top   0.0047169811320754715\n",
      "\n",
      "human linguists   0.021739130434782608\n",
      "\n",
      ", Invoice   0.0005614823133071309\n",
      "\n",
      "entrants companies   1.0\n",
      "\n",
      "rightmost derivation   1.0\n",
      "\n",
      "versions for   0.3333333333333333\n",
      "\n",
      ". .   0.00078003120124805\n",
      "\n",
      "of most   0.00089126559714795\n",
      "\n",
      "-RRB- ''   0.005420054200542005\n",
      "\n",
      "in time   0.0018726591760299626\n",
      "\n",
      "Foucault ,   0.3333333333333333\n",
      "\n",
      "keyphrases can   0.05714285714285714\n",
      "\n",
      "of certain   0.00089126559714795\n",
      "\n",
      "given unfamiliar   0.08333333333333333\n",
      "\n",
      "accurately if   0.5\n",
      "\n",
      "were simply   0.024390243902439025\n",
      "\n",
      "measure -LRB-   0.09090909090909091\n",
      "\n",
      "and simply   0.001445086705202312\n",
      "\n",
      "international relations   0.5\n",
      "\n",
      "for Gisting   0.007220216606498195\n",
      "\n",
      "vertices ?   0.1111111111111111\n",
      "\n",
      "-RRB- would   0.005420054200542005\n",
      "\n",
      "Apollo moon   1.0\n",
      "\n",
      "Questions are   1.0\n",
      "\n",
      "text unit   0.006289308176100629\n",
      "\n",
      "the platform   0.0006920415224913495\n",
      "\n",
      "human summary   0.021739130434782608\n",
      "\n",
      "Starting in   1.0\n",
      "\n",
      "processing part   0.018518518518518517\n",
      "\n",
      "segmentation depends   0.030303030303030304\n",
      "\n",
      "to OCR   0.0013280212483399733\n",
      "\n",
      "be measured   0.004219409282700422\n",
      "\n",
      "and features   0.001445086705202312\n",
      "\n",
      "Automatic vs.   0.1111111111111111\n",
      "\n",
      "a linear   0.00245398773006135\n",
      "\n",
      "heuristics to   0.5\n",
      "\n",
      "the examples   0.0020761245674740486\n",
      "\n",
      "Marc Angenot   1.0\n",
      "\n",
      "short intervals   0.125\n",
      "\n",
      "Computing Machinery   0.5\n",
      "\n",
      "a trillion-word   0.001226993865030675\n",
      "\n",
      "years -LRB-   0.047619047619047616\n",
      "\n",
      "not determine   0.008928571428571428\n",
      "\n",
      "much time   0.045454545454545456\n",
      "\n",
      "sense disambiguation   0.25\n",
      "\n",
      ", time   0.0005614823133071309\n",
      "\n",
      "often make   0.022727272727272728\n",
      "\n",
      "database or   0.2\n",
      "\n",
      "broad and   0.25\n",
      "\n",
      "indicate speech   0.3333333333333333\n",
      "\n",
      "different dialogues   0.02040816326530612\n",
      "\n",
      "sentences but   0.02631578947368421\n",
      "\n",
      "rejecting those   0.3333333333333333\n",
      "\n",
      "extractive summarization   0.42857142857142855\n",
      "\n",
      "semantic disambiguation   0.047619047619047616\n",
      "\n",
      "after stemming   0.08333333333333333\n",
      "\n",
      "are good   0.004149377593360996\n",
      "\n",
      "information contained   0.021739130434782608\n",
      "\n",
      "a phone   0.001226993865030675\n",
      "\n",
      "and comprehension   0.001445086705202312\n",
      "\n",
      "to reformulate   0.0013280212483399733\n",
      "\n",
      "part that   0.037037037037037035\n",
      "\n",
      "use following   0.013888888888888888\n",
      "\n",
      "<s> Search   0.0015372790161414297\n",
      "\n",
      "-RRB- NASA   0.0027100271002710027\n",
      "\n",
      ", was   0.0022459292532285235\n",
      "\n",
      ", PangeaMT   0.0005614823133071309\n",
      "\n",
      "into standard   0.01282051282051282\n",
      "\n",
      "only 10   0.02631578947368421\n",
      "\n",
      "an important   0.015151515151515152\n",
      "\n",
      "parser The   0.125\n",
      "\n",
      "engaging in   1.0\n",
      "\n",
      ", like   0.0016844469399213925\n",
      "\n",
      ", adverb   0.0005614823133071309\n",
      "\n",
      "was connected   0.012987012987012988\n",
      "\n",
      "is the   0.09146341463414634\n",
      "\n",
      "used to   0.19469026548672566\n",
      "\n",
      "input sentence   0.024390243902439025\n",
      "\n",
      "the successful   0.0006920415224913495\n",
      "\n",
      "items in   0.5\n",
      "\n",
      "keyphrases to   0.02857142857142857\n",
      "\n",
      "make up   0.1\n",
      "\n",
      "pre-determined when   1.0\n",
      "\n",
      "Petrov ,   1.0\n",
      "\n",
      "forward-backward algorithm   1.0\n",
      "\n",
      "meaningful portions   0.125\n",
      "\n",
      "relevant information   0.14285714285714285\n",
      "\n",
      "domain posed   0.05\n",
      "\n",
      "and voice   0.001445086705202312\n",
      "\n",
      "characters \\*   0.0625\n",
      "\n",
      "match up   0.16666666666666666\n",
      "\n",
      "keyphrases ``   0.02857142857142857\n",
      "\n",
      "an edge   0.015151515151515152\n",
      "\n",
      "One could   0.07692307692307693\n",
      "\n",
      "Sound is   0.3333333333333333\n",
      "\n",
      "a form   0.001226993865030675\n",
      "\n",
      "`` computer   0.005291005291005291\n",
      "\n",
      ", Racter   0.0005614823133071309\n",
      "\n",
      "an excellent   0.007575757575757576\n",
      "\n",
      "what we   0.09375\n",
      "\n",
      "subjective information   0.3333333333333333\n",
      "\n",
      "or -LRB-   0.0045045045045045045\n",
      "\n",
      "a lattice   0.001226993865030675\n",
      "\n",
      "tagging systems   0.04\n",
      "\n",
      "is presented   0.0040650406504065045\n",
      "\n",
      "various attempts   0.05555555555555555\n",
      "\n",
      "structure rules   0.08333333333333333\n",
      "\n",
      "counts are   1.0\n",
      "\n",
      "also the   0.028985507246376812\n",
      "\n",
      "disambiguation on   0.1\n",
      "\n",
      "Brown University   0.14285714285714285\n",
      "\n",
      "pioneered this   0.3333333333333333\n",
      "\n",
      "are reported   0.004149377593360996\n",
      "\n",
      "psychotherapist ,   1.0\n",
      "\n",
      "with initial   0.00546448087431694\n",
      "\n",
      "Often natural   0.3333333333333333\n",
      "\n",
      "follow-the-bouncing-ball video   1.0\n",
      "\n",
      "similar ideas   0.037037037037037035\n",
      "\n",
      "called morphological   0.05555555555555555\n",
      "\n",
      "of major   0.00089126559714795\n",
      "\n",
      "Woods introduced   1.0\n",
      "\n",
      "linear-time versions   1.0\n",
      "\n",
      "The ``   0.010416666666666666\n",
      "\n",
      "-LRB- EBMT   0.0027100271002710027\n",
      "\n",
      "being processed   0.05555555555555555\n",
      "\n",
      "the article   0.0006920415224913495\n",
      "\n",
      "output of   0.15384615384615385\n",
      "\n",
      "eyes-busy environment   1.0\n",
      "\n",
      "more often   0.010526315789473684\n",
      "\n",
      "In computer   0.009523809523809525\n",
      "\n",
      "M. 1999   0.25\n",
      "\n",
      "research in   0.14285714285714285\n",
      "\n",
      "consult information   1.0\n",
      "\n",
      "mental processes   0.6666666666666666\n",
      "\n",
      "Other measures   0.14285714285714285\n",
      "\n",
      "techniques used   0.043478260869565216\n",
      "\n",
      "descriptive tags   0.3333333333333333\n",
      "\n",
      "the primary   0.001384083044982699\n",
      "\n",
      "by searching   0.005714285714285714\n",
      "\n",
      "alignment method   0.5\n",
      "\n",
      "work derived   0.041666666666666664\n",
      "\n",
      "any speaker   0.03225806451612903\n",
      "\n",
      "extracting sentences   0.2\n",
      "\n",
      "ontology are   0.5\n",
      "\n",
      "meeting summarization   1.0\n",
      "\n",
      "methods when   0.022727272727272728\n",
      "\n",
      "him or   0.5\n",
      "\n",
      "up to   0.22727272727272727\n",
      "\n",
      "is considerable   0.0020325203252032522\n",
      "\n",
      "value .   0.3333333333333333\n",
      "\n",
      "of that   0.0017825311942959\n",
      "\n",
      "the -LRB-   0.0006920415224913495\n",
      "\n",
      "extractor follows   0.5\n",
      "\n",
      "general-purpose speech   1.0\n",
      "\n",
      "with such   0.00546448087431694\n",
      "\n",
      "source software   0.041666666666666664\n",
      "\n",
      "of criteria   0.00089126559714795\n",
      "\n",
      "SHRDLU and   0.16666666666666666\n",
      "\n",
      "<s> Instead   0.0015372790161414297\n",
      "\n",
      ", different   0.0016844469399213925\n",
      "\n",
      "given a   0.16666666666666666\n",
      "\n",
      "the average   0.0006920415224913495\n",
      "\n",
      "L. 1998   1.0\n",
      "\n",
      "in following   0.0018726591760299626\n",
      "\n",
      "user-provided number   1.0\n",
      "\n",
      "benefit from   1.0\n",
      "\n",
      "network approaches   0.3333333333333333\n",
      "\n",
      "conjunction with   0.6666666666666666\n",
      "\n",
      "to form   0.005312084993359893\n",
      "\n",
      "are difficult   0.004149377593360996\n",
      "\n",
      "difficult ,   0.03571428571428571\n",
      "\n",
      "an in-depth   0.007575757575757576\n",
      "\n",
      "voice response   0.07692307692307693\n",
      "\n",
      "types including   0.07142857142857142\n",
      "\n",
      "process of   0.3333333333333333\n",
      "\n",
      "participate in   1.0\n",
      "\n",
      "alone --   0.25\n",
      "\n",
      "dimensions For   0.3333333333333333\n",
      "\n",
      "This article   0.015873015873015872\n",
      "\n",
      "uninterrupted and   1.0\n",
      "\n",
      "language and   0.013513513513513514\n",
      "\n",
      "Decoding of   0.5\n",
      "\n",
      "dictionary entry   0.14285714285714285\n",
      "\n",
      "morphology ,   0.7142857142857143\n",
      "\n",
      "-RRB- ;   0.02168021680216802\n",
      "\n",
      "many others   0.019230769230769232\n",
      "\n",
      "large corpora   0.043478260869565216\n",
      "\n",
      "more consistent   0.010526315789473684\n",
      "\n",
      ", depends   0.0005614823133071309\n",
      "\n",
      "neural-network output   1.0\n",
      "\n",
      "but to   0.014705882352941176\n",
      "\n",
      "As described   0.05555555555555555\n",
      "\n",
      "domain ,   0.15\n",
      "\n",
      ", OnStar   0.0005614823133071309\n",
      "\n",
      "syntactic coverage   0.07692307692307693\n",
      "\n",
      "polynomial-size representations   1.0\n",
      "\n",
      "are called   0.008298755186721992\n",
      "\n",
      "IE additionally   0.3333333333333333\n",
      "\n",
      "stutering ,   1.0\n",
      "\n",
      "evaluation methods   0.018518518518518517\n",
      "\n",
      "by extracting   0.005714285714285714\n",
      "\n",
      "summary based   0.023809523809523808\n",
      "\n",
      "the trainee   0.0006920415224913495\n",
      "\n",
      "interpreters require   1.0\n",
      "\n",
      "their system   0.029411764705882353\n",
      "\n",
      "and ,   0.004335260115606936\n",
      "\n",
      "selecting examples   0.2\n",
      "\n",
      "also used   0.028985507246376812\n",
      "\n",
      "B. ,   1.0\n",
      "\n",
      "easily retrieved   0.1111111111111111\n",
      "\n",
      "similarity of   0.1\n",
      "\n",
      "two methods   0.034482758620689655\n",
      "\n",
      "as interlingual   0.003484320557491289\n",
      "\n",
      "boundary disambiguation   0.3333333333333333\n",
      "\n",
      "the additional   0.0006920415224913495\n",
      "\n",
      "year despite   0.16666666666666666\n",
      "\n",
      "hand .   0.07142857142857142\n",
      "\n",
      "words from   0.01834862385321101\n",
      "\n",
      "continued to   0.3333333333333333\n",
      "\n",
      "uses the   0.07142857142857142\n",
      "\n",
      "POS -RRB-   0.07692307692307693\n",
      "\n",
      "context of   0.15151515151515152\n",
      "\n",
      "to progress   0.0013280212483399733\n",
      "\n",
      "<s> Ensemble   0.0007686395080707148\n",
      "\n",
      "on paper   0.0047169811320754715\n",
      "\n",
      "as pseudo-pilot   0.003484320557491289\n",
      "\n",
      "of converting   0.0017825311942959\n",
      "\n",
      "and left   0.001445086705202312\n",
      "\n",
      "formally expressed   0.5\n",
      "\n",
      "on a   0.10849056603773585\n",
      "\n",
      "-RRB- question   0.0027100271002710027\n",
      "\n",
      "Eurospeech\\/ICSLP -LRB-   1.0\n",
      "\n",
      "researchers found   0.1\n",
      "\n",
      "perform functions   0.09090909090909091\n",
      "\n",
      "text units   0.018867924528301886\n",
      "\n",
      "than 1   0.022222222222222223\n",
      "\n",
      "the fixed   0.0006920415224913495\n",
      "\n",
      "Levenshtein distance   1.0\n",
      "\n",
      "network has   0.16666666666666666\n",
      "\n",
      "also terminate   0.014492753623188406\n",
      "\n",
      "<s> Each   0.003843197540353574\n",
      "\n",
      "Church 's   0.3333333333333333\n",
      "\n",
      "NC ''   1.0\n",
      "\n",
      "pertaining to   1.0\n",
      "\n",
      "summarise financial   0.3333333333333333\n",
      "\n",
      "department in   0.5\n",
      "\n",
      "for modeling   0.0036101083032490976\n",
      "\n",
      "the unwanted   0.0006920415224913495\n",
      "\n",
      "the area   0.001384083044982699\n",
      "\n",
      "and which   0.001445086705202312\n",
      "\n",
      "star ratings   0.5\n",
      "\n",
      "that removing   0.0035460992907801418\n",
      "\n",
      "is commonly   0.0040650406504065045\n",
      "\n",
      "help blind   0.1111111111111111\n",
      "\n",
      "away unlikely   0.5\n",
      "\n",
      "MySpace -RRB-   1.0\n",
      "\n",
      "PARRY ,   1.0\n",
      "\n",
      "event .   0.3333333333333333\n",
      "\n",
      ", making   0.0005614823133071309\n",
      "\n",
      "by limiting   0.005714285714285714\n",
      "\n",
      "human-like interaction   1.0\n",
      "\n",
      "contexts .   0.2857142857142857\n",
      "\n",
      "a psychologist   0.001226993865030675\n",
      "\n",
      "Defense Advanced   1.0\n",
      "\n",
      "graph .   0.15384615384615385\n",
      "\n",
      "its own   0.14285714285714285\n",
      "\n",
      "-LRB- MAHS   0.0027100271002710027\n",
      "\n",
      "is limited   0.0020325203252032522\n",
      "\n",
      "patterns would   0.2\n",
      "\n",
      "table of   0.42857142857142855\n",
      "\n",
      "processing is   0.037037037037037035\n",
      "\n",
      "efficient however   0.3333333333333333\n",
      "\n",
      "located anywhere   1.0\n",
      "\n",
      "extrinsic -RRB-   0.16666666666666666\n",
      "\n",
      "range .   0.14285714285714285\n",
      "\n",
      "<s> Main   0.0007686395080707148\n",
      "\n",
      "languages with   0.02\n",
      "\n",
      "extractive -LRB-   0.14285714285714285\n",
      "\n",
      "for disambiguation   0.0036101083032490976\n",
      "\n",
      "probabilities are   0.09090909090909091\n",
      "\n",
      "replace the   1.0\n",
      "\n",
      "drawback of   1.0\n",
      "\n",
      "started around   0.25\n",
      "\n",
      "or moderate   0.0045045045045045045\n",
      "\n",
      "for any   0.0036101083032490976\n",
      "\n",
      "'' occurs   0.005154639175257732\n",
      "\n",
      "areas with   0.3333333333333333\n",
      "\n",
      "be very   0.012658227848101266\n",
      "\n",
      "linguistic knowledge   0.0625\n",
      "\n",
      "intrinsic and   0.25\n",
      "\n",
      "Was he   1.0\n",
      "\n",
      "of newspaper   0.00089126559714795\n",
      "\n",
      "level features   0.05\n",
      "\n",
      "the potential   0.0020761245674740486\n",
      "\n",
      "the shops   0.0006920415224913495\n",
      "\n",
      "the meantime   0.0006920415224913495\n",
      "\n",
      "waves describe   0.14285714285714285\n",
      "\n",
      "verifiability .   1.0\n",
      "\n",
      "machine for   0.012658227848101266\n",
      "\n",
      "analysis systems   0.015384615384615385\n",
      "\n",
      "cosine similarity   0.3333333333333333\n",
      "\n",
      "Deciding what   1.0\n",
      "\n",
      "tell us   0.3333333333333333\n",
      "\n",
      "given ,   0.041666666666666664\n",
      "\n",
      "almost no   1.0\n",
      "\n",
      "is capitalized   0.0020325203252032522\n",
      "\n",
      "summarization is   0.12\n",
      "\n",
      "have human-made   0.009615384615384616\n",
      "\n",
      "categories and   0.2222222222222222\n",
      "\n",
      "contain multiple   0.08333333333333333\n",
      "\n",
      "A procedure   0.02\n",
      "\n",
      "the type   0.002768166089965398\n",
      "\n",
      "Anaphora resolution   1.0\n",
      "\n",
      "ontologies '   0.16666666666666666\n",
      "\n",
      "Swales ,   1.0\n",
      "\n",
      "one natural   0.03076923076923077\n",
      "\n",
      "Unlike PageRank   1.0\n",
      "\n",
      "examples .   0.16666666666666666\n",
      "\n",
      "Deirdre Wilson   1.0\n",
      "\n",
      "a rainbow   0.001226993865030675\n",
      "\n",
      "training organizations   0.03571428571428571\n",
      "\n",
      "step .   0.13333333333333333\n",
      "\n",
      "results show   0.047619047619047616\n",
      "\n",
      "`` to   0.010582010582010581\n",
      "\n",
      "wave which   0.1111111111111111\n",
      "\n",
      "comprises all   1.0\n",
      "\n",
      "tables to   0.3333333333333333\n",
      "\n",
      "decode the   1.0\n",
      "\n",
      "'' -LRB-   0.04639175257731959\n",
      "\n",
      "Flow of   1.0\n",
      "\n",
      "with learning   0.00546448087431694\n",
      "\n",
      "machine-generated summaries   1.0\n",
      "\n",
      "CSIS -RRB-   0.5\n",
      "\n",
      "<s> Head-driven   0.0007686395080707148\n",
      "\n",
      "their systems   0.058823529411764705\n",
      "\n",
      "terms do   0.07692307692307693\n",
      "\n",
      "`` Man   0.010582010582010581\n",
      "\n",
      "is included   0.0020325203252032522\n",
      "\n",
      "lectures ,   1.0\n",
      "\n",
      "<s> Recent   0.0023059185242121443\n",
      "\n",
      "setting of   0.2\n",
      "\n",
      "steered toward   1.0\n",
      "\n",
      "the media   0.0006920415224913495\n",
      "\n",
      "system ,   0.10752688172043011\n",
      "\n",
      "Note ,   0.1111111111111111\n",
      "\n",
      "apparent from   1.0\n",
      "\n",
      "accuracy because   0.03225806451612903\n",
      "\n",
      "of questions   0.004456327985739751\n",
      "\n",
      "helped improve   0.3333333333333333\n",
      "\n",
      "planning and   0.5\n",
      "\n",
      "recognition within   0.008264462809917356\n",
      "\n",
      "still somewhat   0.06666666666666667\n",
      "\n",
      "approach would   0.02857142857142857\n",
      "\n",
      "features involve   0.038461538461538464\n",
      "\n",
      "multiple topics   0.07692307692307693\n",
      "\n",
      "have corpus   0.009615384615384616\n",
      "\n",
      "usability .   1.0\n",
      "\n",
      "-LRB- by   0.005420054200542005\n",
      "\n",
      "set of   0.717948717948718\n",
      "\n",
      "in research   0.0018726591760299626\n",
      "\n",
      "recent development   0.125\n",
      "\n",
      "tagging for   0.04\n",
      "\n",
      "theoretical aspects   0.3333333333333333\n",
      "\n",
      "machine-learning systems   0.25\n",
      "\n",
      "a combination   0.00245398773006135\n",
      "\n",
      "use only   0.027777777777777776\n",
      "\n",
      "text by   0.006289308176100629\n",
      "\n",
      "with realistic   0.00546448087431694\n",
      "\n",
      "or generated   0.0045045045045045045\n",
      "\n",
      "the process   0.007612456747404845\n",
      "\n",
      "one may   0.015384615384615385\n",
      "\n",
      "for further   0.010830324909747292\n",
      "\n",
      "existing summaries   0.2\n",
      "\n",
      "The methods   0.010416666666666666\n",
      "\n",
      "relations between   0.4166666666666667\n",
      "\n",
      "generally evaluated   0.09090909090909091\n",
      "\n",
      "ultimately want   1.0\n",
      "\n",
      "the part   0.001384083044982699\n",
      "\n",
      "90 %   1.0\n",
      "\n",
      "clauses ,   1.0\n",
      "\n",
      "form of   0.35\n",
      "\n",
      "data maintained   0.012987012987012988\n",
      "\n",
      "statistical and   0.030303030303030304\n",
      "\n",
      "probabilities to   0.09090909090909091\n",
      "\n",
      "learning that   0.023255813953488372\n",
      "\n",
      "problems and   0.11764705882352941\n",
      "\n",
      "Driver-license OCR   1.0\n",
      "\n",
      "transcription of   0.5\n",
      "\n",
      "experiment in   0.2\n",
      "\n",
      "short-time units   0.5\n",
      "\n",
      "is made   0.0040650406504065045\n",
      "\n",
      "as it   0.003484320557491289\n",
      "\n",
      "technology in   0.045454545454545456\n",
      "\n",
      "machine speech   0.012658227848101266\n",
      "\n",
      "Speaker independent   0.16666666666666666\n",
      "\n",
      "- NC   0.0625\n",
      "\n",
      "speech acts   0.019736842105263157\n",
      "\n",
      "are efficient   0.004149377593360996\n",
      "\n",
      "some local   0.012048192771084338\n",
      "\n",
      "may then   0.019230769230769232\n",
      "\n",
      "it listens   0.008547008547008548\n",
      "\n",
      "spirit to   1.0\n",
      "\n",
      "the naval   0.0006920415224913495\n",
      "\n",
      "five commands   0.2\n",
      "\n",
      "two summaries   0.034482758620689655\n",
      "\n",
      "Corpus .   0.0625\n",
      "\n",
      "create more   0.058823529411764705\n",
      "\n",
      "method for   0.125\n",
      "\n",
      "named entities   0.42857142857142855\n",
      "\n",
      "competence ,   1.0\n",
      "\n",
      "to mention   0.0013280212483399733\n",
      "\n",
      "English sentences   0.02702702702702703\n",
      "\n",
      "see Handwriting   0.05\n",
      "\n",
      "their framework   0.029411764705882353\n",
      "\n",
      "reuse ,   1.0\n",
      "\n",
      "POST -RRB-   1.0\n",
      "\n",
      "performance continued   0.05555555555555555\n",
      "\n",
      "Telephone Company   1.0\n",
      "\n",
      ", multi-document   0.0005614823133071309\n",
      "\n",
      "card spending   0.25\n",
      "\n",
      "be faster   0.004219409282700422\n",
      "\n",
      "of personalised   0.00089126559714795\n",
      "\n",
      "sections of   1.0\n",
      "\n",
      "Workshop Hirschman   1.0\n",
      "\n",
      "are provided   0.004149377593360996\n",
      "\n",
      "create summaries   0.058823529411764705\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the supervised   0.0006920415224913495\n",
      "\n",
      "unigram matching   0.2\n",
      "\n",
      "minimize the   1.0\n",
      "\n",
      "data source   0.012987012987012988\n",
      "\n",
      "it led   0.008547008547008548\n",
      "\n",
      "is recall-based   0.0020325203252032522\n",
      "\n",
      "standard method   0.07142857142857142\n",
      "\n",
      "extractive keyphrase   0.14285714285714285\n",
      "\n",
      "chain random   1.0\n",
      "\n",
      "entry .   0.25\n",
      "\n",
      ", Liberman   0.0005614823133071309\n",
      "\n",
      "sentence with   0.020833333333333332\n",
      "\n",
      ", entering   0.0011229646266142617\n",
      "\n",
      "comes into   0.2\n",
      "\n",
      "Dynamic Programming   0.2\n",
      "\n",
      "called query-biased   0.05555555555555555\n",
      "\n",
      "computed as   0.5\n",
      "\n",
      "represent varies   0.1111111111111111\n",
      "\n",
      "corresponding summaries   0.16666666666666666\n",
      "\n",
      "be specified   0.004219409282700422\n",
      "\n",
      "looks natural   0.25\n",
      "\n",
      "provided within   0.2\n",
      "\n",
      "have some   0.009615384615384616\n",
      "\n",
      "speech for   0.02631578947368421\n",
      "\n",
      ": Interlingual   0.00980392156862745\n",
      "\n",
      "by adding   0.011428571428571429\n",
      "\n",
      "IEEE ASRU   0.3333333333333333\n",
      "\n",
      "IR relies   0.3333333333333333\n",
      "\n",
      "in common   0.003745318352059925\n",
      "\n",
      ": Deciding   0.00980392156862745\n",
      "\n",
      "PageRank to   0.3333333333333333\n",
      "\n",
      "engines such   0.3333333333333333\n",
      "\n",
      "an 11   0.007575757575757576\n",
      "\n",
      "synthesis techniques   1.0\n",
      "\n",
      "automatically generate   0.047619047619047616\n",
      "\n",
      "returned by   0.25\n",
      "\n",
      "system output   0.010752688172043012\n",
      "\n",
      "that contains   0.010638297872340425\n",
      "\n",
      "English like   0.02702702702702703\n",
      "\n",
      "the earliest-used   0.001384083044982699\n",
      "\n",
      "where ``   0.02857142857142857\n",
      "\n",
      "intelligence -LRB-   0.125\n",
      "\n",
      "character ,   0.09090909090909091\n",
      "\n",
      "applying a   0.25\n",
      "\n",
      "Weizenbaum between   0.3333333333333333\n",
      "\n",
      "barmaid -RRB-   0.5\n",
      "\n",
      "related to   0.26666666666666666\n",
      "\n",
      "examples can   0.041666666666666664\n",
      "\n",
      "learn from   0.07692307692307693\n",
      "\n",
      "software varied   0.037037037037037035\n",
      "\n",
      "extraction process   0.03225806451612903\n",
      "\n",
      "'' highly   0.005154639175257732\n",
      "\n",
      "waves would   0.14285714285714285\n",
      "\n",
      "learning model   0.023255813953488372\n",
      "\n",
      "tokens ,   0.14285714285714285\n",
      "\n",
      "to use   0.013280212483399735\n",
      "\n",
      "the class   0.0006920415224913495\n",
      "\n",
      "that approximate   0.0035460992907801418\n",
      "\n",
      ": To   0.00980392156862745\n",
      "\n",
      "paradigms .   1.0\n",
      "\n",
      "multiple parts   0.07692307692307693\n",
      "\n",
      "1976 the   0.5\n",
      "\n",
      "support the   0.25\n",
      "\n",
      "pairs ,   1.0\n",
      "\n",
      "contextual polarity   0.5\n",
      "\n",
      "equivalent information   0.2\n",
      "\n",
      "and LR   0.001445086705202312\n",
      "\n",
      "techniques similar   0.043478260869565216\n",
      "\n",
      "War II   1.0\n",
      "\n",
      "as just   0.003484320557491289\n",
      "\n",
      "and computer   0.001445086705202312\n",
      "\n",
      "Holmes ,   1.0\n",
      "\n",
      "results demonstrate   0.047619047619047616\n",
      "\n",
      "articles from   0.125\n",
      "\n",
      "Speech Communication   0.03225806451612903\n",
      "\n",
      "transformed into   1.0\n",
      "\n",
      "-LRB- MMR   0.0027100271002710027\n",
      "\n",
      "tag ``   0.0625\n",
      "\n",
      "was conducted   0.025974025974025976\n",
      "\n",
      "science disciplines   0.1\n",
      "\n",
      "parses the   0.5\n",
      "\n",
      "divided up   0.3333333333333333\n",
      "\n",
      "integrated part   0.3333333333333333\n",
      "\n",
      "numbers that   0.14285714285714285\n",
      "\n",
      "ASR in   0.5\n",
      "\n",
      "quantity .   0.3333333333333333\n",
      "\n",
      "learning .   0.09302325581395349\n",
      "\n",
      "Inclusive choice   1.0\n",
      "\n",
      "that revolutionized   0.0035460992907801418\n",
      "\n",
      "blind ,   0.25\n",
      "\n",
      "'' systems   0.015463917525773196\n",
      "\n",
      "underpinnings discouraged   1.0\n",
      "\n",
      "translation -LRB-   0.02702702702702703\n",
      "\n",
      ", Henry   0.0005614823133071309\n",
      "\n",
      "challenges .   0.5\n",
      "\n",
      "whether to   0.07692307692307693\n",
      "\n",
      "output a   0.07692307692307693\n",
      "\n",
      "of canned   0.00089126559714795\n",
      "\n",
      "online reviews   0.25\n",
      "\n",
      "nouns ,   0.6666666666666666\n",
      "\n",
      "on training   0.0047169811320754715\n",
      "\n",
      "are ambiguities   0.004149377593360996\n",
      "\n",
      "had plateaued   0.07142857142857142\n",
      "\n",
      "more power   0.010526315789473684\n",
      "\n",
      "tends to   1.0\n",
      "\n",
      "instructions .   1.0\n",
      "\n",
      "accepts a   0.5\n",
      "\n",
      "programs ,   0.18181818181818182\n",
      "\n",
      "be sufficient   0.004219409282700422\n",
      "\n",
      "is related   0.0020325203252032522\n",
      "\n",
      "Speech segmentation   0.0967741935483871\n",
      "\n",
      "make better   0.05\n",
      "\n",
      "a reading   0.001226993865030675\n",
      "\n",
      "these represent   0.023809523809523808\n",
      "\n",
      "and Jabberwacky   0.001445086705202312\n",
      "\n",
      "possessive ,   1.0\n",
      "\n",
      "computer can   0.022727272727272728\n",
      "\n",
      "Parsing is   0.4\n",
      "\n",
      "approximating sentence   1.0\n",
      "\n",
      "naval resource   0.6666666666666666\n",
      "\n",
      "human ratings   0.08695652173913043\n",
      "\n",
      "sequences .   0.2222222222222222\n",
      "\n",
      "effect the   0.5\n",
      "\n",
      "page count   0.14285714285714285\n",
      "\n",
      "modeling approach   0.14285714285714285\n",
      "\n",
      "are selected   0.004149377593360996\n",
      "\n",
      "in text   0.0018726591760299626\n",
      "\n",
      "modeling are   0.14285714285714285\n",
      "\n",
      "Treebank -RRB-   0.16666666666666666\n",
      "\n",
      "despite warnings   0.3333333333333333\n",
      "\n",
      "era of   1.0\n",
      "\n",
      "Leo Spitzer   1.0\n",
      "\n",
      "new trend   0.041666666666666664\n",
      "\n",
      "approaches .   0.10714285714285714\n",
      "\n",
      "useful only   0.07142857142857142\n",
      "\n",
      "compared phrase-structure   0.14285714285714285\n",
      "\n",
      "sentiment is   0.04\n",
      "\n",
      "by The   0.005714285714285714\n",
      "\n",
      "those influenced   0.045454545454545456\n",
      "\n",
      "be known   0.004219409282700422\n",
      "\n",
      "a universal   0.001226993865030675\n",
      "\n",
      "a situation   0.001226993865030675\n",
      "\n",
      "expressed by   0.16666666666666666\n",
      "\n",
      "absorbing random   0.3333333333333333\n",
      "\n",
      "of real-world   0.00089126559714795\n",
      "\n",
      "by Yehoshua   0.005714285714285714\n",
      "\n",
      "Das ,   1.0\n",
      "\n",
      "<s> Canada   0.0007686395080707148\n",
      "\n",
      "using photocells   0.01694915254237288\n",
      "\n",
      "assistants such   1.0\n",
      "\n",
      "vs. manual   0.08333333333333333\n",
      "\n",
      "using will   0.01694915254237288\n",
      "\n",
      "yesterday with   0.6666666666666666\n",
      "\n",
      "summaries for   0.023255813953488372\n",
      "\n",
      "certain e-communities   0.14285714285714285\n",
      "\n",
      "voice recognition   0.07692307692307693\n",
      "\n",
      "Liu 's   1.0\n",
      "\n",
      "above .   0.07692307692307693\n",
      "\n",
      "first major   0.06060606060606061\n",
      "\n",
      "and require   0.004335260115606936\n",
      "\n",
      "Modern NLP   0.3333333333333333\n",
      "\n",
      "this aim   0.01098901098901099\n",
      "\n",
      "databases and   0.125\n",
      "\n",
      "a purpose   0.001226993865030675\n",
      "\n",
      "consonants depends   0.3333333333333333\n",
      "\n",
      "objective evaluation   0.2\n",
      "\n",
      "or emails   0.0045045045045045045\n",
      "\n",
      "only do   0.02631578947368421\n",
      "\n",
      "challenging because   1.0\n",
      "\n",
      "this point   0.01098901098901099\n",
      "\n",
      "design of   0.25\n",
      "\n",
      ", idioms   0.0005614823133071309\n",
      "\n",
      "individual speaker   0.08333333333333333\n",
      "\n",
      "of units   0.00089126559714795\n",
      "\n",
      "must compute   0.07142857142857142\n",
      "\n",
      "Computing +   0.5\n",
      "\n",
      ", Animate   0.0005614823133071309\n",
      "\n",
      "parsers were   0.07692307692307693\n",
      "\n",
      "-LRB- Nuance   0.0027100271002710027\n",
      "\n",
      "set on   0.02564102564102564\n",
      "\n",
      "might also   0.038461538461538464\n",
      "\n",
      "techniques could   0.043478260869565216\n",
      "\n",
      "global semitied   0.3333333333333333\n",
      "\n",
      "went past   0.2\n",
      "\n",
      "in very   0.0056179775280898875\n",
      "\n",
      "foreign word   0.5\n",
      "\n",
      "Nations materials   0.5\n",
      "\n",
      "application to   0.07142857142857142\n",
      "\n",
      "Orleans by   0.5\n",
      "\n",
      "precision .   0.2\n",
      "\n",
      "at input   0.014705882352941176\n",
      "\n",
      "pronouns with   0.5\n",
      "\n",
      "discourse analysts   0.05555555555555555\n",
      "\n",
      ", style   0.0005614823133071309\n",
      "\n",
      "features characterize   0.038461538461538464\n",
      "\n",
      "However sentence   0.02702702702702703\n",
      "\n",
      "the desktop   0.0006920415224913495\n",
      "\n",
      "represent natural   0.1111111111111111\n",
      "\n",
      "art for   0.5\n",
      "\n",
      "ability to   0.75\n",
      "\n",
      "the EARS   0.0006920415224913495\n",
      "\n",
      "Understudy for   1.0\n",
      "\n",
      "by grid   0.005714285714285714\n",
      "\n",
      "A first   0.02\n",
      "\n",
      "be evaluated   0.008438818565400843\n",
      "\n",
      "keyphrases assigned   0.02857142857142857\n",
      "\n",
      "of documents   0.004456327985739751\n",
      "\n",
      "include voice   0.037037037037037035\n",
      "\n",
      "and HLT   0.001445086705202312\n",
      "\n",
      "began offering   0.14285714285714285\n",
      "\n",
      "Since this   0.2\n",
      "\n",
      "Lamb ,   1.0\n",
      "\n",
      "to closely   0.0013280212483399733\n",
      "\n",
      "beyond the   0.5\n",
      "\n",
      "be useful   0.012658227848101266\n",
      "\n",
      "to compiled   0.0013280212483399733\n",
      "\n",
      "valuable detailed   0.5\n",
      "\n",
      "be similar   0.004219409282700422\n",
      "\n",
      "proved similarly   0.3333333333333333\n",
      "\n",
      "a scale   0.001226993865030675\n",
      "\n",
      "translation method   0.013513513513513514\n",
      "\n",
      "and question   0.001445086705202312\n",
      "\n",
      "appear within   0.0625\n",
      "\n",
      "research efforts   0.023809523809523808\n",
      "\n",
      "final post-processing   0.1111111111111111\n",
      "\n",
      "first .   0.030303030303030304\n",
      "\n",
      "piecewise stationary   1.0\n",
      "\n",
      "as is   0.013937282229965157\n",
      "\n",
      "translate more   0.16666666666666666\n",
      "\n",
      "Schober ,   1.0\n",
      "\n",
      "context or   0.030303030303030304\n",
      "\n",
      "Its results   0.5\n",
      "\n",
      "The learning   0.005208333333333333\n",
      "\n",
      "translate five   0.16666666666666666\n",
      "\n",
      "into computer-understandable   0.01282051282051282\n",
      "\n",
      "consideration of   0.3333333333333333\n",
      "\n",
      "had been   0.07142857142857142\n",
      "\n",
      "that form   0.0035460992907801418\n",
      "\n",
      "has a   0.047619047619047616\n",
      "\n",
      "LexRank was   0.08333333333333333\n",
      "\n",
      ", Ann   0.0005614823133071309\n",
      "\n",
      "and print   0.001445086705202312\n",
      "\n",
      "Scotland .   0.4\n",
      "\n",
      "on new   0.0047169811320754715\n",
      "\n",
      "analysis as   0.015384615384615385\n",
      "\n",
      "them good   0.05263157894736842\n",
      "\n",
      "logic oriented   0.25\n",
      "\n",
      "U.S. program   0.14285714285714285\n",
      "\n",
      "1966 -RRB-   0.3333333333333333\n",
      "\n",
      ": noun   0.00980392156862745\n",
      "\n",
      "examples of   0.20833333333333334\n",
      "\n",
      "primary topics   0.5\n",
      "\n",
      "basis of   0.6666666666666666\n",
      "\n",
      "discontinuous speech   0.6666666666666666\n",
      "\n",
      "beyond simple   0.16666666666666666\n",
      "\n",
      "from social   0.009615384615384616\n",
      "\n",
      "electronically searched   1.0\n",
      "\n",
      "organised by   1.0\n",
      "\n",
      "performed using   0.1\n",
      "\n",
      "in summary   0.003745318352059925\n",
      "\n",
      "rate .   0.09090909090909091\n",
      "\n",
      "purpose graph-based   0.4\n",
      "\n",
      "After the   0.3333333333333333\n",
      "\n",
      "recognition such   0.008264462809917356\n",
      "\n",
      "inclusion in   1.0\n",
      "\n",
      "coherent discourse   0.2\n",
      "\n",
      "Reukos S.   1.0\n",
      "\n",
      "real progress   0.1111111111111111\n",
      "\n",
      "be automated   0.004219409282700422\n",
      "\n",
      "identifying trends   0.16666666666666666\n",
      "\n",
      "depend on   1.0\n",
      "\n",
      "entities employed   0.14285714285714285\n",
      "\n",
      "Human sentences   0.2\n",
      "\n",
      ", speed   0.0005614823133071309\n",
      "\n",
      "realm of   1.0\n",
      "\n",
      "stochastic purposes   0.125\n",
      "\n",
      "ongoing as   0.5\n",
      "\n",
      "at binary   0.014705882352941176\n",
      "\n",
      "classification task   0.058823529411764705\n",
      "\n",
      "commonly defined   0.125\n",
      "\n",
      "the entity   0.0006920415224913495\n",
      "\n",
      "possible sentences   0.041666666666666664\n",
      "\n",
      "automatic keyphrase   0.043478260869565216\n",
      "\n",
      "some written   0.024096385542168676\n",
      "\n",
      "which to   0.007246376811594203\n",
      "\n",
      "successfully in   0.3333333333333333\n",
      "\n",
      "of faster   0.00089126559714795\n",
      "\n",
      "large text   0.043478260869565216\n",
      "\n",
      "which arise   0.007246376811594203\n",
      "\n",
      "written by   0.23076923076923078\n",
      "\n",
      "they are   0.175\n",
      "\n",
      "that shift   0.0035460992907801418\n",
      "\n",
      "phonemes is   0.16666666666666666\n",
      "\n",
      "distances represented   0.5\n",
      "\n",
      "though we   0.1\n",
      "\n",
      "are obtained   0.008298755186721992\n",
      "\n",
      "specific example   0.047619047619047616\n",
      "\n",
      "called recursively   0.05555555555555555\n",
      "\n",
      "` summary   0.0625\n",
      "\n",
      "on automatically   0.0047169811320754715\n",
      "\n",
      "the fly   0.0006920415224913495\n",
      "\n",
      "Stilstudien -LRB-   1.0\n",
      "\n",
      "two levels   0.034482758620689655\n",
      "\n",
      "defective flood-control   1.0\n",
      "\n",
      "integration with   1.0\n",
      "\n",
      "Biden visit   0.3333333333333333\n",
      "\n",
      "presented with   0.16666666666666666\n",
      "\n",
      "not obvious   0.008928571428571428\n",
      "\n",
      "meteorologist -RRB-   1.0\n",
      "\n",
      "the extremely   0.0006920415224913495\n",
      "\n",
      "both be   0.03225806451612903\n",
      "\n",
      "and `   0.001445086705202312\n",
      "\n",
      "Dog bites   1.0\n",
      "\n",
      "SpeechTEK Europe   0.5\n",
      "\n",
      "address field   0.25\n",
      "\n",
      "n-gram ROUGE   0.5\n",
      "\n",
      "TextRank results   0.07142857142857142\n",
      "\n",
      "simulation vendors   0.3333333333333333\n",
      "\n",
      "same person   0.04\n",
      "\n",
      "formally ,   0.5\n",
      "\n",
      "combination and   0.2\n",
      "\n",
      "accuracy .   0.22580645161290322\n",
      "\n",
      "the speaker   0.001384083044982699\n",
      "\n",
      "recognition rates   0.01652892561983471\n",
      "\n",
      "'' versus   0.005154639175257732\n",
      "\n",
      "best word   0.05555555555555555\n",
      "\n",
      "model Modern   0.03333333333333333\n",
      "\n",
      "ambitious projects   1.0\n",
      "\n",
      "framework based   0.25\n",
      "\n",
      ": fact   0.00980392156862745\n",
      "\n",
      "words -RRB-   0.027522935779816515\n",
      "\n",
      "`` New   0.005291005291005291\n",
      "\n",
      "expected to   0.2857142857142857\n",
      "\n",
      "a maximum   0.00245398773006135\n",
      "\n",
      "rules engine   0.023255813953488372\n",
      "\n",
      "simpler sounds   0.6666666666666666\n",
      "\n",
      "all of   0.09302325581395349\n",
      "\n",
      "project ongoing   0.07692307692307693\n",
      "\n",
      "notably successful   0.3333333333333333\n",
      "\n",
      "classification indicates   0.058823529411764705\n",
      "\n",
      "of processing   0.00089126559714795\n",
      "\n",
      "language from   0.006756756756756757\n",
      "\n",
      "on attaching   0.009433962264150943\n",
      "\n",
      "events .   1.0\n",
      "\n",
      ": Merging   0.00980392156862745\n",
      "\n",
      "restrictions .   1.0\n",
      "\n",
      "high as   0.05555555555555555\n",
      "\n",
      "these other   0.023809523809523808\n",
      "\n",
      "improve document   0.07692307692307693\n",
      "\n",
      "person or   0.10526315789473684\n",
      "\n",
      "`` diversity   0.005291005291005291\n",
      "\n",
      ", object   0.0005614823133071309\n",
      "\n",
      "Northern areas   0.3333333333333333\n",
      "\n",
      "object ``   0.5\n",
      "\n",
      "which structured   0.007246376811594203\n",
      "\n",
      ", Wayne   0.0005614823133071309\n",
      "\n",
      "= common   0.1111111111111111\n",
      "\n",
      "Current QA   0.2\n",
      "\n",
      "this technology   0.01098901098901099\n",
      "\n",
      "computer science   0.09090909090909091\n",
      "\n",
      ", abstracts   0.0005614823133071309\n",
      "\n",
      "G. Lehnart   0.5\n",
      "\n",
      "evaluate the   0.5\n",
      "\n",
      "in various   0.0056179775280898875\n",
      "\n",
      "like being   0.03571428571428571\n",
      "\n",
      "too many   0.3333333333333333\n",
      "\n",
      "for different   0.0036101083032490976\n",
      "\n",
      "businesses looking   0.5\n",
      "\n",
      "terms to   0.07692307692307693\n",
      "\n",
      "-LRB- ISRI   0.0027100271002710027\n",
      "\n",
      "tag for   0.0625\n",
      "\n",
      "the models   0.0006920415224913495\n",
      "\n",
      "has continued   0.011904761904761904\n",
      "\n",
      "slang .   1.0\n",
      "\n",
      "and Intelligence   0.001445086705202312\n",
      "\n",
      "end a   0.125\n",
      "\n",
      "which sentences   0.007246376811594203\n",
      "\n",
      "to authenticate   0.0013280212483399733\n",
      "\n",
      "databases -RRB-   0.125\n",
      "\n",
      "'' implicate   0.005154639175257732\n",
      "\n",
      "search by   0.09090909090909091\n",
      "\n",
      "sentiment analysis   0.52\n",
      "\n",
      "Michael Schober   0.25\n",
      "\n",
      "translator 's   0.2857142857142857\n",
      "\n",
      "Determine the   1.0\n",
      "\n",
      ", searching   0.0005614823133071309\n",
      "\n",
      "only one   0.02631578947368421\n",
      "\n",
      "23 letters   1.0\n",
      "\n",
      "every 10   0.3333333333333333\n",
      "\n",
      "text that   0.025157232704402517\n",
      "\n",
      "simple queries   0.038461538461538464\n",
      "\n",
      "reduced .   0.5\n",
      "\n",
      "words ''   0.01834862385321101\n",
      "\n",
      "LILOG projects   0.5\n",
      "\n",
      "Intrinsic evaluation   0.3333333333333333\n",
      "\n",
      "about nearly   0.025\n",
      "\n",
      "deaf telephony   1.0\n",
      "\n",
      "as one   0.006968641114982578\n",
      "\n",
      "programs in   0.09090909090909091\n",
      "\n",
      "give a   0.25\n",
      "\n",
      "not as   0.008928571428571428\n",
      "\n",
      "shown that   0.2\n",
      "\n",
      "warping -LRB-   0.25\n",
      "\n",
      "→ barmaid   0.3333333333333333\n",
      "\n",
      "of Chomskyan   0.00089126559714795\n",
      "\n",
      "a full-text   0.001226993865030675\n",
      "\n",
      "so forth   0.03333333333333333\n",
      "\n",
      "arguably function   0.5\n",
      "\n",
      "of elaborate   0.00089126559714795\n",
      "\n",
      ", LinguaSys   0.0005614823133071309\n",
      "\n",
      "either explicit   0.1\n",
      "\n",
      "and composing   0.001445086705202312\n",
      "\n",
      "printed messages   0.08333333333333333\n",
      "\n",
      "or Hard   0.0045045045045045045\n",
      "\n",
      "people who   0.125\n",
      "\n",
      "four words   0.14285714285714285\n",
      "\n",
      "-LRB- allowing   0.0027100271002710027\n",
      "\n",
      "NP for   1.0\n",
      "\n",
      "discrete phonetic   0.3333333333333333\n",
      "\n",
      "read musical   0.14285714285714285\n",
      "\n",
      "compiler or   0.3333333333333333\n",
      "\n",
      "practical systems   0.5\n",
      "\n",
      ", Brill   0.0005614823133071309\n",
      "\n",
      "and semantic   0.004335260115606936\n",
      "\n",
      "applications Aerospace   0.04\n",
      "\n",
      "flexibility and   1.0\n",
      "\n",
      "human translators   0.021739130434782608\n",
      "\n",
      ", Jelinek   0.0005614823133071309\n",
      "\n",
      "Wordnet lexicon   1.0\n",
      "\n",
      "The process   0.015625\n",
      "\n",
      "26 letters   1.0\n",
      "\n",
      "such rules   0.008130081300813009\n",
      "\n",
      "<s> This   0.03996925441967717\n",
      "\n",
      "smaller tag-sets   0.14285714285714285\n",
      "\n",
      "or verb   0.0045045045045045045\n",
      "\n",
      "largely dependent   0.2\n",
      "\n",
      "HLDA -RRB-   1.0\n",
      "\n",
      "not the   0.044642857142857144\n",
      "\n",
      "difficult .   0.07142857142857142\n",
      "\n",
      "or otherwise   0.0045045045045045045\n",
      "\n",
      "Huang etc.   1.0\n",
      "\n",
      "Schank 's   0.2\n",
      "\n",
      "the linguistic   0.0006920415224913495\n",
      "\n",
      "billing purposes   1.0\n",
      "\n",
      ", follow-the-bouncing-ball   0.0005614823133071309\n",
      "\n",
      "Claude Piron   1.0\n",
      "\n",
      "the walk   0.0006920415224913495\n",
      "\n",
      "developed and   0.038461538461538464\n",
      "\n",
      "multitude of   1.0\n",
      "\n",
      "evidence for   0.5\n",
      "\n",
      "looking wave   0.2\n",
      "\n",
      "-LRB- as   0.018970189701897018\n",
      "\n",
      "isolated word   0.2\n",
      "\n",
      "major issues   0.08333333333333333\n",
      "\n",
      "computer databases   0.022727272727272728\n",
      "\n",
      "characters to   0.0625\n",
      "\n",
      "`` Conversational   0.005291005291005291\n",
      "\n",
      "Energy -LRB-   1.0\n",
      "\n",
      "computer process   0.022727272727272728\n",
      "\n",
      "the multiple   0.0006920415224913495\n",
      "\n",
      "corpora ,   0.09090909090909091\n",
      "\n",
      "features -LRB-   0.038461538461538464\n",
      "\n",
      "normal human   0.5\n",
      "\n",
      "provide additional   0.16666666666666666\n",
      "\n",
      "methods assess   0.022727272727272728\n",
      "\n",
      "Beginning with   0.5\n",
      "\n",
      "We have   0.14285714285714285\n",
      "\n",
      "word in   0.06666666666666667\n",
      "\n",
      "copied despite   0.5\n",
      "\n",
      "the majority   0.0006920415224913495\n",
      "\n",
      "standard is   0.07142857142857142\n",
      "\n",
      ": Dictionary-based   0.00980392156862745\n",
      "\n",
      "1980s ,   0.5555555555555556\n",
      "\n",
      "normalization to   0.16666666666666666\n",
      "\n",
      "<s> Was   0.0007686395080707148\n",
      "\n",
      "NIST 's   0.5\n",
      "\n",
      "describe developments   0.16666666666666666\n",
      "\n",
      "them for   0.05263157894736842\n",
      "\n",
      "translation paradigm   0.013513513513513514\n",
      "\n",
      "most commonly   0.017241379310344827\n",
      "\n",
      "matter of   0.3333333333333333\n",
      "\n",
      "and Development   0.001445086705202312\n",
      "\n",
      "are language-specific   0.004149377593360996\n",
      "\n",
      "information into   0.043478260869565216\n",
      "\n",
      "Jef Verschueren   1.0\n",
      "\n",
      "Given a   0.7142857142857143\n",
      "\n",
      "scoring function   0.5\n",
      "\n",
      "words two   0.009174311926605505\n",
      "\n",
      "Winograd finished   0.3333333333333333\n",
      "\n",
      "<s> Languages   0.0023059185242121443\n",
      "\n",
      "and assessing   0.001445086705202312\n",
      "\n",
      "a lunar   0.001226993865030675\n",
      "\n",
      "e.g. stating   0.017857142857142856\n",
      "\n",
      "from one   0.028846153846153848\n",
      "\n",
      "not have   0.017857142857142856\n",
      "\n",
      "Hence -LRB-   0.5\n",
      "\n",
      "can increase   0.0055248618784530384\n",
      "\n",
      "up a   0.09090909090909091\n",
      "\n",
      "minimum phone   0.5\n",
      "\n",
      "Training for   0.5\n",
      "\n",
      "sad ,   1.0\n",
      "\n",
      "corresponds to   1.0\n",
      "\n",
      "sentences to   0.07894736842105263\n",
      "\n",
      "making up   0.14285714285714285\n",
      "\n",
      "the result   0.002768166089965398\n",
      "\n",
      "short-time stationary   0.5\n",
      "\n",
      "speaker .   0.16666666666666666\n",
      "\n",
      "' structures   0.10526315789473684\n",
      "\n",
      ", how   0.0005614823133071309\n",
      "\n",
      "the QA   0.0006920415224913495\n",
      "\n",
      "our learned   0.2\n",
      "\n",
      "having to   0.2\n",
      "\n",
      "been written   0.014705882352941176\n",
      "\n",
      "seems to   1.0\n",
      "\n",
      ", substantial   0.0005614823133071309\n",
      "\n",
      "include Single   0.037037037037037035\n",
      "\n",
      "fine-grained analysis   1.0\n",
      "\n",
      "F. ,   1.0\n",
      "\n",
      ", often   0.0016844469399213925\n",
      "\n",
      "Then ,   0.4\n",
      "\n",
      "Biden was   0.3333333333333333\n",
      "\n",
      "asked within   0.3333333333333333\n",
      "\n",
      "himself translated   0.5\n",
      "\n",
      "scores that   0.2\n",
      "\n",
      "also an   0.014492753623188406\n",
      "\n",
      "ELIZA ,   0.3333333333333333\n",
      "\n",
      "ANR-Passage project   1.0\n",
      "\n",
      "debated much   1.0\n",
      "\n",
      "funding was   0.125\n",
      "\n",
      "sentence and   0.020833333333333332\n",
      "\n",
      "these natural   0.023809523809523808\n",
      "\n",
      "Question Answering   0.14285714285714285\n",
      "\n",
      "is fairly   0.0020325203252032522\n",
      "\n",
      "-5 to   1.0\n",
      "\n",
      "the requirements   0.0006920415224913495\n",
      "\n",
      "and controversial   0.001445086705202312\n",
      "\n",
      "on understanding   0.0047169811320754715\n",
      "\n",
      "whose theoretical   0.3333333333333333\n",
      "\n",
      "analyser to   1.0\n",
      "\n",
      "abstraction involves   0.25\n",
      "\n",
      ", Norman   0.0005614823133071309\n",
      "\n",
      "the two   0.0034602076124567475\n",
      "\n",
      "word problems   0.016666666666666666\n",
      "\n",
      "processing Objectives   0.018518518518518517\n",
      "\n",
      "probabilistic modeling   0.14285714285714285\n",
      "\n",
      "Digest coupons   0.3333333333333333\n",
      "\n",
      "human -LRB-   0.043478260869565216\n",
      "\n",
      "methods build   0.022727272727272728\n",
      "\n",
      "context dependency   0.030303030303030304\n",
      "\n",
      "into rule-based   0.01282051282051282\n",
      "\n",
      "or keep   0.0045045045045045045\n",
      "\n",
      "evaluation in   0.05555555555555555\n",
      "\n",
      "understanding and   0.030303030303030304\n",
      "\n",
      "-- indeed   0.04\n",
      "\n",
      "non-existent words   1.0\n",
      "\n",
      "set that   0.02564102564102564\n",
      "\n",
      "robustness of   0.25\n",
      "\n",
      "`` Speech   0.005291005291005291\n",
      "\n",
      "extrinsic ,   0.16666666666666666\n",
      "\n",
      "was -LRB-   0.012987012987012988\n",
      "\n",
      "very recent   0.024390243902439025\n",
      "\n",
      ", business   0.0005614823133071309\n",
      "\n",
      "entropy-based summarization   1.0\n",
      "\n",
      "systems since   0.008928571428571428\n",
      "\n",
      "to unigram   0.0013280212483399733\n",
      "\n",
      "and relevance   0.001445086705202312\n",
      "\n",
      "on contrastive   0.0047169811320754715\n",
      "\n",
      "incorrectly causing   1.0\n",
      "\n",
      ", William   0.0011229646266142617\n",
      "\n",
      "Vauquois '   1.0\n",
      "\n",
      "attached ,   0.5\n",
      "\n",
      "MPE -RRB-   1.0\n",
      "\n",
      "evaluators .   1.0\n",
      "\n",
      "actually playing   0.3333333333333333\n",
      "\n",
      "Sacks ,   1.0\n",
      "\n",
      "to search   0.0013280212483399733\n",
      "\n",
      "determine its   0.08695652173913043\n",
      "\n",
      "of public   0.00089126559714795\n",
      "\n",
      "produce vowels   0.045454545454545456\n",
      "\n",
      "translation MAHT   0.013513513513513514\n",
      "\n",
      "`` Computational   0.005291005291005291\n",
      "\n",
      "Scotland ,   0.2\n",
      "\n",
      "and align   0.001445086705202312\n",
      "\n",
      "relatively simple   1.0\n",
      "\n",
      "to expand   0.0013280212483399733\n",
      "\n",
      "on to   0.009433962264150943\n",
      "\n",
      "automatic speech   0.13043478260869565\n",
      "\n",
      "report in   0.25\n",
      "\n",
      "searching for   0.3333333333333333\n",
      "\n",
      "steadily ,   1.0\n",
      "\n",
      "as multiple   0.003484320557491289\n",
      "\n",
      "systems with   0.017857142857142856\n",
      "\n",
      "to perform   0.005312084993359893\n",
      "\n",
      "toy world   0.5\n",
      "\n",
      "noting that   1.0\n",
      "\n",
      "and 2500   0.001445086705202312\n",
      "\n",
      "active research   0.5\n",
      "\n",
      "<s> Human-machine   0.0007686395080707148\n",
      "\n",
      "up-to-date research   1.0\n",
      "\n",
      "the end   0.001384083044982699\n",
      "\n",
      "say your   0.14285714285714285\n",
      "\n",
      "summarization Like   0.02\n",
      "\n",
      "and typical   0.001445086705202312\n",
      "\n",
      "segmentation In   0.030303030303030304\n",
      "\n",
      "Generation Challenges   0.5\n",
      "\n",
      "The ability   0.005208333333333333\n",
      "\n",
      "appears several   0.2\n",
      "\n",
      "spontaneous speech   1.0\n",
      "\n",
      "keyphrase ,   0.05263157894736842\n",
      "\n",
      "For telephone   0.01639344262295082\n",
      "\n",
      "by numbers   0.005714285714285714\n",
      "\n",
      "free as   0.25\n",
      "\n",
      "<s> Its   0.0015372790161414297\n",
      "\n",
      "This hierarchy   0.015873015873015872\n",
      "\n",
      "quantity -LRB-   0.3333333333333333\n",
      "\n",
      "being asked   0.05555555555555555\n",
      "\n",
      "are focused   0.004149377593360996\n",
      "\n",
      "an urgent   0.007575757575757576\n",
      "\n",
      "cheque -LRB-   1.0\n",
      "\n",
      ", Driver-license   0.0005614823133071309\n",
      "\n",
      "a data   0.001226993865030675\n",
      "\n",
      "<s> From   0.0007686395080707148\n",
      "\n",
      "the stock   0.0006920415224913495\n",
      "\n",
      "publishing ,   1.0\n",
      "\n",
      "often characterised   0.022727272727272728\n",
      "\n",
      "many advantages   0.019230769230769232\n",
      "\n",
      "boundary '   0.16666666666666666\n",
      "\n",
      "out of   0.07142857142857142\n",
      "\n",
      "poetry passages   1.0\n",
      "\n",
      "100000 may   1.0\n",
      "\n",
      "larger volume   0.0625\n",
      "\n",
      "Recognizing the   1.0\n",
      "\n",
      "`` shallow   0.005291005291005291\n",
      "\n",
      "been carried   0.014705882352941176\n",
      "\n",
      "'' vertex   0.005154639175257732\n",
      "\n",
      "as adjectives   0.003484320557491289\n",
      "\n",
      "Automatic tagging   0.1111111111111111\n",
      "\n",
      "overload has   1.0\n",
      "\n",
      "`` fire   0.005291005291005291\n",
      "\n",
      "sentence also   0.020833333333333332\n",
      "\n",
      "lexicons -LRB-   0.5\n",
      "\n",
      "both speech   0.03225806451612903\n",
      "\n",
      "voice has   0.07692307692307693\n",
      "\n",
      "also known   0.08695652173913043\n",
      "\n",
      "formulation The   1.0\n",
      "\n",
      "command centres   0.5\n",
      "\n",
      "spoken languages   0.14285714285714285\n",
      "\n",
      "two distinctive   0.034482758620689655\n",
      "\n",
      "converts a   1.0\n",
      "\n",
      "laughter -RRB-   1.0\n",
      "\n",
      "To address   0.1111111111111111\n",
      "\n",
      "religious services   1.0\n",
      "\n",
      "capitalization can   0.3333333333333333\n",
      "\n",
      "and semi-supervised   0.001445086705202312\n",
      "\n",
      "and syntax   0.001445086705202312\n",
      "\n",
      "which makes   0.021739130434782608\n",
      "\n",
      "assigning the   1.0\n",
      "\n",
      "here ,   0.5\n",
      "\n",
      ", more   0.0022459292532285235\n",
      "\n",
      "out the   0.21428571428571427\n",
      "\n",
      "must interpret   0.07142857142857142\n",
      "\n",
      "first solid   0.030303030303030304\n",
      "\n",
      "computational humor   0.1\n",
      "\n",
      "from floods   0.009615384615384616\n",
      "\n",
      "Independence :   1.0\n",
      "\n",
      ", he   0.0011229646266142617\n",
      "\n",
      "digital assistants   0.14285714285714285\n",
      "\n",
      "the grammar   0.006228373702422145\n",
      "\n",
      "simulated the   0.5\n",
      "\n",
      "the Romance   0.0006920415224913495\n",
      "\n",
      "achieved ,   0.2\n",
      "\n",
      ", separate   0.0011229646266142617\n",
      "\n",
      "notations ,   0.5\n",
      "\n",
      "'s NLP   0.0196078431372549\n",
      "\n",
      "Rabinow .   1.0\n",
      "\n",
      "approaches emphasize   0.03571428571428571\n",
      "\n",
      "of stochastic   0.00089126559714795\n",
      "\n",
      "a test   0.0036809815950920245\n",
      "\n",
      "other terms   0.014285714285714285\n",
      "\n",
      "U.S. Army   0.14285714285714285\n",
      "\n",
      "pour le   1.0\n",
      "\n",
      "domain-independent and   1.0\n",
      "\n",
      "passage web   1.0\n",
      "\n",
      "phones and   0.5\n",
      "\n",
      "e.g. with   0.017857142857142856\n",
      "\n",
      "generating too   0.2\n",
      "\n",
      "to carefully   0.0013280212483399733\n",
      "\n",
      ", Klavans   0.0005614823133071309\n",
      "\n",
      "is importance   0.0020325203252032522\n",
      "\n",
      "If web   0.1\n",
      "\n",
      "most fonts   0.017241379310344827\n",
      "\n",
      "processing problems   0.018518518518518517\n",
      "\n",
      "term used   0.1111111111111111\n",
      "\n",
      "a likelihood   0.001226993865030675\n",
      "\n",
      ", identify   0.0011229646266142617\n",
      "\n",
      ", semantics   0.0016844469399213925\n",
      "\n",
      ", pre-defined   0.0005614823133071309\n",
      "\n",
      "National Corpus   0.3333333333333333\n",
      "\n",
      "corpus denote   0.03225806451612903\n",
      "\n",
      "voice dialog   0.07692307692307693\n",
      "\n",
      "easily parsed   0.1111111111111111\n",
      "\n",
      "speech recogniton   0.006578947368421052\n",
      "\n",
      "most significant   0.017241379310344827\n",
      "\n",
      "<s> human   0.0007686395080707148\n",
      "\n",
      "is too   0.0020325203252032522\n",
      "\n",
      "away -LRB-   0.5\n",
      "\n",
      "that tell   0.0035460992907801418\n",
      "\n",
      "affect the   0.3333333333333333\n",
      "\n",
      "already placed   0.2\n",
      "\n",
      "scanning solution   0.5\n",
      "\n",
      "predict -RRB-   0.16666666666666666\n",
      "\n",
      "of children   0.00089126559714795\n",
      "\n",
      "each dictionary   0.022222222222222223\n",
      "\n",
      "Kittredge &   0.5\n",
      "\n",
      "different speaking   0.02040816326530612\n",
      "\n",
      "process to   0.1111111111111111\n",
      "\n",
      "optimal match   1.0\n",
      "\n",
      "and later   0.001445086705202312\n",
      "\n",
      "may dismiss   0.019230769230769232\n",
      "\n",
      "disagree with   0.3333333333333333\n",
      "\n",
      "<s> Besides   0.0007686395080707148\n",
      "\n",
      "the water   0.0006920415224913495\n",
      "\n",
      "was due   0.012987012987012988\n",
      "\n",
      ", Strzalkowski   0.0005614823133071309\n",
      "\n",
      "operating system   0.5\n",
      "\n",
      "and paragraph   0.001445086705202312\n",
      "\n",
      "transformation ,   1.0\n",
      "\n",
      "to Australia   0.0013280212483399733\n",
      "\n",
      "a speaker-dependent   0.001226993865030675\n",
      "\n",
      "with having   0.00546448087431694\n",
      "\n",
      "bar code   1.0\n",
      "\n",
      "local collection   0.3333333333333333\n",
      "\n",
      "1970 ,   0.3333333333333333\n",
      "\n",
      "influence in   1.0\n",
      "\n",
      "or it   0.0045045045045045045\n",
      "\n",
      "In order   0.01904761904761905\n",
      "\n",
      "in quite   0.0018726591760299626\n",
      "\n",
      "generation ,   0.1111111111111111\n",
      "\n",
      ", on   0.0039303761931499155\n",
      "\n",
      ", Ford   0.0005614823133071309\n",
      "\n",
      "<s> Alternatively   0.0015372790161414297\n",
      "\n",
      ", LUNAR   0.0005614823133071309\n",
      "\n",
      "precision and   0.4\n",
      "\n",
      "from left   0.009615384615384616\n",
      "\n",
      "transform -LRB-   0.2\n",
      "\n",
      "NLP that   0.02127659574468085\n",
      "\n",
      "free speech   0.25\n",
      "\n",
      "phone call   0.25\n",
      "\n",
      "learning applications   0.023255813953488372\n",
      "\n",
      "Stubbs ,   1.0\n",
      "\n",
      "above -RRB-   0.07692307692307693\n",
      "\n",
      "constraints are   0.25\n",
      "\n",
      "Text linguistics   0.16666666666666666\n",
      "\n",
      "becomes .   0.25\n",
      "\n",
      "general term   0.045454545454545456\n",
      "\n",
      "extraction is   0.06451612903225806\n",
      "\n",
      "Amount line   1.0\n",
      "\n",
      "to program   0.0013280212483399733\n",
      "\n",
      "created by   0.2857142857142857\n",
      "\n",
      "-- on   0.04\n",
      "\n",
      "while Snyder   0.05\n",
      "\n",
      "action of   0.2\n",
      "\n",
      "conceptual ontologies   0.5\n",
      "\n",
      "parsing ambiguous   0.03571428571428571\n",
      "\n",
      "separate field   0.1\n",
      "\n",
      "for abbreviations   0.0036101083032490976\n",
      "\n",
      "several teams   0.045454545454545456\n",
      "\n",
      "do all   0.038461538461538464\n",
      "\n",
      "recognition tasks   0.01652892561983471\n",
      "\n",
      "CSR have   0.3333333333333333\n",
      "\n",
      "into modern   0.01282051282051282\n",
      "\n",
      "observe patterns   1.0\n",
      "\n",
      "were repeatedly   0.024390243902439025\n",
      "\n",
      "and Haton   0.001445086705202312\n",
      "\n",
      "slow speech   0.5\n",
      "\n",
      "learning is   0.023255813953488372\n",
      "\n",
      "SHRDLU provided   0.16666666666666666\n",
      "\n",
      "Avionics Research   1.0\n",
      "\n",
      "tell it   0.3333333333333333\n",
      "\n",
      "and VOLSUNGA   0.001445086705202312\n",
      "\n",
      "several ways   0.045454545454545456\n",
      "\n",
      "with equipment   0.00546448087431694\n",
      "\n",
      "Haton -LRB-   1.0\n",
      "\n",
      "has two   0.011904761904761904\n",
      "\n",
      "Red is   1.0\n",
      "\n",
      "text to   0.0440251572327044\n",
      "\n",
      "or larger   0.0045045045045045045\n",
      "\n",
      ", roughness   0.0005614823133071309\n",
      "\n",
      "understanding system   0.030303030303030304\n",
      "\n",
      "Artificial neural   0.5\n",
      "\n",
      "Union as   1.0\n",
      "\n",
      "basic task   0.07692307692307693\n",
      "\n",
      "or continuous   0.0045045045045045045\n",
      "\n",
      "of aircraft   0.00089126559714795\n",
      "\n",
      ", reasoning   0.0005614823133071309\n",
      "\n",
      "five pages   0.2\n",
      "\n",
      "software -LRB-   0.037037037037037035\n",
      "\n",
      ", gestures   0.0005614823133071309\n",
      "\n",
      "are by   0.004149377593360996\n",
      "\n",
      "cares about   1.0\n",
      "\n",
      "is formed   0.0020325203252032522\n",
      "\n",
      "their reputations   0.029411764705882353\n",
      "\n",
      "might not   0.07692307692307693\n",
      "\n",
      "to those   0.0026560424966799467\n",
      "\n",
      "nouns -LRB-   0.1111111111111111\n",
      "\n",
      ", grounded   0.0005614823133071309\n",
      "\n",
      "horizontal mark   1.0\n",
      "\n",
      "Systems that   0.3333333333333333\n",
      "\n",
      "`` Spoken   0.005291005291005291\n",
      "\n",
      "answered about   0.2\n",
      "\n",
      "his visit   0.08333333333333333\n",
      "\n",
      "being a   0.1111111111111111\n",
      "\n",
      "is provided   0.0020325203252032522\n",
      "\n",
      "time-consuming .   0.3333333333333333\n",
      "\n",
      ": David   0.00980392156862745\n",
      "\n",
      "and limited   0.001445086705202312\n",
      "\n",
      "or uncertainties   0.0045045045045045045\n",
      "\n",
      "of assertions   0.00089126559714795\n",
      "\n",
      "were walking   0.024390243902439025\n",
      "\n",
      "usually be   0.03125\n",
      "\n",
      "to error   0.0013280212483399733\n",
      "\n",
      "texts from   0.058823529411764705\n",
      "\n",
      "Greek -LRB-   0.3333333333333333\n",
      "\n",
      "Machine learning   0.1111111111111111\n",
      "\n",
      "prior ranking   0.3333333333333333\n",
      "\n",
      "recognition products   0.008264462809917356\n",
      "\n",
      "text about   0.012578616352201259\n",
      "\n",
      "past thirty   0.3333333333333333\n",
      "\n",
      "The 1970s   0.005208333333333333\n",
      "\n",
      "for a   0.10469314079422383\n",
      "\n",
      "V.J. ,   1.0\n",
      "\n",
      "relationship to   0.16666666666666666\n",
      "\n",
      "rely on   0.8571428571428571\n",
      "\n",
      "converse on   1.0\n",
      "\n",
      "because they   0.13333333333333333\n",
      "\n",
      "aspect is   0.5\n",
      "\n",
      "and reporting   0.001445086705202312\n",
      "\n",
      "day did   1.0\n",
      "\n",
      "recently there   0.3333333333333333\n",
      "\n",
      ", symbolic   0.0005614823133071309\n",
      "\n",
      "language system   0.006756756756756757\n",
      "\n",
      "<s> Because   0.0015372790161414297\n",
      "\n",
      "bought the   1.0\n",
      "\n",
      ", +   0.0011229646266142617\n",
      "\n",
      "nouns were   0.1111111111111111\n",
      "\n",
      "person ,   0.21052631578947367\n",
      "\n",
      "bag of   1.0\n",
      "\n",
      "appropriate syntactic   0.25\n",
      "\n",
      "in both   0.0018726591760299626\n",
      "\n",
      "Tauschek was   0.5\n",
      "\n",
      "is because   0.0020325203252032522\n",
      "\n",
      "by finding   0.005714285714285714\n",
      "\n",
      "choice with   0.125\n",
      "\n",
      "a central   0.001226993865030675\n",
      "\n",
      "stress injuries   0.5\n",
      "\n",
      "errata ,   1.0\n",
      "\n",
      "controllers -LRB-   0.3333333333333333\n",
      "\n",
      "-LRB- basically   0.0027100271002710027\n",
      "\n",
      "mechanisms ,   0.5\n",
      "\n",
      "whether documents   0.07692307692307693\n",
      "\n",
      "are particularly   0.004149377593360996\n",
      "\n",
      "charge services   1.0\n",
      "\n",
      "learns a   1.0\n",
      "\n",
      "lexicon .   0.1111111111111111\n",
      "\n",
      "`` Translation   0.005291005291005291\n",
      "\n",
      "<s> Military   0.0007686395080707148\n",
      "\n",
      "finalized .   1.0\n",
      "\n",
      "of descriptive   0.00089126559714795\n",
      "\n",
      "algorithm As   0.03571428571428571\n",
      "\n",
      "parser attempts   0.0625\n",
      "\n",
      "appliance control   1.0\n",
      "\n",
      "article such   0.034482758620689655\n",
      "\n",
      "greatly reduced   0.14285714285714285\n",
      "\n",
      "psychotherapy .   1.0\n",
      "\n",
      "on Shepard   0.0047169811320754715\n",
      "\n",
      "trigrams ,   0.5\n",
      "\n",
      "more successful   0.031578947368421054\n",
      "\n",
      ": Microsoft   0.00980392156862745\n",
      "\n",
      ", several   0.0005614823133071309\n",
      "\n",
      "letters of   0.2\n",
      "\n",
      "UC and   0.5\n",
      "\n",
      "identified .   0.2\n",
      "\n",
      "course ,   0.3333333333333333\n",
      "\n",
      "and strength   0.001445086705202312\n",
      "\n",
      "constraints Read   0.25\n",
      "\n",
      "method simply   0.0625\n",
      "\n",
      "base of   0.25\n",
      "\n",
      "of NLG   0.00089126559714795\n",
      "\n",
      "what original   0.03125\n",
      "\n",
      "line of   0.3333333333333333\n",
      "\n",
      "right .   0.3\n",
      "\n",
      "forecasts .   0.2\n",
      "\n",
      "statistical approach   0.030303030303030304\n",
      "\n",
      "corresponding text   0.16666666666666666\n",
      "\n",
      "doing extensive   0.5\n",
      "\n",
      "great importance   0.3333333333333333\n",
      "\n",
      "processes implemented   0.2\n",
      "\n",
      ", 7   0.0005614823133071309\n",
      "\n",
      "step that   0.13333333333333333\n",
      "\n",
      "one year   0.015384615384615385\n",
      "\n",
      "best modern   0.05555555555555555\n",
      "\n",
      "Structure ,   1.0\n",
      "\n",
      "the peak   0.0006920415224913495\n",
      "\n",
      "1929 Gustav   1.0\n",
      "\n",
      "length cutoff   0.125\n",
      "\n",
      "like writing   0.03571428571428571\n",
      "\n",
      "match each   0.16666666666666666\n",
      "\n",
      "termed ``   0.5\n",
      "\n",
      "and competitions   0.001445086705202312\n",
      "\n",
      "segmentation approaches   0.030303030303030304\n",
      "\n",
      "high-quality weather   1.0\n",
      "\n",
      "or English   0.0045045045045045045\n",
      "\n",
      "cryptanalyst at   1.0\n",
      "\n",
      "changed direction   0.5\n",
      "\n",
      "most linguists   0.017241379310344827\n",
      "\n",
      "to infer   0.0013280212483399733\n",
      "\n",
      "for word   0.0036101083032490976\n",
      "\n",
      "second system   0.1\n",
      "\n",
      "decoding is   1.0\n",
      "\n",
      "rank order   0.16666666666666666\n",
      "\n",
      "outputting language   0.5\n",
      "\n",
      "first pass   0.030303030303030304\n",
      "\n",
      ", split   0.0005614823133071309\n",
      "\n",
      "shape of   1.0\n",
      "\n",
      "companies -LRB-   0.5\n",
      "\n",
      "evaluation technique   0.018518518518518517\n",
      "\n",
      "where POS   0.02857142857142857\n",
      "\n",
      "<s> LREC   0.0015372790161414297\n",
      "\n",
      "systems :   0.008928571428571428\n",
      "\n",
      "interest was   0.09090909090909091\n",
      "\n",
      "and Unsupervised   0.001445086705202312\n",
      "\n",
      "use text   0.013888888888888888\n",
      "\n",
      "some systems   0.024096385542168676\n",
      "\n",
      "such systems   0.008130081300813009\n",
      "\n",
      "methodology was   0.5\n",
      "\n",
      "Further applications   0.3333333333333333\n",
      "\n",
      "represents a   0.75\n",
      "\n",
      "and speech   0.001445086705202312\n",
      "\n",
      ", Perceptron   0.0005614823133071309\n",
      "\n",
      "Why ,   0.14285714285714285\n",
      "\n",
      "Communications -LRB-   1.0\n",
      "\n",
      "<s> According   0.0007686395080707148\n",
      "\n",
      "Mobile devices   0.3333333333333333\n",
      "\n",
      "Hearing ,   1.0\n",
      "\n",
      "evaluated .   0.14285714285714285\n",
      "\n",
      "sentences from   0.02631578947368421\n",
      "\n",
      "possible forms   0.041666666666666664\n",
      "\n",
      "a speech   0.00245398773006135\n",
      "\n",
      "Web-based +   0.3333333333333333\n",
      "\n",
      "queries ,   0.3333333333333333\n",
      "\n",
      "particular note   0.07692307692307693\n",
      "\n",
      "Pallet D.S.   0.5\n",
      "\n",
      "and Dragon   0.001445086705202312\n",
      "\n",
      "for programming   0.0036101083032490976\n",
      "\n",
      "hybrid system   0.5\n",
      "\n",
      "is usually   0.016260162601626018\n",
      "\n",
      "methods require   0.022727272727272728\n",
      "\n",
      "the IEEE   0.001384083044982699\n",
      "\n",
      "piece of   1.0\n",
      "\n",
      "all these   0.023255813953488372\n",
      "\n",
      "sets from   0.09090909090909091\n",
      "\n",
      ", Reader   0.0005614823133071309\n",
      "\n",
      "closer to   1.0\n",
      "\n",
      "than the   0.08888888888888889\n",
      "\n",
      "strong correlation   0.25\n",
      "\n",
      "either manually   0.1\n",
      "\n",
      "Analysis Although   0.2\n",
      "\n",
      "sophisticated understanding   0.14285714285714285\n",
      "\n",
      "OCR to   0.061224489795918366\n",
      "\n",
      "span several   1.0\n",
      "\n",
      "mining have   0.2\n",
      "\n",
      "has unambiguously   0.011904761904761904\n",
      "\n",
      "well enough   0.03571428571428571\n",
      "\n",
      "to mimic   0.0013280212483399733\n",
      "\n",
      "Digitize the   1.0\n",
      "\n",
      "human knowledge   0.021739130434782608\n",
      "\n",
      ", Jan   0.0005614823133071309\n",
      "\n",
      "complex system   0.08333333333333333\n",
      "\n",
      "of glass-box   0.00089126559714795\n",
      "\n",
      "sentiments expressed   1.0\n",
      "\n",
      "with maximal   0.00546448087431694\n",
      "\n",
      "any kind   0.03225806451612903\n",
      "\n",
      "are capitalized   0.004149377593360996\n",
      "\n",
      "model ''   0.03333333333333333\n",
      "\n",
      "The Apple   0.005208333333333333\n",
      "\n",
      "spoken language   0.14285714285714285\n",
      "\n",
      "included speech   0.125\n",
      "\n",
      "to process   0.00398406374501992\n",
      "\n",
      "systems currently   0.008928571428571428\n",
      "\n",
      "depending what   0.25\n",
      "\n",
      "Pointwise Mutual   1.0\n",
      "\n",
      "and delta-delta   0.002890173410404624\n",
      "\n",
      "the implied   0.0006920415224913495\n",
      "\n",
      "Grammar ,   1.0\n",
      "\n",
      "anthropology ,   1.0\n",
      "\n",
      "jet fighter   1.0\n",
      "\n",
      ": Creating   0.0196078431372549\n",
      "\n",
      "various constructions   0.05555555555555555\n",
      "\n",
      "feature of   0.23076923076923078\n",
      "\n",
      "known for   0.038461538461538464\n",
      "\n",
      "and simpler   0.001445086705202312\n",
      "\n",
      "coverage of   0.3333333333333333\n",
      "\n",
      "context can   0.030303030303030304\n",
      "\n",
      "sort of   0.6666666666666666\n",
      "\n",
      "scanning applications   0.5\n",
      "\n",
      "abbreviations -RRB-   0.2\n",
      "\n",
      "solve the   0.25\n",
      "\n",
      "stochastic methods   0.125\n",
      "\n",
      "similarity classes   0.1\n",
      "\n",
      "another verb   0.07692307692307693\n",
      "\n",
      "requires expansion   0.0625\n",
      "\n",
      "held each   1.0\n",
      "\n",
      "generate jokes   0.05555555555555555\n",
      "\n",
      "are structured   0.004149377593360996\n",
      "\n",
      "of very   0.0017825311942959\n",
      "\n",
      "passages .   0.5\n",
      "\n",
      "in a   0.09363295880149813\n",
      "\n",
      "following :   0.13333333333333333\n",
      "\n",
      "up an   0.045454545454545456\n",
      "\n",
      "automation Interactive   1.0\n",
      "\n",
      "one place   0.015384615384615385\n",
      "\n",
      "a storm   0.001226993865030675\n",
      "\n",
      "Writing -RRB-   1.0\n",
      "\n",
      "produce more   0.09090909090909091\n",
      "\n",
      "and related   0.004335260115606936\n",
      "\n",
      "the state   0.001384083044982699\n",
      "\n",
      "work of   0.08333333333333333\n",
      "\n",
      "without intervening   0.07692307692307693\n",
      "\n",
      "barmaid .   0.16666666666666666\n",
      "\n",
      "of syntactic   0.0017825311942959\n",
      "\n",
      "'s necessary   0.0196078431372549\n",
      "\n",
      "of being   0.00089126559714795\n",
      "\n",
      "on technology   0.0047169811320754715\n",
      "\n",
      "common term   0.04\n",
      "\n",
      "has many   0.023809523809523808\n",
      "\n",
      "text ''   0.006289308176100629\n",
      "\n",
      "do n't   0.07692307692307693\n",
      "\n",
      "these approaches   0.047619047619047616\n",
      "\n",
      "front-end SR   1.0\n",
      "\n",
      ", morphology   0.0011229646266142617\n",
      "\n",
      "automatic metric   0.043478260869565216\n",
      "\n",
      "for specific   0.0036101083032490976\n",
      "\n",
      "preliminary recognition   0.3333333333333333\n",
      "\n",
      "extensive knowledge   0.3333333333333333\n",
      "\n",
      "hurts ''   0.5\n",
      "\n",
      "accuracy using   0.03225806451612903\n",
      "\n",
      "for an   0.0036101083032490976\n",
      "\n",
      "direct comparison   0.16666666666666666\n",
      "\n",
      "solutions .   0.5\n",
      "\n",
      "ground established   1.0\n",
      "\n",
      "smart keyboard   1.0\n",
      "\n",
      "and phrases   0.002890173410404624\n",
      "\n",
      "written texts   0.07692307692307693\n",
      "\n",
      "machine-learning paradigm   0.25\n",
      "\n",
      "conditions Accuracy   0.2\n",
      "\n",
      "questions are   0.07692307692307693\n",
      "\n",
      "same meaning   0.04\n",
      "\n",
      "normalization it   0.16666666666666666\n",
      "\n",
      "meaning then   0.043478260869565216\n",
      "\n",
      "allow for   0.2\n",
      "\n",
      "produces less   0.25\n",
      "\n",
      "previously unseen   0.5\n",
      "\n",
      "our alphabetic   0.2\n",
      "\n",
      "into a   0.21794871794871795\n",
      "\n",
      "Running PageRank\\/TextRank   1.0\n",
      "\n",
      "texts ,   0.11764705882352941\n",
      "\n",
      "injuries to   1.0\n",
      "\n",
      "intended emotional   0.2\n",
      "\n",
      "using edges   0.01694915254237288\n",
      "\n",
      "shown to   0.4\n",
      "\n",
      "a growing   0.001226993865030675\n",
      "\n",
      "parsing -   0.07142857142857142\n",
      "\n",
      "'s OCR   0.0196078431372549\n",
      "\n",
      "This is   0.2698412698412698\n",
      "\n",
      "driven ,   1.0\n",
      "\n",
      "more difficult   0.07368421052631578\n",
      "\n",
      "fly have   1.0\n",
      "\n",
      "lines ,   0.3333333333333333\n",
      "\n",
      "derive meaning   0.5\n",
      "\n",
      "<s> Before   0.0007686395080707148\n",
      "\n",
      "by their   0.005714285714285714\n",
      "\n",
      "technologies for   0.25\n",
      "\n",
      "hearings -RRB-   1.0\n",
      "\n",
      "Although ,   0.125\n",
      "\n",
      "utilize large   0.5\n",
      "\n",
      "shallow ''   0.16666666666666666\n",
      "\n",
      "includes Turney   0.14285714285714285\n",
      "\n",
      "parse individual   0.1111111111111111\n",
      "\n",
      "levels in   0.045454545454545456\n",
      "\n",
      "feature segment   0.07692307692307693\n",
      "\n",
      "accommodate ambiguity   0.4\n",
      "\n",
      "but IE   0.014705882352941176\n",
      "\n",
      "of one   0.0035650623885918\n",
      "\n",
      "commercially available   1.0\n",
      "\n",
      "several alternative   0.045454545454545456\n",
      "\n",
      "However the   0.02702702702702703\n",
      "\n",
      "ACL Anthology   0.5\n",
      "\n",
      "He taught   0.125\n",
      "\n",
      "be translated   0.012658227848101266\n",
      "\n",
      "You are   1.0\n",
      "\n",
      "setting radio   0.2\n",
      "\n",
      ", showing   0.0005614823133071309\n",
      "\n",
      "calling for   1.0\n",
      "\n",
      "an integrated   0.007575757575757576\n",
      "\n",
      "accuracies in   1.0\n",
      "\n",
      "programmers began   1.0\n",
      "\n",
      "necessary to   0.2\n",
      "\n",
      "`` out   0.005291005291005291\n",
      "\n",
      "ontology requires   0.5\n",
      "\n",
      "Robert de   0.25\n",
      "\n",
      "emoticons ,   1.0\n",
      "\n",
      "Vocabulary size   0.3333333333333333\n",
      "\n",
      "DTW has   0.3333333333333333\n",
      "\n",
      "take the   0.2\n",
      "\n",
      "speech Task   0.006578947368421052\n",
      "\n",
      "principled way   1.0\n",
      "\n",
      "Language Processor   0.08333333333333333\n",
      "\n",
      "automotive maintenance   1.0\n",
      "\n",
      "training a   0.03571428571428571\n",
      "\n",
      "an intermediary   0.007575757575757576\n",
      "\n",
      "vendors in   0.25\n",
      "\n",
      "quite similar   0.125\n",
      "\n",
      "pasted ,   1.0\n",
      "\n",
      "or profession   0.0045045045045045045\n",
      "\n",
      "also quite   0.014492753623188406\n",
      "\n",
      "degraded-images ,   1.0\n",
      "\n",
      "Who invented   0.5\n",
      "\n",
      "The performance   0.005208333333333333\n",
      "\n",
      "Language modeling   0.08333333333333333\n",
      "\n",
      "of context   0.0017825311942959\n",
      "\n",
      "of medical   0.0017825311942959\n",
      "\n",
      "it up   0.008547008547008548\n",
      "\n",
      "evaluation systems   0.018518518518518517\n",
      "\n",
      "-RRB- dogs   0.0027100271002710027\n",
      "\n",
      "sentences at   0.013157894736842105\n",
      "\n",
      "that ,   0.0035460992907801418\n",
      "\n",
      "categories ;   0.1111111111111111\n",
      "\n",
      "probability to   0.14285714285714285\n",
      "\n",
      "documents than   0.02631578947368421\n",
      "\n",
      "their linguistic   0.029411764705882353\n",
      "\n",
      "weapon critical   0.5\n",
      "\n",
      "to that   0.0026560424966799467\n",
      "\n",
      "in embedded   0.0018726591760299626\n",
      "\n",
      "highly-specialized natural   1.0\n",
      "\n",
      "autopilot system   1.0\n",
      "\n",
      "-LRB- although   0.005420054200542005\n",
      "\n",
      "grammar Rhetoric   0.02702702702702703\n",
      "\n",
      "isloated and   1.0\n",
      "\n",
      "Why did   0.14285714285714285\n",
      "\n",
      "is necessary   0.0040650406504065045\n",
      "\n",
      "non-trivial techniques   0.5\n",
      "\n",
      "removing objective   0.5\n",
      "\n",
      "all alternative   0.023255813953488372\n",
      "\n",
      "achieved accuracy   0.2\n",
      "\n",
      "a high   0.0036809815950920245\n",
      "\n",
      "tasks due   0.03125\n",
      "\n",
      "better data   0.1111111111111111\n",
      "\n",
      "component of   0.6\n",
      "\n",
      "Sometimes it   1.0\n",
      "\n",
      "not a   0.008928571428571428\n",
      "\n",
      "machine would   0.02531645569620253\n",
      "\n",
      "English POS-taggers   0.02702702702702703\n",
      "\n",
      "task it   0.023809523809523808\n",
      "\n",
      ", cognitive   0.0005614823133071309\n",
      "\n",
      "a grammar   0.00245398773006135\n",
      "\n",
      "turn also   0.16666666666666666\n",
      "\n",
      "answering have   0.08333333333333333\n",
      "\n",
      "`` centroid   0.005291005291005291\n",
      "\n",
      "look -LRB-   0.2\n",
      "\n",
      "anymore ,   1.0\n",
      "\n",
      "Poncini ,   1.0\n",
      "\n",
      "at by   0.014705882352941176\n",
      "\n",
      "but robustness   0.014705882352941176\n",
      "\n",
      "the advent   0.0006920415224913495\n",
      "\n",
      "feature dependencies   0.07692307692307693\n",
      "\n",
      "page .   0.14285714285714285\n",
      "\n",
      "that words   0.0070921985815602835\n",
      "\n",
      "<s> Since   0.0030745580322828594\n",
      "\n",
      "Jay Lemke   1.0\n",
      "\n",
      "in source   0.0018726591760299626\n",
      "\n",
      "addressed in   0.5\n",
      "\n",
      "Audio Processing   0.5\n",
      "\n",
      "available for   0.11764705882352941\n",
      "\n",
      "polynomial time   1.0\n",
      "\n",
      "the application   0.0006920415224913495\n",
      "\n",
      "questioner ,   0.5\n",
      "\n",
      "the basis   0.002768166089965398\n",
      "\n",
      "clip of   1.0\n",
      "\n",
      "extraction can   0.03225806451612903\n",
      "\n",
      "above text   0.07692307692307693\n",
      "\n",
      "as SVM   0.003484320557491289\n",
      "\n",
      "parameter estimation   1.0\n",
      "\n",
      "modeling and   0.14285714285714285\n",
      "\n",
      "2004 ,   0.3333333333333333\n",
      "\n",
      "thousands or   0.3333333333333333\n",
      "\n",
      "Isolated ,   1.0\n",
      "\n",
      "discourse processing   0.027777777777777776\n",
      "\n",
      "should vertices   0.05263157894736842\n",
      "\n",
      "the 1990s   0.001384083044982699\n",
      "\n",
      "and early   0.001445086705202312\n",
      "\n",
      "1990 -RRB-   0.6666666666666666\n",
      "\n",
      "the barmaid   0.0006920415224913495\n",
      "\n",
      "would recognize   0.018867924528301886\n",
      "\n",
      "recogniton by   0.5\n",
      "\n",
      "an autopilot   0.007575757575757576\n",
      "\n",
      "corpus of   0.22580645161290322\n",
      "\n",
      "A more   0.02\n",
      "\n",
      "first order   0.030303030303030304\n",
      "\n",
      "each whole   0.022222222222222223\n",
      "\n",
      "-RRB- an   0.0027100271002710027\n",
      "\n",
      "papers on   0.6666666666666666\n",
      "\n",
      "perform complex   0.09090909090909091\n",
      "\n",
      "tagger ,   0.4444444444444444\n",
      "\n",
      "be reached   0.004219409282700422\n",
      "\n",
      "both time   0.03225806451612903\n",
      "\n",
      "considerable attention   0.2\n",
      "\n",
      "big green   0.5\n",
      "\n",
      "parse natural   0.1111111111111111\n",
      "\n",
      "generated summaries   0.06666666666666667\n",
      "\n",
      "<s> ,   0.0007686395080707148\n",
      "\n",
      "that perform   0.0035460992907801418\n",
      "\n",
      "right-hand-sides of   1.0\n",
      "\n",
      "the simulation   0.0006920415224913495\n",
      "\n",
      "unveiled during   1.0\n",
      "\n",
      "represented by   0.3333333333333333\n",
      "\n",
      "then using   0.02857142857142857\n",
      "\n",
      "they observe   0.025\n",
      "\n",
      "famous article   0.3333333333333333\n",
      "\n",
      "-LRB- a   0.013550135501355014\n",
      "\n",
      "higher error   0.14285714285714285\n",
      "\n",
      "<s> Precision   0.0007686395080707148\n",
      "\n",
      "news documents   0.07692307692307693\n",
      "\n",
      "evaluations have   0.16666666666666666\n",
      "\n",
      "its designers   0.02857142857142857\n",
      "\n",
      "undertaken ,   0.5\n",
      "\n",
      "allow blind   0.2\n",
      "\n",
      "a number   0.024539877300613498\n",
      "\n",
      "interaction Pronunciation   0.125\n",
      "\n",
      "application where   0.07142857142857142\n",
      "\n",
      "Semi-supervised and   1.0\n",
      "\n",
      "Penicillin ''   1.0\n",
      "\n",
      "humans as   0.08333333333333333\n",
      "\n",
      "non-whitespace character   1.0\n",
      "\n",
      "the presence   0.0006920415224913495\n",
      "\n",
      "David 's   0.25\n",
      "\n",
      "languages such   0.1\n",
      "\n",
      "In 1970   0.009523809523809525\n",
      "\n",
      "war camp   1.0\n",
      "\n",
      "quality and   0.1\n",
      "\n",
      "semantics -RRB-   0.07142857142857142\n",
      "\n",
      "sentence .   0.14583333333333334\n",
      "\n",
      "seen before   0.2\n",
      "\n",
      "classes are   0.2\n",
      "\n",
      "analysis aims   0.015384615384615385\n",
      "\n",
      "lexical analyser   0.07692307692307693\n",
      "\n",
      "constructions occur   1.0\n",
      "\n",
      "assigns large   1.0\n",
      "\n",
      "great success   0.3333333333333333\n",
      "\n",
      "in depth   0.0018726591760299626\n",
      "\n",
      "explored .   0.5\n",
      "\n",
      "\\* -LRB-   0.25\n",
      "\n",
      "language using   0.006756756756756757\n",
      "\n",
      ", -LRB-   0.0016844469399213925\n",
      "\n",
      "Lichtenstein ?   1.0\n",
      "\n",
      "French and   0.25\n",
      "\n",
      "vector of   0.3333333333333333\n",
      "\n",
      "developed by   0.038461538461538464\n",
      "\n",
      "We apply   0.14285714285714285\n",
      "\n",
      "it quite   0.008547008547008548\n",
      "\n",
      "often the   0.045454545454545456\n",
      "\n",
      "very dependent   0.024390243902439025\n",
      "\n",
      "desired language   0.2\n",
      "\n",
      "fairly often   0.25\n",
      "\n",
      "in 1989   0.0018726591760299626\n",
      "\n",
      "parsing written   0.03571428571428571\n",
      "\n",
      "of keywords   0.00089126559714795\n",
      "\n",
      "company for   0.3333333333333333\n",
      "\n",
      "have more   0.028846153846153848\n",
      "\n",
      "exploited ;   1.0\n",
      "\n",
      "Cross-Sentence Information   1.0\n",
      "\n",
      "<s> might   0.0007686395080707148\n",
      "\n",
      "Speech is   0.06451612903225806\n",
      "\n",
      "multi-document extractive   0.25\n",
      "\n",
      "a tag   0.001226993865030675\n",
      "\n",
      "despite being   0.3333333333333333\n",
      "\n",
      "of databases   0.00089126559714795\n",
      "\n",
      "A typical   0.04\n",
      "\n",
      "of rule-based   0.00089126559714795\n",
      "\n",
      "In fact   0.0380952380952381\n",
      "\n",
      "for heavily   0.0036101083032490976\n",
      "\n",
      "2005 -RRB-   1.0\n",
      "\n",
      "over sixty   0.08333333333333333\n",
      "\n",
      "of different   0.0017825311942959\n",
      "\n",
      "different strategies   0.02040816326530612\n",
      "\n",
      "Little further   1.0\n",
      "\n",
      "the case   0.005536332179930796\n",
      "\n",
      "man ''   1.0\n",
      "\n",
      "e.g. SCU   0.017857142857142856\n",
      "\n",
      "early successes   0.1\n",
      "\n",
      "for quantitatively   0.0036101083032490976\n",
      "\n",
      "Corpus of   0.0625\n",
      "\n",
      "structure The   0.08333333333333333\n",
      "\n",
      "large corpus   0.043478260869565216\n",
      "\n",
      "a ''   0.001226993865030675\n",
      "\n",
      "approximate at   0.5\n",
      "\n",
      "several words   0.045454545454545456\n",
      "\n",
      "of papers   0.00089126559714795\n",
      "\n",
      "thought of   0.6666666666666666\n",
      "\n",
      "an utterance   0.015151515151515152\n",
      "\n",
      "pauses .   0.25\n",
      "\n",
      "system-generated summaries   0.5\n",
      "\n",
      "part -LRB-   0.037037037037037035\n",
      "\n",
      "translation at   0.013513513513513514\n",
      "\n",
      "produce such   0.045454545454545456\n",
      "\n",
      "has interest   0.011904761904761904\n",
      "\n",
      "<s> Individuals   0.0007686395080707148\n",
      "\n",
      "'s students   0.0196078431372549\n",
      "\n",
      "Corpus and   0.125\n",
      "\n",
      "string of   1.0\n",
      "\n",
      "2004 .   0.3333333333333333\n",
      "\n",
      "be considered   0.008438818565400843\n",
      "\n",
      "volume of   0.5\n",
      "\n",
      "to computers   0.0013280212483399733\n",
      "\n",
      "than of   0.022222222222222223\n",
      "\n",
      "ISO sub-committee   0.5\n",
      "\n",
      "conduct with   1.0\n",
      "\n",
      "meantime ,   1.0\n",
      "\n",
      "list ,   0.09090909090909091\n",
      "\n",
      "other English   0.014285714285714285\n",
      "\n",
      "the quantitative   0.0006920415224913495\n",
      "\n",
      "-LRB- 99   0.0027100271002710027\n",
      "\n",
      "disease ,   1.0\n",
      "\n",
      "Thompson ,   1.0\n",
      "\n",
      "the World   0.0034602076124567475\n",
      "\n",
      "Hulth uses   0.3333333333333333\n",
      "\n",
      "Summarization systems   0.25\n",
      "\n",
      "courses of   1.0\n",
      "\n",
      "more interest   0.010526315789473684\n",
      "\n",
      "`` Sentiment   0.005291005291005291\n",
      "\n",
      "writing style   0.1111111111111111\n",
      "\n",
      "incorrect assignment   0.3333333333333333\n",
      "\n",
      "coined the   1.0\n",
      "\n",
      "applied the   0.06666666666666667\n",
      "\n",
      "150,000 words   1.0\n",
      "\n",
      "over hand-produced   0.08333333333333333\n",
      "\n",
      "accusative ,   1.0\n",
      "\n",
      "with equivalent   0.01092896174863388\n",
      "\n",
      "helicopters is   0.5\n",
      "\n",
      "tasks from   0.03125\n",
      "\n",
      "on machine-learning   0.0047169811320754715\n",
      "\n",
      "going over   0.25\n",
      "\n",
      "trivial due   0.25\n",
      "\n",
      "to help   0.0026560424966799467\n",
      "\n",
      "algorithm could   0.03571428571428571\n",
      "\n",
      ", stutering   0.0005614823133071309\n",
      "\n",
      "and conversations   0.001445086705202312\n",
      "\n",
      "the foreign   0.0006920415224913495\n",
      "\n",
      "random walk   0.5714285714285714\n",
      "\n",
      "automatic analysis   0.043478260869565216\n",
      "\n",
      "use software   0.013888888888888888\n",
      "\n",
      "affected by   1.0\n",
      "\n",
      "linked in   0.3333333333333333\n",
      "\n",
      "Searches ,   1.0\n",
      "\n",
      "an expression   0.007575757575757576\n",
      "\n",
      "Data sources   1.0\n",
      "\n",
      "-RRB- from   0.0027100271002710027\n",
      "\n",
      "to parse   0.005312084993359893\n",
      "\n",
      "original source   0.07692307692307693\n",
      "\n",
      "the relationship   0.0006920415224913495\n",
      "\n",
      "widely used   0.875\n",
      "\n",
      "discriminate between   0.3333333333333333\n",
      "\n",
      "complex matter   0.041666666666666664\n",
      "\n",
      "is parsing   0.0020325203252032522\n",
      "\n",
      "have been   0.25\n",
      "\n",
      "profession -LRB-   1.0\n",
      "\n",
      "more deeply   0.010526315789473684\n",
      "\n",
      "and may   0.002890173410404624\n",
      "\n",
      "declared before   0.5\n",
      "\n",
      "Much remains   0.3333333333333333\n",
      "\n",
      "ICR .   0.3333333333333333\n",
      "\n",
      "language comprehension   0.006756756756756757\n",
      "\n",
      "Sept. 1955   1.0\n",
      "\n",
      "most text   0.017241379310344827\n",
      "\n",
      "signals are   1.0\n",
      "\n",
      "selecting a   0.4\n",
      "\n",
      "`` depth   0.005291005291005291\n",
      "\n",
      "Why unsupervised   0.14285714285714285\n",
      "\n",
      "research also   0.023809523809523808\n",
      "\n",
      "punctuation and   0.2857142857142857\n",
      "\n",
      "its decomposition   0.02857142857142857\n",
      "\n",
      "documents containing   0.02631578947368421\n",
      "\n",
      "strengths of   0.5\n",
      "\n",
      ", made   0.0011229646266142617\n",
      "\n",
      "characterised by   1.0\n",
      "\n",
      "think about   0.3333333333333333\n",
      "\n",
      "triples and   0.3333333333333333\n",
      "\n",
      "lexer would   1.0\n",
      "\n",
      "can aid   0.0055248618784530384\n",
      "\n",
      "field within   0.037037037037037035\n",
      "\n",
      "to text   0.0026560424966799467\n",
      "\n",
      "northeast of   1.0\n",
      "\n",
      "interactivity -LRB-   1.0\n",
      "\n",
      "tag-sets .   1.0\n",
      "\n",
      "inherent expressivity   1.0\n",
      "\n",
      "choice :   0.125\n",
      "\n",
      "tourism information   1.0\n",
      "\n",
      "10msec ,   0.5\n",
      "\n",
      "generated out   0.06666666666666667\n",
      "\n",
      "Giro ,   1.0\n",
      "\n",
      "given rise   0.041666666666666664\n",
      "\n",
      "sublanguage analysis   0.3333333333333333\n",
      "\n",
      "can make   0.016574585635359115\n",
      "\n",
      "intent .   1.0\n",
      "\n",
      "phrase `   0.1\n",
      "\n",
      "times they   0.2\n",
      "\n",
      "and applications   0.001445086705202312\n",
      "\n",
      "corpus -LRB-   0.03225806451612903\n",
      "\n",
      "usually asked   0.03125\n",
      "\n",
      "-LRB- now   0.008130081300813009\n",
      "\n",
      "humans transcribe   0.08333333333333333\n",
      "\n",
      "unit block   0.3333333333333333\n",
      "\n",
      "200 billion   0.5\n",
      "\n",
      "Angenot ,   1.0\n",
      "\n",
      "<s> Consider   0.0015372790161414297\n",
      "\n",
      "summarization system   0.06\n",
      "\n",
      "document production   0.027777777777777776\n",
      "\n",
      "referring expression   0.5\n",
      "\n",
      ": Decoding   0.00980392156862745\n",
      "\n",
      "Similarly ,   1.0\n",
      "\n",
      "recognition vary   0.008264462809917356\n",
      "\n",
      "growing interest   0.5\n",
      "\n",
      "model avoids   0.03333333333333333\n",
      "\n",
      "undertook recognition   1.0\n",
      "\n",
      "expended to   1.0\n",
      "\n",
      "mention in   0.3333333333333333\n",
      "\n",
      "interrogative -LRB-   1.0\n",
      "\n",
      "sociolinguistics Ethnography   0.5\n",
      "\n",
      "statistical properties   0.030303030303030304\n",
      "\n",
      "connected Web   0.2\n",
      "\n",
      "distinction ,   0.2\n",
      "\n",
      "speech into   0.013157894736842105\n",
      "\n",
      "redundant sentences   1.0\n",
      "\n",
      "teams to   0.5\n",
      "\n",
      "of sentence   0.00089126559714795\n",
      "\n",
      "example for   0.024691358024691357\n",
      "\n",
      "and visible   0.001445086705202312\n",
      "\n",
      "Security Agency   1.0\n",
      "\n",
      "2006 hurricane   0.3333333333333333\n",
      "\n",
      "achieved only   0.1\n",
      "\n",
      "of allowing   0.00089126559714795\n",
      "\n",
      "inputting approximately   1.0\n",
      "\n",
      ", people   0.0005614823133071309\n",
      "\n",
      "of effort   0.00089126559714795\n",
      "\n",
      "the photos   0.0006920415224913495\n",
      "\n",
      "the accuracy   0.0006920415224913495\n",
      "\n",
      "candidates for   0.2\n",
      "\n",
      "telephone .   0.5\n",
      "\n",
      "<s> Lexical   0.0015372790161414297\n",
      "\n",
      "unambiguous sentence-ending   0.5\n",
      "\n",
      "The accuracy   0.010416666666666666\n",
      "\n",
      ", funding   0.0016844469399213925\n",
      "\n",
      "D. Faber   0.2\n",
      "\n",
      "be explained   0.004219409282700422\n",
      "\n",
      "being psychotherapy   0.05555555555555555\n",
      "\n",
      ", Rajman   0.0005614823133071309\n",
      "\n",
      "of artificial   0.00089126559714795\n",
      "\n",
      "to automatizing   0.0013280212483399733\n",
      "\n",
      "to language   0.0013280212483399733\n",
      "\n",
      "difficulty of   0.42857142857142855\n",
      "\n",
      "and transmitting   0.001445086705202312\n",
      "\n",
      ", Gdaniec   0.0005614823133071309\n",
      "\n",
      "parsing community   0.03571428571428571\n",
      "\n",
      "language such   0.006756756756756757\n",
      "\n",
      "campaign on   0.2\n",
      "\n",
      "Machinery and   1.0\n",
      "\n",
      "many researchers   0.019230769230769232\n",
      "\n",
      "and Sentences   0.001445086705202312\n",
      "\n",
      "n't see   0.25\n",
      "\n",
      "high degree   0.05555555555555555\n",
      "\n",
      "of these   0.00980392156862745\n",
      "\n",
      "minimizes the   1.0\n",
      "\n",
      "'s Mars   0.0196078431372549\n",
      "\n",
      "Another resource   0.07692307692307693\n",
      "\n",
      "networks make   0.07142857142857142\n",
      "\n",
      "been especially   0.014705882352941176\n",
      "\n",
      "at language   0.014705882352941176\n",
      "\n",
      "He entered   0.125\n",
      "\n",
      "posts and   1.0\n",
      "\n",
      "represent .   0.2222222222222222\n",
      "\n",
      "to Recognize   0.0013280212483399733\n",
      "\n",
      "tags ,   0.3333333333333333\n",
      "\n",
      "text contains   0.006289308176100629\n",
      "\n",
      "Deferred speech   1.0\n",
      "\n",
      "dimensions of   0.6666666666666666\n",
      "\n",
      "Text grammar   0.16666666666666666\n",
      "\n",
      "news-gathering ,   1.0\n",
      "\n",
      "structured into   0.16666666666666666\n",
      "\n",
      "of general   0.00089126559714795\n",
      "\n",
      "can add   0.0055248618784530384\n",
      "\n",
      "software for   0.037037037037037035\n",
      "\n",
      "extensive lexicons   0.3333333333333333\n",
      "\n",
      "years ,   0.23809523809523808\n",
      "\n",
      ", simple   0.0011229646266142617\n",
      "\n",
      "corpus .   0.03225806451612903\n",
      "\n",
      "in solving   0.0018726591760299626\n",
      "\n",
      "reports -RRB-   0.4\n",
      "\n",
      "distinction is   0.4\n",
      "\n",
      "<s> Referring   0.0007686395080707148\n",
      "\n",
      "edges build   0.14285714285714285\n",
      "\n",
      "Large-scale evaluation   1.0\n",
      "\n",
      "absolutely necessary   1.0\n",
      "\n",
      ", aspect   0.0005614823133071309\n",
      "\n",
      "it word   0.008547008547008548\n",
      "\n",
      "also stems   0.014492753623188406\n",
      "\n",
      "analysis or   0.046153846153846156\n",
      "\n",
      "instance some   0.07142857142857142\n",
      "\n",
      "tokens -LRB-   0.14285714285714285\n",
      "\n",
      "Conversation analysis   1.0\n",
      "\n",
      "best guesses   0.05555555555555555\n",
      "\n",
      "robust when   0.5\n",
      "\n",
      "in their   0.00749063670411985\n",
      "\n",
      "burden on   1.0\n",
      "\n",
      "describe informal   0.16666666666666666\n",
      "\n",
      "steps of   0.5\n",
      "\n",
      "quality .   0.1\n",
      "\n",
      "positives by   1.0\n",
      "\n",
      "has fueled   0.011904761904761904\n",
      "\n",
      "could search   0.0625\n",
      "\n",
      "use ``   0.013888888888888888\n",
      "\n",
      "lexical units   0.07692307692307693\n",
      "\n",
      "any markup   0.03225806451612903\n",
      "\n",
      "be able   0.02109704641350211\n",
      "\n",
      "Tipster project   1.0\n",
      "\n",
      "of distinct   0.00089126559714795\n",
      "\n",
      "amongst a   1.0\n",
      "\n",
      "be based   0.004219409282700422\n",
      "\n",
      "Michel Foucault   1.0\n",
      "\n",
      "<s> ``   0.003843197540353574\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from those   0.019230769230769232\n",
      "\n",
      "parsers is   0.07692307692307693\n",
      "\n",
      "machines or   0.25\n",
      "\n",
      "rarely successful   0.3333333333333333\n",
      "\n",
      "objects -LRB-   0.2\n",
      "\n",
      "evaluation comes   0.018518518518518517\n",
      "\n",
      "observed vector   1.0\n",
      "\n",
      "is vital   0.0020325203252032522\n",
      "\n",
      "Joseph Weizenbaum   1.0\n",
      "\n",
      "and hearings   0.001445086705202312\n",
      "\n",
      ". <s/>   0.9875195007800313\n",
      "\n",
      "using the   0.1016949152542373\n",
      "\n",
      "using elements   0.01694915254237288\n",
      "\n",
      "a character   0.001226993865030675\n",
      "\n",
      "both individual   0.03225806451612903\n",
      "\n",
      "the mid   0.0006920415224913495\n",
      "\n",
      "derivation or   0.25\n",
      "\n",
      "sentence such   0.020833333333333332\n",
      "\n",
      "Canadian Hansard   0.5\n",
      "\n",
      "OCR Accuracy   0.02040816326530612\n",
      "\n",
      "are grouped   0.004149377593360996\n",
      "\n",
      "from computer   0.009615384615384616\n",
      "\n",
      "syntax to   0.18181818181818182\n",
      "\n",
      "several systems   0.045454545454545456\n",
      "\n",
      "SemEval -RRB-   1.0\n",
      "\n",
      "unit ,   0.3333333333333333\n",
      "\n",
      "Rabiner can   1.0\n",
      "\n",
      "answers might   0.08333333333333333\n",
      "\n",
      "their underlying   0.029411764705882353\n",
      "\n",
      "has yet   0.011904761904761904\n",
      "\n",
      "broad tags   0.25\n",
      "\n",
      ", sometimes   0.0005614823133071309\n",
      "\n",
      "aloud from   1.0\n",
      "\n",
      "translation studies   0.013513513513513514\n",
      "\n",
      "as keyphrases   0.003484320557491289\n",
      "\n",
      "morphologically rich   1.0\n",
      "\n",
      "profiling for   1.0\n",
      "\n",
      "`` Computing   0.005291005291005291\n",
      "\n",
      "e.g. containing   0.017857142857142856\n",
      "\n",
      "word co-occurrence   0.016666666666666666\n",
      "\n",
      "led to   0.6666666666666666\n",
      "\n",
      "summaries helps   0.023255813953488372\n",
      "\n",
      "answer the   0.03333333333333333\n",
      "\n",
      "sounds on   0.06666666666666667\n",
      "\n",
      "-LRB- disambiguation   0.0027100271002710027\n",
      "\n",
      "theories of   0.6\n",
      "\n",
      "as voice   0.003484320557491289\n",
      "\n",
      "Functional grammar   1.0\n",
      "\n",
      "a deterministic   0.00245398773006135\n",
      "\n",
      "recommend ''   1.0\n",
      "\n",
      "not aid   0.008928571428571428\n",
      "\n",
      "Natural language   0.6666666666666666\n",
      "\n",
      "Mars Polar   0.5\n",
      "\n",
      "action is   0.2\n",
      "\n",
      "made more   0.125\n",
      "\n",
      "included as   0.125\n",
      "\n",
      "in determining   0.0018726591760299626\n",
      "\n",
      "code on   0.14285714285714285\n",
      "\n",
      "single ``   0.07142857142857142\n",
      "\n",
      "adjacent and   0.16666666666666666\n",
      "\n",
      "Q&A systems   1.0\n",
      "\n",
      "companies to   0.5\n",
      "\n",
      "part usually   0.037037037037037035\n",
      "\n",
      "language parsing   0.013513513513513514\n",
      "\n",
      "casual speech   1.0\n",
      "\n",
      "i.e. relationship   0.05263157894736842\n",
      "\n",
      "field which   0.037037037037037035\n",
      "\n",
      "of around   0.0017825311942959\n",
      "\n",
      "with one   0.00546448087431694\n",
      "\n",
      "conducted until   0.2\n",
      "\n",
      "the output   0.0020761245674740486\n",
      "\n",
      "extent with   0.25\n",
      "\n",
      "learned from   0.2\n",
      "\n",
      "Biden visited   0.3333333333333333\n",
      "\n",
      "University by   0.1111111111111111\n",
      "\n",
      "the second   0.001384083044982699\n",
      "\n",
      "learning algorithms   0.11627906976744186\n",
      "\n",
      "the algorithms   0.001384083044982699\n",
      "\n",
      "exploration ,   1.0\n",
      "\n",
      "by PageRank   0.005714285714285714\n",
      "\n",
      "from non   0.009615384615384616\n",
      "\n",
      "who maintains   0.1\n",
      "\n",
      "a function   0.001226993865030675\n",
      "\n",
      "uses spontaneous   0.07142857142857142\n",
      "\n",
      "to acquire   0.0013280212483399733\n",
      "\n",
      "to conduct   0.0013280212483399733\n",
      "\n",
      "NLP Handbook   0.02127659574468085\n",
      "\n",
      "both very   0.03225806451612903\n",
      "\n",
      "` global   0.0625\n",
      "\n",
      "it requires   0.017094017094017096\n",
      "\n",
      "somehow internalize   1.0\n",
      "\n",
      "system also   0.010752688172043012\n",
      "\n",
      "1981 -RRB-   1.0\n",
      "\n",
      "ratings are   0.2222222222222222\n",
      "\n",
      "disambiguation :   0.1\n",
      "\n",
      "system operators   0.010752688172043012\n",
      "\n",
      "spoken ,   0.14285714285714285\n",
      "\n",
      "more and   0.021052631578947368\n",
      "\n",
      "book does   0.125\n",
      "\n",
      "against any   0.2\n",
      "\n",
      "Semantic analysis   0.3333333333333333\n",
      "\n",
      "implemented by   0.2\n",
      "\n",
      "-RRB- approach   0.0027100271002710027\n",
      "\n",
      "undertaken to   0.5\n",
      "\n",
      "in further   0.0018726591760299626\n",
      "\n",
      "of summarization   0.0071301247771836\n",
      "\n",
      "judgments .   1.0\n",
      "\n",
      "corp. .   1.0\n",
      "\n",
      "his students   0.16666666666666666\n",
      "\n",
      "A different   0.04\n",
      "\n",
      "in computational   0.003745318352059925\n",
      "\n",
      "is generally   0.0020325203252032522\n",
      "\n",
      "worth remembering   0.5\n",
      "\n",
      "early text-to-speech   0.1\n",
      "\n",
      "ontologies and   0.16666666666666666\n",
      "\n",
      "on his   0.0047169811320754715\n",
      "\n",
      "to ask   0.0013280212483399733\n",
      "\n",
      "call ''   0.3333333333333333\n",
      "\n",
      "recently identified   0.3333333333333333\n",
      "\n",
      "been explored   0.014705882352941176\n",
      "\n",
      "feature in   0.07692307692307693\n",
      "\n",
      "an adjective   0.03787878787878788\n",
      "\n",
      "notoriously ,   1.0\n",
      "\n",
      "four different   0.2857142857142857\n",
      "\n",
      "computer user   0.022727272727272728\n",
      "\n",
      "1970 -RRB-   0.3333333333333333\n",
      "\n",
      "find answers   0.07692307692307693\n",
      "\n",
      "more recent   0.010526315789473684\n",
      "\n",
      "semantic similarity   0.047619047619047616\n",
      "\n",
      "<s> Trained   0.0007686395080707148\n",
      "\n",
      "as CLAWS   0.003484320557491289\n",
      "\n",
      "each feature\\/aspect   0.022222222222222223\n",
      "\n",
      "where at   0.02857142857142857\n",
      "\n",
      "which associate   0.007246376811594203\n",
      "\n",
      "the lexical   0.0006920415224913495\n",
      "\n",
      "popular being   0.1111111111111111\n",
      "\n",
      "basically a   1.0\n",
      "\n",
      "domains and   0.25\n",
      "\n",
      "with increasing   0.00546448087431694\n",
      "\n",
      "extraction system   0.06451612903225806\n",
      "\n",
      "approach ,   0.05714285714285714\n",
      "\n",
      "card imprints   0.25\n",
      "\n",
      "Turkish ,   1.0\n",
      "\n",
      "12 \\*   0.4\n",
      "\n",
      "recognition scores   0.008264462809917356\n",
      "\n",
      "been encouraging   0.014705882352941176\n",
      "\n",
      "i.e. source   0.05263157894736842\n",
      "\n",
      "exception ,   1.0\n",
      "\n",
      "word ``   0.016666666666666666\n",
      "\n",
      "were spoken   0.024390243902439025\n",
      "\n",
      "ratings for   0.1111111111111111\n",
      "\n",
      "reading text   0.125\n",
      "\n",
      "<s> Application-Oriented   0.0007686395080707148\n",
      "\n",
      "documents in   0.02631578947368421\n",
      "\n",
      "an original   0.007575757575757576\n",
      "\n",
      "-LRB- perhaps   0.0027100271002710027\n",
      "\n",
      "a novel   0.001226993865030675\n",
      "\n",
      "pronunciations or   1.0\n",
      "\n",
      "<s> Hybrid   0.0007686395080707148\n",
      "\n",
      "computational linguistics   0.6\n",
      "\n",
      "be defined   0.004219409282700422\n",
      "\n",
      "device required   0.5\n",
      "\n",
      "giving these   0.5\n",
      "\n",
      "political forums   0.3333333333333333\n",
      "\n",
      "into each   0.01282051282051282\n",
      "\n",
      "for medical   0.0036101083032490976\n",
      "\n",
      "`` centrality   0.005291005291005291\n",
      "\n",
      "position of   0.25\n",
      "\n",
      "and life   0.001445086705202312\n",
      "\n",
      "probability is   0.14285714285714285\n",
      "\n",
      "1993 .   0.3333333333333333\n",
      "\n",
      "factory -RRB-   1.0\n",
      "\n",
      "Lightning II   1.0\n",
      "\n",
      "punctuation marks   0.2857142857142857\n",
      "\n",
      "of trying   0.00089126559714795\n",
      "\n",
      "ALPAC report   1.0\n",
      "\n",
      "humans to   0.08333333333333333\n",
      "\n",
      "of 500   0.0017825311942959\n",
      "\n",
      "any condition   0.03225806451612903\n",
      "\n",
      "upper level   1.0\n",
      "\n",
      "after 30   0.08333333333333333\n",
      "\n",
      "typically uses   0.05555555555555555\n",
      "\n",
      "to resort   0.0013280212483399733\n",
      "\n",
      "evaluation metrics   0.018518518518518517\n",
      "\n",
      "Black-box vs.   0.5\n",
      "\n",
      "make ;   0.05\n",
      "\n",
      ", answered   0.0005614823133071309\n",
      "\n",
      "RCA product   0.2\n",
      "\n",
      "reliable sources   0.25\n",
      "\n",
      "studied more   1.0\n",
      "\n",
      ", merging   0.0005614823133071309\n",
      "\n",
      "boundaries are   0.09090909090909091\n",
      "\n",
      "was used   0.05194805194805195\n",
      "\n",
      "distinct parts   0.14285714285714285\n",
      "\n",
      "-LRB- IE   0.005420054200542005\n",
      "\n",
      "of anaphora   0.00089126559714795\n",
      "\n",
      "50 %   0.6666666666666666\n",
      "\n",
      "Wilensky ,   1.0\n",
      "\n",
      "the evaluation   0.0034602076124567475\n",
      "\n",
      "psychologist .   1.0\n",
      "\n",
      "Part-of-speech Tagging   0.5\n",
      "\n",
      "being followed   0.05555555555555555\n",
      "\n",
      "machine printed   0.012658227848101266\n",
      "\n",
      "Fairclough ,   1.0\n",
      "\n",
      "the legends   0.0006920415224913495\n",
      "\n",
      "noun -LRB-   0.07142857142857142\n",
      "\n",
      "projects never   0.5\n",
      "\n",
      "lessons learned   1.0\n",
      "\n",
      "E-set :   1.0\n",
      "\n",
      "above to   0.07692307692307693\n",
      "\n",
      "into two   0.01282051282051282\n",
      "\n",
      "robot in   0.5\n",
      "\n",
      "engineers worked   1.0\n",
      "\n",
      "Corps of   1.0\n",
      "\n",
      "inserts those   1.0\n",
      "\n",
      "which make   0.014492753623188406\n",
      "\n",
      "knowledge representation   0.037037037037037035\n",
      "\n",
      "work in   0.125\n",
      "\n",
      "'' of   0.005154639175257732\n",
      "\n",
      "here there   0.5\n",
      "\n",
      "must take   0.07142857142857142\n",
      "\n",
      "to dozens   0.0013280212483399733\n",
      "\n",
      "usage is   1.0\n",
      "\n",
      "moves ,   1.0\n",
      "\n",
      "summaries -RRB-   0.023255813953488372\n",
      "\n",
      "also growing   0.014492753623188406\n",
      "\n",
      "a wave   0.0049079754601227\n",
      "\n",
      "easier to   0.25\n",
      "\n",
      "difficult for   0.03571428571428571\n",
      "\n",
      "extraction :   0.06451612903225806\n",
      "\n",
      "large-scale content-analysis   1.0\n",
      "\n",
      "can condense   0.0055248618784530384\n",
      "\n",
      "input features   0.024390243902439025\n",
      "\n",
      "from small   0.019230769230769232\n",
      "\n",
      "program a   0.09090909090909091\n",
      "\n",
      "task-effectiveness at   0.5\n",
      "\n",
      "sometimes provided   0.07692307692307693\n",
      "\n",
      "in classifying   0.0018726591760299626\n",
      "\n",
      "the part-of-speech   0.0006920415224913495\n",
      "\n",
      "reporting -RRB-   0.3333333333333333\n",
      "\n",
      "questioner 's   0.25\n",
      "\n",
      "to Iraq   0.0013280212483399733\n",
      "\n",
      "translator that   0.14285714285714285\n",
      "\n",
      "`` higher   0.005291005291005291\n",
      "\n",
      "<s> Discourse   0.0023059185242121443\n",
      "\n",
      "as debates   0.003484320557491289\n",
      "\n",
      "-RRB- Interactional   0.0027100271002710027\n",
      "\n",
      "continued development   0.1111111111111111\n",
      "\n",
      "recognition applications   0.008264462809917356\n",
      "\n",
      "challenges -RRB-   0.5\n",
      "\n",
      "of integration   0.00089126559714795\n",
      "\n",
      "a conversation   0.001226993865030675\n",
      "\n",
      "marks ,   0.25\n",
      "\n",
      "to correlate   0.0013280212483399733\n",
      "\n",
      "reached 20,000   0.5\n",
      "\n",
      "formalisms are   0.5\n",
      "\n",
      "now done   0.07692307692307693\n",
      "\n",
      "groups submit   0.2\n",
      "\n",
      "Adda G.   0.5\n",
      "\n",
      "V ,   1.0\n",
      "\n",
      "performance is   0.1111111111111111\n",
      "\n",
      "emotional states   0.25\n",
      "\n",
      "video captioning   0.2\n",
      "\n",
      "this document   0.01098901098901099\n",
      "\n",
      "unsupervised summarization   0.25\n",
      "\n",
      "word spaces   0.016666666666666666\n",
      "\n",
      "speech -RRB-   0.02631578947368421\n",
      "\n",
      "a preliminary   0.001226993865030675\n",
      "\n",
      "partial answers   1.0\n",
      "\n",
      "seen in   0.1\n",
      "\n",
      "techniques use   0.043478260869565216\n",
      "\n",
      "be made   0.016877637130801686\n",
      "\n",
      "a score   0.001226993865030675\n",
      "\n",
      "30 years   0.6666666666666666\n",
      "\n",
      "new POS   0.041666666666666664\n",
      "\n",
      "-LRB- creating   0.0027100271002710027\n",
      "\n",
      "standard techniques   0.07142857142857142\n",
      "\n",
      "under stress   0.2\n",
      "\n",
      "portion of   1.0\n",
      "\n",
      "Parliament .   0.5\n",
      "\n",
      "optimizing a   1.0\n",
      "\n",
      "paragraph summary   0.3333333333333333\n",
      "\n",
      "has been   0.3333333333333333\n",
      "\n",
      "created .   0.14285714285714285\n",
      "\n",
      "are sometimes   0.004149377593360996\n",
      "\n",
      "are parsed   0.004149377593360996\n",
      "\n",
      "1933 -LRB-   1.0\n",
      "\n",
      "Category :   0.5\n",
      "\n",
      "working examples   0.14285714285714285\n",
      "\n",
      "quickly ,   1.0\n",
      "\n",
      "Turney paper   0.2222222222222222\n",
      "\n",
      "using punctuation   0.01694915254237288\n",
      "\n",
      "and Windows   0.001445086705202312\n",
      "\n",
      "receipts ,   1.0\n",
      "\n",
      "typical sentences   0.1111111111111111\n",
      "\n",
      "than processing   0.022222222222222223\n",
      "\n",
      "of several   0.00267379679144385\n",
      "\n",
      "applied ,   0.06666666666666667\n",
      "\n",
      "and most   0.001445086705202312\n",
      "\n",
      "<s> Intuitively   0.0007686395080707148\n",
      "\n",
      "person uses   0.05263157894736842\n",
      "\n",
      "characterize a   0.5\n",
      "\n",
      "rich lexicon   0.6\n",
      "\n",
      "perform data   0.09090909090909091\n",
      "\n",
      "structure is   0.08333333333333333\n",
      "\n",
      "product line   0.14285714285714285\n",
      "\n",
      "connected by   0.2\n",
      "\n",
      "years researchers   0.047619047619047616\n",
      "\n",
      "and generating   0.001445086705202312\n",
      "\n",
      "<s> Brain   0.0007686395080707148\n",
      "\n",
      "possible to   0.125\n",
      "\n",
      "smoothing to   1.0\n",
      "\n",
      "translation paradigms   0.013513513513513514\n",
      "\n",
      "OCR service   0.04081632653061224\n",
      "\n",
      "diagramming of   1.0\n",
      "\n",
      "also very   0.028985507246376812\n",
      "\n",
      "% range   0.02564102564102564\n",
      "\n",
      "shallow .   0.16666666666666666\n",
      "\n",
      "cases make   0.05555555555555555\n",
      "\n",
      "free of   0.25\n",
      "\n",
      ", GRASSHOPPER   0.0005614823133071309\n",
      "\n",
      "a syntactic   0.001226993865030675\n",
      "\n",
      "efforts are   0.14285714285714285\n",
      "\n",
      "Windows Mobile   1.0\n",
      "\n",
      "Current state   0.2\n",
      "\n",
      "Winograd was   0.3333333333333333\n",
      "\n",
      "Chinese is   0.14285714285714285\n",
      "\n",
      "These range   0.058823529411764705\n",
      "\n",
      "-LRB- 3   0.005420054200542005\n",
      "\n",
      "sentences have   0.02631578947368421\n",
      "\n",
      "early market   0.1\n",
      "\n",
      "These results   0.058823529411764705\n",
      "\n",
      "GALE project   1.0\n",
      "\n",
      "world currently   0.06666666666666667\n",
      "\n",
      "program and   0.045454545454545456\n",
      "\n",
      "degree to   0.16666666666666666\n",
      "\n",
      "vs. open   0.08333333333333333\n",
      "\n",
      "set to   0.02564102564102564\n",
      "\n",
      "`` machine   0.005291005291005291\n",
      "\n",
      "texts so   0.058823529411764705\n",
      "\n",
      "OCR Software   0.02040816326530612\n",
      "\n",
      "of Business-card   0.00089126559714795\n",
      "\n",
      "no effects   0.07692307692307693\n",
      "\n",
      "principles which   1.0\n",
      "\n",
      "LREC Granada   1.0\n",
      "\n",
      "authors decide   0.2\n",
      "\n",
      "software had   0.037037037037037035\n",
      "\n",
      "about a   0.025\n",
      "\n",
      ", definitional   0.0005614823133071309\n",
      "\n",
      "Treebank project   0.16666666666666666\n",
      "\n",
      "caused problems   1.0\n",
      "\n",
      "<s> On   0.003843197540353574\n",
      "\n",
      "n't for   0.25\n",
      "\n",
      "measured in   0.16666666666666666\n",
      "\n",
      "`` right   0.005291005291005291\n",
      "\n",
      "SPHINX toolkit   1.0\n",
      "\n",
      "<s> n   0.0007686395080707148\n",
      "\n",
      "the ten-year-long   0.0006920415224913495\n",
      "\n",
      "focused solely   0.09090909090909091\n",
      "\n",
      "attention ,   0.5\n",
      "\n",
      "systems ,   0.05357142857142857\n",
      "\n",
      "within another   0.05555555555555555\n",
      "\n",
      "NP-complete .   1.0\n",
      "\n",
      "2001 and   0.5\n",
      "\n",
      "can produce   0.0055248618784530384\n",
      "\n",
      "backward ,   1.0\n",
      "\n",
      "processed documents   0.16666666666666666\n",
      "\n",
      "<s> Recall   0.0023059185242121443\n",
      "\n",
      "vs. Spontaneous   0.08333333333333333\n",
      "\n",
      "commonplace and   1.0\n",
      "\n",
      "select ``   0.16666666666666666\n",
      "\n",
      "such features   0.008130081300813009\n",
      "\n",
      "labeled as   0.3333333333333333\n",
      "\n",
      "<s> Voice   0.0007686395080707148\n",
      "\n",
      "we create   0.044444444444444446\n",
      "\n",
      "Francis ,   1.0\n",
      "\n",
      "methods work   0.045454545454545456\n",
      "\n",
      "example Mr.   0.012345679012345678\n",
      "\n",
      "summary that   0.047619047619047616\n",
      "\n",
      "to convey   0.00398406374501992\n",
      "\n",
      "knowledge but   0.037037037037037035\n",
      "\n",
      ", speech   0.004491858506457047\n",
      "\n",
      "now looking   0.07692307692307693\n",
      "\n",
      "answers ,   0.08333333333333333\n",
      "\n",
      "without documents   0.07692307692307693\n",
      "\n",
      "TextRank algorithm   0.07142857142857142\n",
      "\n",
      "arbitrary piece   0.3333333333333333\n",
      "\n",
      "language interaction   0.006756756756756757\n",
      "\n",
      "7 in   0.2857142857142857\n",
      "\n",
      "canonical form   1.0\n",
      "\n",
      "by Naomi   0.005714285714285714\n",
      "\n",
      "a rate   0.001226993865030675\n",
      "\n",
      "-LRB- AVRADA   0.0027100271002710027\n",
      "\n",
      "Some systems   0.09523809523809523\n",
      "\n",
      "exceptions -RRB-   1.0\n",
      "\n",
      "senses ,   0.5\n",
      "\n",
      "texts by   0.058823529411764705\n",
      "\n",
      "Machine Learning   0.1111111111111111\n",
      "\n",
      ", sets   0.0005614823133071309\n",
      "\n",
      "larger tasks   0.0625\n",
      "\n",
      "United Nations   0.2222222222222222\n",
      "\n",
      "many authors   0.019230769230769232\n",
      "\n",
      "hitcha '   1.0\n",
      "\n",
      "computer ,   0.022727272727272728\n",
      "\n",
      "Amharic and   1.0\n",
      "\n",
      "proven useful   1.0\n",
      "\n",
      "wave and   0.1111111111111111\n",
      "\n",
      "document summarization   0.1388888888888889\n",
      "\n",
      "any QA   0.03225806451612903\n",
      "\n",
      "abstractive methods   0.3333333333333333\n",
      "\n",
      "recognition is   0.0743801652892562\n",
      "\n",
      "does n't   0.1\n",
      "\n",
      "analytical approaches   0.5\n",
      "\n",
      "extraction ,   0.1935483870967742\n",
      "\n",
      "ASR is   0.16666666666666666\n",
      "\n",
      "conducted in   0.4\n",
      "\n",
      "'' .   0.06701030927835051\n",
      "\n",
      "itself is   0.2\n",
      "\n",
      ", \\*   0.0005614823133071309\n",
      "\n",
      "for testing   0.0036101083032490976\n",
      "\n",
      "simple morphology   0.038461538461538464\n",
      "\n",
      "allows movement   0.125\n",
      "\n",
      "possible word   0.041666666666666664\n",
      "\n",
      ", unless   0.0005614823133071309\n",
      "\n",
      "the particular   0.001384083044982699\n",
      "\n",
      "be roughly   0.004219409282700422\n",
      "\n",
      "and confusability   0.001445086705202312\n",
      "\n",
      "libraries GRM   0.5\n",
      "\n",
      ", simulated   0.0005614823133071309\n",
      "\n",
      ", topics   0.0005614823133071309\n",
      "\n",
      "-LRB- rather   0.0027100271002710027\n",
      "\n",
      ", up   0.0005614823133071309\n",
      "\n",
      ", read   0.0011229646266142617\n",
      "\n",
      "for ASR   0.0036101083032490976\n",
      "\n",
      "Tagset ''   1.0\n",
      "\n",
      "project were   0.07692307692307693\n",
      "\n",
      "NN for   1.0\n",
      "\n",
      "presented in   0.5\n",
      "\n",
      "analyzing human-written   0.2\n",
      "\n",
      "not contain   0.008928571428571428\n",
      "\n",
      "use this   0.027777777777777776\n",
      "\n",
      ", symbols   0.0005614823133071309\n",
      "\n",
      "when writing   0.05714285714285714\n",
      "\n",
      "is broken   0.0020325203252032522\n",
      "\n",
      "system needs   0.043010752688172046\n",
      "\n",
      "more human-generated   0.010526315789473684\n",
      "\n",
      "function -LRB-   0.125\n",
      "\n",
      "in Jones   0.0018726591760299626\n",
      "\n",
      ". ''   0.00546021840873635\n",
      "\n",
      "system that   0.03225806451612903\n",
      "\n",
      "<s> All   0.0007686395080707148\n",
      "\n",
      "the can   0.0006920415224913495\n",
      "\n",
      "ultraviolet light   1.0\n",
      "\n",
      "check for   0.5\n",
      "\n",
      "article verb   0.034482758620689655\n",
      "\n",
      "not only   0.0625\n",
      "\n",
      "although these   0.16666666666666666\n",
      "\n",
      "conversations ,   0.3333333333333333\n",
      "\n",
      "lexicon representation   0.1111111111111111\n",
      "\n",
      "`` generalized   0.005291005291005291\n",
      "\n",
      "is like   0.0040650406504065045\n",
      "\n",
      "many words   0.038461538461538464\n",
      "\n",
      "learning methods   0.023255813953488372\n",
      "\n",
      "English-French record   1.0\n",
      "\n",
      "interest in   0.6363636363636364\n",
      "\n",
      "needed to   0.09523809523809523\n",
      "\n",
      "a greater   0.001226993865030675\n",
      "\n",
      "particular feature   0.07692307692307693\n",
      "\n",
      "would not   0.018867924528301886\n",
      "\n",
      "Peter Turney   1.0\n",
      "\n",
      "this refined   0.01098901098901099\n",
      "\n",
      "machine at   0.012658227848101266\n",
      "\n",
      "Convert chunks   0.5\n",
      "\n",
      "mimic the   1.0\n",
      "\n",
      "% still   0.02564102564102564\n",
      "\n",
      "sailor ''   0.4\n",
      "\n",
      "using online   0.01694915254237288\n",
      "\n",
      "best option   0.05555555555555555\n",
      "\n",
      "a hybrid   0.00245398773006135\n",
      "\n",
      "<s> Optical   0.0015372790161414297\n",
      "\n",
      "Pyramid Method   1.0\n",
      "\n",
      "the web   0.001384083044982699\n",
      "\n",
      "<s> Virtually   0.0007686395080707148\n",
      "\n",
      "resources such   0.16666666666666666\n",
      "\n",
      "portions .   1.0\n",
      "\n",
      "Frederick Jelinek   1.0\n",
      "\n",
      "to 1966   0.0013280212483399733\n",
      "\n",
      "such keyphrases   0.008130081300813009\n",
      "\n",
      "obtained a   0.2857142857142857\n",
      "\n",
      "features making   0.038461538461538464\n",
      "\n",
      "multileveled pattern   1.0\n",
      "\n",
      "Electronic Health   0.5\n",
      "\n",
      "speaking speeds   0.125\n",
      "\n",
      "- and   0.125\n",
      "\n",
      "network to   0.16666666666666666\n",
      "\n",
      "be located   0.004219409282700422\n",
      "\n",
      "C ,   1.0\n",
      "\n",
      "are in   0.012448132780082987\n",
      "\n",
      "Solving System   0.5\n",
      "\n",
      "-LRB- 95   0.0027100271002710027\n",
      "\n",
      "initial capital   0.3333333333333333\n",
      "\n",
      "boundaries between   0.18181818181818182\n",
      "\n",
      "basic techniques   0.07692307692307693\n",
      "\n",
      ", produced   0.0016844469399213925\n",
      "\n",
      "are pulled   0.004149377593360996\n",
      "\n",
      "maximum likelihood   0.3333333333333333\n",
      "\n",
      "comprehension and   0.14285714285714285\n",
      "\n",
      "two extremes   0.034482758620689655\n",
      "\n",
      "average text   0.5\n",
      "\n",
      "mostly work   0.5\n",
      "\n",
      "syntactic relations   0.07692307692307693\n",
      "\n",
      "a sense   0.001226993865030675\n",
      "\n",
      "to overfitting   0.0013280212483399733\n",
      "\n",
      "performs simple   1.0\n",
      "\n",
      "Querying application   1.0\n",
      "\n",
      "then taking   0.02857142857142857\n",
      "\n",
      "sound to   0.05\n",
      "\n",
      "in walking   0.0018726591760299626\n",
      "\n",
      "A year   0.02\n",
      "\n",
      "arbitrary new   0.3333333333333333\n",
      "\n",
      "Methods for   0.5\n",
      "\n",
      "opening ''   1.0\n",
      "\n",
      "for billing   0.0036101083032490976\n",
      "\n",
      "& lines   0.125\n",
      "\n",
      "Further restricted-domain   0.3333333333333333\n",
      "\n",
      "safety critical   1.0\n",
      "\n",
      "discussing what   0.5\n",
      "\n",
      "-LRB- greater   0.0027100271002710027\n",
      "\n",
      "that adaptation   0.0035460992907801418\n",
      "\n",
      ", among   0.0005614823133071309\n",
      "\n",
      "as short   0.003484320557491289\n",
      "\n",
      "any of   0.06451612903225806\n",
      "\n",
      "of online   0.00089126559714795\n",
      "\n",
      "1987 ,   0.6666666666666666\n",
      "\n",
      "specific tasks   0.047619047619047616\n",
      "\n",
      "-LRB- 1966   0.0027100271002710027\n",
      "\n",
      "greatly .   0.2857142857142857\n",
      "\n",
      "will seem   0.02857142857142857\n",
      "\n",
      "and also   0.001445086705202312\n",
      "\n",
      "examples have   0.041666666666666664\n",
      "\n",
      "modified in   1.0\n",
      "\n",
      "either as   0.3\n",
      "\n",
      "commercial version   0.09090909090909091\n",
      "\n",
      "a Rogerian   0.001226993865030675\n",
      "\n",
      "different realizations   0.02040816326530612\n",
      "\n",
      "popular evaluation   0.1111111111111111\n",
      "\n",
      "system is   0.0967741935483871\n",
      "\n",
      "code ,   0.14285714285714285\n",
      "\n",
      "simply model   0.08333333333333333\n",
      "\n",
      ", Svenka   0.0005614823133071309\n",
      "\n",
      "translation was   0.02702702702702703\n",
      "\n",
      "absorbing states   0.3333333333333333\n",
      "\n",
      "assumptions on   0.2\n",
      "\n",
      "` caught   0.0625\n",
      "\n",
      "languages have   0.04\n",
      "\n",
      "Short history   1.0\n",
      "\n",
      "data that   0.025974025974025976\n",
      "\n",
      "him perform   0.5\n",
      "\n",
      "Annual Test   1.0\n",
      "\n",
      "the 1950s   0.0020761245674740486\n",
      "\n",
      "or verify   0.0045045045045045045\n",
      "\n",
      "submit their   0.5\n",
      "\n",
      "of analyses   0.00089126559714795\n",
      "\n",
      "naive Bayes   0.5\n",
      "\n",
      "collections ,   0.5\n",
      "\n",
      "same type   0.04\n",
      "\n",
      "problem setting   0.022727272727272728\n",
      "\n",
      "this article   0.04395604395604396\n",
      "\n",
      "basic knowledge   0.07692307692307693\n",
      "\n",
      "themselves sometimes   0.25\n",
      "\n",
      "first commercial   0.06060606060606061\n",
      "\n",
      "extraction removes   0.03225806451612903\n",
      "\n",
      "fundamentally different   1.0\n",
      "\n",
      "<s> Helicopters   0.0007686395080707148\n",
      "\n",
      "document may   0.05555555555555555\n",
      "\n",
      "`` fastens   0.005291005291005291\n",
      "\n",
      "of original   0.00089126559714795\n",
      "\n",
      "-LRB- 2008   0.0027100271002710027\n",
      "\n",
      "Solutions have   1.0\n",
      "\n",
      "they improved   0.025\n",
      "\n",
      "neat ,   1.0\n",
      "\n",
      "cohesion ''   1.0\n",
      "\n",
      "processing text   0.018518518518518517\n",
      "\n",
      "is permuted   0.0020325203252032522\n",
      "\n",
      "microphone .   1.0\n",
      "\n",
      "inspired the   1.0\n",
      "\n",
      "to two   0.0013280212483399733\n",
      "\n",
      "to serve   0.0013280212483399733\n",
      "\n",
      "about 30   0.025\n",
      "\n",
      "markup like   1.0\n",
      "\n",
      "term is   0.05555555555555555\n",
      "\n",
      "sentences -LRB-   0.02631578947368421\n",
      "\n",
      "a subsystem   0.001226993865030675\n",
      "\n",
      "\\/ -LRB-   0.3333333333333333\n",
      "\n",
      "title concentrates   1.0\n",
      "\n",
      "Stef Slembrouck   1.0\n",
      "\n",
      "segmentation task   0.030303030303030304\n",
      "\n",
      "Research Institute   0.125\n",
      "\n",
      "surprisingly ,   0.3333333333333333\n",
      "\n",
      "dictionary .   0.14285714285714285\n",
      "\n",
      "estimate ,   0.25\n",
      "\n",
      "service with   0.2\n",
      "\n",
      "overfitting the   0.5\n",
      "\n",
      "answering :   0.08333333333333333\n",
      "\n",
      "character alone   0.045454545454545456\n",
      "\n",
      "and echoes   0.001445086705202312\n",
      "\n",
      "<s> Like   0.0007686395080707148\n",
      "\n",
      "an opinion   0.007575757575757576\n",
      "\n",
      "This convinced   0.015873015873015872\n",
      "\n",
      "Elinor Ochs   1.0\n",
      "\n",
      "of diagonal   0.00089126559714795\n",
      "\n",
      "further research   0.125\n",
      "\n",
      "-LRB- natural   0.0027100271002710027\n",
      "\n",
      "a sentence   0.01717791411042945\n",
      "\n",
      "- for   0.0625\n",
      "\n",
      "that NLG   0.0070921985815602835\n",
      "\n",
      "constraints ;   0.25\n",
      "\n",
      "can do   0.011049723756906077\n",
      "\n",
      "Sample a   1.0\n",
      "\n",
      "eventually spun   1.0\n",
      "\n",
      "for editing   0.0036101083032490976\n",
      "\n",
      "nor even   1.0\n",
      "\n",
      "ideal deep   1.0\n",
      "\n",
      "rare --   0.25\n",
      "\n",
      "needs a   0.2\n",
      "\n",
      "hierarchically in   1.0\n",
      "\n",
      "sentence importance   0.020833333333333332\n",
      "\n",
      "summarization algorithms   0.02\n",
      "\n",
      "Scotland to   0.2\n",
      "\n",
      "disambiguate parts   0.3333333333333333\n",
      "\n",
      "rules similar   0.046511627906976744\n",
      "\n",
      "to right   0.0013280212483399733\n",
      "\n",
      "usable output   1.0\n",
      "\n",
      "the source   0.008304498269896194\n",
      "\n",
      "Such algorithms   0.125\n",
      "\n",
      "usually termed   0.03125\n",
      "\n",
      "fail to   0.3333333333333333\n",
      "\n",
      "text fragments   0.006289308176100629\n",
      "\n",
      ", Nuance   0.0005614823133071309\n",
      "\n",
      "we have   0.06666666666666667\n",
      "\n",
      "planning an   0.5\n",
      "\n",
      "P ,   0.5\n",
      "\n",
      "entire content   0.3333333333333333\n",
      "\n",
      "excess of   1.0\n",
      "\n",
      "allowable substitutions   0.5\n",
      "\n",
      "tagger is   0.1111111111111111\n",
      "\n",
      "podcast where   1.0\n",
      "\n",
      "systems favor   0.008928571428571428\n",
      "\n",
      "to many   0.005312084993359893\n",
      "\n",
      "the affect   0.0006920415224913495\n",
      "\n",
      "produce both   0.045454545454545456\n",
      "\n",
      "sense a   0.125\n",
      "\n",
      "contain punctuation   0.08333333333333333\n",
      "\n",
      "significant momentum   0.1111111111111111\n",
      "\n",
      "not necessarily   0.017857142857142856\n",
      "\n",
      "grammar methods   0.02702702702702703\n",
      "\n",
      "stating that   1.0\n",
      "\n",
      "vastly less   1.0\n",
      "\n",
      "related fields   0.06666666666666667\n",
      "\n",
      "common case   0.04\n",
      "\n",
      "time-consuming part   0.3333333333333333\n",
      "\n",
      "of anomalies   0.00089126559714795\n",
      "\n",
      "wingmen with   1.0\n",
      "\n",
      ", heavy-noise   0.0005614823133071309\n",
      "\n",
      "1996 ,   1.0\n",
      "\n",
      "left to   0.16666666666666666\n",
      "\n",
      "clear why   0.25\n",
      "\n",
      "and Re-encoding   0.001445086705202312\n",
      "\n",
      "CANDIDE from   1.0\n",
      "\n",
      "preliminary approach   0.3333333333333333\n",
      "\n",
      "coherent or   0.2\n",
      "\n",
      "pauses in   0.25\n",
      "\n",
      "stub reader   1.0\n",
      "\n",
      "defined ,   0.16666666666666666\n",
      "\n",
      "This makes   0.015873015873015872\n",
      "\n",
      "medial and   1.0\n",
      "\n",
      "date -LRB-   0.6666666666666666\n",
      "\n",
      "The vectors   0.005208333333333333\n",
      "\n",
      "Are there   1.0\n",
      "\n",
      "generates a   0.6666666666666666\n",
      "\n",
      "invention of   1.0\n",
      "\n",
      "in titles   0.0018726591760299626\n",
      "\n",
      "it in   0.008547008547008548\n",
      "\n",
      "usually called   0.03125\n",
      "\n",
      "with no   0.01092896174863388\n",
      "\n",
      "2006 and   0.3333333333333333\n",
      "\n",
      "Robert E.   0.5\n",
      "\n",
      "finding the   0.4\n",
      "\n",
      "devices take   0.25\n",
      "\n",
      "their device   0.029411764705882353\n",
      "\n",
      "<s> NLG   0.0015372790161414297\n",
      "\n",
      "use neural   0.013888888888888888\n",
      "\n",
      "makes it   0.25\n",
      "\n",
      "to any   0.00398406374501992\n",
      "\n",
      "either positive   0.1\n",
      "\n",
      "related .   0.06666666666666667\n",
      "\n",
      "= 2PR   0.1111111111111111\n",
      "\n",
      "how a   0.06896551724137931\n",
      "\n",
      ", thanks   0.0005614823133071309\n",
      "\n",
      "<s> Today   0.0007686395080707148\n",
      "\n",
      "Speech and   0.16129032258064516\n",
      "\n",
      "This criterion   0.015873015873015872\n",
      "\n",
      "The combination   0.005208333333333333\n",
      "\n",
      "of freely   0.00089126559714795\n",
      "\n",
      "What you   0.09090909090909091\n",
      "\n",
      "hidden Markov   0.875\n",
      "\n",
      "boolean syntactic   1.0\n",
      "\n",
      "possible ,   0.125\n",
      "\n",
      "exclamation marks   1.0\n",
      "\n",
      "produced ,   0.1111111111111111\n",
      "\n",
      "thereby editing   1.0\n",
      "\n",
      "is used   0.026422764227642278\n",
      "\n",
      "Some of   0.19047619047619047\n",
      "\n",
      "improve this   0.15384615384615385\n",
      "\n",
      "report finalized   0.25\n",
      "\n",
      "and split   0.001445086705202312\n",
      "\n",
      "reduced amount   0.25\n",
      "\n",
      "within that   0.05555555555555555\n",
      "\n",
      "of context-free   0.00089126559714795\n",
      "\n",
      "orthogonal to   1.0\n",
      "\n",
      "entered the   0.5\n",
      "\n",
      "no. .   1.0\n",
      "\n",
      ", encoding   0.0005614823133071309\n",
      "\n",
      "a handheld   0.001226993865030675\n",
      "\n",
      "Corpus tag   0.125\n",
      "\n",
      "book on   0.125\n",
      "\n",
      "topic or   0.125\n",
      "\n",
      "networks have   0.07142857142857142\n",
      "\n",
      "the tokens   0.001384083044982699\n",
      "\n",
      "such capabilities   0.008130081300813009\n",
      "\n",
      "specified in   1.0\n",
      "\n",
      "PageRank .   0.16666666666666666\n",
      "\n",
      "-LRB- AFTI   0.0027100271002710027\n",
      "\n",
      "translations using   0.5\n",
      "\n",
      "produce keyphrases   0.045454545454545456\n",
      "\n",
      "These waves   0.058823529411764705\n",
      "\n",
      "grammars for   0.07142857142857142\n",
      "\n",
      "current major   0.14285714285714285\n",
      "\n",
      "written text   0.11538461538461539\n",
      "\n",
      "-RRB- output   0.0027100271002710027\n",
      "\n",
      "threshold to   0.25\n",
      "\n",
      "means Category   0.16666666666666666\n",
      "\n",
      "input a   0.024390243902439025\n",
      "\n",
      "with boundary   0.00546448087431694\n",
      "\n",
      "word-forms are   1.0\n",
      "\n",
      "omitted -RRB-   1.0\n",
      "\n",
      "of features   0.00089126559714795\n",
      "\n",
      "applications it   0.04\n",
      "\n",
      "into machine-encoded   0.01282051282051282\n",
      "\n",
      "ambiguity in   0.125\n",
      "\n",
      "and speaker   0.001445086705202312\n",
      "\n",
      "information usually   0.021739130434782608\n",
      "\n",
      "language search   0.006756756756756757\n",
      "\n",
      "American Recovery   0.2\n",
      "\n",
      "must be   0.42857142857142855\n",
      "\n",
      "then direct   0.02857142857142857\n",
      "\n",
      "respectively .   1.0\n",
      "\n",
      "help automatic   0.1111111111111111\n",
      "\n",
      "and naturalness   0.001445086705202312\n",
      "\n",
      "the company   0.0006920415224913495\n",
      "\n",
      "uses stochastic   0.07142857142857142\n",
      "\n",
      "rich information   0.2\n",
      "\n",
      "scanner and   0.3333333333333333\n",
      "\n",
      "Animate =   1.0\n",
      "\n",
      "'' sentence   0.005154639175257732\n",
      "\n",
      "Nielsen automatically   1.0\n",
      "\n",
      "1987 -LRB-   0.3333333333333333\n",
      "\n",
      "approximately 200   0.5\n",
      "\n",
      ", contains   0.0005614823133071309\n",
      "\n",
      "draws on   1.0\n",
      "\n",
      "test the   0.1\n",
      "\n",
      "in Scotland   0.0018726591760299626\n",
      "\n",
      "discussions about   0.3333333333333333\n",
      "\n",
      "sound creates   0.05\n",
      "\n",
      "brought together   1.0\n",
      "\n",
      "linguistic way   0.0625\n",
      "\n",
      "learning approaches   0.023255813953488372\n",
      "\n",
      "derive part-of-speech   0.5\n",
      "\n",
      "question processing   0.07142857142857142\n",
      "\n",
      "that users   0.0035460992907801418\n",
      "\n",
      "improve results   0.07692307692307693\n",
      "\n",
      "speech .   0.06578947368421052\n",
      "\n",
      "-LRB- CWA   0.0027100271002710027\n",
      "\n",
      "in translating   0.0018726591760299626\n",
      "\n",
      "about each   0.025\n",
      "\n",
      "'s and   0.0196078431372549\n",
      "\n",
      "if a   0.03571428571428571\n",
      "\n",
      "be processed   0.004219409282700422\n",
      "\n",
      "classification-related measure   1.0\n",
      "\n",
      "See also   0.5\n",
      "\n",
      "requires fairly   0.0625\n",
      "\n",
      "fields .   0.16666666666666666\n",
      "\n",
      "requiring all   0.5\n",
      "\n",
      "unigram ,   0.6\n",
      "\n",
      ", NP   0.0005614823133071309\n",
      "\n",
      "distinctive groups   0.5\n",
      "\n",
      "of as   0.0017825311942959\n",
      "\n",
      "and techniques   0.001445086705202312\n",
      "\n",
      "often has   0.045454545454545456\n",
      "\n",
      "question .   0.047619047619047616\n",
      "\n",
      "as division   0.003484320557491289\n",
      "\n",
      "dictator is   1.0\n",
      "\n",
      "English this   0.02702702702702703\n",
      "\n",
      "is RDF   0.0020325203252032522\n",
      "\n",
      "of repeated   0.00089126559714795\n",
      "\n",
      "gonna do   1.0\n",
      "\n",
      "successful NLP   0.1111111111111111\n",
      "\n",
      "and what   0.001445086705202312\n",
      "\n",
      "German city   0.25\n",
      "\n",
      "web 2.0   0.125\n",
      "\n",
      "Transactions on   1.0\n",
      "\n",
      "Friday have   1.0\n",
      "\n",
      "they also   0.025\n",
      "\n",
      "HMT -RRB-   1.0\n",
      "\n",
      "grammar :   0.02702702702702703\n",
      "\n",
      "are written   0.004149377593360996\n",
      "\n",
      "roadmap of   1.0\n",
      "\n",
      "gather information   1.0\n",
      "\n",
      "language other   0.006756756756756757\n",
      "\n",
      "for clarification   0.0036101083032490976\n",
      "\n",
      "system selects   0.010752688172043012\n",
      "\n",
      "features into   0.038461538461538464\n",
      "\n",
      "to date   0.0026560424966799467\n",
      "\n",
      ": Example-based   0.00980392156862745\n",
      "\n",
      "evaluating the   0.2\n",
      "\n",
      "order ''   0.07142857142857142\n",
      "\n",
      "only some   0.05263157894736842\n",
      "\n",
      "-RRB- to   0.01084010840108401\n",
      "\n",
      "James A.   0.5\n",
      "\n",
      "handwritten cursive   0.5\n",
      "\n",
      "would difficult   0.018867924528301886\n",
      "\n",
      "meaning -LRB-   0.043478260869565216\n",
      "\n",
      "polarity classification   0.125\n",
      "\n",
      "typical real-world   0.1111111111111111\n",
      "\n",
      "potential redundancy   0.14285714285714285\n",
      "\n",
      "to clarify   0.0013280212483399733\n",
      "\n",
      "the unigram   0.0006920415224913495\n",
      "\n",
      "parser with   0.0625\n",
      "\n",
      "the TextRank   0.001384083044982699\n",
      "\n",
      "selling a   1.0\n",
      "\n",
      "also possible   0.043478260869565216\n",
      "\n",
      "prisoner-of-war camp   1.0\n",
      "\n",
      "and natural   0.005780346820809248\n",
      "\n",
      "speaker recognition   0.05555555555555555\n",
      "\n",
      "of high   0.00089126559714795\n",
      "\n",
      "measure that   0.09090909090909091\n",
      "\n",
      "therapy -LRB-   1.0\n",
      "\n",
      "build an   0.6666666666666666\n",
      "\n",
      "more severe   0.010526315789473684\n",
      "\n",
      ", adjective   0.0005614823133071309\n",
      "\n",
      "world assumption   0.13333333333333333\n",
      "\n",
      "identify new   0.08333333333333333\n",
      "\n",
      "phonemes -LRB-   0.16666666666666666\n",
      "\n",
      "treat words   0.5\n",
      "\n",
      "about NLP   0.025\n",
      "\n",
      "R -RRB-   1.0\n",
      "\n",
      "phrase How   0.1\n",
      "\n",
      "enhance accessibility   1.0\n",
      "\n",
      "to assist   0.0013280212483399733\n",
      "\n",
      "to pre-process   0.0013280212483399733\n",
      "\n",
      "construction ,   0.3333333333333333\n",
      "\n",
      "systems usually   0.017857142857142856\n",
      "\n",
      "recognition ,   0.11570247933884298\n",
      "\n",
      "idea ,   0.14285714285714285\n",
      "\n",
      "functioning as   0.6666666666666666\n",
      "\n",
      "difficult words   0.03571428571428571\n",
      "\n",
      "file to   1.0\n",
      "\n",
      "Snyder -LRB-   0.5\n",
      "\n",
      "words of   0.027522935779816515\n",
      "\n",
      "a higher   0.00245398773006135\n",
      "\n",
      "% or   0.02564102564102564\n",
      "\n",
      "computer-type OCR   1.0\n",
      "\n",
      "freely available   1.0\n",
      "\n",
      "as within   0.003484320557491289\n",
      "\n",
      "a letter   0.001226993865030675\n",
      "\n",
      "often marked   0.022727272727272728\n",
      "\n",
      "British General   0.3333333333333333\n",
      "\n",
      "to five   0.0013280212483399733\n",
      "\n",
      "and practical   0.001445086705202312\n",
      "\n",
      "very difficult   0.04878048780487805\n",
      "\n",
      "indifferent to   1.0\n",
      "\n",
      "recognition benchmark   0.008264462809917356\n",
      "\n",
      "that statistical   0.0035460992907801418\n",
      "\n",
      "translator for   0.14285714285714285\n",
      "\n",
      "handmade list   1.0\n",
      "\n",
      "an extension   0.007575757575757576\n",
      "\n",
      "readable English   0.3333333333333333\n",
      "\n",
      "highest level   0.3333333333333333\n",
      "\n",
      "of unlabeled   0.00089126559714795\n",
      "\n",
      "capabilities by   0.2\n",
      "\n",
      "-LRB- normalized   0.0027100271002710027\n",
      "\n",
      "Syntactic ;   1.0\n",
      "\n",
      "that accuracy   0.0035460992907801418\n",
      "\n",
      "1960s were   0.3333333333333333\n",
      "\n",
      "theory it   0.07692307692307693\n",
      "\n",
      "since the   0.1\n",
      "\n",
      ", selecting   0.0005614823133071309\n",
      "\n",
      "taken up   0.3333333333333333\n",
      "\n",
      "user about   0.07142857142857142\n",
      "\n",
      "declared during   0.5\n",
      "\n",
      "trained hidden   0.3333333333333333\n",
      "\n",
      "is relevant   0.0020325203252032522\n",
      "\n",
      "are both   0.008298755186721992\n",
      "\n",
      "invented Penicillin   0.5\n",
      "\n",
      "an abstract   0.007575757575757576\n",
      "\n",
      "would use   0.018867924528301886\n",
      "\n",
      "massive collections   1.0\n",
      "\n",
      "constructed ,   0.5\n",
      "\n",
      "1993 -RRB-   0.3333333333333333\n",
      "\n",
      "Yet ELIZA   1.0\n",
      "\n",
      "abstraction .   0.25\n",
      "\n",
      "are the   0.04564315352697095\n",
      "\n",
      "` naturally   0.0625\n",
      "\n",
      "different contexts   0.02040816326530612\n",
      "\n",
      "using NLG   0.05084745762711865\n",
      "\n",
      "installing speech   1.0\n",
      "\n",
      "same summary   0.04\n",
      "\n",
      ", Ernesto   0.0005614823133071309\n",
      "\n",
      "platforms .   1.0\n",
      "\n",
      "to different   0.0013280212483399733\n",
      "\n",
      "in languages   0.0018726591760299626\n",
      "\n",
      "campaign was   0.2\n",
      "\n",
      "might shed   0.038461538461538464\n",
      "\n",
      "boundary identification   0.16666666666666666\n",
      "\n",
      "recognition deteriorated   0.008264462809917356\n",
      "\n",
      "anywhere on   1.0\n",
      "\n",
      "speed for   0.14285714285714285\n",
      "\n",
      "measuring similarity   1.0\n",
      "\n",
      ": give   0.0196078431372549\n",
      "\n",
      "flying in   1.0\n",
      "\n",
      "in politics   0.0018726591760299626\n",
      "\n",
      "processing of   0.037037037037037035\n",
      "\n",
      "into English   0.02564102564102564\n",
      "\n",
      "Text-proofing Natural   1.0\n",
      "\n",
      "the early   0.0020761245674740486\n",
      "\n",
      "displayed on-line   0.5\n",
      "\n",
      "e.g. transformational   0.017857142857142856\n",
      "\n",
      "sophisticated methods   0.14285714285714285\n",
      "\n",
      "not predict   0.008928571428571428\n",
      "\n",
      "the correct   0.004152249134948097\n",
      "\n",
      "then the   0.05714285714285714\n",
      "\n",
      "about 70   0.05\n",
      "\n",
      "recall-based measure   0.5\n",
      "\n",
      "of SHRDLU   0.00089126559714795\n",
      "\n",
      "this vocabulary   0.01098901098901099\n",
      "\n",
      "1957 and   1.0\n",
      "\n",
      "induction .   1.0\n",
      "\n",
      "information need   0.021739130434782608\n",
      "\n",
      "will have   0.05714285714285714\n",
      "\n",
      "Note that   0.7777777777777778\n",
      "\n",
      "`` AI-complete   0.010582010582010581\n",
      "\n",
      "an input   0.022727272727272728\n",
      "\n",
      "notably by   0.3333333333333333\n",
      "\n",
      "between adjacent   0.05128205128205128\n",
      "\n",
      "only unigrams   0.02631578947368421\n",
      "\n",
      "What distinguishes   0.09090909090909091\n",
      "\n",
      "top-down parsing   0.5\n",
      "\n",
      "recognition efforts   0.008264462809917356\n",
      "\n",
      ", modules   0.0005614823133071309\n",
      "\n",
      "quantitative evaluation   0.5\n",
      "\n",
      "technology Sensory   0.045454545454545456\n",
      "\n",
      "ontologies .   0.5\n",
      "\n",
      "analysis of   0.18461538461538463\n",
      "\n",
      "be asking   0.004219409282700422\n",
      "\n",
      "generation of   0.1111111111111111\n",
      "\n",
      "can help   0.0055248618784530384\n",
      "\n",
      "text of   0.006289308176100629\n",
      "\n",
      "JAS-39 Gripen   1.0\n",
      "\n",
      "allowing for   0.3333333333333333\n",
      "\n",
      "which items   0.007246376811594203\n",
      "\n",
      "in service   0.0018726591760299626\n",
      "\n",
      "dependency parsers   0.2\n",
      "\n",
      "was much   0.025974025974025976\n",
      "\n",
      "outside the   0.5\n",
      "\n",
      "; Given   0.02127659574468085\n",
      "\n",
      "in those   0.0018726591760299626\n",
      "\n",
      ", not   0.0039303761931499155\n",
      "\n",
      "tense ,   0.5\n",
      "\n",
      "is doing   0.0020325203252032522\n",
      "\n",
      "Henry Kucera   0.5\n",
      "\n",
      "method that   0.0625\n",
      "\n",
      "with computer-aided   0.00546448087431694\n",
      "\n",
      "library are   0.5\n",
      "\n",
      "only by   0.05263157894736842\n",
      "\n",
      "term frequencies   0.05555555555555555\n",
      "\n",
      "formalization of   0.5\n",
      "\n",
      "similarity metrics   0.1\n",
      "\n",
      "largely an   0.2\n",
      "\n",
      "function either   0.125\n",
      "\n",
      "application for   0.07142857142857142\n",
      "\n",
      "analyzing written   0.2\n",
      "\n",
      "corrected by   1.0\n",
      "\n",
      "perform by   0.09090909090909091\n",
      "\n",
      "be referred   0.004219409282700422\n",
      "\n",
      "it -RRB-   0.008547008547008548\n",
      "\n",
      "every combination   0.3333333333333333\n",
      "\n",
      ", containing   0.0011229646266142617\n",
      "\n",
      "Did Marilyn   1.0\n",
      "\n",
      "while parsing   0.05\n",
      "\n",
      "maintains that   1.0\n",
      "\n",
      "methods for   0.045454545454545456\n",
      "\n",
      "to TextRank   0.0013280212483399733\n",
      "\n",
      ", reliability   0.0005614823133071309\n",
      "\n",
      "better than   0.1111111111111111\n",
      "\n",
      "the Royal   0.001384083044982699\n",
      "\n",
      ", Charles   0.0005614823133071309\n",
      "\n",
      "in US   0.0018726591760299626\n",
      "\n",
      "98 %   1.0\n",
      "\n",
      "by simple   0.005714285714285714\n",
      "\n",
      "<s> Improved   0.0007686395080707148\n",
      "\n",
      "-LRB- semi   0.0027100271002710027\n",
      "\n",
      "not rely   0.017857142857142856\n",
      "\n",
      "criteria and   0.25\n",
      "\n",
      "the inherent   0.0006920415224913495\n",
      "\n",
      "Deaf or   1.0\n",
      "\n",
      "Church independently   0.3333333333333333\n",
      "\n",
      "desired -RRB-   0.2\n",
      "\n",
      "via the   1.0\n",
      "\n",
      "a hierarchy   0.001226993865030675\n",
      "\n",
      "dismiss the   1.0\n",
      "\n",
      "relationships in   0.16666666666666666\n",
      "\n",
      "paragraphs -RRB-   0.25\n",
      "\n",
      "-LRB- ParaEval   0.0027100271002710027\n",
      "\n",
      "asked for   0.3333333333333333\n",
      "\n",
      "sentences flow   0.013157894736842105\n",
      "\n",
      "and speed   0.002890173410404624\n",
      "\n",
      ", verbs   0.0011229646266142617\n",
      "\n",
      "might generate   0.038461538461538464\n",
      "\n",
      "by DARPA   0.005714285714285714\n",
      "\n",
      "used English   0.008849557522123894\n",
      "\n",
      "though it   0.2\n",
      "\n",
      "Essentially ,   1.0\n",
      "\n",
      "accidentally omitted   1.0\n",
      "\n",
      "more probabilistic   0.010526315789473684\n",
      "\n",
      "Extractor -RRB-   1.0\n",
      "\n",
      "dictionaries ,   1.0\n",
      "\n",
      "financial message   0.25\n",
      "\n",
      "quality can   0.1\n",
      "\n",
      "output distribution   0.038461538461538464\n",
      "\n",
      "high probability   0.05555555555555555\n",
      "\n",
      "graph will   0.15384615384615385\n",
      "\n",
      ", thereby   0.0005614823133071309\n",
      "\n",
      "Journal .   0.3333333333333333\n",
      "\n",
      "real-time written   0.5\n",
      "\n",
      "is sometimes   0.006097560975609756\n",
      "\n",
      "of hyphenation   0.00089126559714795\n",
      "\n",
      "or FST   0.0045045045045045045\n",
      "\n",
      "more complex   0.08421052631578947\n",
      "\n",
      "it .   0.042735042735042736\n",
      "\n",
      "that depend   0.0035460992907801418\n",
      "\n",
      "describing graphs   0.25\n",
      "\n",
      "was CANDIDE   0.012987012987012988\n",
      "\n",
      "2009 -LRB-   0.3333333333333333\n",
      "\n",
      "by comparing   0.005714285714285714\n",
      "\n",
      "working out   0.14285714285714285\n",
      "\n",
      "simplified form   0.5\n",
      "\n",
      "exist .   1.0\n",
      "\n",
      "being said   0.05555555555555555\n",
      "\n",
      "print a   1.0\n",
      "\n",
      "translation by   0.013513513513513514\n",
      "\n",
      "a construct   0.001226993865030675\n",
      "\n",
      "actual NLP   0.2\n",
      "\n",
      "analog signal   0.5\n",
      "\n",
      "For sentiment   0.01639344262295082\n",
      "\n",
      "or probabilities   0.0045045045045045045\n",
      "\n",
      "a car   0.001226993865030675\n",
      "\n",
      "or movies   0.0045045045045045045\n",
      "\n",
      "sequence of   0.875\n",
      "\n",
      "augmented transition   1.0\n",
      "\n",
      "removal of   1.0\n",
      "\n",
      "summaries to   0.046511627906976744\n",
      "\n",
      "languages ,   0.22\n",
      "\n",
      ", individual   0.0005614823133071309\n",
      "\n",
      "1971 and   0.3333333333333333\n",
      "\n",
      "to turn   0.0013280212483399733\n",
      "\n",
      "-RRB- evaluation   0.0027100271002710027\n",
      "\n",
      "interlingua .   1.0\n",
      "\n",
      "fluent native   1.0\n",
      "\n",
      "of FoG   0.00089126559714795\n",
      "\n",
      "extractors are   1.0\n",
      "\n",
      "networks discussions   0.07142857142857142\n",
      "\n",
      "`` sad   0.005291005291005291\n",
      "\n",
      "<s> History   0.0015372790161414297\n",
      "\n",
      "than 150   0.022222222222222223\n",
      "\n",
      "semantic equivalence   0.047619047619047616\n",
      "\n",
      "develop as   0.2\n",
      "\n",
      "Brill Tagger   0.3333333333333333\n",
      "\n",
      "many languages   0.019230769230769232\n",
      "\n",
      "Parsing algorithms   0.2\n",
      "\n",
      "management of   0.2857142857142857\n",
      "\n",
      "simple domains   0.038461538461538464\n",
      "\n",
      "syntactic features   0.07692307692307693\n",
      "\n",
      "Apart from   1.0\n",
      "\n",
      "and evaluation   0.004335260115606936\n",
      "\n",
      "automatizing the   1.0\n",
      "\n",
      "or deferred   0.0045045045045045045\n",
      "\n",
      "summarization :   0.02\n",
      "\n",
      "set a   0.05128205128205128\n",
      "\n",
      "method is   0.0625\n",
      "\n",
      "of semantics   0.00089126559714795\n",
      "\n",
      "PAM -LRB-   1.0\n",
      "\n",
      "the methods   0.0006920415224913495\n",
      "\n",
      "expressed like   0.16666666666666666\n",
      "\n",
      "be written   0.004219409282700422\n",
      "\n",
      "deciding to   0.3333333333333333\n",
      "\n",
      "methods are   0.045454545454545456\n",
      "\n",
      "image representing   0.3333333333333333\n",
      "\n",
      "entity ,   0.4\n",
      "\n",
      "- based   0.1875\n",
      "\n",
      "natural -RRB-   0.013333333333333334\n",
      "\n",
      "select keyphrases   0.16666666666666666\n",
      "\n",
      "Potentially ,   1.0\n",
      "\n",
      "representing printed   0.5\n",
      "\n",
      "maximum mutual   0.16666666666666666\n",
      "\n",
      "`` understanding   0.005291005291005291\n",
      "\n",
      "`` tag   0.010582010582010581\n",
      "\n",
      "helped the   0.3333333333333333\n",
      "\n",
      "and printed   0.001445086705202312\n",
      "\n",
      "500 samples   0.5\n",
      "\n",
      "or lexical   0.009009009009009009\n",
      "\n",
      "been produced   0.014705882352941176\n",
      "\n",
      "Ethnomethodology .   1.0\n",
      "\n",
      "that speech   0.0035460992907801418\n",
      "\n",
      "important example   0.0625\n",
      "\n",
      "to correct   0.0013280212483399733\n",
      "\n",
      "January ,   0.25\n",
      "\n",
      "and discontinuous   0.001445086705202312\n",
      "\n",
      "various fine   0.05555555555555555\n",
      "\n",
      "from Latin   0.009615384615384616\n",
      "\n",
      "and artificial   0.001445086705202312\n",
      "\n",
      "have already   0.009615384615384616\n",
      "\n",
      "advantages over   1.0\n",
      "\n",
      "ambiguity by   0.125\n",
      "\n",
      "that adjectives   0.0035460992907801418\n",
      "\n",
      "frequency with   0.5\n",
      "\n",
      "are probably   0.004149377593360996\n",
      "\n",
      "supervised learning   0.3125\n",
      "\n",
      "social psychology   0.07142857142857142\n",
      "\n",
      "responding to   1.0\n",
      "\n",
      "where it   0.02857142857142857\n",
      "\n",
      "a appropriate   0.001226993865030675\n",
      "\n",
      "and Vietnamese   0.001445086705202312\n",
      "\n",
      "an upper-case   0.007575757575757576\n",
      "\n",
      "usually creating   0.03125\n",
      "\n",
      "two conflicting   0.034482758620689655\n",
      "\n",
      "taught the   0.6666666666666666\n",
      "\n",
      "harder 75   0.14285714285714285\n",
      "\n",
      "<s> It   0.026133743274404306\n",
      "\n",
      "PageRank selects   0.16666666666666666\n",
      "\n",
      "which soon   0.007246376811594203\n",
      "\n",
      "Neural networks   0.75\n",
      "\n",
      "technology for   0.09090909090909091\n",
      "\n",
      "deteriorated with   1.0\n",
      "\n",
      "social contexts   0.07142857142857142\n",
      "\n",
      "Battle Management   0.5\n",
      "\n",
      "Medical Records   0.5\n",
      "\n",
      "for the   0.11191335740072202\n",
      "\n",
      "<s> Rescoring   0.0007686395080707148\n",
      "\n",
      "general software   0.045454545454545456\n",
      "\n",
      "positions as   1.0\n",
      "\n",
      "Gisting Evaluation   1.0\n",
      "\n",
      "spaces or   0.2\n",
      "\n",
      "which sounds   0.007246376811594203\n",
      "\n",
      "claimed that   1.0\n",
      "\n",
      "E. Longacre   0.5\n",
      "\n",
      "and regions   0.001445086705202312\n",
      "\n",
      "against which   0.2\n",
      "\n",
      "project was   0.07692307692307693\n",
      "\n",
      "of analysis   0.00089126559714795\n",
      "\n",
      ": Manual   0.00980392156862745\n",
      "\n",
      "political negligence   0.3333333333333333\n",
      "\n",
      "the recognized   0.001384083044982699\n",
      "\n",
      "Bar-Hillel .   1.0\n",
      "\n",
      "unfamiliar input   1.0\n",
      "\n",
      "Edmund Fournier   1.0\n",
      "\n",
      "expression or   0.1\n",
      "\n",
      "were found   0.04878048780487805\n",
      "\n",
      "in `   0.003745318352059925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "make no   0.05\n",
      "\n",
      "accurate results   0.14285714285714285\n",
      "\n",
      "discourse are   0.027777777777777776\n",
      "\n",
      "could understand   0.0625\n",
      "\n",
      "-RRB- showed   0.0027100271002710027\n",
      "\n",
      "to select   0.005312084993359893\n",
      "\n",
      "as ACL   0.003484320557491289\n",
      "\n",
      "grammars of   0.07142857142857142\n",
      "\n",
      "NLP as   0.02127659574468085\n",
      "\n",
      "to overcome   0.0013280212483399733\n",
      "\n",
      "Symantec Corporation   0.5\n",
      "\n",
      "keyphrases your   0.02857142857142857\n",
      "\n",
      "that domain   0.0035460992907801418\n",
      "\n",
      "including recognition   0.07142857142857142\n",
      "\n",
      "and 1957   0.001445086705202312\n",
      "\n",
      "segment text   0.2222222222222222\n",
      "\n",
      ", perhaps   0.0016844469399213925\n",
      "\n",
      "device converted   0.5\n",
      "\n",
      "Harris at   0.1111111111111111\n",
      "\n",
      "selecting and   0.2\n",
      "\n",
      "section needs   0.16666666666666666\n",
      "\n",
      "user can   0.07142857142857142\n",
      "\n",
      "with disabilities   0.01092896174863388\n",
      "\n",
      "syntactic analysis   0.15384615384615385\n",
      "\n",
      "world knowledge   0.13333333333333333\n",
      "\n",
      "by providing   0.005714285714285714\n",
      "\n",
      "people 's   0.0625\n",
      "\n",
      "`` recommend   0.010582010582010581\n",
      "\n",
      "requirements of   0.5\n",
      "\n",
      "read the   0.14285714285714285\n",
      "\n",
      "-LRB- arguably   0.0027100271002710027\n",
      "\n",
      "ends up   0.5\n",
      "\n",
      "2.0 was   0.5\n",
      "\n",
      "5 %   0.5\n",
      "\n",
      "fail during   0.3333333333333333\n",
      "\n",
      "human vocabularies   0.021739130434782608\n",
      "\n",
      "data redundancy   0.012987012987012988\n",
      "\n",
      ": Putting   0.00980392156862745\n",
      "\n",
      "supervised keyphrase   0.125\n",
      "\n",
      "bases ,   1.0\n",
      "\n",
      "JSF -RRB-   1.0\n",
      "\n",
      "computer performance   0.022727272727272728\n",
      "\n",
      "campaign compared   0.2\n",
      "\n",
      "-LRB- k   0.0027100271002710027\n",
      "\n",
      "even larger   0.037037037037037035\n",
      "\n",
      "this shifting   0.01098901098901099\n",
      "\n",
      "it ends   0.017094017094017096\n",
      "\n",
      "email Multimodal   0.5\n",
      "\n",
      "so phonemes   0.03333333333333333\n",
      "\n",
      "what extent   0.03125\n",
      "\n",
      "that carried   0.0035460992907801418\n",
      "\n",
      "See Peter   0.16666666666666666\n",
      "\n",
      "be learned   0.004219409282700422\n",
      "\n",
      "listening to   1.0\n",
      "\n",
      "where sentences   0.05714285714285714\n",
      "\n",
      "corpus has   0.03225806451612903\n",
      "\n",
      "word-frequency and   1.0\n",
      "\n",
      "other country   0.014285714285714285\n",
      "\n",
      "Obama ,   1.0\n",
      "\n",
      "writing custom   0.1111111111111111\n",
      "\n",
      "decades -LRB-   1.0\n",
      "\n",
      "discourse structure   0.027777777777777776\n",
      "\n",
      "a pre-structured   0.001226993865030675\n",
      "\n",
      "beforehand -LRB-   1.0\n",
      "\n",
      "wrote ELIZA   0.16666666666666666\n",
      "\n",
      "by increasing   0.005714285714285714\n",
      "\n",
      "and perhaps   0.001445086705202312\n",
      "\n",
      "problem yet   0.022727272727272728\n",
      "\n",
      "of typical   0.00089126559714795\n",
      "\n",
      "words occur   0.009174311926605505\n",
      "\n",
      "very distant   0.024390243902439025\n",
      "\n",
      "The difference   0.005208333333333333\n",
      "\n",
      "are traditionally   0.008298755186721992\n",
      "\n",
      "numbers on   0.14285714285714285\n",
      "\n",
      "names .   0.2857142857142857\n",
      "\n",
      "Web -RRB-   0.1111111111111111\n",
      "\n",
      "Fully Automated   1.0\n",
      "\n",
      "René Descartes   1.0\n",
      "\n",
      "corpora specifically   0.09090909090909091\n",
      "\n",
      "lower than   0.2\n",
      "\n",
      "teams in   0.5\n",
      "\n",
      "extraction or   0.03225806451612903\n",
      "\n",
      ", favor   0.0005614823133071309\n",
      "\n",
      "papers by   0.3333333333333333\n",
      "\n",
      "needed -RRB-   0.6190476190476191\n",
      "\n",
      "-LRB- Computational   0.0027100271002710027\n",
      "\n",
      "to remain   0.0013280212483399733\n",
      "\n",
      "Airline Ticket   1.0\n",
      "\n",
      "underlies the   1.0\n",
      "\n",
      "given restaurant   0.041666666666666664\n",
      "\n",
      "other hand   0.07142857142857142\n",
      "\n",
      "and going   0.001445086705202312\n",
      "\n",
      "rates can   0.125\n",
      "\n",
      "keyphrases of   0.02857142857142857\n",
      "\n",
      "whole workday   0.1111111111111111\n",
      "\n",
      "and similar   0.001445086705202312\n",
      "\n",
      "<s> Please   0.0023059185242121443\n",
      "\n",
      ", 1952   0.0005614823133071309\n",
      "\n",
      "discussing how   0.5\n",
      "\n",
      "generate translations   0.05555555555555555\n",
      "\n",
      "modules that   0.5\n",
      "\n",
      "derivations of   1.0\n",
      "\n",
      "Chantal Mouffe   1.0\n",
      "\n",
      "approach in   0.02857142857142857\n",
      "\n",
      "support personnel   0.25\n",
      "\n",
      "other possible   0.014285714285714285\n",
      "\n",
      "Two years   0.42857142857142855\n",
      "\n",
      "to deal   0.0013280212483399733\n",
      "\n",
      "the exception   0.0006920415224913495\n",
      "\n",
      "but evaluation   0.014705882352941176\n",
      "\n",
      "-LRB- 2000   0.0027100271002710027\n",
      "\n",
      "Hard of   0.5\n",
      "\n",
      "ellipsis ,   1.0\n",
      "\n",
      "increased so   0.2\n",
      "\n",
      ", generally   0.0005614823133071309\n",
      "\n",
      "This corpus   0.031746031746031744\n",
      "\n",
      "printed in   0.08333333333333333\n",
      "\n",
      "expand our   1.0\n",
      "\n",
      "languages using   0.02\n",
      "\n",
      "translator needs   0.14285714285714285\n",
      "\n",
      "1956 and   1.0\n",
      "\n",
      "a readable   0.001226993865030675\n",
      "\n",
      "than text   0.022222222222222223\n",
      "\n",
      "DA -RRB-   0.6666666666666666\n",
      "\n",
      "appear ``   0.0625\n",
      "\n",
      "it offered   0.008547008547008548\n",
      "\n",
      "largely similar   0.2\n",
      "\n",
      "agree -RRB-   0.3333333333333333\n",
      "\n",
      "different relationships   0.02040816326530612\n",
      "\n",
      "Markov chain   0.05555555555555555\n",
      "\n",
      "<s> Unsupervised   0.003843197540353574\n",
      "\n",
      "scripts -LRB-   0.6666666666666666\n",
      "\n",
      "delimited ,   0.5\n",
      "\n",
      "data within   0.012987012987012988\n",
      "\n",
      "He pointed   0.125\n",
      "\n",
      "to explore   0.0026560424966799467\n",
      "\n",
      "the authors   0.0006920415224913495\n",
      "\n",
      "a sophisticated   0.001226993865030675\n",
      "\n",
      "commercial perspective   0.09090909090909091\n",
      "\n",
      "a phrase   0.00245398773006135\n",
      "\n",
      ", engaging   0.0005614823133071309\n",
      "\n",
      "computing :   0.5\n",
      "\n",
      "there may   0.025\n",
      "\n",
      "into phonetic-based   0.01282051282051282\n",
      "\n",
      "of which   0.008912655971479501\n",
      "\n",
      "`` patient   0.005291005291005291\n",
      "\n",
      "her to   0.5\n",
      "\n",
      "general format   0.045454545454545456\n",
      "\n",
      "are easier   0.004149377593360996\n",
      "\n",
      "general speaker   0.045454545454545456\n",
      "\n",
      "the Blind   0.001384083044982699\n",
      "\n",
      "Machines Research   1.0\n",
      "\n",
      "the Parseval\\/GEIG   0.0006920415224913495\n",
      "\n",
      "to aid   0.0013280212483399733\n",
      "\n",
      "common when   0.04\n",
      "\n",
      "system whose   0.010752688172043012\n",
      "\n",
      ", analyze   0.0005614823133071309\n",
      "\n",
      "certain restrictions   0.14285714285714285\n",
      "\n",
      "grid &   1.0\n",
      "\n",
      "inferior results   1.0\n",
      "\n",
      "correct ''   0.06666666666666667\n",
      "\n",
      "vs. independence   0.08333333333333333\n",
      "\n",
      "However ,   0.8648648648648649\n",
      "\n",
      "issue ,   0.125\n",
      "\n",
      "an advanced   0.007575757575757576\n",
      "\n",
      "for descriptive   0.0036101083032490976\n",
      "\n",
      "has published   0.011904761904761904\n",
      "\n",
      "NLG researchers   0.047619047619047616\n",
      "\n",
      "sets for   0.09090909090909091\n",
      "\n",
      "... .   0.5\n",
      "\n",
      "meaning ``   0.043478260869565216\n",
      "\n",
      "gets about   0.5\n",
      "\n",
      "so that   0.2\n",
      "\n",
      "statistics .   0.375\n",
      "\n",
      "improve robustness   0.07692307692307693\n",
      "\n",
      "30 %   0.3333333333333333\n",
      "\n",
      "broadband technologies   1.0\n",
      "\n",
      "expanded the   1.0\n",
      "\n",
      "can find   0.0055248618784530384\n",
      "\n",
      "in January   0.003745318352059925\n",
      "\n",
      "get the   0.2857142857142857\n",
      "\n",
      "contain densely   0.08333333333333333\n",
      "\n",
      "annual Document   0.5\n",
      "\n",
      "introduction of   1.0\n",
      "\n",
      "<s> Vocabulary   0.0007686395080707148\n",
      "\n",
      "those of   0.045454545454545456\n",
      "\n",
      "adjective ,   0.14285714285714285\n",
      "\n",
      "document collections   0.027777777777777776\n",
      "\n",
      "'' the   0.005154639175257732\n",
      "\n",
      "superimpose one   1.0\n",
      "\n",
      "are divided   0.004149377593360996\n",
      "\n",
      "usually abbreviated   0.03125\n",
      "\n",
      "this case   0.01098901098901099\n",
      "\n",
      "Another area   0.07692307692307693\n",
      "\n",
      "<s> Significant   0.0007686395080707148\n",
      "\n",
      "summarization have   0.02\n",
      "\n",
      "many cases   0.038461538461538464\n",
      "\n",
      "correct software   0.06666666666666667\n",
      "\n",
      "computer programming   0.022727272727272728\n",
      "\n",
      "scores for   0.2\n",
      "\n",
      "dividing written   0.3333333333333333\n",
      "\n",
      "`` blue   0.010582010582010581\n",
      "\n",
      "-RRB- If   0.005420054200542005\n",
      "\n",
      "the set   0.001384083044982699\n",
      "\n",
      "<s> Introduction   0.0007686395080707148\n",
      "\n",
      "Rate -LRB-   1.0\n",
      "\n",
      "one on   0.015384615384615385\n",
      "\n",
      "AI systems   0.6666666666666666\n",
      "\n",
      "into smaller   0.01282051282051282\n",
      "\n",
      "Often used   0.3333333333333333\n",
      "\n",
      "the orthography   0.0006920415224913495\n",
      "\n",
      "spacecraft ,   1.0\n",
      "\n",
      "In Italy   0.009523809523809525\n",
      "\n",
      "give predicted   0.25\n",
      "\n",
      "The shorter   0.005208333333333333\n",
      "\n",
      "were developed   0.12195121951219512\n",
      "\n",
      "millions of   1.0\n",
      "\n",
      "continued ,   0.1111111111111111\n",
      "\n",
      "given amount   0.041666666666666664\n",
      "\n",
      "learn parameters   0.07692307692307693\n",
      "\n",
      "this problem   0.07692307692307693\n",
      "\n",
      "data rather   0.012987012987012988\n",
      "\n",
      "<s> When   0.004611837048424289\n",
      "\n",
      "were written   0.024390243902439025\n",
      "\n",
      "and knowledge   0.001445086705202312\n",
      "\n",
      "Marginal Relevance   1.0\n",
      "\n",
      "Speech recognition   0.2903225806451613\n",
      "\n",
      "` best   0.0625\n",
      "\n",
      "predict keyphrases   0.16666666666666666\n",
      "\n",
      "arise because   1.0\n",
      "\n",
      "other sentences   0.014285714285714285\n",
      "\n",
      "constructed by   0.5\n",
      "\n",
      "the clusters   0.0006920415224913495\n",
      "\n",
      "that combines   0.0035460992907801418\n",
      "\n",
      "Alessandro Duranti   1.0\n",
      "\n",
      "a cryptanalyst   0.001226993865030675\n",
      "\n",
      "visible Markov   0.3333333333333333\n",
      "\n",
      ", during   0.0005614823133071309\n",
      "\n",
      "walk on   0.4\n",
      "\n",
      "though the   0.1\n",
      "\n",
      "effort has   0.25\n",
      "\n",
      "1990s .   0.3333333333333333\n",
      "\n",
      "towards this   1.0\n",
      "\n",
      "other POS   0.014285714285714285\n",
      "\n",
      "or after   0.0045045045045045045\n",
      "\n",
      "and Latin   0.001445086705202312\n",
      "\n",
      "i.e. requiring   0.05263157894736842\n",
      "\n",
      "in free   0.003745318352059925\n",
      "\n",
      "was by   0.025974025974025976\n",
      "\n",
      "expression just   0.1\n",
      "\n",
      "move items   1.0\n",
      "\n",
      "be quite   0.004219409282700422\n",
      "\n",
      "is probably   0.0020325203252032522\n",
      "\n",
      "through its   0.125\n",
      "\n",
      "by Henry   0.005714285714285714\n",
      "\n",
      "Acoustical distortions   0.5\n",
      "\n",
      ", adverbs   0.0005614823133071309\n",
      "\n",
      "the previous   0.001384083044982699\n",
      "\n",
      "measurement is   0.5\n",
      "\n",
      "which the   0.057971014492753624\n",
      "\n",
      "description and   1.0\n",
      "\n",
      "is written   0.0020325203252032522\n",
      "\n",
      "processing plain   0.018518518518518517\n",
      "\n",
      "yet to   0.5\n",
      "\n",
      "general approaches   0.045454545454545456\n",
      "\n",
      "writing ,   0.2222222222222222\n",
      "\n",
      "see List   0.05\n",
      "\n",
      "to such   0.0026560424966799467\n",
      "\n",
      "significant task   0.1111111111111111\n",
      "\n",
      "the different   0.0006920415224913495\n",
      "\n",
      "very sophisticated   0.024390243902439025\n",
      "\n",
      "the corpus   0.0006920415224913495\n",
      "\n",
      "a user   0.00245398773006135\n",
      "\n",
      "paper ,   0.09090909090909091\n",
      "\n",
      "so accurate   0.03333333333333333\n",
      "\n",
      "'' will   0.005154639175257732\n",
      "\n",
      "formal modeling   0.1111111111111111\n",
      "\n",
      "the RCA   0.0006920415224913495\n",
      "\n",
      ", meanings   0.0005614823133071309\n",
      "\n",
      "The first   0.036458333333333336\n",
      "\n",
      "be ''   0.008438818565400843\n",
      "\n",
      "<s> Tokens   0.0007686395080707148\n",
      "\n",
      "asking for   0.5\n",
      "\n",
      "from the   0.21153846153846154\n",
      "\n",
      "and sub-categories   0.001445086705202312\n",
      "\n",
      "the implications   0.0006920415224913495\n",
      "\n",
      "Example-based machine   0.6666666666666666\n",
      "\n",
      "lexical resources   0.07692307692307693\n",
      "\n",
      "summaries humans   0.023255813953488372\n",
      "\n",
      "users .   0.2222222222222222\n",
      "\n",
      "<s> Sometimes   0.0007686395080707148\n",
      "\n",
      "usually involves   0.03125\n",
      "\n",
      "punctuation characters   0.14285714285714285\n",
      "\n",
      "for inclusion   0.0036101083032490976\n",
      "\n",
      "figure on   0.5\n",
      "\n",
      "removes the   1.0\n",
      "\n",
      "images ,   0.3333333333333333\n",
      "\n",
      "system whereby   0.010752688172043012\n",
      "\n",
      "key clauses   0.16666666666666666\n",
      "\n",
      "e.g. Phonemes   0.017857142857142856\n",
      "\n",
      "system should   0.010752688172043012\n",
      "\n",
      "chatterbots were   0.5\n",
      "\n",
      "200 ,   0.5\n",
      "\n",
      "finding a   0.4\n",
      "\n",
      "it extremely   0.008547008547008548\n",
      "\n",
      "-LRB- though   0.0027100271002710027\n",
      "\n",
      "rules by   0.023255813953488372\n",
      "\n",
      "speeds made   0.5\n",
      "\n",
      "`` inadequate   0.005291005291005291\n",
      "\n",
      "the extent   0.001384083044982699\n",
      "\n",
      "a vertex   0.00245398773006135\n",
      "\n",
      "data for   0.012987012987012988\n",
      "\n",
      "Gina Poncini   1.0\n",
      "\n",
      ", disturbed   0.0005614823133071309\n",
      "\n",
      "standards are   0.2\n",
      "\n",
      "of Ethnomethodology   0.00089126559714795\n",
      "\n",
      ", texts   0.0005614823133071309\n",
      "\n",
      "issues Disambiguation   0.2\n",
      "\n",
      "difference between   0.25\n",
      "\n",
      "HMMs underlie   0.125\n",
      "\n",
      "telephony is   0.3333333333333333\n",
      "\n",
      ", any   0.0005614823133071309\n",
      "\n",
      "emphasize different   1.0\n",
      "\n",
      "the SR   0.0006920415224913495\n",
      "\n",
      "are displayed   0.004149377593360996\n",
      "\n",
      "major design   0.08333333333333333\n",
      "\n",
      "food and   1.0\n",
      "\n",
      "which bore   0.007246376811594203\n",
      "\n",
      "languages like   0.02\n",
      "\n",
      "Homayoon Beigi   1.0\n",
      "\n",
      "people or   0.0625\n",
      "\n",
      "multiplying together   1.0\n",
      "\n",
      "text summaries   0.006289308176100629\n",
      "\n",
      "to eigenvalue   0.0013280212483399733\n",
      "\n",
      "two approaches   0.034482758620689655\n",
      "\n",
      "Handel also   1.0\n",
      "\n",
      "computerized text   0.5\n",
      "\n",
      "builds a   0.5\n",
      "\n",
      "applies both   0.2857142857142857\n",
      "\n",
      "off on   0.5\n",
      "\n",
      "-RRB- MorphoChallenge   0.0027100271002710027\n",
      "\n",
      "video -RRB-   0.2\n",
      "\n",
      "These systems   0.23529411764705882\n",
      "\n",
      "individual vertices   0.08333333333333333\n",
      "\n",
      "be ranked   0.004219409282700422\n",
      "\n",
      "would run   0.03773584905660377\n",
      "\n",
      "we produce   0.044444444444444446\n",
      "\n",
      "of ISO\\/TC37   0.00089126559714795\n",
      "\n",
      "through sentiment   0.125\n",
      "\n",
      "materials to   0.5\n",
      "\n",
      "question is   0.09523809523809523\n",
      "\n",
      "as English   0.010452961672473868\n",
      "\n",
      "simply too   0.08333333333333333\n",
      "\n",
      "next word   0.2857142857142857\n",
      "\n",
      "that did   0.0070921985815602835\n",
      "\n",
      "apply statistical   0.2\n",
      "\n",
      "specialized algorithms   0.5\n",
      "\n",
      "Voice Control   0.2\n",
      "\n",
      "information from   0.06521739130434782\n",
      "\n",
      "limited applications   0.1\n",
      "\n",
      "four step   0.14285714285714285\n",
      "\n",
      "handles both   1.0\n",
      "\n",
      "video the   0.2\n",
      "\n",
      "with restricted   0.00546448087431694\n",
      "\n",
      "summarise electronic   0.3333333333333333\n",
      "\n",
      "Work on   0.5\n",
      "\n",
      "corpora on   0.09090909090909091\n",
      "\n",
      "of English   0.00267379679144385\n",
      "\n",
      "common plural   0.04\n",
      "\n",
      "been trained   0.014705882352941176\n",
      "\n",
      "submit them   0.5\n",
      "\n",
      "each with   0.022222222222222223\n",
      "\n",
      "Inc. and   0.5\n",
      "\n",
      "benchmark tests   1.0\n",
      "\n",
      "The sentences   0.005208333333333333\n",
      "\n",
      "knowledge to   0.037037037037037035\n",
      "\n",
      "% -LRB-   0.07692307692307693\n",
      "\n",
      "the topic   0.001384083044982699\n",
      "\n",
      "HMM-based part   0.3333333333333333\n",
      "\n",
      "strokes for   1.0\n",
      "\n",
      "and converted   0.001445086705202312\n",
      "\n",
      "analysis which   0.015384615384615385\n",
      "\n",
      "restricted world   0.25\n",
      "\n",
      "tasks like   0.0625\n",
      "\n",
      "tractability .   1.0\n",
      "\n",
      "a window   0.001226993865030675\n",
      "\n",
      "'' has   0.010309278350515464\n",
      "\n",
      "state -LRB-   0.07142857142857142\n",
      "\n",
      "Establishment -LRB-   1.0\n",
      "\n",
      "claiming to   1.0\n",
      "\n",
      "which focused   0.007246376811594203\n",
      "\n",
      "constructs can   0.3333333333333333\n",
      "\n",
      "step -LRB-   0.06666666666666667\n",
      "\n",
      "contains the   0.2\n",
      "\n",
      "weather forecasts   0.5714285714285714\n",
      "\n",
      "words as   0.009174311926605505\n",
      "\n",
      "predicting ratings   0.5\n",
      "\n",
      "language for   0.02027027027027027\n",
      "\n",
      "summaries or   0.023255813953488372\n",
      "\n",
      "rules and   0.023255813953488372\n",
      "\n",
      "In information   0.009523809523809525\n",
      "\n",
      "a frame   0.001226993865030675\n",
      "\n",
      "a lexicon   0.00245398773006135\n",
      "\n",
      "Language Input   0.08333333333333333\n",
      "\n",
      "that converts   0.0035460992907801418\n",
      "\n",
      "that by   0.0035460992907801418\n",
      "\n",
      "smaller .   0.14285714285714285\n",
      "\n",
      "between Internet   0.02564102564102564\n",
      "\n",
      "required the   0.14285714285714285\n",
      "\n",
      "the book   0.001384083044982699\n",
      "\n",
      "be obtained   0.004219409282700422\n",
      "\n",
      ", i.e.   0.0039303761931499155\n",
      "\n",
      "is different   0.0020325203252032522\n",
      "\n",
      "systems will   0.008928571428571428\n",
      "\n",
      "HMM parameter   0.3333333333333333\n",
      "\n",
      "Such strategy   0.125\n",
      "\n",
      "same words   0.04\n",
      "\n",
      "rapidly growing   0.5\n",
      "\n",
      "number -RRB-   0.046511627906976744\n",
      "\n",
      "PC platform   0.25\n",
      "\n",
      "dependencies .   1.0\n",
      "\n",
      "non-linearly to   1.0\n",
      "\n",
      ", facts   0.0005614823133071309\n",
      "\n",
      "The Brill   0.005208333333333333\n",
      "\n",
      "with values   0.01639344262295082\n",
      "\n",
      "the initial   0.0006920415224913495\n",
      "\n",
      "DTW -RRB-   0.3333333333333333\n",
      "\n",
      "Granada Different   0.5\n",
      "\n",
      "templates may   1.0\n",
      "\n",
      "general ontologies   0.045454545454545456\n",
      "\n",
      "the OCR-A   0.0006920415224913495\n",
      "\n",
      "eigenvector corresponding   0.5\n",
      "\n",
      "overlaps between   0.5\n",
      "\n",
      "grammars -LRB-   0.07142857142857142\n",
      "\n",
      "Japanese -RRB-   0.125\n",
      "\n",
      "ranking sentences   0.14285714285714285\n",
      "\n",
      ", machine   0.0016844469399213925\n",
      "\n",
      "more time-consuming   0.010526315789473684\n",
      "\n",
      "aspects such   0.14285714285714285\n",
      "\n",
      "with which   0.00546448087431694\n",
      "\n",
      "dynamic programming   0.2\n",
      "\n",
      "Ruth Wodak   1.0\n",
      "\n",
      "this field   0.02197802197802198\n",
      "\n",
      "plural ,   0.4\n",
      "\n",
      "issues are   0.2\n",
      "\n",
      "used over   0.008849557522123894\n",
      "\n",
      "a specialist   0.001226993865030675\n",
      "\n",
      "sense of   0.125\n",
      "\n",
      "of conversations   0.00089126559714795\n",
      "\n",
      "selected as   0.5\n",
      "\n",
      "preparation of   1.0\n",
      "\n",
      "algorithm or   0.03571428571428571\n",
      "\n",
      "typically given   0.05555555555555555\n",
      "\n",
      "-RRB- at   0.0027100271002710027\n",
      "\n",
      "as working   0.003484320557491289\n",
      "\n",
      "Association for   1.0\n",
      "\n",
      "the research   0.0020761245674740486\n",
      "\n",
      "well as   0.4642857142857143\n",
      "\n",
      "specification is   0.5\n",
      "\n",
      "individual lines   0.08333333333333333\n",
      "\n",
      "or noun   0.0045045045045045045\n",
      "\n",
      "was FoG   0.012987012987012988\n",
      "\n",
      "commonly researched   0.125\n",
      "\n",
      "to break   0.0013280212483399733\n",
      "\n",
      "Research on   0.125\n",
      "\n",
      "an NLP   0.022727272727272728\n",
      "\n",
      "history .   0.25\n",
      "\n",
      "C. ,   1.0\n",
      "\n",
      "Words and   0.25\n",
      "\n",
      "the computer-aided   0.0006920415224913495\n",
      "\n",
      "mentioned in   0.16666666666666666\n",
      "\n",
      "a sequence   0.007361963190184049\n",
      "\n",
      "by the   0.15428571428571428\n",
      "\n",
      "<s> Recognition   0.0015372790161414297\n",
      "\n",
      ", either   0.0011229646266142617\n",
      "\n",
      "see LMF   0.05\n",
      "\n",
      "market for   0.3333333333333333\n",
      "\n",
      "is definite   0.0020325203252032522\n",
      "\n",
      "is publicly   0.0020325203252032522\n",
      "\n",
      "pulled directly   1.0\n",
      "\n",
      "marks and   0.25\n",
      "\n",
      "library ,   0.5\n",
      "\n",
      "most often   0.017241379310344827\n",
      "\n",
      "for continued   0.0036101083032490976\n",
      "\n",
      "Cloud Computing   1.0\n",
      "\n",
      "breaks are   0.5\n",
      "\n",
      "as candidates   0.003484320557491289\n",
      "\n",
      "far from   0.125\n",
      "\n",
      "between IR   0.02564102564102564\n",
      "\n",
      "where word   0.02857142857142857\n",
      "\n",
      "capitalization may   0.3333333333333333\n",
      "\n",
      "parsing input   0.03571428571428571\n",
      "\n",
      "1999 L'action   0.5\n",
      "\n",
      "fact ,   0.45454545454545453\n",
      "\n",
      "an Australian   0.007575757575757576\n",
      "\n",
      "rules generated   0.023255813953488372\n",
      "\n",
      "disambiguate sentence   0.3333333333333333\n",
      "\n",
      "speakers were   0.25\n",
      "\n",
      "Translator -RRB-   1.0\n",
      "\n",
      "-LRB- See   0.01084010840108401\n",
      "\n",
      "fine degrees   0.5\n",
      "\n",
      "notations of   0.5\n",
      "\n",
      "considerable variation   0.2\n",
      "\n",
      "evaluating NLG   0.2\n",
      "\n",
      "edge if   0.3333333333333333\n",
      "\n",
      "faster but   0.3333333333333333\n",
      "\n",
      "understand why   0.14285714285714285\n",
      "\n",
      ", Wallace   0.0005614823133071309\n",
      "\n",
      "Language Constraints   0.08333333333333333\n",
      "\n",
      "with using   0.00546448087431694\n",
      "\n",
      "French .   0.25\n",
      "\n",
      "a routing   0.001226993865030675\n",
      "\n",
      "language models   0.013513513513513514\n",
      "\n",
      "potentially unlimited   0.3333333333333333\n",
      "\n",
      "-LRB- MEAD   0.0027100271002710027\n",
      "\n",
      "and Semantic   0.001445086705202312\n",
      "\n",
      "be identified   0.008438818565400843\n",
      "\n",
      ", Phrases   0.0005614823133071309\n",
      "\n",
      "new data   0.041666666666666664\n",
      "\n",
      "large amount   0.043478260869565216\n",
      "\n",
      "was able   0.05194805194805195\n",
      "\n",
      "spaces used   0.2\n",
      "\n",
      "Topics of   1.0\n",
      "\n",
      "syntax and   0.09090909090909091\n",
      "\n",
      "for parse   0.0036101083032490976\n",
      "\n",
      "opportunities and   1.0\n",
      "\n",
      "involved in   0.16666666666666666\n",
      "\n",
      "phoneme classification   0.5\n",
      "\n",
      "lessening of   1.0\n",
      "\n",
      "means that   0.6666666666666666\n",
      "\n",
      "learner ,   0.5\n",
      "\n",
      "idea of   0.2857142857142857\n",
      "\n",
      "pauses between   0.5\n",
      "\n",
      "elements containing   0.25\n",
      "\n",
      "use context-free   0.013888888888888888\n",
      "\n",
      "convention in   1.0\n",
      "\n",
      "symbolic representation   1.0\n",
      "\n",
      "first sentence-end   0.030303030303030304\n",
      "\n",
      "to bootstrap   0.0013280212483399733\n",
      "\n",
      "delimited -LRB-   0.25\n",
      "\n",
      "related languages   0.06666666666666667\n",
      "\n",
      ", to   0.0072992700729927005\n",
      "\n",
      "whether the   0.15384615384615385\n",
      "\n",
      "logical form   0.16666666666666666\n",
      "\n",
      "`` book   0.005291005291005291\n",
      "\n",
      "grammars are   0.07142857142857142\n",
      "\n",
      "because recognition   0.03333333333333333\n",
      "\n",
      "that will   0.0070921985815602835\n",
      "\n",
      "perspectives and   1.0\n",
      "\n",
      "famous QA   0.3333333333333333\n",
      "\n",
      "Sandra Thompson   1.0\n",
      "\n",
      "that attempt   0.0035460992907801418\n",
      "\n",
      "For a   0.03278688524590164\n",
      "\n",
      "algorithm ?   0.03571428571428571\n",
      "\n",
      "and statistics   0.002890173410404624\n",
      "\n",
      "resource consumption   0.2\n",
      "\n",
      "of hand-written   0.00267379679144385\n",
      "\n",
      "type provided   0.07142857142857142\n",
      "\n",
      "reason ,   0.5\n",
      "\n",
      ", question   0.0011229646266142617\n",
      "\n",
      "right-most derivations   1.0\n",
      "\n",
      "poor coverage   1.0\n",
      "\n",
      "how often   0.034482758620689655\n",
      "\n",
      "To perform   0.1111111111111111\n",
      "\n",
      "now commonplace   0.07692307692307693\n",
      "\n",
      "readers .   0.5\n",
      "\n",
      "helping people   1.0\n",
      "\n",
      "productions .   1.0\n",
      "\n",
      "settle on   1.0\n",
      "\n",
      "corpus such   0.03225806451612903\n",
      "\n",
      "Piron mentions   0.3333333333333333\n",
      "\n",
      "The problem   0.015625\n",
      "\n",
      "article accuracy   0.034482758620689655\n",
      "\n",
      "deep ''   0.14285714285714285\n",
      "\n",
      "not rare   0.008928571428571428\n",
      "\n",
      "Languages like   0.3333333333333333\n",
      "\n",
      "questioner might   0.25\n",
      "\n",
      "combining those   0.25\n",
      "\n",
      "an experiment   0.007575757575757576\n",
      "\n",
      "of restaurant   0.00089126559714795\n",
      "\n",
      "include overt   0.037037037037037035\n",
      "\n",
      "need a   0.19047619047619047\n",
      "\n",
      "grammar parsing   0.02702702702702703\n",
      "\n",
      "determining whether   0.16666666666666666\n",
      "\n",
      "any answer   0.03225806451612903\n",
      "\n",
      "differently on   1.0\n",
      "\n",
      "negative to   0.125\n",
      "\n",
      "the proliferation   0.0006920415224913495\n",
      "\n",
      "QA -RRB-   0.047619047619047616\n",
      "\n",
      "and volume   0.001445086705202312\n",
      "\n",
      "traditionally written   0.5\n",
      "\n",
      "allowing us   0.3333333333333333\n",
      "\n",
      "other in   0.014285714285714285\n",
      "\n",
      "language .   0.07432432432432433\n",
      "\n",
      "life scientists   0.25\n",
      "\n",
      "direct hand   0.16666666666666666\n",
      "\n",
      "text from   0.012578616352201259\n",
      "\n",
      "M. De   0.25\n",
      "\n",
      "than supervised   0.022222222222222223\n",
      "\n",
      "The Brown   0.015625\n",
      "\n",
      "formatted output   1.0\n",
      "\n",
      "people untrained   0.0625\n",
      "\n",
      "display format   0.5\n",
      "\n",
      "often it   0.022727272727272728\n",
      "\n",
      "word .   0.13333333333333333\n",
      "\n",
      "good candidates   0.23076923076923078\n",
      "\n",
      "who used   0.1\n",
      "\n",
      "sources or   0.16666666666666666\n",
      "\n",
      "many significant   0.019230769230769232\n",
      "\n",
      "-LRB- HMMs   0.005420054200542005\n",
      "\n",
      "forth .   1.0\n",
      "\n",
      "in evaluating   0.0018726591760299626\n",
      "\n",
      "more reliable   0.031578947368421054\n",
      "\n",
      "denote abbreviations   0.5\n",
      "\n",
      "-LRB- FAS   0.0027100271002710027\n",
      "\n",
      "module looks   0.3333333333333333\n",
      "\n",
      "diverse ''   0.5\n",
      "\n",
      "prisoner of   1.0\n",
      "\n",
      "on whether   0.0047169811320754715\n",
      "\n",
      "continued more   0.1111111111111111\n",
      "\n",
      "search method   0.09090909090909091\n",
      "\n",
      "strong feeling   0.25\n",
      "\n",
      "seem to   0.5\n",
      "\n",
      "accommodate various   0.2\n",
      "\n",
      "what features   0.03125\n",
      "\n",
      "<s> Running   0.0007686395080707148\n",
      "\n",
      "more formal   0.010526315789473684\n",
      "\n",
      "a fancy   0.001226993865030675\n",
      "\n",
      "Popular speech   1.0\n",
      "\n",
      ", Stef   0.0005614823133071309\n",
      "\n",
      "a Computer   0.001226993865030675\n",
      "\n",
      "past decade   0.3333333333333333\n",
      "\n",
      "levels are   0.045454545454545456\n",
      "\n",
      "early precursor   0.1\n",
      "\n",
      "taking the   0.6\n",
      "\n",
      "science convention   0.1\n",
      "\n",
      "John Du   0.125\n",
      "\n",
      "the detection   0.0006920415224913495\n",
      "\n",
      "importantly ,   1.0\n",
      "\n",
      "still not   0.06666666666666667\n",
      "\n",
      "states are   0.25\n",
      "\n",
      "the Vulcan   0.0006920415224913495\n",
      "\n",
      "languages -LRB-   0.04\n",
      "\n",
      "natural-language processing   1.0\n",
      "\n",
      "the text   0.017993079584775088\n",
      "\n",
      "the SIGGEN   0.0006920415224913495\n",
      "\n",
      "traditional linguistics   1.0\n",
      "\n",
      "different times   0.02040816326530612\n",
      "\n",
      "significant semiotic   0.1111111111111111\n",
      "\n",
      "order logic   0.07142857142857142\n",
      "\n",
      "break sentences   0.5\n",
      "\n",
      "term ``   0.1111111111111111\n",
      "\n",
      "of sentiment   0.004456327985739751\n",
      "\n",
      "<s> LexRank   0.0015372790161414297\n",
      "\n",
      "to measure   0.005312084993359893\n",
      "\n",
      "NLP systems   0.06382978723404255\n",
      "\n",
      ", Barbara   0.0005614823133071309\n",
      "\n",
      "discourse -RRB-   0.027777777777777776\n",
      "\n",
      "of POS   0.0017825311942959\n",
      "\n",
      "might contain   0.038461538461538464\n",
      "\n",
      "typically based   0.05555555555555555\n",
      "\n",
      "Designing a   1.0\n",
      "\n",
      "to input   0.0026560424966799467\n",
      "\n",
      "it formed   0.008547008547008548\n",
      "\n",
      "to human-written   0.0013280212483399733\n",
      "\n",
      "<s> and   0.0007686395080707148\n",
      "\n",
      "may use   0.019230769230769232\n",
      "\n",
      "vulnerable to   1.0\n",
      "\n",
      "use cepstral   0.013888888888888888\n",
      "\n",
      "can greatly   0.0055248618784530384\n",
      "\n",
      "1629 ,   1.0\n",
      "\n",
      "signed language   1.0\n",
      "\n",
      "extract sentences   0.25\n",
      "\n",
      "pilot ,   0.2\n",
      "\n",
      "often under   0.022727272727272728\n",
      "\n",
      "recognize equivalent   0.1111111111111111\n",
      "\n",
      "is devoted   0.0020325203252032522\n",
      "\n",
      "foreign ''   0.5\n",
      "\n",
      "separated by   0.6666666666666666\n",
      "\n",
      "are fields   0.004149377593360996\n",
      "\n",
      "of tags   0.00089126559714795\n",
      "\n",
      "graph small   0.07692307692307693\n",
      "\n",
      "lexicons with   0.5\n",
      "\n",
      "shops in   1.0\n",
      "\n",
      "achieve accuracy   0.5\n",
      "\n",
      "linguistic resources   0.0625\n",
      "\n",
      "complicating the   1.0\n",
      "\n",
      "combine various   0.6666666666666666\n",
      "\n",
      "is lessened   0.0020325203252032522\n",
      "\n",
      "providers began   1.0\n",
      "\n",
      "helps him   0.5\n",
      "\n",
      "it statically   0.008547008547008548\n",
      "\n",
      ", negative   0.0005614823133071309\n",
      "\n",
      "recognition software   0.024793388429752067\n",
      "\n",
      "substitutions .   1.0\n",
      "\n",
      "has characterized   0.011904761904761904\n",
      "\n",
      "highly ambiguous   0.1111111111111111\n",
      "\n",
      "heard or   1.0\n",
      "\n",
      "potential parses   0.14285714285714285\n",
      "\n",
      "observation .   1.0\n",
      "\n",
      "experimenting .   1.0\n",
      "\n",
      "separate tokens   0.1\n",
      "\n",
      "linguists can   0.3333333333333333\n",
      "\n",
      "the dictator   0.0006920415224913495\n",
      "\n",
      "recognized or   0.16666666666666666\n",
      "\n",
      "semitied covariance   1.0\n",
      "\n",
      "that for   0.0035460992907801418\n",
      "\n",
      "negative labels   0.125\n",
      "\n",
      "seize the   1.0\n",
      "\n",
      "not found   0.008928571428571428\n",
      "\n",
      "ranked highly   0.4\n",
      "\n",
      "to suggest   0.0013280212483399733\n",
      "\n",
      "automated online   0.14285714285714285\n",
      "\n",
      "tagging techniques   0.04\n",
      "\n",
      "term artificial   0.05555555555555555\n",
      "\n",
      "intelligence technologies   0.125\n",
      "\n",
      "C4 .5   1.0\n",
      "\n",
      "choose different   0.5\n",
      "\n",
      "been operated   0.014705882352941176\n",
      "\n",
      "printed texts   0.08333333333333333\n",
      "\n",
      "corpus as   0.03225806451612903\n",
      "\n",
      "Sentences ;   1.0\n",
      "\n",
      "answering systems   0.08333333333333333\n",
      "\n",
      "potential and   0.14285714285714285\n",
      "\n",
      "specifically developed   0.5\n",
      "\n",
      "languages text   0.02\n",
      "\n",
      "70 %   0.75\n",
      "\n",
      "<s> Natural   0.004611837048424289\n",
      "\n",
      "van Dijk   0.5\n",
      "\n",
      "together ,   0.125\n",
      "\n",
      ", speeches   0.0005614823133071309\n",
      "\n",
      "or subjective   0.009009009009009009\n",
      "\n",
      "% to   0.05128205128205128\n",
      "\n",
      "holder of   1.0\n",
      "\n",
      "This was   0.015873015873015872\n",
      "\n",
      "pursued after   1.0\n",
      "\n",
      "sentences of   0.02631578947368421\n",
      "\n",
      "of case-based   0.00089126559714795\n",
      "\n",
      "engines ,   0.3333333333333333\n",
      "\n",
      "and business   0.001445086705202312\n",
      "\n",
      ", ICASSP   0.0005614823133071309\n",
      "\n",
      "methods Some   0.022727272727272728\n",
      "\n",
      "documents -LRB-   0.13157894736842105\n",
      "\n",
      "the wave   0.0006920415224913495\n",
      "\n",
      "or by   0.0045045045045045045\n",
      "\n",
      "theories on   0.2\n",
      "\n",
      "you meant   0.07692307692307693\n",
      "\n",
      "general ,   0.2727272727272727\n",
      "\n",
      "Speech Technology   0.03225806451612903\n",
      "\n",
      "it generalizes   0.008547008547008548\n",
      "\n",
      "inter-word spaces   1.0\n",
      "\n",
      "help prevent   0.1111111111111111\n",
      "\n",
      "generally without   0.09090909090909091\n",
      "\n",
      "is best   0.0020325203252032522\n",
      "\n",
      "`` create   0.005291005291005291\n",
      "\n",
      "less expensive   0.08333333333333333\n",
      "\n",
      "Components and   1.0\n",
      "\n",
      "are extractive   0.004149377593360996\n",
      "\n",
      "statistics ,   0.125\n",
      "\n",
      "Such inflection   0.125\n",
      "\n",
      "a statistical   0.0036809815950920245\n",
      "\n",
      "confusability Speaker   1.0\n",
      "\n",
      "Document reader   0.25\n",
      "\n",
      "and ``   0.028901734104046242\n",
      "\n",
      "Yes\\/No vs.   1.0\n",
      "\n",
      "according to   1.0\n",
      "\n",
      "voice commands   0.07692307692307693\n",
      "\n",
      "and encouraged   0.001445086705202312\n",
      "\n",
      "advanced ''   0.2\n",
      "\n",
      ", Art   0.0005614823133071309\n",
      "\n",
      "medicine or   1.0\n",
      "\n",
      "phonemes .   0.16666666666666666\n",
      "\n",
      "in ontologies   0.0018726591760299626\n",
      "\n",
      "QA The   0.047619047619047616\n",
      "\n",
      "few sentences   1.0\n",
      "\n",
      "in computer-aided   0.0018726591760299626\n",
      "\n",
      "without much   0.07692307692307693\n",
      "\n",
      "NLG -RRB-   0.047619047619047616\n",
      "\n",
      "reading credit   0.125\n",
      "\n",
      "This parses   0.015873015873015872\n",
      "\n",
      "Pennsylvania in   1.0\n",
      "\n",
      ", leads   0.0005614823133071309\n",
      "\n",
      "task .   0.23809523809523808\n",
      "\n",
      "while on-line   0.05\n",
      "\n",
      "obstacles to   1.0\n",
      "\n",
      "much of   0.09090909090909091\n",
      "\n",
      "be declared   0.004219409282700422\n",
      "\n",
      "difficult to   0.39285714285714285\n",
      "\n",
      "notion that   0.25\n",
      "\n",
      "<s> Correct   0.0007686395080707148\n",
      "\n",
      ", article   0.0016844469399213925\n",
      "\n",
      "exactly as   0.3333333333333333\n",
      "\n",
      ", grammars   0.0005614823133071309\n",
      "\n",
      "on post-processing   0.0047169811320754715\n",
      "\n",
      ", political   0.0005614823133071309\n",
      "\n",
      "the years   0.0006920415224913495\n",
      "\n",
      "unlikely analyses   1.0\n",
      "\n",
      "documents as   0.02631578947368421\n",
      "\n",
      ", tables   0.0005614823133071309\n",
      "\n",
      "best that   0.1111111111111111\n",
      "\n",
      "entirely committed   0.5\n",
      "\n",
      "complex formalisms   0.041666666666666664\n",
      "\n",
      "plant OCR   1.0\n",
      "\n",
      "often .   0.022727272727272728\n",
      "\n",
      "likely uttered   0.0625\n",
      "\n",
      "Blommaert ,   1.0\n",
      "\n",
      "or English-like   0.0045045045045045045\n",
      "\n",
      "structured databases   0.16666666666666666\n",
      "\n",
      "normalized by   1.0\n",
      "\n",
      "proper evaluation   0.14285714285714285\n",
      "\n",
      "often disagree   0.022727272727272728\n",
      "\n",
      "usually takes   0.03125\n",
      "\n",
      "characters from   0.0625\n",
      "\n",
      "the KEA   0.0006920415224913495\n",
      "\n",
      "should indicate   0.05263157894736842\n",
      "\n",
      "the reported   0.0006920415224913495\n",
      "\n",
      "answers the   0.08333333333333333\n",
      "\n",
      "of marking   0.00089126559714795\n",
      "\n",
      "together in   0.125\n",
      "\n",
      "been achieved   0.029411764705882353\n",
      "\n",
      "indicates that   1.0\n",
      "\n",
      "If a   0.1\n",
      "\n",
      "looking waves   0.2\n",
      "\n",
      "released speech   0.5\n",
      "\n",
      "erroneous input   1.0\n",
      "\n",
      "though such   0.1\n",
      "\n",
      "specific to   0.047619047619047616\n",
      "\n",
      "than by   0.022222222222222223\n",
      "\n",
      "voice applications   0.07692307692307693\n",
      "\n",
      "meaningful symbol   0.125\n",
      "\n",
      "the co-occurrence   0.0006920415224913495\n",
      "\n",
      "Associated Press   1.0\n",
      "\n",
      "corpus with   0.03225806451612903\n",
      "\n",
      "parsing refers   0.03571428571428571\n",
      "\n",
      "knowledge and   0.07407407407407407\n",
      "\n",
      "versa first-cut   1.0\n",
      "\n",
      "of man-hours   0.00089126559714795\n",
      "\n",
      "tools deploy   0.16666666666666666\n",
      "\n",
      "a problem   0.0036809815950920245\n",
      "\n",
      "<s> Information   0.0007686395080707148\n",
      "\n",
      "the smaller   0.0006920415224913495\n",
      "\n",
      "which used   0.007246376811594203\n",
      "\n",
      "and bought   0.001445086705202312\n",
      "\n",
      "of neural   0.00089126559714795\n",
      "\n",
      "and 2   0.001445086705202312\n",
      "\n",
      "extract subjective   0.25\n",
      "\n",
      "cockpit ,   0.5\n",
      "\n",
      "unable to   1.0\n",
      "\n",
      "fail for   0.3333333333333333\n",
      "\n",
      "should predict   0.05263157894736842\n",
      "\n",
      "full stop   0.4\n",
      "\n",
      "and that   0.002890173410404624\n",
      "\n",
      ": expanded   0.00980392156862745\n",
      "\n",
      "`` central   0.010582010582010581\n",
      "\n",
      "are harder   0.004149377593360996\n",
      "\n",
      "most famous   0.034482758620689655\n",
      "\n",
      "visual and\\/or   0.5\n",
      "\n",
      ", one   0.003368893879842785\n",
      "\n",
      "also be   0.10144927536231885\n",
      "\n",
      "Last level   1.0\n",
      "\n",
      "explore and   0.25\n",
      "\n",
      "In such   0.009523809523809525\n",
      "\n",
      "first-cut can   1.0\n",
      "\n",
      "equivalent set   0.2\n",
      "\n",
      "interaction Genres   0.125\n",
      "\n",
      "many more   0.019230769230769232\n",
      "\n",
      "Paul Chilton   0.2\n",
      "\n",
      "or might   0.0045045045045045045\n",
      "\n",
      "identity of   1.0\n",
      "\n",
      "for customisation   0.0036101083032490976\n",
      "\n",
      "-RRB- The   0.005420054200542005\n",
      "\n",
      "open ,   0.25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system or   0.021505376344086023\n",
      "\n",
      "1960s and   0.3333333333333333\n",
      "\n",
      "of mainland   0.0017825311942959\n",
      "\n",
      "matching up   0.2\n",
      "\n",
      "late 70s   0.1111111111111111\n",
      "\n",
      "Statistical Methods   0.1111111111111111\n",
      "\n",
      "and classification   0.001445086705202312\n",
      "\n",
      "GRASSHOPPER for   0.3333333333333333\n",
      "\n",
      "on several   0.0047169811320754715\n",
      "\n",
      "after Fourier   0.08333333333333333\n",
      "\n",
      "processing ,   0.16666666666666666\n",
      "\n",
      "Beigi covers   1.0\n",
      "\n",
      "`` beyond   0.005291005291005291\n",
      "\n",
      "The cache   0.005208333333333333\n",
      "\n",
      "the bridging   0.0006920415224913495\n",
      "\n",
      "without limits   0.07692307692307693\n",
      "\n",
      "sound in   0.05\n",
      "\n",
      "maintain tractability   1.0\n",
      "\n",
      "find the   0.3076923076923077\n",
      "\n",
      "alone usually   0.25\n",
      "\n",
      "'' where   0.005154639175257732\n",
      "\n",
      "table is   0.14285714285714285\n",
      "\n",
      "although capitalization   0.16666666666666666\n",
      "\n",
      "Hands-free computing   1.0\n",
      "\n",
      "rules are   0.023255813953488372\n",
      "\n",
      "is accomplished   0.0020325203252032522\n",
      "\n",
      "and attempt   0.001445086705202312\n",
      "\n",
      "values of   0.5\n",
      "\n",
      "relations among   0.16666666666666666\n",
      "\n",
      "of OCR   0.0035650623885918\n",
      "\n",
      "To translate   0.1111111111111111\n",
      "\n",
      "TWA where   1.0\n",
      "\n",
      ", Battle   0.0005614823133071309\n",
      "\n",
      "strategies to   0.5\n",
      "\n",
      "probably the   0.25\n",
      "\n",
      "having a   0.2\n",
      "\n",
      "and both   0.001445086705202312\n",
      "\n",
      ": syntax   0.00980392156862745\n",
      "\n",
      "by induction   0.005714285714285714\n",
      "\n",
      "course of   0.3333333333333333\n",
      "\n",
      "and then   0.010115606936416185\n",
      "\n",
      "Research in   0.125\n",
      "\n",
      "Test of   1.0\n",
      "\n",
      "linguists decided   0.3333333333333333\n",
      "\n",
      "Keyphrase extraction   0.5\n",
      "\n",
      "impersonate a   1.0\n",
      "\n",
      "-LRB- of   0.005420054200542005\n",
      "\n",
      "Overview of   1.0\n",
      "\n",
      "sub-signals .   1.0\n",
      "\n",
      "into general   0.01282051282051282\n",
      "\n",
      "management task   0.14285714285714285\n",
      "\n",
      "M. ,   0.5\n",
      "\n",
      "as a   0.11846689895470383\n",
      "\n",
      "by domain   0.005714285714285714\n",
      "\n",
      "translation programs   0.013513513513513514\n",
      "\n",
      "science and   0.1\n",
      "\n",
      "<s> Intrinsic   0.0015372790161414297\n",
      "\n",
      "syllables ,   0.5\n",
      "\n",
      "Context and   1.0\n",
      "\n",
      "web ,   0.125\n",
      "\n",
      "language expression   0.006756756756756757\n",
      "\n",
      "a specific   0.006134969325153374\n",
      "\n",
      "cepstral normalization   0.5\n",
      "\n",
      "rule-based ,   0.14285714285714285\n",
      "\n",
      "data .   0.22077922077922077\n",
      "\n",
      "may contain   0.038461538461538464\n",
      "\n",
      "that do   0.0035460992907801418\n",
      "\n",
      "Users were   1.0\n",
      "\n",
      "recognition we   0.008264462809917356\n",
      "\n",
      "of language-processing   0.00089126559714795\n",
      "\n",
      "both query   0.03225806451612903\n",
      "\n",
      "watertight barmaid   1.0\n",
      "\n",
      "Systran ,   1.0\n",
      "\n",
      "graph using   0.07692307692307693\n",
      "\n",
      "there general   0.025\n",
      "\n",
      "various boolean   0.05555555555555555\n",
      "\n",
      "before .   0.16666666666666666\n",
      "\n",
      "reconfiguring them   1.0\n",
      "\n",
      "summaries but   0.023255813953488372\n",
      "\n",
      "components that   0.2\n",
      "\n",
      "by concatenating   0.005714285714285714\n",
      "\n",
      "process .   0.1388888888888889\n",
      "\n",
      "by ears   0.005714285714285714\n",
      "\n",
      "space character   0.2\n",
      "\n",
      "and typically   0.002890173410404624\n",
      "\n",
      "is insufficient   0.0020325203252032522\n",
      "\n",
      "Real time   0.5\n",
      "\n",
      "all caps   0.023255813953488372\n",
      "\n",
      "caught '   1.0\n",
      "\n",
      ", displayed   0.0005614823133071309\n",
      "\n",
      "impossible when   0.5\n",
      "\n",
      "the choices   0.0006920415224913495\n",
      "\n",
      "A. Lauriault\\/Loriot   0.4\n",
      "\n",
      "direction .   0.3333333333333333\n",
      "\n",
      "subtopic of   1.0\n",
      "\n",
      "or ``   0.018018018018018018\n",
      "\n",
      "assign labels   0.2\n",
      "\n",
      "with either   0.00546448087431694\n",
      "\n",
      "allows a   0.125\n",
      "\n",
      "NLP programs   0.02127659574468085\n",
      "\n",
      "During this   0.5\n",
      "\n",
      "by selecting   0.011428571428571429\n",
      "\n",
      "Some classifiers   0.047619047619047616\n",
      "\n",
      "this information   0.01098901098901099\n",
      "\n",
      "and example   0.001445086705202312\n",
      "\n",
      "Discontinuous or   1.0\n",
      "\n",
      "an error   0.007575757575757576\n",
      "\n",
      "<s> Effective   0.0007686395080707148\n",
      "\n",
      "a horizontal   0.001226993865030675\n",
      "\n",
      "including PARRY   0.07142857142857142\n",
      "\n",
      "they rely   0.025\n",
      "\n",
      "both appear   0.03225806451612903\n",
      "\n",
      "<s> Knowing   0.0007686395080707148\n",
      "\n",
      "geography ,   1.0\n",
      "\n",
      "goal .   0.14285714285714285\n",
      "\n",
      "that occurs   0.0035460992907801418\n",
      "\n",
      "London -RRB-   1.0\n",
      "\n",
      "Once these   0.2\n",
      "\n",
      "networks emerged   0.07142857142857142\n",
      "\n",
      "ranked adjacent   0.2\n",
      "\n",
      "season ,   1.0\n",
      "\n",
      "use techniques   0.013888888888888888\n",
      "\n",
      "to English   0.0013280212483399733\n",
      "\n",
      "He received   0.125\n",
      "\n",
      "sentences so   0.013157894736842105\n",
      "\n",
      "evaluation with   0.018518518518518517\n",
      "\n",
      "of hard   0.0017825311942959\n",
      "\n",
      "effectively launched   0.3333333333333333\n",
      "\n",
      "called ISO\\/TC37\\/SC4   0.05555555555555555\n",
      "\n",
      "separate lexical   0.1\n",
      "\n",
      "which we   0.007246376811594203\n",
      "\n",
      "the domain   0.001384083044982699\n",
      "\n",
      "it vibrates   0.008547008547008548\n",
      "\n",
      "and semantics   0.004335260115606936\n",
      "\n",
      "Edges are   1.0\n",
      "\n",
      "`` Part-of-speech   0.005291005291005291\n",
      "\n",
      "equivalent ideas   0.2\n",
      "\n",
      "taken place   0.3333333333333333\n",
      "\n",
      "people from   0.0625\n",
      "\n",
      "as questions   0.003484320557491289\n",
      "\n",
      "describe a   0.16666666666666666\n",
      "\n",
      "the standard   0.001384083044982699\n",
      "\n",
      "the parse   0.0006920415224913495\n",
      "\n",
      "importance would   0.16666666666666666\n",
      "\n",
      "ROUGE-1 is   0.2\n",
      "\n",
      "Xerox eventually   0.5\n",
      "\n",
      "Adverse conditions   1.0\n",
      "\n",
      "-LRB- 1993   0.0027100271002710027\n",
      "\n",
      "useful keyphrases   0.07142857142857142\n",
      "\n",
      "high quality   0.05555555555555555\n",
      "\n",
      "expected -LRB-   0.14285714285714285\n",
      "\n",
      "education ,   1.0\n",
      "\n",
      "it enumerated   0.008547008547008548\n",
      "\n",
      "<s> Mention   0.0007686395080707148\n",
      "\n",
      "the sort   0.0006920415224913495\n",
      "\n",
      "of statistical   0.0017825311942959\n",
      "\n",
      "-LRB- most   0.01084010840108401\n",
      "\n",
      "each pilot   0.022222222222222223\n",
      "\n",
      "data set   0.012987012987012988\n",
      "\n",
      "task also   0.023809523809523808\n",
      "\n",
      "million books   0.3333333333333333\n",
      "\n",
      "and QA   0.001445086705202312\n",
      "\n",
      "as possible   0.017421602787456445\n",
      "\n",
      "its use   0.02857142857142857\n",
      "\n",
      "module uses   0.3333333333333333\n",
      "\n",
      "expressions that   0.3333333333333333\n",
      "\n",
      "of ability   0.00089126559714795\n",
      "\n",
      "DTW .   0.3333333333333333\n",
      "\n",
      "Hybrid machine   0.5\n",
      "\n",
      "start experimenting   0.14285714285714285\n",
      "\n",
      "for speech   0.01444043321299639\n",
      "\n",
      "text used   0.006289308176100629\n",
      "\n",
      "Harris The   0.1111111111111111\n",
      "\n",
      "<s> e.g.   0.0015372790161414297\n",
      "\n",
      "were identified   0.024390243902439025\n",
      "\n",
      "conferences held   1.0\n",
      "\n",
      "1,000,000 words   1.0\n",
      "\n",
      "is facing   0.0020325203252032522\n",
      "\n",
      "direct translation   0.16666666666666666\n",
      "\n",
      "aural feedback   1.0\n",
      "\n",
      "at short   0.014705882352941176\n",
      "\n",
      "corresponding systems   0.16666666666666666\n",
      "\n",
      "a -5   0.001226993865030675\n",
      "\n",
      "System -RRB-   1.0\n",
      "\n",
      "coughing ,   1.0\n",
      "\n",
      "an OCR   0.007575757575757576\n",
      "\n",
      "relay services   1.0\n",
      "\n",
      "to fulfill   0.0026560424966799467\n",
      "\n",
      "input that   0.04878048780487805\n",
      "\n",
      "<s> Ideally   0.0015372790161414297\n",
      "\n",
      "business rules   0.25\n",
      "\n",
      "applications have   0.08\n",
      "\n",
      "<s> ...   0.0007686395080707148\n",
      "\n",
      "of discourse   0.00980392156862745\n",
      "\n",
      "one human   0.015384615384615385\n",
      "\n",
      "models can   0.038461538461538464\n",
      "\n",
      "results of   0.047619047619047616\n",
      "\n",
      "and extrinsic   0.001445086705202312\n",
      "\n",
      "changing information   1.0\n",
      "\n",
      "particularly speech   0.2\n",
      "\n",
      ", which   0.031443009545199324\n",
      "\n",
      "For instance   0.11475409836065574\n",
      "\n",
      "being conducted   0.05555555555555555\n",
      "\n",
      "VRX and   1.0\n",
      "\n",
      "all rules   0.023255813953488372\n",
      "\n",
      "adjective 40   0.14285714285714285\n",
      "\n",
      "metric such   0.3333333333333333\n",
      "\n",
      "the gold   0.0020761245674740486\n",
      "\n",
      "systems simply   0.008928571428571428\n",
      "\n",
      "fundamental errors   0.5\n",
      "\n",
      "linguistic cues   0.0625\n",
      "\n",
      "described as   0.3333333333333333\n",
      "\n",
      "be decided   0.004219409282700422\n",
      "\n",
      "useful NLG   0.07142857142857142\n",
      "\n",
      "car or   1.0\n",
      "\n",
      "get high   0.14285714285714285\n",
      "\n",
      "translation of   0.14864864864864866\n",
      "\n",
      "the token   0.0006920415224913495\n",
      "\n",
      "Rubin ,   1.0\n",
      "\n",
      "just validated   0.1111111111111111\n",
      "\n",
      "insurance bills   1.0\n",
      "\n",
      "the parsing   0.001384083044982699\n",
      "\n",
      "news article   0.15384615384615385\n",
      "\n",
      "issue in   0.125\n",
      "\n",
      ", resource   0.0005614823133071309\n",
      "\n",
      "item may   1.0\n",
      "\n",
      "domain .   0.3\n",
      "\n",
      "spending limit   1.0\n",
      "\n",
      ", Abney   0.0005614823133071309\n",
      "\n",
      "summarization methods   0.02\n",
      "\n",
      ", science   0.0005614823133071309\n",
      "\n",
      "this centroid   0.01098901098901099\n",
      "\n",
      ", contain   0.0005614823133071309\n",
      "\n",
      ", social   0.0011229646266142617\n",
      "\n",
      "SR systems   0.3333333333333333\n",
      "\n",
      "verb :   0.07692307692307693\n",
      "\n",
      "of developing   0.00089126559714795\n",
      "\n",
      "immediately to   1.0\n",
      "\n",
      "maintenance -RRB-   1.0\n",
      "\n",
      "define these   0.5\n",
      "\n",
      "The program   0.005208333333333333\n",
      "\n",
      "respect to   1.0\n",
      "\n",
      "a template   0.00245398773006135\n",
      "\n",
      "accuracy reported   0.03225806451612903\n",
      "\n",
      "vowels and   0.3333333333333333\n",
      "\n",
      "grammar is   0.05405405405405406\n",
      "\n",
      "This comparison   0.015873015873015872\n",
      "\n",
      "far ,   0.125\n",
      "\n",
      "systems take   0.008928571428571428\n",
      "\n",
      ", Theo   0.0005614823133071309\n",
      "\n",
      "a list   0.008588957055214725\n",
      "\n",
      "keep the   0.3333333333333333\n",
      "\n",
      "a cosine   0.001226993865030675\n",
      "\n",
      "simulated a   0.5\n",
      "\n",
      "in 1997   0.003745318352059925\n",
      "\n",
      "in political   0.0018726591760299626\n",
      "\n",
      "because fast   0.03333333333333333\n",
      "\n",
      "as 7   0.003484320557491289\n",
      "\n",
      ", by   0.002807411566535654\n",
      "\n",
      "recognition in   0.024793388429752067\n",
      "\n",
      "a short   0.006134969325153374\n",
      "\n",
      "speech tools   0.006578947368421052\n",
      "\n",
      "at NYU   0.014705882352941176\n",
      "\n",
      "large probabilities   0.043478260869565216\n",
      "\n",
      "equipment based   0.3333333333333333\n",
      "\n",
      "-RRB- found   0.0027100271002710027\n",
      "\n",
      "recall-based to   0.5\n",
      "\n",
      "Disambiguation Main   1.0\n",
      "\n",
      "open letter   0.25\n",
      "\n",
      "the important   0.0006920415224913495\n",
      "\n",
      "is compounded   0.0020325203252032522\n",
      "\n",
      "for these   0.0036101083032490976\n",
      "\n",
      "successes occurred   1.0\n",
      "\n",
      "is about   0.0020325203252032522\n",
      "\n",
      "Senseval and   1.0\n",
      "\n",
      "see below   0.05\n",
      "\n",
      "be -LRB-   0.004219409282700422\n",
      "\n",
      "waves and   0.14285714285714285\n",
      "\n",
      "involves paraphrasing   0.1\n",
      "\n",
      "-RRB- Telematics   0.0027100271002710027\n",
      "\n",
      "post-processing by   0.3333333333333333\n",
      "\n",
      "would have   0.05660377358490566\n",
      "\n",
      "and answer   0.001445086705202312\n",
      "\n",
      "corpora are   0.18181818181818182\n",
      "\n",
      "English on   0.02702702702702703\n",
      "\n",
      "achieves 98.5   0.5\n",
      "\n",
      "like in   0.03571428571428571\n",
      "\n",
      "recognition algorithms   0.008264462809917356\n",
      "\n",
      "will generate   0.08571428571428572\n",
      "\n",
      "a worldwide   0.001226993865030675\n",
      "\n",
      "a bank   0.001226993865030675\n",
      "\n",
      "probabilities ,   0.09090909090909091\n",
      "\n",
      "government sponsored   0.3333333333333333\n",
      "\n",
      "and turns   0.001445086705202312\n",
      "\n",
      "its grammatical   0.02857142857142857\n",
      "\n",
      "`` natural   0.015873015873015872\n",
      "\n",
      "model of   0.03333333333333333\n",
      "\n",
      "Grass pollen   1.0\n",
      "\n",
      "Network classifies   1.0\n",
      "\n",
      "Given the   0.07142857142857142\n",
      "\n",
      ", Pang   0.0005614823133071309\n",
      "\n",
      "as focusing   0.003484320557491289\n",
      "\n",
      "100 million   0.3333333333333333\n",
      "\n",
      "States Postal   0.14285714285714285\n",
      "\n",
      "summarization ,   0.08\n",
      "\n",
      "One key   0.07692307692307693\n",
      "\n",
      "layer of   1.0\n",
      "\n",
      ", Kurzweil   0.0016844469399213925\n",
      "\n",
      ", comprising   0.0005614823133071309\n",
      "\n",
      "or desired   0.0045045045045045045\n",
      "\n",
      "order for   0.07142857142857142\n",
      "\n",
      "possible without   0.041666666666666664\n",
      "\n",
      "Typical stages   0.5\n",
      "\n",
      "generalizes as   1.0\n",
      "\n",
      "if they   0.03571428571428571\n",
      "\n",
      "'' do   0.005154639175257732\n",
      "\n",
      "documents onto   0.02631578947368421\n",
      "\n",
      "for example   0.06498194945848375\n",
      "\n",
      "with Fourier   0.00546448087431694\n",
      "\n",
      "FST ,   1.0\n",
      "\n",
      "<s> LL   0.0015372790161414297\n",
      "\n",
      "Unsupervised tagging   0.16666666666666666\n",
      "\n",
      "typewritten text   0.2\n",
      "\n",
      "gradually reduced   1.0\n",
      "\n",
      "QA performance   0.047619047619047616\n",
      "\n",
      "showing evidence   0.5\n",
      "\n",
      "The readers   0.005208333333333333\n",
      "\n",
      "meaning of   0.30434782608695654\n",
      "\n",
      "question classification   0.023809523809523808\n",
      "\n",
      "range from   0.2857142857142857\n",
      "\n",
      "but this   0.058823529411764705\n",
      "\n",
      "levels or   0.045454545454545456\n",
      "\n",
      "compare various   0.14285714285714285\n",
      "\n",
      "and Nearest-neighbor   0.001445086705202312\n",
      "\n",
      "amounts of   1.0\n",
      "\n",
      "degrees depending   0.5\n",
      "\n",
      "form ?   0.05\n",
      "\n",
      "If it   0.1\n",
      "\n",
      "depended on   1.0\n",
      "\n",
      "a stochastic   0.001226993865030675\n",
      "\n",
      "air -LRB-   0.2\n",
      "\n",
      "transcriptions is   0.5\n",
      "\n",
      "online assistant   0.125\n",
      "\n",
      "across a   0.2\n",
      "\n",
      "or semantics   0.0045045045045045045\n",
      "\n",
      "expansion Automated   0.3333333333333333\n",
      "\n",
      "Unsupervised Morpheme   0.16666666666666666\n",
      "\n",
      "been seen   0.04411764705882353\n",
      "\n",
      "are germane   0.004149377593360996\n",
      "\n",
      "still very   0.06666666666666667\n",
      "\n",
      "still have   0.06666666666666667\n",
      "\n",
      "approach that   0.05714285714285714\n",
      "\n",
      "subset of   1.0\n",
      "\n",
      "be required   0.004219409282700422\n",
      "\n",
      "given sentence   0.08333333333333333\n",
      "\n",
      "diverse set   0.5\n",
      "\n",
      "did exactly   0.2\n",
      "\n",
      "been characterized   0.014705882352941176\n",
      "\n",
      "opinion mining   0.2\n",
      "\n",
      "a security   0.001226993865030675\n",
      "\n",
      "development in   0.08333333333333333\n",
      "\n",
      "media such   0.16666666666666666\n",
      "\n",
      "sentences presented   0.013157894736842105\n",
      "\n",
      "containing these   0.125\n",
      "\n",
      "hurricane season   1.0\n",
      "\n",
      "reader installed   0.1\n",
      "\n",
      "but a   0.014705882352941176\n",
      "\n",
      "- Top-down   0.0625\n",
      "\n",
      "around 2   0.125\n",
      "\n",
      "covers speech   0.25\n",
      "\n",
      "topic ,   0.25\n",
      "\n",
      "evaluation Intrinsic   0.018518518518518517\n",
      "\n",
      "a campaign   0.001226993865030675\n",
      "\n",
      "learning procedures   0.046511627906976744\n",
      "\n",
      "space exploration   0.2\n",
      "\n",
      "pseudo-pilot ''   0.5\n",
      "\n",
      "researchers in   0.1\n",
      "\n",
      "accuracy was   0.03225806451612903\n",
      "\n",
      "`` language   0.010582010582010581\n",
      "\n",
      "that describe   0.0035460992907801418\n",
      "\n",
      "phenomenon of   0.6\n",
      "\n",
      "could therefore   0.0625\n",
      "\n",
      "an EHR   0.007575757575757576\n",
      "\n",
      "coefficients .   0.25\n",
      "\n",
      "technique uses   0.14285714285714285\n",
      "\n",
      "trying to   1.0\n",
      "\n",
      "Aided Machine   0.3333333333333333\n",
      "\n",
      "be unique   0.004219409282700422\n",
      "\n",
      "states such   0.25\n",
      "\n",
      "on tasks   0.009433962264150943\n",
      "\n",
      "calls instead   1.0\n",
      "\n",
      "focus is   0.14285714285714285\n",
      "\n",
      "with misspelled   0.00546448087431694\n",
      "\n",
      "'' to   0.015463917525773196\n",
      "\n",
      "special fonts   0.2\n",
      "\n",
      "various algorithms   0.05555555555555555\n",
      "\n",
      "meant that   0.5\n",
      "\n",
      "financial section   0.25\n",
      "\n",
      "some interrogative   0.012048192771084338\n",
      "\n",
      "produce one   0.045454545454545456\n",
      "\n",
      "Hollenbach 1970   1.0\n",
      "\n",
      "tell whether   0.3333333333333333\n",
      "\n",
      "larger system   0.125\n",
      "\n",
      "Generally ,   0.6\n",
      "\n",
      "adding citations   0.5\n",
      "\n",
      "Creating the   0.5\n",
      "\n",
      "and merging   0.001445086705202312\n",
      "\n",
      "other medium   0.014285714285714285\n",
      "\n",
      "the elements   0.0006920415224913495\n",
      "\n",
      "in terms   0.011235955056179775\n",
      "\n",
      "the EVALITA   0.0006920415224913495\n",
      "\n",
      "answer corpus   0.03333333333333333\n",
      "\n",
      "model that   0.13333333333333333\n",
      "\n",
      "ASRU .   1.0\n",
      "\n",
      "can still   0.0055248618784530384\n",
      "\n",
      "F =   1.0\n",
      "\n",
      "impossible .   0.5\n",
      "\n",
      "it learns   0.008547008547008548\n",
      "\n",
      "Our brain   0.6666666666666666\n",
      "\n",
      "it Contains   0.008547008547008548\n",
      "\n",
      "and a   0.023121387283236993\n",
      "\n",
      "but also   0.07352941176470588\n",
      "\n",
      "defined in   0.16666666666666666\n",
      "\n",
      "<s> Read   0.0007686395080707148\n",
      "\n",
      "1949 .   0.5\n",
      "\n",
      "7 across   0.42857142857142855\n",
      "\n",
      "also general   0.014492753623188406\n",
      "\n",
      ", incomplete   0.0005614823133071309\n",
      "\n",
      "Loebner prize   1.0\n",
      "\n",
      "May 2012   0.5\n",
      "\n",
      "to clean   0.0013280212483399733\n",
      "\n",
      ", QUALM   0.0005614823133071309\n",
      "\n",
      "proposed by   0.1111111111111111\n",
      "\n",
      "preclude using   1.0\n",
      "\n",
      "software libraries   0.037037037037037035\n",
      "\n",
      "form letters   0.05\n",
      "\n",
      "select individual   0.16666666666666666\n",
      "\n",
      "segment the   0.1111111111111111\n",
      "\n",
      "filtered out   0.3333333333333333\n",
      "\n",
      "model is   0.1\n",
      "\n",
      "cartoon animation   1.0\n",
      "\n",
      "patterns of   0.2\n",
      "\n",
      "merging the   0.5\n",
      "\n",
      "be fully   0.008438818565400843\n",
      "\n",
      "- EVALITA   0.0625\n",
      "\n",
      "Barbara Johnstone   1.0\n",
      "\n",
      "funding of   0.125\n",
      "\n",
      "it to   0.042735042735042736\n",
      "\n",
      "into segments   0.02564102564102564\n",
      "\n",
      "same example-generation   0.04\n",
      "\n",
      "natural speech   0.02666666666666667\n",
      "\n",
      "Vulcan later   0.5\n",
      "\n",
      "the dBase   0.0006920415224913495\n",
      "\n",
      "to :   0.0013280212483399733\n",
      "\n",
      "still disagree   0.06666666666666667\n",
      "\n",
      "recognition because   0.008264462809917356\n",
      "\n",
      "Throughout the   1.0\n",
      "\n",
      "Increasingly ,   1.0\n",
      "\n",
      "modern statistical   0.2\n",
      "\n",
      "the front   0.0020761245674740486\n",
      "\n",
      "better QA   0.1111111111111111\n",
      "\n",
      "to grow   0.0013280212483399733\n",
      "\n",
      "lies the   0.5\n",
      "\n",
      "from improved   0.009615384615384616\n",
      "\n",
      "been believed   0.014705882352941176\n",
      "\n",
      "features would   0.038461538461538464\n",
      "\n",
      "well be   0.03571428571428571\n",
      "\n",
      "variables such   1.0\n",
      "\n",
      "linked with   0.3333333333333333\n",
      "\n",
      "bill stub   0.5\n",
      "\n",
      "citations to   0.6666666666666666\n",
      "\n",
      "not agree   0.008928571428571428\n",
      "\n",
      "unreferenced section   1.0\n",
      "\n",
      "this .   0.01098901098901099\n",
      "\n",
      "blocks worlds   0.25\n",
      "\n",
      "adjectives ,   0.3333333333333333\n",
      "\n",
      "it takes   0.008547008547008548\n",
      "\n",
      ", assertion   0.0005614823133071309\n",
      "\n",
      "costs -LRB-   1.0\n",
      "\n",
      "is always   0.0040650406504065045\n",
      "\n",
      "pioneered the   0.3333333333333333\n",
      "\n",
      "as consideration   0.003484320557491289\n",
      "\n",
      "Kurzweil 's   0.14285714285714285\n",
      "\n",
      "topic by   0.125\n",
      "\n",
      "was evident   0.012987012987012988\n",
      "\n",
      "through the   0.5\n",
      "\n",
      "late 1930s   0.1111111111111111\n",
      "\n",
      "General Post   1.0\n",
      "\n",
      "matching ,   0.2\n",
      "\n",
      "its communicative   0.02857142857142857\n",
      "\n",
      "Systems released   0.16666666666666666\n",
      "\n",
      "reads sections   0.5\n",
      "\n",
      "Spanish do   0.5\n",
      "\n",
      "question into   0.023809523809523808\n",
      "\n",
      "time are   0.030303030303030304\n",
      "\n",
      "Germany ,   0.5\n",
      "\n",
      "developed dynamic   0.038461538461538464\n",
      "\n",
      "chunks of   1.0\n",
      "\n",
      "multiple references   0.07692307692307693\n",
      "\n",
      "employs a   0.5\n",
      "\n",
      "Early work   0.5\n",
      "\n",
      "N words   0.3333333333333333\n",
      "\n",
      "are popular   0.004149377593360996\n",
      "\n",
      "-RRB- Current   0.0027100271002710027\n",
      "\n",
      "concerns finding   0.5\n",
      "\n",
      ", Joseph   0.0005614823133071309\n",
      "\n",
      "<s> Schools   0.0007686395080707148\n",
      "\n",
      "enough data   0.4\n",
      "\n",
      "to understand   0.00398406374501992\n",
      "\n",
      "While LexRank   0.2\n",
      "\n",
      "any capitalization   0.03225806451612903\n",
      "\n",
      "Dynamic time   0.8\n",
      "\n",
      "and synthesis   0.001445086705202312\n",
      "\n",
      "overlap metrics   0.25\n",
      "\n",
      "categorization ,   1.0\n",
      "\n",
      "much more   0.18181818181818182\n",
      "\n",
      "may denote   0.019230769230769232\n",
      "\n",
      "which discourse   0.007246376811594203\n",
      "\n",
      "they disagree   0.025\n",
      "\n",
      "classification error   0.058823529411764705\n",
      "\n",
      "polarity of   0.25\n",
      "\n",
      "of achieving   0.0017825311942959\n",
      "\n",
      "somewhat recent   0.5\n",
      "\n",
      "than others   0.044444444444444446\n",
      "\n",
      "thus makes   0.1\n",
      "\n",
      "case-based reasoning   1.0\n",
      "\n",
      "next item   0.14285714285714285\n",
      "\n",
      ", OCR   0.0011229646266142617\n",
      "\n",
      "on hand-crafted   0.0047169811320754715\n",
      "\n",
      "<s> Telephony   0.0007686395080707148\n",
      "\n",
      "Cognitive Systems   0.3333333333333333\n",
      "\n",
      ", recently   0.0005614823133071309\n",
      "\n",
      "a tool   0.00245398773006135\n",
      "\n",
      "keyphrases are   0.05714285714285714\n",
      "\n",
      "Conferences ,   0.5\n",
      "\n",
      "In these   0.009523809523809525\n",
      "\n",
      "example demonstrates   0.012345679012345678\n",
      "\n",
      "and removed   0.001445086705202312\n",
      "\n",
      "as weather   0.003484320557491289\n",
      "\n",
      "only specific   0.02631578947368421\n",
      "\n",
      "This allows   0.031746031746031744\n",
      "\n",
      "labels to   1.0\n",
      "\n",
      "Drew ,   1.0\n",
      "\n",
      "that was   0.010638297872340425\n",
      "\n",
      "the 1960s   0.001384083044982699\n",
      "\n",
      "to work   0.0026560424966799467\n",
      "\n",
      "Rules are   0.6666666666666666\n",
      "\n",
      ", David   0.0016844469399213925\n",
      "\n",
      "characterized DARPA   0.25\n",
      "\n",
      "speech tagging   0.013157894736842105\n",
      "\n",
      "always a   0.3333333333333333\n",
      "\n",
      "understanding ''   0.06060606060606061\n",
      "\n",
      "reference for   0.125\n",
      "\n",
      "night .   1.0\n",
      "\n",
      "iteration ,   1.0\n",
      "\n",
      "the impact   0.001384083044982699\n",
      "\n",
      "output nodes   0.07692307692307693\n",
      "\n",
      "reputations .   1.0\n",
      "\n",
      "Morphological segmentation   1.0\n",
      "\n",
      "informal behavior   0.5\n",
      "\n",
      "use heteroscedastic   0.013888888888888888\n",
      "\n",
      "written English   0.038461538461538464\n",
      "\n",
      "text-to-speech and   0.5\n",
      "\n",
      "source text   0.20833333333333334\n",
      "\n",
      "the basic   0.001384083044982699\n",
      "\n",
      "evaluation purposes   0.018518518518518517\n",
      "\n",
      "some but   0.012048192771084338\n",
      "\n",
      "<s> IBM   0.0007686395080707148\n",
      "\n",
      "certain assumptions   0.14285714285714285\n",
      "\n",
      "letter to   0.16666666666666666\n",
      "\n",
      "specific context   0.047619047619047616\n",
      "\n",
      "an average   0.007575757575757576\n",
      "\n",
      "intermediary representation   0.6666666666666666\n",
      "\n",
      "concept into   0.25\n",
      "\n",
      "seek to   1.0\n",
      "\n",
      "them are   0.10526315789473684\n",
      "\n",
      "<s> the   0.0007686395080707148\n",
      "\n",
      "using some   0.03389830508474576\n",
      "\n",
      "were accelerations   0.024390243902439025\n",
      "\n",
      "Statistical techniques   0.1111111111111111\n",
      "\n",
      "out ''   0.07142857142857142\n",
      "\n",
      "Carston ,   1.0\n",
      "\n",
      ", although   0.0022459292532285235\n",
      "\n",
      "such input   0.008130081300813009\n",
      "\n",
      "on the   0.30660377358490565\n",
      "\n",
      "of speech   0.040998217468805706\n",
      "\n",
      "standard result   0.07142857142857142\n",
      "\n",
      "normalization and   0.16666666666666666\n",
      "\n",
      "work progressed   0.041666666666666664\n",
      "\n",
      "area include   0.09090909090909091\n",
      "\n",
      "subproblem of   1.0\n",
      "\n",
      "or aspects   0.0045045045045045045\n",
      "\n",
      ", unverified   0.0005614823133071309\n",
      "\n",
      "Rogerian psychotherapist   1.0\n",
      "\n",
      "SpeechTEK and   0.5\n",
      "\n",
      "uttered one   0.3333333333333333\n",
      "\n",
      "without reference   0.07692307692307693\n",
      "\n",
      "quite distinct   0.125\n",
      "\n",
      "or insufficient   0.0045045045045045045\n",
      "\n",
      "released ``   0.5\n",
      "\n",
      ", rhetoric   0.0005614823133071309\n",
      "\n",
      "sentences can   0.039473684210526314\n",
      "\n",
      "convey meaning   0.3333333333333333\n",
      "\n",
      "The paradigm   0.005208333333333333\n",
      "\n",
      "a diverse   0.001226993865030675\n",
      "\n",
      "algorithm known   0.03571428571428571\n",
      "\n",
      "speakers might   0.25\n",
      "\n",
      "distinctions are   0.5\n",
      "\n",
      "unsupervised approach   0.125\n",
      "\n",
      "P +   0.5\n",
      "\n",
      ", semantically   0.0005614823133071309\n",
      "\n",
      "thus has   0.1\n",
      "\n",
      "Weizenbaum at   0.3333333333333333\n",
      "\n",
      "by context-free   0.005714285714285714\n",
      "\n",
      "even for   0.037037037037037035\n",
      "\n",
      "The fonts   0.005208333333333333\n",
      "\n",
      "in its   0.003745318352059925\n",
      "\n",
      "and laughter   0.001445086705202312\n",
      "\n",
      "one meaning   0.03076923076923077\n",
      "\n",
      "start to   0.14285714285714285\n",
      "\n",
      "ease interoperability   1.0\n",
      "\n",
      "<s> POS   0.0007686395080707148\n",
      "\n",
      "etc. -RRB-   0.4090909090909091\n",
      "\n",
      "would enable   0.018867924528301886\n",
      "\n",
      "style and   0.5\n",
      "\n",
      "ranking algorithm   0.2857142857142857\n",
      "\n",
      "of Question   0.00089126559714795\n",
      "\n",
      "movement to   1.0\n",
      "\n",
      "and support   0.001445086705202312\n",
      "\n",
      "input and   0.04878048780487805\n",
      "\n",
      "included analyses   0.125\n",
      "\n",
      "consecutive years   0.5\n",
      "\n",
      "OCR is   0.061224489795918366\n",
      "\n",
      "Rule-based The   0.5\n",
      "\n",
      ", UMLS   0.0005614823133071309\n",
      "\n",
      "would need   0.018867924528301886\n",
      "\n",
      "MARGIE -LRB-   1.0\n",
      "\n",
      "However such   0.02702702702702703\n",
      "\n",
      "representations such   0.25\n",
      "\n",
      "by A.   0.005714285714285714\n",
      "\n",
      "which is   0.09420289855072464\n",
      "\n",
      "for up-to-date   0.0036101083032490976\n",
      "\n",
      "a major   0.006134969325153374\n",
      "\n",
      "dominance of   1.0\n",
      "\n",
      "rules should   0.023255813953488372\n",
      "\n",
      "the results   0.002768166089965398\n",
      "\n",
      "is orthogonal   0.0020325203252032522\n",
      "\n",
      "methods already   0.022727272727272728\n",
      "\n",
      "document level   0.027777777777777776\n",
      "\n",
      "`` main   0.005291005291005291\n",
      "\n",
      "as social   0.003484320557491289\n",
      "\n",
      "such cases   0.016260162601626018\n",
      "\n",
      "Corpus contains   0.0625\n",
      "\n",
      "user has   0.07142857142857142\n",
      "\n",
      "solutions to   0.5\n",
      "\n",
      "Dogged ''   1.0\n",
      "\n",
      "is typically   0.006097560975609756\n",
      "\n",
      "analysis -RRB-   0.03076923076923077\n",
      "\n",
      "web may   0.125\n",
      "\n",
      "evaluation would   0.05555555555555555\n",
      "\n",
      "field .   0.14814814814814814\n",
      "\n",
      "; Michel   0.02127659574468085\n",
      "\n",
      "The technique   0.005208333333333333\n",
      "\n",
      "currently require   0.14285714285714285\n",
      "\n",
      "topics discussed   0.14285714285714285\n",
      "\n",
      "was proposed   0.025974025974025976\n",
      "\n",
      "James Paul   0.25\n",
      "\n",
      "shorter and   0.5\n",
      "\n",
      "could thus   0.0625\n",
      "\n",
      "develop in   0.2\n",
      "\n",
      "on any   0.018867924528301886\n",
      "\n",
      "linguistic term   0.0625\n",
      "\n",
      "semi-supervised learning   0.5\n",
      "\n",
      "searched ,   1.0\n",
      "\n",
      "of Mandarin   0.00089126559714795\n",
      "\n",
      "market their   0.3333333333333333\n",
      "\n",
      "its output   0.08571428571428572\n",
      "\n",
      "-LRB- University   0.0027100271002710027\n",
      "\n",
      "this level   0.01098901098901099\n",
      "\n",
      "and noise   0.001445086705202312\n",
      "\n",
      "statistical output   0.030303030303030304\n",
      "\n",
      "to more   0.0026560424966799467\n",
      "\n",
      "pre-processing e.g.   1.0\n",
      "\n",
      "same time   0.12\n",
      "\n",
      "that act   0.0035460992907801418\n",
      "\n",
      "vowels .   0.3333333333333333\n",
      "\n",
      "definition of   0.6\n",
      "\n",
      "as controlled   0.003484320557491289\n",
      "\n",
      "typewritten reports   0.2\n",
      "\n",
      "development has   0.08333333333333333\n",
      "\n",
      "broad agreement   0.25\n",
      "\n",
      "with many   0.00546448087431694\n",
      "\n",
      "the Turney   0.0006920415224913495\n",
      "\n",
      "varies greatly   1.0\n",
      "\n",
      "match certain   0.16666666666666666\n",
      "\n",
      "grow without   1.0\n",
      "\n",
      "Givón ,   1.0\n",
      "\n",
      "with an   0.0273224043715847\n",
      "\n",
      "practical dimensions   0.5\n",
      "\n",
      "rate crossed   0.09090909090909091\n",
      "\n",
      "but discards   0.014705882352941176\n",
      "\n",
      "the phrases   0.0006920415224913495\n",
      "\n",
      "person was   0.05263157894736842\n",
      "\n",
      "and 2007   0.001445086705202312\n",
      "\n",
      "funding continued   0.125\n",
      "\n",
      "The popular   0.005208333333333333\n",
      "\n",
      "producing the   0.3333333333333333\n",
      "\n",
      "control when   0.2\n",
      "\n",
      "textbook of   0.5\n",
      "\n",
      "this meaning   0.01098901098901099\n",
      "\n",
      "could recognize   0.0625\n",
      "\n",
      "the founder   0.0006920415224913495\n",
      "\n",
      "where one   0.02857142857142857\n",
      "\n",
      "proper declaration   0.14285714285714285\n",
      "\n",
      "speech sounds   0.006578947368421052\n",
      "\n",
      "a written-out   0.001226993865030675\n",
      "\n",
      "reports into   0.4\n",
      "\n",
      "these good   0.023809523809523808\n",
      "\n",
      "received a   0.5\n",
      "\n",
      "famous early   0.3333333333333333\n",
      "\n",
      "At the   0.3333333333333333\n",
      "\n",
      "slowly and   0.5\n",
      "\n",
      "who have   0.2\n",
      "\n",
      "summaries qualitatively   0.023255813953488372\n",
      "\n",
      "UK RAF   0.25\n",
      "\n",
      "a subset   0.0036809815950920245\n",
      "\n",
      "semantic schemes   0.047619047619047616\n",
      "\n",
      "slow and   0.5\n",
      "\n",
      "<s> Named   0.0007686395080707148\n",
      "\n",
      "T final   0.16666666666666666\n",
      "\n",
      "train their   1.0\n",
      "\n",
      "five years   0.4\n",
      "\n",
      "a natural   0.006134969325153374\n",
      "\n",
      "do research   0.038461538461538464\n",
      "\n",
      "acoustics -RRB-   1.0\n",
      "\n",
      "a fair   0.001226993865030675\n",
      "\n",
      ", Type   0.0005614823133071309\n",
      "\n",
      "font at   0.3333333333333333\n",
      "\n",
      "the questioner   0.002768166089965398\n",
      "\n",
      "Voice Command   0.2\n",
      "\n",
      "as that   0.003484320557491289\n",
      "\n",
      "<s> In   0.07455803228285934\n",
      "\n",
      "sounds representing   0.06666666666666667\n",
      "\n",
      ", 13   0.0005614823133071309\n",
      "\n",
      "can discriminate   0.0055248618784530384\n",
      "\n",
      "form the   0.05\n",
      "\n",
      "structuring :   1.0\n",
      "\n",
      "and analyze   0.001445086705202312\n",
      "\n",
      "measurement of   0.5\n",
      "\n",
      "tasks such   0.0625\n",
      "\n",
      "are beginning   0.004149377593360996\n",
      "\n",
      "sequences ,   0.1111111111111111\n",
      "\n",
      "sciences concurrently   0.5\n",
      "\n",
      "was later   0.012987012987012988\n",
      "\n",
      "Su ,   1.0\n",
      "\n",
      "called the   0.1111111111111111\n",
      "\n",
      "the ARNS   0.0006920415224913495\n",
      "\n",
      "difficult problems   0.10714285714285714\n",
      "\n",
      "1995 -RRB-   1.0\n",
      "\n",
      "process termed   0.027777777777777776\n",
      "\n",
      "an early   0.007575757575757576\n",
      "\n",
      "Fournier d'Albe   1.0\n",
      "\n",
      "had an   0.07142857142857142\n",
      "\n",
      "turn ,   0.16666666666666666\n",
      "\n",
      "<s> Technologies   0.0007686395080707148\n",
      "\n",
      "Words :   0.25\n",
      "\n",
      "<s> Progress   0.0007686395080707148\n",
      "\n",
      "the translator   0.0006920415224913495\n",
      "\n",
      "this basic   0.01098901098901099\n",
      "\n",
      "'' other   0.005154639175257732\n",
      "\n",
      "each phoneme   0.022222222222222223\n",
      "\n",
      "on hand-written   0.0047169811320754715\n",
      "\n",
      "and allows   0.002890173410404624\n",
      "\n",
      "Society ,   1.0\n",
      "\n",
      "the grammar-based   0.0006920415224913495\n",
      "\n",
      "on Text   0.0047169811320754715\n",
      "\n",
      "explicit word   0.2\n",
      "\n",
      "simply focused   0.08333333333333333\n",
      "\n",
      "appears that   0.2\n",
      "\n",
      ", their   0.0005614823133071309\n",
      "\n",
      "like Ncmsan   0.03571428571428571\n",
      "\n",
      "learning and   0.023255813953488372\n",
      "\n",
      "<s> Parsing   0.0030745580322828594\n",
      "\n",
      "section titles   0.16666666666666666\n",
      "\n",
      "a rapidly   0.001226993865030675\n",
      "\n",
      "the gap   0.0006920415224913495\n",
      "\n",
      "Widdowson ,   1.0\n",
      "\n",
      "the specific   0.0020761245674740486\n",
      "\n",
      "at revealing   0.014705882352941176\n",
      "\n",
      "of over   0.00089126559714795\n",
      "\n",
      "keywords or   0.5\n",
      "\n",
      "of software   0.00089126559714795\n",
      "\n",
      "see references   0.05\n",
      "\n",
      "Question answering   0.2857142857142857\n",
      "\n",
      "is at   0.0020325203252032522\n",
      "\n",
      "like ``   0.10714285714285714\n",
      "\n",
      "WebOCR also   0.25\n",
      "\n",
      "and substitution   0.001445086705202312\n",
      "\n",
      "photographing data   1.0\n",
      "\n",
      "components -RRB-   0.2\n",
      "\n",
      "design the   0.25\n",
      "\n",
      "document 's   0.027777777777777776\n",
      "\n",
      "an action   0.007575757575757576\n",
      "\n",
      "by multiplying   0.005714285714285714\n",
      "\n",
      "votes from   1.0\n",
      "\n",
      "documents where   0.02631578947368421\n",
      "\n",
      "before classifying   0.16666666666666666\n",
      "\n",
      "performance and   0.1111111111111111\n",
      "\n",
      "from technology   0.009615384615384616\n",
      "\n",
      "think that   0.3333333333333333\n",
      "\n",
      "formed ?   0.4\n",
      "\n",
      "level 7   0.05\n",
      "\n",
      "system will   0.010752688172043012\n",
      "\n",
      "how close   0.034482758620689655\n",
      "\n",
      "appears multiple   0.2\n",
      "\n",
      "generally achieved   0.09090909090909091\n",
      "\n",
      "1 -LRB-   0.25\n",
      "\n",
      "this graph   0.01098901098901099\n",
      "\n",
      "<s> Every   0.0007686395080707148\n",
      "\n",
      "summarization often   0.02\n",
      "\n",
      "SourceForge .   1.0\n",
      "\n",
      "moderate to   0.6\n",
      "\n",
      ", POS   0.0005614823133071309\n",
      "\n",
      "other related   0.014285714285714285\n",
      "\n",
      "Dale -LRB-   1.0\n",
      "\n",
      "500,000 .   1.0\n",
      "\n",
      "often much   0.022727272727272728\n",
      "\n",
      "QA It   0.047619047619047616\n",
      "\n",
      "`` Application-Oriented   0.005291005291005291\n",
      "\n",
      "a member   0.001226993865030675\n",
      "\n",
      "much like   0.045454545454545456\n",
      "\n",
      "noun can   0.07142857142857142\n",
      "\n",
      "OCR ,   0.14285714285714285\n",
      "\n",
      "recognition instead   0.008264462809917356\n",
      "\n",
      "done both   0.09090909090909091\n",
      "\n",
      "Reiter and   1.0\n",
      "\n",
      "<s> Little   0.0007686395080707148\n",
      "\n",
      ", location   0.0005614823133071309\n",
      "\n",
      "summarization technology   0.02\n",
      "\n",
      "American English   0.2\n",
      "\n",
      "the Armed   0.0006920415224913495\n",
      "\n",
      "dividing a   0.3333333333333333\n",
      "\n",
      "teletype typewritten   1.0\n",
      "\n",
      "and taking   0.001445086705202312\n",
      "\n",
      "typewritten or   0.2\n",
      "\n",
      "fact that   0.45454545454545453\n",
      "\n",
      "'' could   0.005154639175257732\n",
      "\n",
      "applications of   0.04\n",
      "\n",
      "but has   0.014705882352941176\n",
      "\n",
      "linguistics is   0.15\n",
      "\n",
      ": Overall   0.00980392156862745\n",
      "\n",
      "Conversational analysis   1.0\n",
      "\n",
      ", Jim   0.0005614823133071309\n",
      "\n",
      "a rule   0.001226993865030675\n",
      "\n",
      "usually evaluated   0.03125\n",
      "\n",
      "language metamodel   0.006756756756756757\n",
      "\n",
      "results can   0.047619047619047616\n",
      "\n",
      "This includes   0.015873015873015872\n",
      "\n",
      "other levels   0.014285714285714285\n",
      "\n",
      "decade to   0.3333333333333333\n",
      "\n",
      "the core   0.0006920415224913495\n",
      "\n",
      "book ''   0.125\n",
      "\n",
      "we will   0.08888888888888889\n",
      "\n",
      "formalization .   0.5\n",
      "\n",
      "sentences correct   0.013157894736842105\n",
      "\n",
      "by transfer-based   0.005714285714285714\n",
      "\n",
      ", dynamic   0.0005614823133071309\n",
      "\n",
      "speech attached   0.006578947368421052\n",
      "\n",
      "for large-vocabulary   0.0036101083032490976\n",
      "\n",
      "ATNs and   0.3333333333333333\n",
      "\n",
      "Japanese ,   0.125\n",
      "\n",
      "world and   0.06666666666666667\n",
      "\n",
      "different meanings   0.02040816326530612\n",
      "\n",
      "textual corpora   0.2\n",
      "\n",
      "are discussed   0.004149377593360996\n",
      "\n",
      "not describe   0.008928571428571428\n",
      "\n",
      "Stanford University   0.5\n",
      "\n",
      "QA system   0.23809523809523808\n",
      "\n",
      "his famous   0.08333333333333333\n",
      "\n",
      "with morphological   0.00546448087431694\n",
      "\n",
      "as Turkish   0.003484320557491289\n",
      "\n",
      "1,915,993 -RRB-   1.0\n",
      "\n",
      "is obtained   0.0020325203252032522\n",
      "\n",
      "data of   0.012987012987012988\n",
      "\n",
      "project -LRB-   0.07692307692307693\n",
      "\n",
      "can assign   0.0055248618784530384\n",
      "\n",
      "EARS project   1.0\n",
      "\n",
      "tokens from   0.14285714285714285\n",
      "\n",
      "punched cards   1.0\n",
      "\n",
      "For individuals   0.01639344262295082\n",
      "\n",
      "the preceding   0.0006920415224913495\n",
      "\n",
      "that sentences   0.0035460992907801418\n",
      "\n",
      "then ,   0.08571428571428572\n",
      "\n",
      ", Number   0.0005614823133071309\n",
      "\n",
      "Ingria R.   1.0\n",
      "\n",
      "the Latin   0.0006920415224913495\n",
      "\n",
      "achieve performance   0.5\n",
      "\n",
      "and insurance   0.001445086705202312\n",
      "\n",
      "successful for   0.1111111111111111\n",
      "\n",
      "Improved output   1.0\n",
      "\n",
      "Markov model   0.4444444444444444\n",
      "\n",
      "developments in   0.6666666666666666\n",
      "\n",
      "Grace project   1.0\n",
      "\n",
      "should soon   0.05263157894736842\n",
      "\n",
      "designed grammars   0.14285714285714285\n",
      "\n",
      "talking about   1.0\n",
      "\n",
      "not before   0.008928571428571428\n",
      "\n",
      "term voice   0.05555555555555555\n",
      "\n",
      ", Vito   0.0005614823133071309\n",
      "\n",
      "In 1996   0.009523809523809525\n",
      "\n",
      "it would   0.03418803418803419\n",
      "\n",
      "verbs ,   0.6\n",
      "\n",
      "are known   0.012448132780082987\n",
      "\n",
      "against noise   0.2\n",
      "\n",
      "analysis include   0.015384615384615385\n",
      "\n",
      "-LRB- December   0.0027100271002710027\n",
      "\n",
      "and questions   0.001445086705202312\n",
      "\n",
      "vertices in   0.1111111111111111\n",
      "\n",
      "scores as   0.2\n",
      "\n",
      "deemed the   0.5\n",
      "\n",
      "when outputting   0.02857142857142857\n",
      "\n",
      "and TextRank   0.001445086705202312\n",
      "\n",
      "independent system   0.5\n",
      "\n",
      "the meeting   0.0006920415224913495\n",
      "\n",
      "research and   0.11904761904761904\n",
      "\n",
      "<s> Up   0.0007686395080707148\n",
      "\n",
      "became one   0.2\n",
      "\n",
      "an inseparable   0.007575757575757576\n",
      "\n",
      "On-line character   0.6666666666666666\n",
      "\n",
      "refers to   1.0\n",
      "\n",
      "networks Main   0.07142857142857142\n",
      "\n",
      "English or   0.02702702702702703\n",
      "\n",
      "or syntactic   0.0045045045045045045\n",
      "\n",
      "in agglutinative   0.0018726591760299626\n",
      "\n",
      "2010 -RRB-   0.3333333333333333\n",
      "\n",
      "given an   0.041666666666666664\n",
      "\n",
      "compared a   0.14285714285714285\n",
      "\n",
      "tune the   1.0\n",
      "\n",
      "The Associated   0.005208333333333333\n",
      "\n",
      "on ;   0.0047169811320754715\n",
      "\n",
      "summarization based   0.02\n",
      "\n",
      "view language   0.3333333333333333\n",
      "\n",
      "This technique   0.015873015873015872\n",
      "\n",
      "sometimes suggest   0.07692307692307693\n",
      "\n",
      "method -LRB-   0.0625\n",
      "\n",
      "using natural   0.01694915254237288\n",
      "\n",
      "or disease   0.0045045045045045045\n",
      "\n",
      "language representation   0.006756756756756757\n",
      "\n",
      "meet a   0.25\n",
      "\n",
      ", Words   0.0005614823133071309\n",
      "\n",
      "are now   0.016597510373443983\n",
      "\n",
      "determine whether   0.043478260869565216\n",
      "\n",
      "CSR -RRB-   0.6666666666666666\n",
      "\n",
      "<s> Given   0.0023059185242121443\n",
      "\n",
      "interest Topics   0.09090909090909091\n",
      "\n",
      "can achieve   0.0055248618784530384\n",
      "\n",
      "particular dataset   0.07692307692307693\n",
      "\n",
      "that ROUGE   0.0035460992907801418\n",
      "\n",
      "cepstral coefficients   0.5\n",
      "\n",
      "as Robert   0.003484320557491289\n",
      "\n",
      "grammars alone   0.07142857142857142\n",
      "\n",
      "models -LRB-   0.11538461538461539\n",
      "\n",
      "approximate meaning   0.5\n",
      "\n",
      "^ ,   0.6666666666666666\n",
      "\n",
      "Iraq and   0.5\n",
      "\n",
      "of candidates   0.00089126559714795\n",
      "\n",
      "fraction of   1.0\n",
      "\n",
      "using statistical   0.03389830508474576\n",
      "\n",
      "recognize For   0.1111111111111111\n",
      "\n",
      "save time   1.0\n",
      "\n",
      "mentioned above   0.16666666666666666\n",
      "\n",
      "algorithms currently   0.02857142857142857\n",
      "\n",
      "have in   0.019230769230769232\n",
      "\n",
      "-LRB- not   0.0027100271002710027\n",
      "\n",
      "heritage -LRB-   1.0\n",
      "\n",
      "metrics ,   0.1111111111111111\n",
      "\n",
      "of corpora   0.00089126559714795\n",
      "\n",
      "rules of   0.09302325581395349\n",
      "\n",
      "Hansard corpus   1.0\n",
      "\n",
      "of commercial   0.00089126559714795\n",
      "\n",
      "instance ,   0.6428571428571429\n",
      "\n",
      ", length   0.0005614823133071309\n",
      "\n",
      "` local   0.0625\n",
      "\n",
      ": complicated   0.00980392156862745\n",
      "\n",
      "http:\\/\\/haydn.isi.edu\\/ROUGE\\/ -RRB-   1.0\n",
      "\n",
      "between two   0.05128205128205128\n",
      "\n",
      "answered ,   0.2\n",
      "\n",
      "be more   0.02109704641350211\n",
      "\n",
      "task depends   0.023809523809523808\n",
      "\n",
      "and we   0.001445086705202312\n",
      "\n",
      "used as   0.04424778761061947\n",
      "\n",
      "captures data   1.0\n",
      "\n",
      "value is   0.3333333333333333\n",
      "\n",
      "trigram found   0.3333333333333333\n",
      "\n",
      "dependent system   0.3333333333333333\n",
      "\n",
      "out from   0.07142857142857142\n",
      "\n",
      "In one   0.009523809523809525\n",
      "\n",
      "-LRB- SemEval   0.0027100271002710027\n",
      "\n",
      "information -LRB-   0.021739130434782608\n",
      "\n",
      "be expressed   0.012658227848101266\n",
      "\n",
      "1980s .   0.2222222222222222\n",
      "\n",
      "`` a   0.005291005291005291\n",
      "\n",
      "expectations ,   1.0\n",
      "\n",
      "below -RRB-   0.4\n",
      "\n",
      "are put   0.004149377593360996\n",
      "\n",
      "phrase that   0.1\n",
      "\n",
      "BLEU measure   0.3333333333333333\n",
      "\n",
      "enough to   0.2\n",
      "\n",
      "central ``   0.3333333333333333\n",
      "\n",
      "still translates   0.06666666666666667\n",
      "\n",
      "comprising context   0.5\n",
      "\n",
      "own it   0.16666666666666666\n",
      "\n",
      "as normalization   0.003484320557491289\n",
      "\n",
      "interpreter .   0.5\n",
      "\n",
      "their features\\/aspects   0.029411764705882353\n",
      "\n",
      "search .   0.09090909090909091\n",
      "\n",
      "and NLP   0.002890173410404624\n",
      "\n",
      "delayed until   1.0\n",
      "\n",
      "-LRB- for   0.018970189701897018\n",
      "\n",
      "has specialized   0.011904761904761904\n",
      "\n",
      ", shallow   0.0005614823133071309\n",
      "\n",
      "stage is   0.4\n",
      "\n",
      "generated .   0.2\n",
      "\n",
      "in turn   0.009363295880149813\n",
      "\n",
      "and\\/or religious   0.3333333333333333\n",
      "\n",
      "method used   0.0625\n",
      "\n",
      "operated successfully   0.5\n",
      "\n",
      "their estimated   0.029411764705882353\n",
      "\n",
      "we could   0.022222222222222223\n",
      "\n",
      "what Biden   0.03125\n",
      "\n",
      "was recognized   0.012987012987012988\n",
      "\n",
      "learning As   0.023255813953488372\n",
      "\n",
      "accompanying HTK   1.0\n",
      "\n",
      ", Facebook   0.0005614823133071309\n",
      "\n",
      ", domain   0.0005614823133071309\n",
      "\n",
      "mid-90s .   1.0\n",
      "\n",
      "complex spoken   0.041666666666666664\n",
      "\n",
      "that you   0.0035460992907801418\n",
      "\n",
      "these programs   0.023809523809523808\n",
      "\n",
      "phrase ``   0.1\n",
      "\n",
      "by Schank   0.005714285714285714\n",
      "\n",
      "of inflected   0.00089126559714795\n",
      "\n",
      "shallowest ,   1.0\n",
      "\n",
      "automating abstractive   1.0\n",
      "\n",
      "fire truck   0.5\n",
      "\n",
      "to each   0.006640106241699867\n",
      "\n",
      "History Some   0.5\n",
      "\n",
      "workload ,   1.0\n",
      "\n",
      "speaker of   0.1111111111111111\n",
      "\n",
      "of characters   0.0017825311942959\n",
      "\n",
      "articles on   0.125\n",
      "\n",
      "in reverse   0.0018726591760299626\n",
      "\n",
      "when we   0.05714285714285714\n",
      "\n",
      "or formulaic   0.0045045045045045045\n",
      "\n",
      "treat them   0.5\n",
      "\n",
      "general cursive   0.045454545454545456\n",
      "\n",
      "documents and   0.02631578947368421\n",
      "\n",
      "input devices   0.04878048780487805\n",
      "\n",
      "presents the   1.0\n",
      "\n",
      "basic categories   0.07692307692307693\n",
      "\n",
      "as EAGLi   0.003484320557491289\n",
      "\n",
      "10 milliseconds   0.25\n",
      "\n",
      "to some   0.006640106241699867\n",
      "\n",
      "from an   0.009615384615384616\n",
      "\n",
      "Federation of   1.0\n",
      "\n",
      "urgent early   1.0\n",
      "\n",
      "or phones   0.0045045045045045045\n",
      "\n",
      "Wayne Ratliff   1.0\n",
      "\n",
      "not 100   0.008928571428571428\n",
      "\n",
      "and actioning   0.001445086705202312\n",
      "\n",
      "<s> Prior   0.0007686395080707148\n",
      "\n",
      "`` not   0.005291005291005291\n",
      "\n",
      "are important   0.004149377593360996\n",
      "\n",
      "mid 1980s   1.0\n",
      "\n",
      "systems is   0.026785714285714284\n",
      "\n",
      "lexicon reached   0.1111111111111111\n",
      "\n",
      "the centers   0.0006920415224913495\n",
      "\n",
      "field since   0.037037037037037035\n",
      "\n",
      "kind to   0.09090909090909091\n",
      "\n",
      "ambiguous words   0.16666666666666666\n",
      "\n",
      "algorithms one   0.02857142857142857\n",
      "\n",
      "Abney S.   1.0\n",
      "\n",
      "parsing and   0.03571428571428571\n",
      "\n",
      "on-line recognition   0.3333333333333333\n",
      "\n",
      "text may   0.006289308176100629\n",
      "\n",
      "classify a   0.5\n",
      "\n",
      "conversion .   0.3333333333333333\n",
      "\n",
      "optimization methods   1.0\n",
      "\n",
      "into separate   0.02564102564102564\n",
      "\n",
      "1,000 parts   0.5\n",
      "\n",
      "complex expressions   0.041666666666666664\n",
      "\n",
      "of AI   0.00089126559714795\n",
      "\n",
      ", bigram   0.0016844469399213925\n",
      "\n",
      "Heritage ,   1.0\n",
      "\n",
      "machine is   0.012658227848101266\n",
      "\n",
      "a human-language   0.001226993865030675\n",
      "\n",
      "Web is   0.1111111111111111\n",
      "\n",
      "speech and   0.013157894736842105\n",
      "\n",
      "the top   0.002768166089965398\n",
      "\n",
      "the sequence   0.0006920415224913495\n",
      "\n",
      "vertices\\/unigrams are   1.0\n",
      "\n",
      "Baum-Welch algorithm   1.0\n",
      "\n",
      "le français   1.0\n",
      "\n",
      "generating examples   0.2\n",
      "\n",
      "hand printing   0.07142857142857142\n",
      "\n",
      "an online   0.007575757575757576\n",
      "\n",
      "documents or   0.02631578947368421\n",
      "\n",
      "and generally   0.001445086705202312\n",
      "\n",
      "and decorrelating   0.001445086705202312\n",
      "\n",
      "a table   0.0036809815950920245\n",
      "\n",
      "corpora and   0.09090909090909091\n",
      "\n",
      "statistical translation   0.030303030303030304\n",
      "\n",
      "segmentation process   0.030303030303030304\n",
      "\n",
      "In normal   0.009523809523809525\n",
      "\n",
      "of automatic   0.0017825311942959\n",
      "\n",
      "soon .   0.3333333333333333\n",
      "\n",
      "Another key   0.07692307692307693\n",
      "\n",
      ", Verbyx   0.0005614823133071309\n",
      "\n",
      "e-communities die   0.5\n",
      "\n",
      "reranking in   1.0\n",
      "\n",
      "Human Summarization   0.2\n",
      "\n",
      "to require   0.0013280212483399733\n",
      "\n",
      "and Weizenbaum   0.001445086705202312\n",
      "\n",
      "which generate   0.021739130434782608\n",
      "\n",
      "technology ,   0.13636363636363635\n",
      "\n",
      "your head   0.5\n",
      "\n",
      "the phrase   0.002768166089965398\n",
      "\n",
      "But unfortunately   0.16666666666666666\n",
      "\n",
      "British English   0.3333333333333333\n",
      "\n",
      "similar contexts   0.037037037037037035\n",
      "\n",
      "large sets   0.08695652173913043\n",
      "\n",
      "On-line systems   0.3333333333333333\n",
      "\n",
      "labor involved   0.5\n",
      "\n",
      "and interaction   0.001445086705202312\n",
      "\n",
      "case in   0.058823529411764705\n",
      "\n",
      "name is   0.2\n",
      "\n",
      "was extensively   0.012987012987012988\n",
      "\n",
      "extracting answers   0.2\n",
      "\n",
      "the resulting   0.001384083044982699\n",
      "\n",
      "<s> One   0.009223674096848577\n",
      "\n",
      "it belongs   0.008547008547008548\n",
      "\n",
      "summarization systems   0.1\n",
      "\n",
      "EBMT -RRB-   1.0\n",
      "\n",
      "of written   0.0035650623885918\n",
      "\n",
      "systems existing   0.008928571428571428\n",
      "\n",
      "the president   0.001384083044982699\n",
      "\n",
      "right information   0.1\n",
      "\n",
      "Turney and   0.2222222222222222\n",
      "\n",
      "grammatical tagging   0.18181818181818182\n",
      "\n",
      "also includes   0.014492753623188406\n",
      "\n",
      "look-up tables   1.0\n",
      "\n",
      "dynamic character   0.2\n",
      "\n",
      "analysis model   0.015384615384615385\n",
      "\n",
      "accuracy will   0.03225806451612903\n",
      "\n",
      ", creating   0.0011229646266142617\n",
      "\n",
      ", call   0.0005614823133071309\n",
      "\n",
      "other commercial   0.014285714285714285\n",
      "\n",
      "then use   0.02857142857142857\n",
      "\n",
      "corpus and   0.03225806451612903\n",
      "\n",
      "Europe was   0.2\n",
      "\n",
      "paradigm calls   0.3333333333333333\n",
      "\n",
      "the text-to-speech   0.0006920415224913495\n",
      "\n",
      "increase in   0.75\n",
      "\n",
      "field because   0.037037037037037035\n",
      "\n",
      "emerged as   1.0\n",
      "\n",
      "news release   0.07692307692307693\n",
      "\n",
      "sentence boundaries   0.08333333333333333\n",
      "\n",
      "calculator program   0.5\n",
      "\n",
      "in some   0.00749063670411985\n",
      "\n",
      "tried to   0.3333333333333333\n",
      "\n",
      "Lehnert ,   0.6666666666666666\n",
      "\n",
      "hence reducing   0.5\n",
      "\n",
      "the personal   0.0006920415224913495\n",
      "\n",
      "examples for   0.041666666666666664\n",
      "\n",
      ": What   0.00980392156862745\n",
      "\n",
      ", possibly   0.0005614823133071309\n",
      "\n",
      "by Greene   0.005714285714285714\n",
      "\n",
      "Shallow approaches   0.5\n",
      "\n",
      "ROUGE measures   0.2\n",
      "\n",
      "frequencies ,   0.5\n",
      "\n",
      "also classify   0.014492753623188406\n",
      "\n",
      "in spoken   0.003745318352059925\n",
      "\n",
      "algorithms work   0.02857142857142857\n",
      "\n",
      "wrote that   0.16666666666666666\n",
      "\n",
      "methodology to   0.5\n",
      "\n",
      "picture quality   0.25\n",
      "\n",
      "help to   0.1111111111111111\n",
      "\n",
      "-- or   0.04\n",
      "\n",
      "Lehrberger 1982   1.0\n",
      "\n",
      "-LRB- grammar   0.0027100271002710027\n",
      "\n",
      "graphic user   1.0\n",
      "\n",
      "we may   0.022222222222222223\n",
      "\n",
      "otherwise ,   0.5\n",
      "\n",
      "or ICR   0.0045045045045045045\n",
      "\n",
      ", since   0.002807411566535654\n",
      "\n",
      "computer OCR   0.022727272727272728\n",
      "\n",
      "be possible   0.008438818565400843\n",
      "\n",
      "switched to   1.0\n",
      "\n",
      "is how   0.0040650406504065045\n",
      "\n",
      "methods related   0.022727272727272728\n",
      "\n",
      "The main   0.015625\n",
      "\n",
      "Joe Biden   1.0\n",
      "\n",
      "stages of   0.5\n",
      "\n",
      "the filter   0.0006920415224913495\n",
      "\n",
      "greater accuracy   0.3333333333333333\n",
      "\n",
      "Statistics are   0.3333333333333333\n",
      "\n",
      "all about   0.023255813953488372\n",
      "\n",
      "authors found   0.2\n",
      "\n",
      "analyzed ,   0.2\n",
      "\n",
      "to 150,000   0.0013280212483399733\n",
      "\n",
      "MT has   0.2\n",
      "\n",
      "criterion of   0.5\n",
      "\n",
      "as first-order   0.003484320557491289\n",
      "\n",
      "this paper   0.01098901098901099\n",
      "\n",
      "Verbyx VRX   1.0\n",
      "\n",
      "NASA 's   1.0\n",
      "\n",
      ", 1977   0.0005614823133071309\n",
      "\n",
      "reader was   0.2\n",
      "\n",
      "up In   0.045454545454545456\n",
      "\n",
      "learn features   0.07692307692307693\n",
      "\n",
      "rare or   0.25\n",
      "\n",
      "short time   0.125\n",
      "\n",
      "interlingual machine   0.75\n",
      "\n",
      "text map   0.006289308176100629\n",
      "\n",
      "training step   0.07142857142857142\n",
      "\n",
      "LexRank applies   0.08333333333333333\n",
      "\n",
      "edit distances   1.0\n",
      "\n",
      "extended in   1.0\n",
      "\n",
      "dynamically creating   0.5\n",
      "\n",
      "system which   0.010752688172043012\n",
      "\n",
      "performance had   0.05555555555555555\n",
      "\n",
      "for innumerable   0.0036101083032490976\n",
      "\n",
      "fighter applications   0.16666666666666666\n",
      "\n",
      "The construction   0.005208333333333333\n",
      "\n",
      "sequences -LRB-   0.1111111111111111\n",
      "\n",
      ", supervised   0.0005614823133071309\n",
      "\n",
      "lessened .   1.0\n",
      "\n",
      "except some   1.0\n",
      "\n",
      "Known word   1.0\n",
      "\n",
      "over most   0.08333333333333333\n",
      "\n",
      "Northern Isles   0.6666666666666666\n",
      "\n",
      "mine the   1.0\n",
      "\n",
      "<s> OCR   0.0030745580322828594\n",
      "\n",
      "IBM .   0.3333333333333333\n",
      "\n",
      "a user-provided   0.001226993865030675\n",
      "\n",
      "shallow approach   0.3333333333333333\n",
      "\n",
      "for Computational   0.0036101083032490976\n",
      "\n",
      "the Tablet   0.0006920415224913495\n",
      "\n",
      "used SYSTRAN   0.008849557522123894\n",
      "\n",
      "are names   0.004149377593360996\n",
      "\n",
      "combines the   1.0\n",
      "\n",
      "of government   0.0017825311942959\n",
      "\n",
      "anaphora .   1.0\n",
      "\n",
      "Then the   0.4\n",
      "\n",
      "convey intended   0.3333333333333333\n",
      "\n",
      "letter ?   0.16666666666666666\n",
      "\n",
      "BASEBALL and   0.5\n",
      "\n",
      "dictionary is   0.14285714285714285\n",
      "\n",
      "system takes   0.010752688172043012\n",
      "\n",
      "the model   0.0020761245674740486\n",
      "\n",
      "sources .   0.3333333333333333\n",
      "\n",
      "<s> Based   0.0007686395080707148\n",
      "\n",
      "and would   0.001445086705202312\n",
      "\n",
      "Judith M.   1.0\n",
      "\n",
      "words immediately   0.009174311926605505\n",
      "\n",
      "should correspond   0.05263157894736842\n",
      "\n",
      "tool to   0.5\n",
      "\n",
      "trigram ,   0.6666666666666666\n",
      "\n",
      "tagging will   0.04\n",
      "\n",
      "included question-answering   0.125\n",
      "\n",
      "marks may   0.25\n",
      "\n",
      "their part   0.029411764705882353\n",
      "\n",
      "users sent   0.1111111111111111\n",
      "\n",
      "; that   0.02127659574468085\n",
      "\n",
      "domotic appliance   1.0\n",
      "\n",
      "database look-up   0.1\n",
      "\n",
      "; Computed   0.02127659574468085\n",
      "\n",
      "any other   0.06451612903225806\n",
      "\n",
      "vertices .   0.2222222222222222\n",
      "\n",
      "both in   0.03225806451612903\n",
      "\n",
      "fundamental ,   0.5\n",
      "\n",
      "with corpus   0.00546448087431694\n",
      "\n",
      "changed from   0.5\n",
      "\n",
      "levels of   0.3181818181818182\n",
      "\n",
      "of about   0.00089126559714795\n",
      "\n",
      "many times   0.019230769230769232\n",
      "\n",
      "fast-evolving field   1.0\n",
      "\n",
      "`` STT   0.005291005291005291\n",
      "\n",
      "the opinions   0.0006920415224913495\n",
      "\n",
      "the character   0.0006920415224913495\n",
      "\n",
      "by receivers   0.005714285714285714\n",
      "\n",
      "series of   0.875\n",
      "\n",
      "skip the   1.0\n",
      "\n",
      "while some   0.05\n",
      "\n",
      "-LRB- ARRA   0.0027100271002710027\n",
      "\n",
      "titles ,   0.5\n",
      "\n",
      "or two   0.009009009009009009\n",
      "\n",
      "Pike ,   1.0\n",
      "\n",
      "is based   0.008130081300813009\n",
      "\n",
      "more forms   0.010526315789473684\n",
      "\n",
      "appropriate action   0.25\n",
      "\n",
      "when multiple   0.02857142857142857\n",
      "\n",
      "Again ,   1.0\n",
      "\n",
      "request can   1.0\n",
      "\n",
      ", turns   0.0005614823133071309\n",
      "\n",
      "ID card   1.0\n",
      "\n",
      "and syntactic   0.002890173410404624\n",
      "\n",
      "easier than   0.25\n",
      "\n",
      "source ,   0.041666666666666664\n",
      "\n",
      "T unigrams   0.3333333333333333\n",
      "\n",
      "crucial to   1.0\n",
      "\n",
      "labor intensive   0.5\n",
      "\n",
      ", syntactic   0.0016844469399213925\n",
      "\n",
      "that affective   0.0035460992907801418\n",
      "\n",
      "Mutual Information   1.0\n",
      "\n",
      "humans would   0.08333333333333333\n",
      "\n",
      "objects .   0.2\n",
      "\n",
      "is growing   0.0020325203252032522\n",
      "\n",
      "typical sentence   0.1111111111111111\n",
      "\n",
      "` conceptual   0.0625\n",
      "\n",
      "existing words   0.2\n",
      "\n",
      "time -LRB-   0.06060606060606061\n",
      "\n",
      "understood only   1.0\n",
      "\n",
      "Carmen Rosa   1.0\n",
      "\n",
      "efforts have   0.5714285714285714\n",
      "\n",
      "to all   0.00398406374501992\n",
      "\n",
      "a typical   0.00245398773006135\n",
      "\n",
      "questioners expect   1.0\n",
      "\n",
      "Document structuring   0.25\n",
      "\n",
      "tagging :   0.04\n",
      "\n",
      "be selected   0.004219409282700422\n",
      "\n",
      "produce ,   0.045454545454545456\n",
      "\n",
      "are beyond   0.004149377593360996\n",
      "\n",
      "methods ,   0.09090909090909091\n",
      "\n",
      "in 1987   0.003745318352059925\n",
      "\n",
      "tagged as   0.3333333333333333\n",
      "\n",
      "program focuses   0.045454545454545456\n",
      "\n",
      "methods presented   0.022727272727272728\n",
      "\n",
      "is 7   0.0020325203252032522\n",
      "\n",
      "<s> You   0.0007686395080707148\n",
      "\n",
      ", contrast   0.0005614823133071309\n",
      "\n",
      "cultural factors   1.0\n",
      "\n",
      "sounds -LRB-   0.13333333333333333\n",
      "\n",
      ", only   0.0011229646266142617\n",
      "\n",
      "appear as   0.0625\n",
      "\n",
      "filtering out   1.0\n",
      "\n",
      "Tom Clancy   1.0\n",
      "\n",
      "may or   0.019230769230769232\n",
      "\n",
      "which accommodate   0.007246376811594203\n",
      "\n",
      "trees using   0.16666666666666666\n",
      "\n",
      "program may   0.045454545454545456\n",
      "\n",
      "and it   0.0072254335260115606\n",
      "\n",
      "which its   0.007246376811594203\n",
      "\n",
      "Studies -RRB-   1.0\n",
      "\n",
      "way they   0.041666666666666664\n",
      "\n",
      "offered the   1.0\n",
      "\n",
      "say `   0.2857142857142857\n",
      "\n",
      "as text   0.003484320557491289\n",
      "\n",
      "others seem   0.08333333333333333\n",
      "\n",
      "the current   0.001384083044982699\n",
      "\n",
      "walk to   0.2\n",
      "\n",
      "above are   0.07692307692307693\n",
      "\n",
      "Automatic segmentation   0.3333333333333333\n",
      "\n",
      "was also   0.025974025974025976\n",
      "\n",
      "objective True\\/False   0.2\n",
      "\n",
      "of count   0.00089126559714795\n",
      "\n",
      "a hard   0.00245398773006135\n",
      "\n",
      "a logical   0.001226993865030675\n",
      "\n",
      "area is   0.18181818181818182\n",
      "\n",
      "contains a   0.1\n",
      "\n",
      "TextRank is   0.07142857142857142\n",
      "\n",
      "started trying   0.25\n",
      "\n",
      "top-down parsers   0.25\n",
      "\n",
      "acts in   0.3333333333333333\n",
      "\n",
      "generating natural   0.2\n",
      "\n",
      "for special   0.0036101083032490976\n",
      "\n",
      "Accuracy for   0.14285714285714285\n",
      "\n",
      "to dry   0.0013280212483399733\n",
      "\n",
      "as named   0.003484320557491289\n",
      "\n",
      "Prominent discourse   1.0\n",
      "\n",
      "'' standards   0.005154639175257732\n",
      "\n",
      "describing language   0.25\n",
      "\n",
      "systems .   0.08928571428571429\n",
      "\n",
      "evaluation tests   0.037037037037037035\n",
      "\n",
      "tokens like   0.14285714285714285\n",
      "\n",
      "translation methodologies   0.013513513513513514\n",
      "\n",
      "VITO Voice2Go   1.0\n",
      "\n",
      "principle ,   1.0\n",
      "\n",
      "act as   0.75\n",
      "\n",
      "ParaEval -RRB-   1.0\n",
      "\n",
      "Up to   1.0\n",
      "\n",
      ": Error   0.00980392156862745\n",
      "\n",
      "from this   0.009615384615384616\n",
      "\n",
      "Kenneth Lee   1.0\n",
      "\n",
      "an opportunity   0.007575757575757576\n",
      "\n",
      "two -LRB-   0.034482758620689655\n",
      "\n",
      "Handwriting recognition   1.0\n",
      "\n",
      "to blind   0.0013280212483399733\n",
      "\n",
      "people to   0.125\n",
      "\n",
      "category that   0.5\n",
      "\n",
      "following .   0.13333333333333333\n",
      "\n",
      "a strength   0.001226993865030675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "comes mainly   0.2\n",
      "\n",
      "automate sentiment   0.3333333333333333\n",
      "\n",
      "but IR   0.014705882352941176\n",
      "\n",
      "written conversation   0.038461538461538464\n",
      "\n",
      "feasibility demonstration   0.5\n",
      "\n",
      "as first   0.003484320557491289\n",
      "\n",
      "recognized essentially   0.16666666666666666\n",
      "\n",
      ", systems   0.0011229646266142617\n",
      "\n",
      "also cut   0.014492753623188406\n",
      "\n",
      ", Alan   0.0005614823133071309\n",
      "\n",
      "in rank   0.0018726591760299626\n",
      "\n",
      "also Machine   0.014492753623188406\n",
      "\n",
      "in recent   0.003745318352059925\n",
      "\n",
      "hand-written by   0.14285714285714285\n",
      "\n",
      "and other   0.01300578034682081\n",
      "\n",
      "and generic   0.001445086705202312\n",
      "\n",
      "less accurate   0.08333333333333333\n",
      "\n",
      "from closely   0.009615384615384616\n",
      "\n",
      "Gender =   1.0\n",
      "\n",
      "the meaning   0.006920415224913495\n",
      "\n",
      "the wife   0.0006920415224913495\n",
      "\n",
      "or lowering   0.0045045045045045045\n",
      "\n",
      "saying .   1.0\n",
      "\n",
      "summaries formed   0.023255813953488372\n",
      "\n",
      "the contents   0.0006920415224913495\n",
      "\n",
      "Patent 2,663,758   0.3333333333333333\n",
      "\n",
      "vocabulary of   0.125\n",
      "\n",
      "we might   0.022222222222222223\n",
      "\n",
      "with models   0.00546448087431694\n",
      "\n",
      "In both   0.01904761904761905\n",
      "\n",
      "of morphologically   0.00089126559714795\n",
      "\n",
      "The relationships   0.005208333333333333\n",
      "\n",
      "the morphemes   0.0006920415224913495\n",
      "\n",
      "morphological analysis   0.3333333333333333\n",
      "\n",
      "aims at   0.3333333333333333\n",
      "\n",
      "one word   0.03076923076923077\n",
      "\n",
      "a revolution   0.001226993865030675\n",
      "\n",
      "-LRB- DTW   0.0027100271002710027\n",
      "\n",
      "part may   0.037037037037037035\n",
      "\n",
      "lend well   1.0\n",
      "\n",
      "as doctors   0.003484320557491289\n",
      "\n",
      "by Ask.com   0.005714285714285714\n",
      "\n",
      "manipulate it   0.3333333333333333\n",
      "\n",
      "POS tagger   0.3076923076923077\n",
      "\n",
      "? <s/>   0.5\n",
      "\n",
      "that involve   0.0035460992907801418\n",
      "\n",
      "explored using   0.5\n",
      "\n",
      "also characterized   0.014492753623188406\n",
      "\n",
      "storing ,   1.0\n",
      "\n",
      "and linear   0.001445086705202312\n",
      "\n",
      "promise to   1.0\n",
      "\n",
      "in texts   0.0018726591760299626\n",
      "\n",
      "NLP comprises   0.02127659574468085\n",
      "\n",
      "learning ''   0.11627906976744186\n",
      "\n",
      "deliberately inserts   1.0\n",
      "\n",
      "linear algebra   0.14285714285714285\n",
      "\n",
      "<s> Despite   0.0007686395080707148\n",
      "\n",
      "and cross-lingual   0.001445086705202312\n",
      "\n",
      "and current   0.001445086705202312\n",
      "\n",
      "FoG triggered   0.5\n",
      "\n",
      "create tokens   0.058823529411764705\n",
      "\n",
      "expressed on   0.3333333333333333\n",
      "\n",
      "angry .   0.5\n",
      "\n",
      "test how   0.1\n",
      "\n",
      "Conference Evaluation   0.5\n",
      "\n",
      "ever appear   1.0\n",
      "\n",
      "the adviser   0.0006920415224913495\n",
      "\n",
      "dependency for   0.2\n",
      "\n",
      "called GRASSHOPPER   0.05555555555555555\n",
      "\n",
      "Nunan ,   1.0\n",
      "\n",
      "Chinese characters   0.14285714285714285\n",
      "\n",
      "page scanner   0.14285714285714285\n",
      "\n",
      "will usually   0.02857142857142857\n",
      "\n",
      "but triples   0.014705882352941176\n",
      "\n",
      "digital camera   0.14285714285714285\n",
      "\n",
      "been data-to-text   0.014705882352941176\n",
      "\n",
      "is essentially   0.006097560975609756\n",
      "\n",
      "simple rules   0.038461538461538464\n",
      "\n",
      ", grammatical   0.0005614823133071309\n",
      "\n",
      "second ;   0.1\n",
      "\n",
      "-LRB- DARPA   0.0027100271002710027\n",
      "\n",
      "way --   0.041666666666666664\n",
      "\n",
      "Web 2.0   0.1111111111111111\n",
      "\n",
      "different distances   0.02040816326530612\n",
      "\n",
      "`` warped   0.005291005291005291\n",
      "\n",
      "further subdivided   0.125\n",
      "\n",
      "type as   0.07142857142857142\n",
      "\n",
      "` discourse   0.0625\n",
      "\n",
      "have unambiguous   0.009615384615384616\n",
      "\n",
      "and large   0.001445086705202312\n",
      "\n",
      "Because progress   0.5\n",
      "\n",
      "grammar -RRB-   0.08108108108108109\n",
      "\n",
      "the techniques   0.0006920415224913495\n",
      "\n",
      "a sensible   0.001226993865030675\n",
      "\n",
      "from naive   0.009615384615384616\n",
      "\n",
      "representation language   0.10526315789473684\n",
      "\n",
      "unigrams in   0.25\n",
      "\n",
      "first ,   0.030303030303030304\n",
      "\n",
      "approach ;   0.02857142857142857\n",
      "\n",
      "need context   0.047619047619047616\n",
      "\n",
      ", fuse   0.0005614823133071309\n",
      "\n",
      "parsing ,   0.07142857142857142\n",
      "\n",
      "`` Naturally   0.005291005291005291\n",
      "\n",
      "developing a   0.25\n",
      "\n",
      "corpus is   0.03225806451612903\n",
      "\n",
      "one more   0.015384615384615385\n",
      "\n",
      "and reasoning   0.002890173410404624\n",
      "\n",
      "attempted by   1.0\n",
      "\n",
      "large multilingual   0.043478260869565216\n",
      "\n",
      "<s> Comparing   0.0007686395080707148\n",
      "\n",
      "Dec. 2011   1.0\n",
      "\n",
      "NLP An   0.02127659574468085\n",
      "\n",
      "keyphrase to   0.05263157894736842\n",
      "\n",
      "one needs   0.015384615384615385\n",
      "\n",
      "1991 -RRB-   0.6666666666666666\n",
      "\n",
      "spoken version   0.07142857142857142\n",
      "\n",
      "become repetitive   0.25\n",
      "\n",
      "results are   0.19047619047619047\n",
      "\n",
      "fuse with   1.0\n",
      "\n",
      "word boundaries   0.016666666666666666\n",
      "\n",
      "have shown   0.009615384615384616\n",
      "\n",
      "roughly ,   0.6666666666666666\n",
      "\n",
      "in one   0.00749063670411985\n",
      "\n",
      "machines ,   0.25\n",
      "\n",
      "light .   0.3333333333333333\n",
      "\n",
      "1965 ,   0.5\n",
      "\n",
      "read text   0.14285714285714285\n",
      "\n",
      "number 20   0.023255813953488372\n",
      "\n",
      "sound ,   0.1\n",
      "\n",
      "`` words   0.005291005291005291\n",
      "\n",
      "plain text   1.0\n",
      "\n",
      "the very   0.0006920415224913495\n",
      "\n",
      "is red   0.0020325203252032522\n",
      "\n",
      "leading to   1.0\n",
      "\n",
      "higher levels   0.2857142857142857\n",
      "\n",
      "or any   0.013513513513513514\n",
      "\n",
      "virtually impossible   0.5\n",
      "\n",
      "of laws   0.00089126559714795\n",
      "\n",
      "Each concept   0.16666666666666666\n",
      "\n",
      "idea that   0.2857142857142857\n",
      "\n",
      "<s> Users   0.0007686395080707148\n",
      "\n",
      "extension of   1.0\n",
      "\n",
      "were rare   0.024390243902439025\n",
      "\n",
      "very attractive   0.024390243902439025\n",
      "\n",
      "highly ranked   0.1111111111111111\n",
      "\n",
      "certain region   0.14285714285714285\n",
      "\n",
      "recognize the   0.4444444444444444\n",
      "\n",
      "best candidate   0.05555555555555555\n",
      "\n",
      "use the   0.013888888888888888\n",
      "\n",
      "common components   0.04\n",
      "\n",
      "<s> But   0.004611837048424289\n",
      "\n",
      "Leading software   1.0\n",
      "\n",
      "as weighted   0.003484320557491289\n",
      "\n",
      "topics in   0.14285714285714285\n",
      "\n",
      "e.g. Querying   0.017857142857142856\n",
      "\n",
      "document ,   0.1388888888888889\n",
      "\n",
      "simple terms   0.038461538461538464\n",
      "\n",
      "only a   0.05263157894736842\n",
      "\n",
      "quality standards   0.1\n",
      "\n",
      "the morphology   0.0006920415224913495\n",
      "\n",
      "task often   0.023809523809523808\n",
      "\n",
      "presence of   1.0\n",
      "\n",
      "-RRB- :   0.024390243902439025\n",
      "\n",
      "much larger   0.09090909090909091\n",
      "\n",
      "to computer   0.0013280212483399733\n",
      "\n",
      "to post-process   0.0013280212483399733\n",
      "\n",
      "generation techniques   0.1111111111111111\n",
      "\n",
      "journal article   0.3333333333333333\n",
      "\n",
      "correct values   0.06666666666666667\n",
      "\n",
      "1969 Roger   0.5\n",
      "\n",
      "for multi-document   0.0036101083032490976\n",
      "\n",
      "knowledge source   0.037037037037037035\n",
      "\n",
      "these tools   0.023809523809523808\n",
      "\n",
      "triggered other   1.0\n",
      "\n",
      "1971 -LRB-   0.3333333333333333\n",
      "\n",
      "Typically features   1.0\n",
      "\n",
      "closest counterparts   0.5\n",
      "\n",
      "Wetherell ,   1.0\n",
      "\n",
      "process new   0.027777777777777776\n",
      "\n",
      "knowledge base   0.14814814814814814\n",
      "\n",
      "segments each   0.2\n",
      "\n",
      "a separate   0.00245398773006135\n",
      "\n",
      "<s> Context   0.0007686395080707148\n",
      "\n",
      "articulation ,   1.0\n",
      "\n",
      "Beginning in   0.5\n",
      "\n",
      "for natural   0.01444043321299639\n",
      "\n",
      "business ,   0.25\n",
      "\n",
      "and continued   0.001445086705202312\n",
      "\n",
      "a unit   0.001226993865030675\n",
      "\n",
      "technology would   0.045454545454545456\n",
      "\n",
      "Speereo Voice   0.5\n",
      "\n",
      "best to   0.1111111111111111\n",
      "\n",
      "single character   0.07142857142857142\n",
      "\n",
      "we learn   0.022222222222222223\n",
      "\n",
      "understanding programs   0.030303030303030304\n",
      "\n",
      "can prove   0.0055248618784530384\n",
      "\n",
      "different features   0.02040816326530612\n",
      "\n",
      "attractive acoustic   0.3333333333333333\n",
      "\n",
      "predefined template   1.0\n",
      "\n",
      "January 2010   0.5\n",
      "\n",
      "to current   0.0013280212483399733\n",
      "\n",
      "metric for   0.3333333333333333\n",
      "\n",
      "likely be   0.0625\n",
      "\n",
      "Realtime Speech   1.0\n",
      "\n",
      "from printed   0.009615384615384616\n",
      "\n",
      "computer to   0.045454545454545456\n",
      "\n",
      "sub-titling ,   1.0\n",
      "\n",
      "Conferences in   0.5\n",
      "\n",
      "process -LRB-   0.027777777777777776\n",
      "\n",
      "using digital   0.01694915254237288\n",
      "\n",
      "automatically do   0.047619047619047616\n",
      "\n",
      "the vowel   0.001384083044982699\n",
      "\n",
      "Ge'ez script   1.0\n",
      "\n",
      "in October   0.0018726591760299626\n",
      "\n",
      "was influenced   0.012987012987012988\n",
      "\n",
      "speech Adverse   0.006578947368421052\n",
      "\n",
      "organizations such   1.0\n",
      "\n",
      "other non-textual   0.014285714285714285\n",
      "\n",
      "the intended   0.001384083044982699\n",
      "\n",
      "→ <verb>   0.3333333333333333\n",
      "\n",
      "2,663,758 .   1.0\n",
      "\n",
      "Unicode Consortium   1.0\n",
      "\n",
      "gap between   1.0\n",
      "\n",
      "are arranged   0.004149377593360996\n",
      "\n",
      "+ Web-based   0.16666666666666666\n",
      "\n",
      "should not   0.05263157894736842\n",
      "\n",
      "short commands   0.125\n",
      "\n",
      "semantic theory   0.09523809523809523\n",
      "\n",
      "William A.   0.5\n",
      "\n",
      "psycholinguistics when   0.5\n",
      "\n",
      "it should   0.008547008547008548\n",
      "\n",
      "strategy for   0.2\n",
      "\n",
      "readily produces   0.3333333333333333\n",
      "\n",
      "Internet financial   0.5\n",
      "\n",
      "text lacks   0.006289308176100629\n",
      "\n",
      "blue ''   1.0\n",
      "\n",
      "conversations .   0.3333333333333333\n",
      "\n",
      "their solutions   0.029411764705882353\n",
      "\n",
      "data which   0.012987012987012988\n",
      "\n",
      "desired identification   0.2\n",
      "\n",
      "termed Direct   0.25\n",
      "\n",
      "be divided   0.004219409282700422\n",
      "\n",
      "an approximation   0.015151515151515152\n",
      "\n",
      "PangeaMT ,   1.0\n",
      "\n",
      "or answers   0.0045045045045045045\n",
      "\n",
      "for Friday   0.010830324909747292\n",
      "\n",
      "in word   0.0018726591760299626\n",
      "\n",
      "Information retrieval   0.2\n",
      "\n",
      ", Google   0.0005614823133071309\n",
      "\n",
      "allow a   0.2\n",
      "\n",
      "text ;   0.006289308176100629\n",
      "\n",
      "hand-crafted knowledge   0.5\n",
      "\n",
      "or using   0.009009009009009009\n",
      "\n",
      "tagging work   0.04\n",
      "\n",
      "approaches based   0.03571428571428571\n",
      "\n",
      "those which   0.045454545454545456\n",
      "\n",
      "beginning to   0.5\n",
      "\n",
      "specifically concerned   0.5\n",
      "\n",
      "to accommodate   0.0026560424966799467\n",
      "\n",
      "is critical   0.0020325203252032522\n",
      "\n",
      "and to   0.015895953757225433\n",
      "\n",
      "recognition computer   0.01652892561983471\n",
      "\n",
      "Search to   0.5\n",
      "\n",
      "-- discourse   0.04\n",
      "\n",
      "there would   0.025\n",
      "\n",
      "An example   0.1875\n",
      "\n",
      "input-stream by   1.0\n",
      "\n",
      "found in   0.21428571428571427\n",
      "\n",
      "among other   0.375\n",
      "\n",
      "delimited .   0.25\n",
      "\n",
      "a speech-recognition   0.0036809815950920245\n",
      "\n",
      "of complex   0.00089126559714795\n",
      "\n",
      "systems -RRB-   0.008928571428571428\n",
      "\n",
      "matter how   0.3333333333333333\n",
      "\n",
      "information and   0.021739130434782608\n",
      "\n",
      "while ``   0.05\n",
      "\n",
      "The task   0.020833333333333332\n",
      "\n",
      "systems use   0.05357142857142857\n",
      "\n",
      "speaking computer   0.125\n",
      "\n",
      "paper explored   0.09090909090909091\n",
      "\n",
      "The problems   0.005208333333333333\n",
      "\n",
      "Although Harris   0.125\n",
      "\n",
      "previous questions   0.3333333333333333\n",
      "\n",
      "original training   0.07692307692307693\n",
      "\n",
      "controlled by   1.0\n",
      "\n",
      "a class   0.001226993865030675\n",
      "\n",
      "rarely the   0.3333333333333333\n",
      "\n",
      "the ability   0.001384083044982699\n",
      "\n",
      "suggest a   0.3333333333333333\n",
      "\n",
      "is entirely   0.0020325203252032522\n",
      "\n",
      "and characterizes   0.001445086705202312\n",
      "\n",
      "tasks -LRB-   0.03125\n",
      "\n",
      "segments at   0.2\n",
      "\n",
      "combination of   0.2\n",
      "\n",
      "temporal dependencies   0.5\n",
      "\n",
      "stochastic taggers   0.125\n",
      "\n",
      "very preliminary   0.024390243902439025\n",
      "\n",
      "term for   0.16666666666666666\n",
      "\n",
      "pronouns and   0.5\n",
      "\n",
      "from natural   0.009615384615384616\n",
      "\n",
      "recursively defines   0.5\n",
      "\n",
      "wear a   1.0\n",
      "\n",
      "organization -RRB-   0.2\n",
      "\n",
      "mission to   1.0\n",
      "\n",
      "translates to   1.0\n",
      "\n",
      "BASEBALL answered   0.5\n",
      "\n",
      "More advanced   0.1111111111111111\n",
      "\n",
      "or quantities   0.0045045045045045045\n",
      "\n",
      "answering a   0.08333333333333333\n",
      "\n",
      "Schank ,   0.2\n",
      "\n",
      "metrics :   0.1111111111111111\n",
      "\n",
      "emotional effect   0.25\n",
      "\n",
      "for singular   0.007220216606498195\n",
      "\n",
      ", sales   0.0005614823133071309\n",
      "\n",
      "humans deemed   0.08333333333333333\n",
      "\n",
      "occurs in   1.0\n",
      "\n",
      "Voice Translator   0.2\n",
      "\n",
      "critics claim   1.0\n",
      "\n",
      "termed coarticulation   0.25\n",
      "\n",
      "-LRB- corpus   0.0027100271002710027\n",
      "\n",
      "embedded lists   0.25\n",
      "\n",
      "<s> SHRDLU   0.0015372790161414297\n",
      "\n",
      "-RRB- \\/   0.0027100271002710027\n",
      "\n",
      ", with   0.004491858506457047\n",
      "\n",
      "algorithm exploits   0.03571428571428571\n",
      "\n",
      "<s> Among   0.0007686395080707148\n",
      "\n",
      "of theories   0.00089126559714795\n",
      "\n",
      "and non-linear   0.001445086705202312\n",
      "\n",
      "designers ,   1.0\n",
      "\n",
      "level is   0.05\n",
      "\n",
      "technology useful   0.045454545454545456\n",
      "\n",
      "system by   0.010752688172043012\n",
      "\n",
      "as simply   0.003484320557491289\n",
      "\n",
      "possible transcriptions   0.08333333333333333\n",
      "\n",
      "were performed   0.024390243902439025\n",
      "\n",
      "including the   0.07142857142857142\n",
      "\n",
      "categories ,   0.1111111111111111\n",
      "\n",
      "Unfortunately ,   1.0\n",
      "\n",
      "tuned weights   1.0\n",
      "\n",
      "analytics to   1.0\n",
      "\n",
      "Even though   1.0\n",
      "\n",
      "32 -RRB-   1.0\n",
      "\n",
      ": ``   0.0196078431372549\n",
      "\n",
      "values correlate   0.125\n",
      "\n",
      "assume no   0.5\n",
      "\n",
      "Scope and   1.0\n",
      "\n",
      "as of   0.006968641114982578\n",
      "\n",
      "transformations to   0.5\n",
      "\n",
      "resorting to   1.0\n",
      "\n",
      "lunar science   1.0\n",
      "\n",
      "to benefit   0.0013280212483399733\n",
      "\n",
      "and alignment   0.001445086705202312\n",
      "\n",
      "open problem   0.25\n",
      "\n",
      "and LUNAR   0.001445086705202312\n",
      "\n",
      "NER -RRB-   1.0\n",
      "\n",
      "different vendors   0.02040816326530612\n",
      "\n",
      "is transformed   0.0020325203252032522\n",
      "\n",
      "part-of-speech possibilities   0.06666666666666667\n",
      "\n",
      "<s> Perhaps   0.0007686395080707148\n",
      "\n",
      "identify .   0.08333333333333333\n",
      "\n",
      "for most   0.007220216606498195\n",
      "\n",
      "computer applications   0.022727272727272728\n",
      "\n",
      "Oil Company   1.0\n",
      "\n",
      "Beatrice Santorini   1.0\n",
      "\n",
      "OCR vendors   0.02040816326530612\n",
      "\n",
      "modeling salience   0.14285714285714285\n",
      "\n",
      "target value   0.09090909090909091\n",
      "\n",
      "'s specific   0.0196078431372549\n",
      "\n",
      "edition published   1.0\n",
      "\n",
      "learning ,   0.09302325581395349\n",
      "\n",
      "term first   0.05555555555555555\n",
      "\n",
      "units as   0.14285714285714285\n",
      "\n",
      "computer that   0.022727272727272728\n",
      "\n",
      "positive ,   0.14285714285714285\n",
      "\n",
      "Marilyn Monroe   1.0\n",
      "\n",
      "main underlying   0.125\n",
      "\n",
      "some rules   0.012048192771084338\n",
      "\n",
      "discourse -LRB-   0.05555555555555555\n",
      "\n",
      "answer .   0.23333333333333334\n",
      "\n",
      "represent only   0.1111111111111111\n",
      "\n",
      "<s> Summarization   0.0015372790161414297\n",
      "\n",
      "-RRB- had   0.0027100271002710027\n",
      "\n",
      "David R.   0.25\n",
      "\n",
      "approaches designed   0.03571428571428571\n",
      "\n",
      "Most modern   0.5\n",
      "\n",
      "least partly   0.2\n",
      "\n",
      "about how   0.025\n",
      "\n",
      "processing tasks   0.018518518518518517\n",
      "\n",
      "<s> Speaker   0.0015372790161414297\n",
      "\n",
      "-RRB- of   0.018970189701897018\n",
      "\n",
      "rule-based and   0.14285714285714285\n",
      "\n",
      "not appear   0.008928571428571428\n",
      "\n",
      "training are   0.07142857142857142\n",
      "\n",
      "community ,   1.0\n",
      "\n",
      "should be   0.47368421052631576\n",
      "\n",
      "CCD flatbed   1.0\n",
      "\n",
      "template slot   0.25\n",
      "\n",
      "Among these   1.0\n",
      "\n",
      "workshops dedicated   0.5\n",
      "\n",
      "author wishes   0.3333333333333333\n",
      "\n",
      "objects of   0.2\n",
      "\n",
      "fueled interest   1.0\n",
      "\n",
      "Romance languages   1.0\n",
      "\n",
      "an extractive   0.007575757575757576\n",
      "\n",
      "we normally   0.022222222222222223\n",
      "\n",
      "a positive   0.001226993865030675\n",
      "\n",
      "formed by   0.2\n",
      "\n",
      "is intended   0.0040650406504065045\n",
      "\n",
      "during verbalization   0.1\n",
      "\n",
      "proliferation of   1.0\n",
      "\n",
      "<s> Again   0.0007686395080707148\n",
      "\n",
      "blend into   0.3333333333333333\n",
      "\n",
      "sophisticated algorithms   0.2857142857142857\n",
      "\n",
      "semantic or   0.047619047619047616\n",
      "\n",
      ", partially   0.0005614823133071309\n",
      "\n",
      "program that   0.09090909090909091\n",
      "\n",
      "con sentiment   1.0\n",
      "\n",
      "classifying its   0.2\n",
      "\n",
      "filling may   1.0\n",
      "\n",
      "measure summary   0.09090909090909091\n",
      "\n",
      "one according   0.015384615384615385\n",
      "\n",
      "card number   0.25\n",
      "\n",
      "amenable to   1.0\n",
      "\n",
      "when discussing   0.05714285714285714\n",
      "\n",
      "with isolated   0.00546448087431694\n",
      "\n",
      "analysts not   0.5\n",
      "\n",
      "paper skew   0.09090909090909091\n",
      "\n",
      "It thus   0.02631578947368421\n",
      "\n",
      "` hit   0.0625\n",
      "\n",
      "; Speech   0.02127659574468085\n",
      "\n",
      "complex cognitive   0.041666666666666664\n",
      "\n",
      "RCA engineers   0.2\n",
      "\n",
      "these words   0.047619047619047616\n",
      "\n",
      "statistical natural   0.030303030303030304\n",
      "\n",
      "with matching   0.00546448087431694\n",
      "\n",
      "involve grammar   0.16666666666666666\n",
      "\n",
      "satisfactory in   1.0\n",
      "\n",
      "and dictionary-based   0.001445086705202312\n",
      "\n",
      "might appear   0.038461538461538464\n",
      "\n",
      "recognition using   0.008264462809917356\n",
      "\n",
      "knowledge that   0.037037037037037035\n",
      "\n",
      "uses a   0.2857142857142857\n",
      "\n",
      "evaluate summaries   0.25\n",
      "\n",
      "distinctions -LRB-   0.5\n",
      "\n",
      ": This   0.0392156862745098\n",
      "\n",
      "structured speech   0.16666666666666666\n",
      "\n",
      "however empirical   0.07692307692307693\n",
      "\n",
      "domains where   0.125\n",
      "\n",
      "to high   0.00398406374501992\n",
      "\n",
      "an example   0.03787878787878788\n",
      "\n",
      "splitting may   0.5\n",
      "\n",
      "-LRB- intonation   0.0027100271002710027\n",
      "\n",
      "and entered   0.001445086705202312\n",
      "\n",
      "systems based   0.017857142857142856\n",
      "\n",
      "it conducted   0.008547008547008548\n",
      "\n",
      "later licensed   0.1\n",
      "\n",
      "G. ,   0.5\n",
      "\n",
      "printer using   1.0\n",
      "\n",
      "published in   0.14285714285714285\n",
      "\n",
      "applying PageRank   0.5\n",
      "\n",
      "flood-control pumps   1.0\n",
      "\n",
      "people .   0.125\n",
      "\n",
      "intended meaning   0.2\n",
      "\n",
      "nearly anything   0.5\n",
      "\n",
      "on speaker   0.0047169811320754715\n",
      "\n",
      "-LRB- Kittredge   0.0027100271002710027\n",
      "\n",
      "topic of   0.125\n",
      "\n",
      "general concepts   0.045454545454545456\n",
      "\n",
      "the neural-network   0.0006920415224913495\n",
      "\n",
      "measure ,   0.09090909090909091\n",
      "\n",
      "For some   0.01639344262295082\n",
      "\n",
      "as many   0.006968641114982578\n",
      "\n",
      "capitalizes all   1.0\n",
      "\n",
      "basic elements   0.07692307692307693\n",
      "\n",
      "another language   0.23076923076923078\n",
      "\n",
      "can get   0.0055248618784530384\n",
      "\n",
      "with a   0.1092896174863388\n",
      "\n",
      "another ,   0.07692307692307693\n",
      "\n",
      "content overlap   0.16666666666666666\n",
      "\n",
      "larger corpora   0.0625\n",
      "\n",
      "of distinctions   0.00089126559714795\n",
      "\n",
      "`` defective   0.005291005291005291\n",
      "\n",
      "split ,   0.25\n",
      "\n",
      "Accuracy of   0.42857142857142855\n",
      "\n",
      "are pre-marked   0.004149377593360996\n",
      "\n",
      "compared .   0.2857142857142857\n",
      "\n",
      "cross-lingual questions   0.5\n",
      "\n",
      "<s> Other   0.005380476556495004\n",
      "\n",
      "of news   0.0017825311942959\n",
      "\n",
      "+ ,   0.3333333333333333\n",
      "\n",
      ", computer   0.0011229646266142617\n",
      "\n",
      "better translations   0.1111111111111111\n",
      "\n",
      "well it   0.07142857142857142\n",
      "\n",
      "express the   0.4\n",
      "\n",
      "corresponded to   1.0\n",
      "\n",
      "clues are   0.3333333333333333\n",
      "\n",
      "mentioned the   0.16666666666666666\n",
      "\n",
      "document\\/text summarization   0.5\n",
      "\n",
      "or interpreter   0.009009009009009009\n",
      "\n",
      "similar sentences   0.1111111111111111\n",
      "\n",
      "inference within   0.25\n",
      "\n",
      "Naomi Sager   1.0\n",
      "\n",
      "adjacent unigrams   0.16666666666666666\n",
      "\n",
      "possibilities multiply   0.2\n",
      "\n",
      "the intermediary   0.0006920415224913495\n",
      "\n",
      "Nations and   0.5\n",
      "\n",
      "particular NLP   0.07692307692307693\n",
      "\n",
      "first approximation   0.030303030303030304\n",
      "\n",
      ", V   0.0005614823133071309\n",
      "\n",
      "is far   0.0040650406504065045\n",
      "\n",
      ", Maximum   0.0005614823133071309\n",
      "\n",
      "SVOX .   1.0\n",
      "\n",
      "of an   0.011586452762923352\n",
      "\n",
      "programming languages   0.6\n",
      "\n",
      "then appear   0.02857142857142857\n",
      "\n",
      "rule that   0.3333333333333333\n",
      "\n",
      "application ,   0.14285714285714285\n",
      "\n",
      "preferable ,   1.0\n",
      "\n",
      "graph is   0.23076923076923078\n",
      "\n",
      "SCU in   1.0\n",
      "\n",
      "Genre Analysis   1.0\n",
      "\n",
      "to allow   0.00398406374501992\n",
      "\n",
      "rise of   0.5\n",
      "\n",
      "generation .   0.2222222222222222\n",
      "\n",
      "precise set   0.3333333333333333\n",
      "\n",
      "Piron ,   0.3333333333333333\n",
      "\n",
      "they must   0.025\n",
      "\n",
      "have different   0.019230769230769232\n",
      "\n",
      "might include   0.038461538461538464\n",
      "\n",
      "has grown   0.011904761904761904\n",
      "\n",
      "ratings produced   0.1111111111111111\n",
      "\n",
      "generally rely   0.09090909090909091\n",
      "\n",
      "require their   0.045454545454545456\n",
      "\n",
      "Separate words   0.5\n",
      "\n",
      "tasks are   0.125\n",
      "\n",
      "whereas speed   0.3333333333333333\n",
      "\n",
      "-RRB- HMMs   0.0027100271002710027\n",
      "\n",
      "has dried   0.011904761904761904\n",
      "\n",
      "describing a   0.25\n",
      "\n",
      "annual Loebner   0.5\n",
      "\n",
      "If ``   0.1\n",
      "\n",
      "example :   0.024691358024691357\n",
      "\n",
      "first agree   0.030303030303030304\n",
      "\n",
      "in that   0.003745318352059925\n",
      "\n",
      "that looks   0.0035460992907801418\n",
      "\n",
      "most popular   0.05172413793103448\n",
      "\n",
      "noise but   0.125\n",
      "\n",
      "or Spanish   0.0045045045045045045\n",
      "\n",
      "language processing   0.22297297297297297\n",
      "\n",
      "<s> Our   0.0023059185242121443\n",
      "\n",
      "E ,   1.0\n",
      "\n",
      "speech there   0.006578947368421052\n",
      "\n",
      "systems however   0.008928571428571428\n",
      "\n",
      "verb .   0.15384615384615385\n",
      "\n",
      "Statistical natural-language   0.1111111111111111\n",
      "\n",
      "In 1935   0.009523809523809525\n",
      "\n",
      "the speech   0.006920415224913495\n",
      "\n",
      "well .   0.07142857142857142\n",
      "\n",
      "main difficulty   0.25\n",
      "\n",
      "levels is   0.045454545454545456\n",
      "\n",
      "top ranking   0.2\n",
      "\n",
      "In terms   0.009523809523809525\n",
      "\n",
      "input such   0.024390243902439025\n",
      "\n",
      "+5 scale   1.0\n",
      "\n",
      "too -RRB-   0.16666666666666666\n",
      "\n",
      "register by   1.0\n",
      "\n",
      "the sentence   0.004152249134948097\n",
      "\n",
      "e.g. ,   0.4642857142857143\n",
      "\n",
      "black holes   1.0\n",
      "\n",
      "two ways   0.034482758620689655\n",
      "\n",
      "This model   0.031746031746031744\n",
      "\n",
      "idioms ,   1.0\n",
      "\n",
      "`` proper   0.005291005291005291\n",
      "\n",
      "map one   0.5\n",
      "\n",
      "good translation   0.07692307692307693\n",
      "\n",
      "greater than   0.3333333333333333\n",
      "\n",
      "the stationary   0.0006920415224913495\n",
      "\n",
      "been more   0.029411764705882353\n",
      "\n",
      "further speaker   0.125\n",
      "\n",
      "its answer   0.02857142857142857\n",
      "\n",
      "linguistics -RRB-   0.1\n",
      "\n",
      "production and   0.3333333333333333\n",
      "\n",
      "that character-by-character   0.0035460992907801418\n",
      "\n",
      "is called   0.012195121951219513\n",
      "\n",
      "metrics like   0.1111111111111111\n",
      "\n",
      "EMR according   0.3333333333333333\n",
      "\n",
      "and expensive   0.002890173410404624\n",
      "\n",
      "basic sound   0.15384615384615385\n",
      "\n",
      "automatic machine   0.043478260869565216\n",
      "\n",
      "segmentation will   0.030303030303030304\n",
      "\n",
      "purposes .   0.5\n",
      "\n",
      "processed ,   0.16666666666666666\n",
      "\n",
      "over a   0.08333333333333333\n",
      "\n",
      "mechanism for   1.0\n",
      "\n",
      "approximated as   1.0\n",
      "\n",
      "where using   0.02857142857142857\n",
      "\n",
      "large amounts   0.043478260869565216\n",
      "\n",
      "recursive-descent parser   1.0\n",
      "\n",
      "for input   0.0036101083032490976\n",
      "\n",
      "`` correct   0.005291005291005291\n",
      "\n",
      "expected answer   0.14285714285714285\n",
      "\n",
      "societal problem   1.0\n",
      "\n",
      "beer ,   1.0\n",
      "\n",
      "and widely   0.001445086705202312\n",
      "\n",
      "-LRB- end   0.0027100271002710027\n",
      "\n",
      "He took   0.125\n",
      "\n",
      "years development   0.09523809523809523\n",
      "\n",
      "both left-most   0.03225806451612903\n",
      "\n",
      "and include   0.002890173410404624\n",
      "\n",
      "Treebank data   0.16666666666666666\n",
      "\n",
      "-LRB- grammatical   0.0027100271002710027\n",
      "\n",
      "unverified or   1.0\n",
      "\n",
      "study of   0.25\n",
      "\n",
      "excellent application   1.0\n",
      "\n",
      "<s> Then   0.003843197540353574\n",
      "\n",
      "formalized in   1.0\n",
      "\n",
      "being developed   0.05555555555555555\n",
      "\n",
      "gracefully with   1.0\n",
      "\n",
      "from all   0.009615384615384616\n",
      "\n",
      "correct -RRB-   0.06666666666666667\n",
      "\n",
      ", Hafiz   0.0005614823133071309\n",
      "\n",
      "Viterbi algorithm   1.0\n",
      "\n",
      "multiple subtasks   0.07692307692307693\n",
      "\n",
      "complex setting   0.041666666666666664\n",
      "\n",
      "tagging is   0.08\n",
      "\n",
      "the sentiment   0.001384083044982699\n",
      "\n",
      "often uses   0.022727272727272728\n",
      "\n",
      ", mainly   0.0005614823133071309\n",
      "\n",
      "a correct   0.00245398773006135\n",
      "\n",
      "commercial products   0.09090909090909091\n",
      "\n",
      "enables several   1.0\n",
      "\n",
      "systems ''   0.008928571428571428\n",
      "\n",
      "Marcus M.   1.0\n",
      "\n",
      "of disparate   0.00089126559714795\n",
      "\n",
      "-LRB- roughly   0.005420054200542005\n",
      "\n",
      "pattern recognition   0.6666666666666666\n",
      "\n",
      "from text   0.019230769230769232\n",
      "\n",
      "Grows :   1.0\n",
      "\n",
      "a method   0.0049079754601227\n",
      "\n",
      "humor -RRB-   1.0\n",
      "\n",
      ", combined   0.0005614823133071309\n",
      "\n",
      "SAM -LRB-   1.0\n",
      "\n",
      "most other   0.017241379310344827\n",
      "\n",
      "The attitude   0.005208333333333333\n",
      "\n",
      "; total   0.02127659574468085\n",
      "\n",
      "automatically as   0.047619047619047616\n",
      "\n",
      "also called   0.043478260869565216\n",
      "\n",
      "by Xuedong   0.005714285714285714\n",
      "\n",
      "gives less   0.5\n",
      "\n",
      "So ,   0.3333333333333333\n",
      "\n",
      "issue .   0.25\n",
      "\n",
      "to another   0.00398406374501992\n",
      "\n",
      "theories in   0.2\n",
      "\n",
      "edge between   0.3333333333333333\n",
      "\n",
      "text printed   0.006289308176100629\n",
      "\n",
      ", culminating   0.0005614823133071309\n",
      "\n",
      "full comprehension   0.2\n",
      "\n",
      "issues were   0.2\n",
      "\n",
      "Michael Dyer   0.25\n",
      "\n",
      "` kick   0.0625\n",
      "\n",
      "run on   0.2\n",
      "\n",
      "nearly perfect   0.5\n",
      "\n",
      "newspaper pages   0.3333333333333333\n",
      "\n",
      "include SpeechTEK   0.037037037037037035\n",
      "\n",
      "Martin ,   0.5\n",
      "\n",
      "of such   0.004456327985739751\n",
      "\n",
      "so-called ROUGE   0.3333333333333333\n",
      "\n",
      "considered for   0.1111111111111111\n",
      "\n",
      "prepared ,   1.0\n",
      "\n",
      "each of   0.1111111111111111\n",
      "\n",
      "<s> Back-End   0.0007686395080707148\n",
      "\n",
      "<s> Features   0.0007686395080707148\n",
      "\n",
      "disambiguation -RRB-   0.2\n",
      "\n",
      "of 19th   0.00089126559714795\n",
      "\n",
      "QA Questions   0.047619047619047616\n",
      "\n",
      "meaning .   0.08695652173913043\n",
      "\n",
      "quality criteria   0.1\n",
      "\n",
      "definition ,   0.4\n",
      "\n",
      "simplest -LRB-   1.0\n",
      "\n",
      "too similar   0.16666666666666666\n",
      "\n",
      "than when   0.022222222222222223\n",
      "\n",
      "language being   0.013513513513513514\n",
      "\n",
      "Oklahoma ,   1.0\n",
      "\n",
      "components can   0.2\n",
      "\n",
      "the proposed   0.001384083044982699\n",
      "\n",
      "groups at   0.2\n",
      "\n",
      "of ambitious   0.00089126559714795\n",
      "\n",
      "as `   0.003484320557491289\n",
      "\n",
      "different output   0.02040816326530612\n",
      "\n",
      "choice of   0.25\n",
      "\n",
      ", could   0.0005614823133071309\n",
      "\n",
      "sense in   0.125\n",
      "\n",
      "Anthology .   1.0\n",
      "\n",
      "many other   0.09615384615384616\n",
      "\n",
      "EVALITA campaign   0.5\n",
      "\n",
      "whether an   0.07692307692307693\n",
      "\n",
      "the conversations   0.0006920415224913495\n",
      "\n",
      "when inter-annotator   0.02857142857142857\n",
      "\n",
      "technology has   0.045454545454545456\n",
      "\n",
      "can tell   0.0055248618784530384\n",
      "\n",
      "actually more   0.3333333333333333\n",
      "\n",
      "models upon   0.038461538461538464\n",
      "\n",
      "'s EndWar   0.0196078431372549\n",
      "\n",
      "search engine   0.09090909090909091\n",
      "\n",
      "and achieved   0.001445086705202312\n",
      "\n",
      "PDF to   1.0\n",
      "\n",
      "automates the   1.0\n",
      "\n",
      "was higher   0.012987012987012988\n",
      "\n",
      "for male-female   0.0036101083032490976\n",
      "\n",
      "a feasibility   0.001226993865030675\n",
      "\n",
      "of 1928   0.00089126559714795\n",
      "\n",
      "learn to   0.07692307692307693\n",
      "\n",
      "of front-end   0.00089126559714795\n",
      "\n",
      "there were   0.075\n",
      "\n",
      "on-line character   0.3333333333333333\n",
      "\n",
      "The loss   0.005208333333333333\n",
      "\n",
      "Mandarin and   1.0\n",
      "\n",
      "all be   0.023255813953488372\n",
      "\n",
      "decisions only   0.1\n",
      "\n",
      "language ''   0.013513513513513514\n",
      "\n",
      "of disambiguation   0.00089126559714795\n",
      "\n",
      "find an   0.15384615384615385\n",
      "\n",
      "98.5 %   1.0\n",
      "\n",
      "-RRB- for   0.005420054200542005\n",
      "\n",
      "probability ,   0.14285714285714285\n",
      "\n",
      "an entity   0.007575757575757576\n",
      "\n",
      "With continuous   0.14285714285714285\n",
      "\n",
      "an instance   0.007575757575757576\n",
      "\n",
      "some detail   0.012048192771084338\n",
      "\n",
      "of Hearing   0.00089126559714795\n",
      "\n",
      "An extractive   0.0625\n",
      "\n",
      "case that   0.058823529411764705\n",
      "\n",
      "or form   0.0045045045045045045\n",
      "\n",
      "or content   0.0045045045045045045\n",
      "\n",
      "made by   0.0625\n",
      "\n",
      "especially if   0.06666666666666667\n",
      "\n",
      "tense of   0.5\n",
      "\n",
      "to performance   0.0013280212483399733\n",
      "\n",
      "in reference   0.003745318352059925\n",
      "\n",
      "networks allow   0.07142857142857142\n",
      "\n",
      "of coherent   0.00089126559714795\n",
      "\n",
      "sentences that   0.06578947368421052\n",
      "\n",
      "assess the   0.3333333333333333\n",
      "\n",
      "Inuit virtually   1.0\n",
      "\n",
      "vocabularies ,   1.0\n",
      "\n",
      "parser often   0.0625\n",
      "\n",
      "Keyphrase extractors   0.25\n",
      "\n",
      "large-vocabulary system   0.3333333333333333\n",
      "\n",
      "to converse   0.0013280212483399733\n",
      "\n",
      "large-vocabulary speech   0.6666666666666666\n",
      "\n",
      "computer database   0.022727272727272728\n",
      "\n",
      "AVRADA tests   0.5\n",
      "\n",
      "expectancy of   1.0\n",
      "\n",
      "this constraint   0.01098901098901099\n",
      "\n",
      "mentions within   0.3333333333333333\n",
      "\n",
      ", at   0.0016844469399213925\n",
      "\n",
      "research had   0.047619047619047616\n",
      "\n",
      "be difficult   0.004219409282700422\n",
      "\n",
      "well ,   0.03571428571428571\n",
      "\n",
      "spoken sentences   0.07142857142857142\n",
      "\n",
      "on either   0.0047169811320754715\n",
      "\n",
      "NYU ,   1.0\n",
      "\n",
      "rates .   0.125\n",
      "\n",
      "FAS -RRB-   1.0\n",
      "\n",
      ", factors   0.0005614823133071309\n",
      "\n",
      "recognition As   0.008264462809917356\n",
      "\n",
      "of 1,000   0.00089126559714795\n",
      "\n",
      "Discursive psychology   1.0\n",
      "\n",
      "between `   0.02564102564102564\n",
      "\n",
      "In all   0.009523809523809525\n",
      "\n",
      "Another important   0.07692307692307693\n",
      "\n",
      "years to   0.047619047619047616\n",
      "\n",
      "process correctly   0.027777777777777776\n",
      "\n",
      "factor .   0.5\n",
      "\n",
      "combination with   0.4\n",
      "\n",
      "risk -LRB-   0.5\n",
      "\n",
      "second edition   0.1\n",
      "\n",
      "first-order logic   1.0\n",
      "\n",
      "were ambiguous   0.024390243902439025\n",
      "\n",
      "initially clear   1.0\n",
      "\n",
      "source materials   0.041666666666666664\n",
      "\n",
      "Walter Kintsch   1.0\n",
      "\n",
      "plural noun   0.4\n",
      "\n",
      "mutual information   1.0\n",
      "\n",
      "bottom-up parsers   1.0\n",
      "\n",
      "a smaller   0.001226993865030675\n",
      "\n",
      "the label   0.0006920415224913495\n",
      "\n",
      "these devices   0.023809523809523808\n",
      "\n",
      "1976 -RRB-   0.5\n",
      "\n",
      "With sufficient   0.14285714285714285\n",
      "\n",
      "hand-printed text   0.5\n",
      "\n",
      "moderate should   0.2\n",
      "\n",
      "measured by   0.5\n",
      "\n",
      "be semantic   0.004219409282700422\n",
      "\n",
      "of text   0.0213903743315508\n",
      "\n",
      "disambiguate the   0.3333333333333333\n",
      "\n",
      "adequately solved   1.0\n",
      "\n",
      "The translator   0.005208333333333333\n",
      "\n",
      "at each   0.014705882352941176\n",
      "\n",
      "can start   0.0055248618784530384\n",
      "\n",
      "techniques for   0.08695652173913043\n",
      "\n",
      "this procedure   0.01098901098901099\n",
      "\n",
      "included a   0.125\n",
      "\n",
      "A comprehensive   0.02\n",
      "\n",
      "U.S. Department   0.14285714285714285\n",
      "\n",
      "`` He   0.005291005291005291\n",
      "\n",
      "common-sense reasoning   1.0\n",
      "\n",
      "to analyzing   0.0013280212483399733\n",
      "\n",
      "or phonemes   0.009009009009009009\n",
      "\n",
      "written for   0.038461538461538464\n",
      "\n",
      "possible analyses   0.08333333333333333\n",
      "\n",
      "up pronouns   0.045454545454545456\n",
      "\n",
      "can often   0.0055248618784530384\n",
      "\n",
      "is better   0.0020325203252032522\n",
      "\n",
      ", Judith   0.0005614823133071309\n",
      "\n",
      "their translation   0.029411764705882353\n",
      "\n",
      "the nature   0.0034602076124567475\n",
      "\n",
      "and experience   0.001445086705202312\n",
      "\n",
      "scale rather   0.16666666666666666\n",
      "\n",
      ", syllables   0.0005614823133071309\n",
      "\n",
      "70 's   0.25\n",
      "\n",
      "non-textual components   1.0\n",
      "\n",
      "warped ''   1.0\n",
      "\n",
      "good summary   0.15384615384615385\n",
      "\n",
      "word forms   0.016666666666666666\n",
      "\n",
      "FAA document   0.5\n",
      "\n",
      "not also   0.008928571428571428\n",
      "\n",
      "<s> Training   0.0007686395080707148\n",
      "\n",
      "to is   0.0013280212483399733\n",
      "\n",
      "Digest ,   0.3333333333333333\n",
      "\n",
      "Record or   1.0\n",
      "\n",
      "both the   0.06451612903225806\n",
      "\n",
      "An automated   0.0625\n",
      "\n",
      "that connects   0.0035460992907801418\n",
      "\n",
      "different from   0.12244897959183673\n",
      "\n",
      "this data   0.01098901098901099\n",
      "\n",
      "candidate passages   0.3333333333333333\n",
      "\n",
      "Goodwin ,   1.0\n",
      "\n",
      "that appear   0.014184397163120567\n",
      "\n",
      "of running   0.00089126559714795\n",
      "\n",
      "At this   0.3333333333333333\n",
      "\n",
      "World War   0.14285714285714285\n",
      "\n",
      "the University   0.0006920415224913495\n",
      "\n",
      "message boards   0.5\n",
      "\n",
      "translators and   1.0\n",
      "\n",
      "training documents   0.10714285714285714\n",
      "\n",
      "risk of   0.5\n",
      "\n",
      "of how   0.00089126559714795\n",
      "\n",
      "major corpus   0.08333333333333333\n",
      "\n",
      "unseen data   1.0\n",
      "\n",
      "for reading   0.007220216606498195\n",
      "\n",
      "<s> Note   0.006917755572636433\n",
      "\n",
      "went on   0.2\n",
      "\n",
      "interlingual ,   0.25\n",
      "\n",
      "of scholars   0.00089126559714795\n",
      "\n",
      "optical character   1.0\n",
      "\n",
      "Japanese .   0.125\n",
      "\n",
      "or produce   0.0045045045045045045\n",
      "\n",
      "of stock   0.00089126559714795\n",
      "\n",
      "tried ,   0.3333333333333333\n",
      "\n",
      "modern approaches   0.2\n",
      "\n",
      "measure for   0.09090909090909091\n",
      "\n",
      "parsing In   0.03571428571428571\n",
      "\n",
      "on their   0.009433962264150943\n",
      "\n",
      "Michael Halliday   0.25\n",
      "\n",
      "surrounding words   0.4\n",
      "\n",
      "closest the   0.5\n",
      "\n",
      "the suffix   0.0006920415224913495\n",
      "\n",
      "the delta   0.0006920415224913495\n",
      "\n",
      "most common   0.10344827586206896\n",
      "\n",
      "fully articulated   0.16666666666666666\n",
      "\n",
      "error -LRB-   0.16666666666666666\n",
      "\n",
      "indeed answer   0.3333333333333333\n",
      "\n",
      "something similar   1.0\n",
      "\n",
      "impressive .   0.5\n",
      "\n",
      "more corpus   0.010526315789473684\n",
      "\n",
      "incomplete sentences   1.0\n",
      "\n",
      ", candidacies   0.0005614823133071309\n",
      "\n",
      "at MIT   0.029411764705882353\n",
      "\n",
      "working in   0.2857142857142857\n",
      "\n",
      "1 -RRB-   0.25\n",
      "\n",
      "<s> Adverse   0.0007686395080707148\n",
      "\n",
      "sentiment words   0.04\n",
      "\n",
      "simple as   0.07692307692307693\n",
      "\n",
      ": e.g.   0.0196078431372549\n",
      "\n",
      "In 1965   0.009523809523809525\n",
      "\n",
      "calculates n-gram   1.0\n",
      "\n",
      "postal code   1.0\n",
      "\n",
      "Section ,   1.0\n",
      "\n",
      "ones already   0.1\n",
      "\n",
      "networks .   0.21428571428571427\n",
      "\n",
      "be applied   0.012658227848101266\n",
      "\n",
      "from advertisements   0.009615384615384616\n",
      "\n",
      "will tend   0.02857142857142857\n",
      "\n",
      "remarkably similar   1.0\n",
      "\n",
      "more words   0.010526315789473684\n",
      "\n",
      "as articles   0.003484320557491289\n",
      "\n",
      "or speech   0.0045045045045045045\n",
      "\n",
      "19th -   1.0\n",
      "\n",
      "language with   0.006756756756756757\n",
      "\n",
      "rules :   0.046511627906976744\n",
      "\n",
      "on linguistic   0.0047169811320754715\n",
      "\n",
      "for avoiding   0.0036101083032490976\n",
      "\n",
      "instead for   0.14285714285714285\n",
      "\n",
      ", reading   0.0005614823133071309\n",
      "\n",
      ", preparation   0.0005614823133071309\n",
      "\n",
      "speech the   0.006578947368421052\n",
      "\n",
      "<s> Speech   0.011529592621060722\n",
      "\n",
      "categorical .   1.0\n",
      "\n",
      "computer program   0.11363636363636363\n",
      "\n",
      "MLLR -RRB-   1.0\n",
      "\n",
      "around 6   0.375\n",
      "\n",
      "Another approach   0.15384615384615385\n",
      "\n",
      "matching and   0.2\n",
      "\n",
      "very limited   0.04878048780487805\n",
      "\n",
      "interest ,   0.09090909090909091\n",
      "\n",
      "not an   0.008928571428571428\n",
      "\n",
      "-LRB- DOE   0.0027100271002710027\n",
      "\n",
      "affine and   1.0\n",
      "\n",
      "from multimedia   0.009615384615384616\n",
      "\n",
      "problem .   0.22727272727272727\n",
      "\n",
      "program in   0.09090909090909091\n",
      "\n",
      "and LexRank   0.004335260115606936\n",
      "\n",
      "overall contextual   0.16666666666666666\n",
      "\n",
      "fonts are   0.3333333333333333\n",
      "\n",
      "trained automatically   0.3333333333333333\n",
      "\n",
      "linear discriminant   0.2857142857142857\n",
      "\n",
      "one symbol   0.015384615384615385\n",
      "\n",
      "problem than   0.022727272727272728\n",
      "\n",
      "thresholded to   1.0\n",
      "\n",
      "training ''   0.03571428571428571\n",
      "\n",
      "to this   0.00796812749003984\n",
      "\n",
      "summarizing multiple   1.0\n",
      "\n",
      "rates greatly   0.125\n",
      "\n",
      "with weights   0.00546448087431694\n",
      "\n",
      "by Frederick   0.005714285714285714\n",
      "\n",
      "or generators   0.0045045045045045045\n",
      "\n",
      "phrases ,   0.125\n",
      "\n",
      "established within   1.0\n",
      "\n",
      "by humans   0.011428571428571429\n",
      "\n",
      "is as   0.0020325203252032522\n",
      "\n",
      "to rank   0.00398406374501992\n",
      "\n",
      "and Italian   0.001445086705202312\n",
      "\n",
      "or just   0.0045045045045045045\n",
      "\n",
      "expensive since   0.14285714285714285\n",
      "\n",
      "dissertation at   0.3333333333333333\n",
      "\n",
      "captioned telephone   1.0\n",
      "\n",
      "require in   0.045454545454545456\n",
      "\n",
      ": statistical   0.00980392156862745\n",
      "\n",
      "constituents ,   0.5\n",
      "\n",
      ", on-line   0.0005614823133071309\n",
      "\n",
      "a purely   0.001226993865030675\n",
      "\n",
      "controllers .   0.3333333333333333\n",
      "\n",
      "author when   0.3333333333333333\n",
      "\n",
      "floods ''   1.0\n",
      "\n",
      "A word   0.02\n",
      "\n",
      "vs. preposition   0.08333333333333333\n",
      "\n",
      "where semantics   0.02857142857142857\n",
      "\n",
      "and LILOG   0.001445086705202312\n",
      "\n",
      "`` un-supervised   0.005291005291005291\n",
      "\n",
      "splicing and   1.0\n",
      "\n",
      "collections of   0.25\n",
      "\n",
      "to decoding   0.0013280212483399733\n",
      "\n",
      "speech single   0.006578947368421052\n",
      "\n",
      "and usefulness   0.001445086705202312\n",
      "\n",
      "the parts   0.0006920415224913495\n",
      "\n",
      "For more   0.03278688524590164\n",
      "\n",
      "speaking ,   0.625\n",
      "\n",
      "marked for   0.6666666666666666\n",
      "\n",
      "relevant to   0.14285714285714285\n",
      "\n",
      "cut and   1.0\n",
      "\n",
      "Technology -LRB-   0.3333333333333333\n",
      "\n",
      "representation can   0.05263157894736842\n",
      "\n",
      "to set   0.00398406374501992\n",
      "\n",
      "domain-specific knowledge   0.5\n",
      "\n",
      "in 1966   0.0018726591760299626\n",
      "\n",
      "data needed   0.012987012987012988\n",
      "\n",
      "in question   0.003745318352059925\n",
      "\n",
      "question-answering engines   0.5\n",
      "\n",
      "combinations of   1.0\n",
      "\n",
      "access to   1.0\n",
      "\n",
      ", rather   0.0011229646266142617\n",
      "\n",
      "to much   0.0013280212483399733\n",
      "\n",
      "the Information   0.0006920415224913495\n",
      "\n",
      "at phrasing   0.014705882352941176\n",
      "\n",
      "be thresholded   0.004219409282700422\n",
      "\n",
      "or more   0.018018018018018018\n",
      "\n",
      "late Claude   0.1111111111111111\n",
      "\n",
      "comprehension of   0.2857142857142857\n",
      "\n",
      "speech a   0.006578947368421052\n",
      "\n",
      "the speakers   0.0006920415224913495\n",
      "\n",
      "has more   0.011904761904761904\n",
      "\n",
      ", US   0.0011229646266142617\n",
      "\n",
      "in automatic   0.003745318352059925\n",
      "\n",
      "sublanguage domains   0.3333333333333333\n",
      "\n",
      "ranks ,   0.5\n",
      "\n",
      "-LRB- An   0.005420054200542005\n",
      "\n",
      "achieved translating   0.1\n",
      "\n",
      "concatenating the   1.0\n",
      "\n",
      "also referred   0.014492753623188406\n",
      "\n",
      ", who   0.0005614823133071309\n",
      "\n",
      "are words   0.004149377593360996\n",
      "\n",
      "page including   0.14285714285714285\n",
      "\n",
      "which was   0.036231884057971016\n",
      "\n",
      "any topic   0.06451612903225806\n",
      "\n",
      "assume there   0.5\n",
      "\n",
      "the adjacent   0.0006920415224913495\n",
      "\n",
      "It is   0.6052631578947368\n",
      "\n",
      "and interactive   0.001445086705202312\n",
      "\n",
      "lexicon of   0.2222222222222222\n",
      "\n",
      "More sophisticated   0.3333333333333333\n",
      "\n",
      "any font   0.03225806451612903\n",
      "\n",
      "great deal   0.3333333333333333\n",
      "\n",
      "for results   0.0036101083032490976\n",
      "\n",
      "their context   0.029411764705882353\n",
      "\n",
      "correctly-developed summaries   1.0\n",
      "\n",
      "parser for   0.0625\n",
      "\n",
      "LexRank differences   0.08333333333333333\n",
      "\n",
      "Speereo Software   0.5\n",
      "\n",
      "indicate a   0.3333333333333333\n",
      "\n",
      "was dramatically   0.012987012987012988\n",
      "\n",
      "we would   0.06666666666666667\n",
      "\n",
      "to integrate   0.0013280212483399733\n",
      "\n",
      "where only   0.02857142857142857\n",
      "\n",
      "posed by   0.3333333333333333\n",
      "\n",
      "readily reveal   0.3333333333333333\n",
      "\n",
      "makes tagging   0.125\n",
      "\n",
      "Latin very   0.25\n",
      "\n",
      ": By   0.00980392156862745\n",
      "\n",
      "then there   0.02857142857142857\n",
      "\n",
      ", evaluation   0.0005614823133071309\n",
      "\n",
      "speech-enabled Symbian   1.0\n",
      "\n",
      "overlaps to   0.5\n",
      "\n",
      "learn the   0.07692307692307693\n",
      "\n",
      "rules to   0.06976744186046512\n",
      "\n",
      "The rule-based   0.005208333333333333\n",
      "\n",
      "He tried   0.125\n",
      "\n",
      "primarily by   0.5\n",
      "\n",
      "own sentence   0.16666666666666666\n",
      "\n",
      "translating speech   0.25\n",
      "\n",
      "June 1990   1.0\n",
      "\n",
      "to define   0.0026560424966799467\n",
      "\n",
      "segmentation ,   0.09090909090909091\n",
      "\n",
      "A very   0.02\n",
      "\n",
      "in abstractive   0.0018726591760299626\n",
      "\n",
      "between an   0.02564102564102564\n",
      "\n",
      "advanced -LRB-   0.2\n",
      "\n",
      "Constraints are   0.3333333333333333\n",
      "\n",
      "on bilingual   0.0047169811320754715\n",
      "\n",
      "evaluation workshops   0.018518518518518517\n",
      "\n",
      "far northeast   0.25\n",
      "\n",
      "in English   0.009363295880149813\n",
      "\n",
      "software technology   0.037037037037037035\n",
      "\n",
      "at emotional   0.014705882352941176\n",
      "\n",
      "making decisions   0.14285714285714285\n",
      "\n",
      "a heuristic   0.00245398773006135\n",
      "\n",
      ", Air   0.0005614823133071309\n",
      "\n",
      "million word   0.3333333333333333\n",
      "\n",
      "oral talk-in-interaction   1.0\n",
      "\n",
      "two measures   0.034482758620689655\n",
      "\n",
      "who applied   0.1\n",
      "\n",
      "depth understanding   0.3333333333333333\n",
      "\n",
      "a professional   0.001226993865030675\n",
      "\n",
      "reporting -LRB-   0.3333333333333333\n",
      "\n",
      "a given   0.014723926380368098\n",
      "\n",
      "developed .   0.07692307692307693\n",
      "\n",
      "text normally   0.006289308176100629\n",
      "\n",
      "-LRB- F-16   0.0027100271002710027\n",
      "\n",
      "techniques in   0.043478260869565216\n",
      "\n",
      "and frequency   0.001445086705202312\n",
      "\n",
      "semantics is   0.07142857142857142\n",
      "\n",
      "the N-best   0.0006920415224913495\n",
      "\n",
      "if we   0.07142857142857142\n",
      "\n",
      ", styles   0.0005614823133071309\n",
      "\n",
      "such corpora   0.016260162601626018\n",
      "\n",
      "recognizer ,   1.0\n",
      "\n",
      "the reduction   0.0006920415224913495\n",
      "\n",
      "evaluations are   0.3333333333333333\n",
      "\n",
      "statistical ;   0.030303030303030304\n",
      "\n",
      "; a   0.02127659574468085\n",
      "\n",
      "limited vocabulary   0.1\n",
      "\n",
      "According to   1.0\n",
      "\n",
      "degradation in   1.0\n",
      "\n",
      "graph specially   0.07692307692307693\n",
      "\n",
      "findings were   1.0\n",
      "\n",
      "relations are   0.08333333333333333\n",
      "\n",
      "or cross-lingual   0.0045045045045045045\n",
      "\n",
      "Carnegie Mellon   1.0\n",
      "\n",
      "of Quechua   0.00089126559714795\n",
      "\n",
      "the phonemes   0.001384083044982699\n",
      "\n",
      "natural language   0.76\n",
      "\n",
      "rate still   0.09090909090909091\n",
      "\n",
      "SHRDLU could   0.16666666666666666\n",
      "\n",
      "it that   0.008547008547008548\n",
      "\n",
      "perhaps because   0.16666666666666666\n",
      "\n",
      "necessarily match   0.5\n",
      "\n",
      "by Manfred   0.005714285714285714\n",
      "\n",
      "its speakers   0.02857142857142857\n",
      "\n",
      "chosen domains   0.2\n",
      "\n",
      "where an   0.02857142857142857\n",
      "\n",
      "Kittredge ,   0.5\n",
      "\n",
      "deploy machine   1.0\n",
      "\n",
      "upper-case letter   1.0\n",
      "\n",
      "apple is   0.6666666666666666\n",
      "\n",
      "referenced .   1.0\n",
      "\n",
      "cosine values   0.3333333333333333\n",
      "\n",
      "be maintained   0.004219409282700422\n",
      "\n",
      "word at   0.016666666666666666\n",
      "\n",
      "unweighted edges   1.0\n",
      "\n",
      "the BORIS   0.0006920415224913495\n",
      "\n",
      "in information   0.0018726591760299626\n",
      "\n",
      "human judgments   0.021739130434782608\n",
      "\n",
      "assigned ,   0.5\n",
      "\n",
      "larger context   0.0625\n",
      "\n",
      "uses continuous   0.07142857142857142\n",
      "\n",
      "the record   0.0006920415224913495\n",
      "\n",
      "derived from   0.5\n",
      "\n",
      "stochastic semantic   0.125\n",
      "\n",
      "have direct   0.009615384615384616\n",
      "\n",
      "<s> Acoustical   0.0007686395080707148\n",
      "\n",
      "hypothetical ,   1.0\n",
      "\n",
      "Information -LRB-   0.2\n",
      "\n",
      "most difficult   0.017241379310344827\n",
      "\n",
      "output .   0.15384615384615385\n",
      "\n",
      "the robot   0.0006920415224913495\n",
      "\n",
      "protect New   1.0\n",
      "\n",
      "processes of   0.2\n",
      "\n",
      "software was   0.037037037037037035\n",
      "\n",
      "specific objects   0.047619047619047616\n",
      "\n",
      "The same   0.010416666666666666\n",
      "\n",
      "standard corpora   0.07142857142857142\n",
      "\n",
      "perhaps by   0.16666666666666666\n",
      "\n",
      "copying important   1.0\n",
      "\n",
      "keyphrases available   0.02857142857142857\n",
      "\n",
      "lies a   0.5\n",
      "\n",
      "Type =   1.0\n",
      "\n",
      "Carla Willig   1.0\n",
      "\n",
      "<s> Part-of-speech   0.0007686395080707148\n",
      "\n",
      "widely applied   0.125\n",
      "\n",
      "symbols ,   0.3333333333333333\n",
      "\n",
      "A.C. Nielsen   1.0\n",
      "\n",
      "English alphabet   0.05405405405405406\n",
      "\n",
      ", minimum   0.0005614823133071309\n",
      "\n",
      "dialog that   0.5\n",
      "\n",
      "texts to   0.11764705882352941\n",
      "\n",
      "<s> Semantic   0.0007686395080707148\n",
      "\n",
      "in 2007   0.0018726591760299626\n",
      "\n",
      "takes the   0.3333333333333333\n",
      "\n",
      "examples Performance   0.041666666666666664\n",
      "\n",
      "still contains   0.06666666666666667\n",
      "\n",
      "Translation process   0.6666666666666666\n",
      "\n",
      "Examples are   0.6666666666666666\n",
      "\n",
      "test as   0.1\n",
      "\n",
      "search for   0.09090909090909091\n",
      "\n",
      "time series   0.030303030303030304\n",
      "\n",
      "Language Workshop   0.08333333333333333\n",
      "\n",
      "more basic   0.021052631578947368\n",
      "\n",
      "popular media   0.1111111111111111\n",
      "\n",
      "single verbal   0.07142857142857142\n",
      "\n",
      "turn simplified   0.16666666666666666\n",
      "\n",
      "those meanings   0.045454545454545456\n",
      "\n",
      "diversity during   0.25\n",
      "\n",
      "tests ,   0.25\n",
      "\n",
      "associating a   1.0\n",
      "\n",
      "Xerox ,   0.5\n",
      "\n",
      ", Japanese   0.0011229646266142617\n",
      "\n",
      "very slow   0.024390243902439025\n",
      "\n",
      "turns-at-talk .   1.0\n",
      "\n",
      "-LRB- Sonic   0.0027100271002710027\n",
      "\n",
      "of subjectivity   0.00089126559714795\n",
      "\n",
      "or from   0.0045045045045045045\n",
      "\n",
      "allowing greater   0.3333333333333333\n",
      "\n",
      "and more   0.0072254335260115606\n",
      "\n",
      "applying some   0.25\n",
      "\n",
      "trillion-word corpus   1.0\n",
      "\n",
      "but such   0.014705882352941176\n",
      "\n",
      "process include   0.027777777777777776\n",
      "\n",
      "data available   0.03896103896103896\n",
      "\n",
      ", Shipibo   0.0005614823133071309\n",
      "\n",
      "a gold   0.00245398773006135\n",
      "\n",
      "'s coherence   0.0196078431372549\n",
      "\n",
      "dependency theory   0.2\n",
      "\n",
      "from script   0.009615384615384616\n",
      "\n",
      "that causes   0.0035460992907801418\n",
      "\n",
      "How should   0.14285714285714285\n",
      "\n",
      "Machine translation   0.5555555555555556\n",
      "\n",
      "assertion ,   1.0\n",
      "\n",
      "also obtained   0.014492753623188406\n",
      "\n",
      "The user   0.005208333333333333\n",
      "\n",
      "on it   0.0047169811320754715\n",
      "\n",
      "person reads   0.05263157894736842\n",
      "\n",
      "for errors   0.0036101083032490976\n",
      "\n",
      "making them   0.14285714285714285\n",
      "\n",
      "continuous text   0.16666666666666666\n",
      "\n",
      "models that   0.11538461538461539\n",
      "\n",
      "my hand-compiled   1.0\n",
      "\n",
      "<s> Design   0.0023059185242121443\n",
      "\n",
      "function with   0.125\n",
      "\n",
      "looks for   0.25\n",
      "\n",
      "defines components   0.5\n",
      "\n",
      "quality of   0.5\n",
      "\n",
      "to HMM   0.0013280212483399733\n",
      "\n",
      "defined only   0.16666666666666666\n",
      "\n",
      "machine digitized   0.012658227848101266\n",
      "\n",
      "representations of   0.25\n",
      "\n",
      "mainly with   0.16666666666666666\n",
      "\n",
      "' properties   0.05263157894736842\n",
      "\n",
      "extremely difficult   0.75\n",
      "\n",
      "verbs are   0.2\n",
      "\n",
      "theory Functional   0.07692307692307693\n",
      "\n",
      "common strategy   0.04\n",
      "\n",
      "document -LRB-   0.05555555555555555\n",
      "\n",
      "George Lakoff   1.0\n",
      "\n",
      "continuous similarity   0.16666666666666666\n",
      "\n",
      "specify precisely   1.0\n",
      "\n",
      "the British   0.0006920415224913495\n",
      "\n",
      "The European   0.005208333333333333\n",
      "\n",
      "segment and   0.1111111111111111\n",
      "\n",
      "to determining   0.0013280212483399733\n",
      "\n",
      "that simultaneously   0.0035460992907801418\n",
      "\n",
      "full-text search   1.0\n",
      "\n",
      "mostly as   0.5\n",
      "\n",
      "given NLP   0.041666666666666664\n",
      "\n",
      "Speech-to-text reporter   1.0\n",
      "\n",
      "Our evaluation   0.3333333333333333\n",
      "\n",
      "properly .   0.5\n",
      "\n",
      "function for   0.125\n",
      "\n",
      "be turned   0.004219409282700422\n",
      "\n",
      "`` prestige   0.005291005291005291\n",
      "\n",
      "easier for   0.125\n",
      "\n",
      "into canned   0.01282051282051282\n",
      "\n",
      "hierarchy of   1.0\n",
      "\n",
      "specific task   0.047619047619047616\n",
      "\n",
      "systems sold   0.008928571428571428\n",
      "\n",
      "break hyphenated   0.5\n",
      "\n",
      "artificial neural   0.09090909090909091\n",
      "\n",
      "summary .   0.2619047619047619\n",
      "\n",
      "also that   0.014492753623188406\n",
      "\n",
      "up with   0.13636363636363635\n",
      "\n",
      "and movie   0.001445086705202312\n",
      "\n",
      "the Morpholympics   0.0006920415224913495\n",
      "\n",
      "subject ,   0.25\n",
      "\n",
      "the invention   0.0006920415224913495\n",
      "\n",
      "Video games   1.0\n",
      "\n",
      "sentence-ending markers   1.0\n",
      "\n",
      ", coreference   0.0005614823133071309\n",
      "\n",
      "Research and   0.125\n",
      "\n",
      "or legal   0.0045045045045045045\n",
      "\n",
      "assertive -LRB-   1.0\n",
      "\n",
      "to both   0.00398406374501992\n",
      "\n",
      "improve the   0.07692307692307693\n",
      "\n",
      "a program   0.0049079754601227\n",
      "\n",
      "program .   0.13636363636363635\n",
      "\n",
      "the creation   0.0006920415224913495\n",
      "\n",
      "an Electronic   0.007575757575757576\n",
      "\n",
      "1994 ,   1.0\n",
      "\n",
      "Jelinek and   0.5\n",
      "\n",
      "fall into   0.5\n",
      "\n",
      "considerable success   0.2\n",
      "\n",
      "in pattern   0.0018726591760299626\n",
      "\n",
      "now absorbing   0.07692307692307693\n",
      "\n",
      "implicit assumptions   1.0\n",
      "\n",
      "because of   0.2\n",
      "\n",
      "a database   0.0036809815950920245\n",
      "\n",
      "the Lancaster-Oslo-Bergen   0.0006920415224913495\n",
      "\n",
      "of deciding   0.00089126559714795\n",
      "\n",
      "`` uh   0.005291005291005291\n",
      "\n",
      "A Universal   0.02\n",
      "\n",
      "A promising   0.02\n",
      "\n",
      "function is   0.125\n",
      "\n",
      "view -LRB-   0.3333333333333333\n",
      "\n",
      "was unveiled   0.012987012987012988\n",
      "\n",
      "emigre Leo   1.0\n",
      "\n",
      "purpose when   0.2\n",
      "\n",
      "original text   0.46153846153846156\n",
      "\n",
      "such system   0.008130081300813009\n",
      "\n",
      "thus it   0.1\n",
      "\n",
      "essence of   1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstration in   0.2\n",
      "\n",
      "the jet   0.0006920415224913495\n",
      "\n",
      "before it   0.16666666666666666\n",
      "\n",
      "e.g. The   0.03571428571428571\n",
      "\n",
      "matter .   0.3333333333333333\n",
      "\n",
      "sentences when   0.013157894736842105\n",
      "\n",
      "that answered   0.0035460992907801418\n",
      "\n",
      "as its   0.010452961672473868\n",
      "\n",
      "an Inuit   0.007575757575757576\n",
      "\n",
      "single source   0.14285714285714285\n",
      "\n",
      "In the   0.13333333333333333\n",
      "\n",
      ", decimal   0.0005614823133071309\n",
      "\n",
      "analysis ''   0.015384615384615385\n",
      "\n",
      "Internet and   0.5\n",
      "\n",
      "database available   0.1\n",
      "\n",
      "<s> Shared   0.0007686395080707148\n",
      "\n",
      "What is   0.2727272727272727\n",
      "\n",
      "founder of   1.0\n",
      "\n",
      "visit Iraq   0.5\n",
      "\n",
      "Answer extraction   0.6666666666666666\n",
      "\n",
      "boundaries and   0.09090909090909091\n",
      "\n",
      "and singular   0.001445086705202312\n",
      "\n",
      "and Civil   0.001445086705202312\n",
      "\n",
      "return a   0.5\n",
      "\n",
      "launched the   1.0\n",
      "\n",
      "compared German   0.14285714285714285\n",
      "\n",
      "computer-understandable data   1.0\n",
      "\n",
      ", key   0.0005614823133071309\n",
      "\n",
      "`` can   0.005291005291005291\n",
      "\n",
      "common ones   0.04\n",
      "\n",
      "Japanese and   0.25\n",
      "\n",
      "the objectives   0.0006920415224913495\n",
      "\n",
      "wave in   0.1111111111111111\n",
      "\n",
      "Computationally ,   1.0\n",
      "\n",
      "driving social   1.0\n",
      "\n",
      "compiler due   0.3333333333333333\n",
      "\n",
      "norm .   1.0\n",
      "\n",
      "very hard   0.024390243902439025\n",
      "\n",
      "and efficient   0.002890173410404624\n",
      "\n",
      "realistic grammars   1.0\n",
      "\n",
      "ranks the   0.5\n",
      "\n",
      "neighbors are   0.3333333333333333\n",
      "\n",
      "The results   0.005208333333333333\n",
      "\n",
      "deterministic problem   0.25\n",
      "\n",
      "projects in   0.5\n",
      "\n",
      "based representation   0.018518518518518517\n",
      "\n",
      "test documents   0.2\n",
      "\n",
      "a text-understanding   0.001226993865030675\n",
      "\n",
      "uh ''   1.0\n",
      "\n",
      "the chosen   0.0006920415224913495\n",
      "\n",
      "upload paper   1.0\n",
      "\n",
      "Category =   0.5\n",
      "\n",
      "radio frequencies   1.0\n",
      "\n",
      "look ''   0.2\n",
      "\n",
      "-- only   0.04\n",
      "\n",
      "D. Booth   0.2\n",
      "\n",
      "extent to   0.25\n",
      "\n",
      "can learn   0.0055248618784530384\n",
      "\n",
      "consider the   0.5\n",
      "\n",
      "of HMM-based   0.00089126559714795\n",
      "\n",
      "general with   0.045454545454545456\n",
      "\n",
      "Evaluation exercises   0.1111111111111111\n",
      "\n",
      "mild repetitive   1.0\n",
      "\n",
      "resolve ambiguities   0.5\n",
      "\n",
      "the left   0.001384083044982699\n",
      "\n",
      "Telematics -LRB-   1.0\n",
      "\n",
      "as content   0.003484320557491289\n",
      "\n",
      "significant effort   0.1111111111111111\n",
      "\n",
      "left-most and   0.5\n",
      "\n",
      "early as   0.1\n",
      "\n",
      "it builds   0.008547008547008548\n",
      "\n",
      "one way   0.015384615384615385\n",
      "\n",
      "demonstrated at   1.0\n",
      "\n",
      "word is   0.06666666666666667\n",
      "\n",
      "the ranking   0.001384083044982699\n",
      "\n",
      "by a   0.10285714285714286\n",
      "\n",
      "Battle management   0.5\n",
      "\n",
      ", possessive   0.0005614823133071309\n",
      "\n",
      ", computational   0.0005614823133071309\n",
      "\n",
      "<s> After   0.0023059185242121443\n",
      "\n",
      "removed .   1.0\n",
      "\n",
      "material may   0.5\n",
      "\n",
      "vectors -LRB-   0.3333333333333333\n",
      "\n",
      "contexts in   0.14285714285714285\n",
      "\n",
      "human language   0.06521739130434782\n",
      "\n",
      "future developments   0.3333333333333333\n",
      "\n",
      "Analysis &   0.2\n",
      "\n",
      "of human   0.004456327985739751\n",
      "\n",
      "for his   0.007220216606498195\n",
      "\n",
      "-LRB- actual   0.0027100271002710027\n",
      "\n",
      "one alternative   0.015384615384615385\n",
      "\n",
      "simplify the   1.0\n",
      "\n",
      "OCR or   0.02040816326530612\n",
      "\n",
      "system working   0.010752688172043012\n",
      "\n",
      "anomalies .   1.0\n",
      "\n",
      "are hardly   0.004149377593360996\n",
      "\n",
      "that deals   0.0035460992907801418\n",
      "\n",
      "produce output   0.09090909090909091\n",
      "\n",
      "waves .   0.14285714285714285\n",
      "\n",
      "though ROUGE-1   0.1\n",
      "\n",
      "general purpose   0.09090909090909091\n",
      "\n",
      "recent news   0.125\n",
      "\n",
      ", where   0.008422234699606962\n",
      "\n",
      "arbitrarily long   1.0\n",
      "\n",
      "'ve just   0.5\n",
      "\n",
      "`` understand   0.005291005291005291\n",
      "\n",
      "W. Handel   0.5\n",
      "\n",
      "any human   0.03225806451612903\n",
      "\n",
      "unigrams .   0.16666666666666666\n",
      "\n",
      "1997 -LRB-   0.5\n",
      "\n",
      "PC +   0.25\n",
      "\n",
      "when describing   0.05714285714285714\n",
      "\n",
      "I would   1.0\n",
      "\n",
      "in accordance   0.0018726591760299626\n",
      "\n",
      "Web-based OCR   0.6666666666666666\n",
      "\n",
      "resource -LRB-   0.2\n",
      "\n",
      "as shallow-transfer   0.003484320557491289\n",
      "\n",
      "human capabilities   0.021739130434782608\n",
      "\n",
      "to machine-learning   0.0013280212483399733\n",
      "\n",
      "of recognition   0.0017825311942959\n",
      "\n",
      "speech choice   0.006578947368421052\n",
      "\n",
      "`` A   0.005291005291005291\n",
      "\n",
      "approximates that   0.5\n",
      "\n",
      "modern statistically-based   0.2\n",
      "\n",
      "by metrics   0.005714285714285714\n",
      "\n",
      "of extracted   0.00089126559714795\n",
      "\n",
      "Eastern Peru   1.0\n",
      "\n",
      "questions and   0.038461538461538464\n",
      "\n",
      "used include   0.008849557522123894\n",
      "\n",
      "` hitcha   0.0625\n",
      "\n",
      "field of   0.4444444444444444\n",
      "\n",
      "automata that   1.0\n",
      "\n",
      "read not   0.14285714285714285\n",
      "\n",
      "some nice   0.012048192771084338\n",
      "\n",
      "'' non-linearly   0.005154639175257732\n",
      "\n",
      "Linguistics -LRB-   0.3333333333333333\n",
      "\n",
      "model taggers   0.03333333333333333\n",
      "\n",
      "-LRB- unigram   0.0027100271002710027\n",
      "\n",
      "Command -RRB-   0.5\n",
      "\n",
      "fire ''   0.5\n",
      "\n",
      "that appears   0.0035460992907801418\n",
      "\n",
      "collection -RRB-   0.2\n",
      "\n",
      "Goldberg continued   0.5\n",
      "\n",
      "word can   0.03333333333333333\n",
      "\n",
      "some glue   0.012048192771084338\n",
      "\n",
      "perhaps trivial   0.16666666666666666\n",
      "\n",
      "like summarization   0.03571428571428571\n",
      "\n",
      "until 1970   0.5\n",
      "\n",
      "des parties   1.0\n",
      "\n",
      "The relations   0.026041666666666668\n",
      "\n",
      "otherwise achieves   0.5\n",
      "\n",
      "AVRADA -RRB-   0.5\n",
      "\n",
      ", need   0.0005614823133071309\n",
      "\n",
      ", second   0.0005614823133071309\n",
      "\n",
      "peak ,   1.0\n",
      "\n",
      "sentence boundary   0.0625\n",
      "\n",
      "of translating   0.00089126559714795\n",
      "\n",
      "<s> Black-box   0.0007686395080707148\n",
      "\n",
      "holes ''   1.0\n",
      "\n",
      ", rapidly   0.0005614823133071309\n",
      "\n",
      "by looking   0.005714285714285714\n",
      "\n",
      "start with   0.14285714285714285\n",
      "\n",
      "generate some   0.05555555555555555\n",
      "\n",
      "patient ''   1.0\n",
      "\n",
      "percentage of   1.0\n",
      "\n",
      "a past-tense   0.001226993865030675\n",
      "\n",
      "company Kurzweil   0.3333333333333333\n",
      "\n",
      "typical features   0.1111111111111111\n",
      "\n",
      "be done   0.02109704641350211\n",
      "\n",
      "probability what   0.14285714285714285\n",
      "\n",
      "input with   0.024390243902439025\n",
      "\n",
      "a Japanese   0.001226993865030675\n",
      "\n",
      "protection from   1.0\n",
      "\n",
      "pseudo-pilot ,   0.5\n",
      "\n",
      "makes use   0.125\n",
      "\n",
      "associate or   0.5\n",
      "\n",
      "so we   0.03333333333333333\n",
      "\n",
      "the subsequent   0.0006920415224913495\n",
      "\n",
      "a speaker   0.00245398773006135\n",
      "\n",
      "after going   0.08333333333333333\n",
      "\n",
      "combine the   0.3333333333333333\n",
      "\n",
      "and gets   0.001445086705202312\n",
      "\n",
      "experience ,   0.5\n",
      "\n",
      ", current   0.0005614823133071309\n",
      "\n",
      "natural as   0.013333333333333334\n",
      "\n",
      "and French   0.001445086705202312\n",
      "\n",
      "sort mail   0.3333333333333333\n",
      "\n",
      "POS-tagging algorithms   1.0\n",
      "\n",
      "hand-annotated with   1.0\n",
      "\n",
      "with DTW   0.00546448087431694\n",
      "\n",
      "properly the   0.5\n",
      "\n",
      "possibility of   0.75\n",
      "\n",
      "vowel in   1.0\n",
      "\n",
      "seen as   0.3\n",
      "\n",
      "they had   0.025\n",
      "\n",
      "trend to   1.0\n",
      "\n",
      "progressed over   1.0\n",
      "\n",
      "text categorization   0.006289308176100629\n",
      "\n",
      "perception that   0.5\n",
      "\n",
      "may all   0.019230769230769232\n",
      "\n",
      "been successfully   0.014705882352941176\n",
      "\n",
      "it becomes   0.03418803418803419\n",
      "\n",
      "a roadmap   0.001226993865030675\n",
      "\n",
      "models are   0.038461538461538464\n",
      "\n",
      "than 98   0.022222222222222223\n",
      "\n",
      "important words   0.0625\n",
      "\n",
      "`` The   0.015873015873015872\n",
      "\n",
      "change focus   1.0\n",
      "\n",
      "of 3   0.00089126559714795\n",
      "\n",
      "categories can   0.1111111111111111\n",
      "\n",
      "words will   0.01834862385321101\n",
      "\n",
      "to most   0.0013280212483399733\n",
      "\n",
      "multi-word phrases   1.0\n",
      "\n",
      "of co-articulation   0.00089126559714795\n",
      "\n",
      "The approaches   0.005208333333333333\n",
      "\n",
      "grammar because   0.02702702702702703\n",
      "\n",
      "that identify   0.0035460992907801418\n",
      "\n",
      "resolution is   0.25\n",
      "\n",
      "independently developed   1.0\n",
      "\n",
      "ability of   0.25\n",
      "\n",
      "the labor   0.0006920415224913495\n",
      "\n",
      "the recognizer   0.0006920415224913495\n",
      "\n",
      "<s> The   0.11222136817832437\n",
      "\n",
      "Guzman ,   1.0\n",
      "\n",
      "Ontology -RRB-   1.0\n",
      "\n",
      "article deal   0.034482758620689655\n",
      "\n",
      "as latent   0.003484320557491289\n",
      "\n",
      "feature .   0.15384615384615385\n",
      "\n",
      "to highly   0.0013280212483399733\n",
      "\n",
      "the natural   0.001384083044982699\n",
      "\n",
      "a known   0.00245398773006135\n",
      "\n",
      "-RRB- ,   0.21138211382113822\n",
      "\n",
      "by people   0.011428571428571429\n",
      "\n",
      "hurts ?   0.5\n",
      "\n",
      "distinguish from   0.2\n",
      "\n",
      ", real-time   0.0005614823133071309\n",
      "\n",
      "report -RRB-   0.25\n",
      "\n",
      "call to   0.3333333333333333\n",
      "\n",
      "reasoning to   0.14285714285714285\n",
      "\n",
      "relations to   0.08333333333333333\n",
      "\n",
      "Japanese prisoner   0.125\n",
      "\n",
      "difficulty using   0.14285714285714285\n",
      "\n",
      "A feature   0.02\n",
      "\n",
      "<s> Scope   0.0007686395080707148\n",
      "\n",
      "mainly evaluation   0.16666666666666666\n",
      "\n",
      "the occurrence   0.0006920415224913495\n",
      "\n",
      "only on   0.05263157894736842\n",
      "\n",
      "from mild   0.009615384615384616\n",
      "\n",
      "A direct   0.02\n",
      "\n",
      "always the   0.3333333333333333\n",
      "\n",
      "system answers   0.010752688172043012\n",
      "\n",
      "input character   0.024390243902439025\n",
      "\n",
      "symbol of   0.25\n",
      "\n",
      "popular ``   0.1111111111111111\n",
      "\n",
      "-LRB- sailor   0.005420054200542005\n",
      "\n",
      "the perception   0.0006920415224913495\n",
      "\n",
      "-- is   0.04\n",
      "\n",
      ", voice-activation   0.0005614823133071309\n",
      "\n",
      "most notoriously   0.017241379310344827\n",
      "\n",
      "Some text   0.047619047619047616\n",
      "\n",
      "length normalization   0.125\n",
      "\n",
      "length of   0.25\n",
      "\n",
      "`` angry   0.005291005291005291\n",
      "\n",
      "but is   0.029411764705882353\n",
      "\n",
      "technique is   0.14285714285714285\n",
      "\n",
      "suitable translation   0.25\n",
      "\n",
      "To mine   0.1111111111111111\n",
      "\n",
      "forecasts to   0.2\n",
      "\n",
      "language sentences   0.006756756756756757\n",
      "\n",
      "of scanned   0.00089126559714795\n",
      "\n",
      "e.g. WordNet   0.017857142857142856\n",
      "\n",
      "the metrics   0.0006920415224913495\n",
      "\n",
      "Artificial Intelligence   0.5\n",
      "\n",
      "detecting the   1.0\n",
      "\n",
      "and trigrams   0.002890173410404624\n",
      "\n",
      "the behavior   0.0006920415224913495\n",
      "\n",
      "-LRB- written   0.0027100271002710027\n",
      "\n",
      "in 1984   0.0018726591760299626\n",
      "\n",
      "human translation   0.043478260869565216\n",
      "\n",
      "'s voices   0.0196078431372549\n",
      "\n",
      "reference to   0.25\n",
      "\n",
      "seen an   0.2\n",
      "\n",
      "approximation to   0.3333333333333333\n",
      "\n",
      "deal with   0.5\n",
      "\n",
      "<s> On-line   0.0023059185242121443\n",
      "\n",
      "translation and   0.04054054054054054\n",
      "\n",
      "<s> Searches   0.0007686395080707148\n",
      "\n",
      "with adjacent   0.00546448087431694\n",
      "\n",
      "rules ATNs   0.023255813953488372\n",
      "\n",
      "evaluation might   0.018518518518518517\n",
      "\n",
      "far is   0.125\n",
      "\n",
      "from other   0.009615384615384616\n",
      "\n",
      "multiple documents   0.15384615384615385\n",
      "\n",
      "ambiguity ''   0.125\n",
      "\n",
      "labeled keyphrases   0.3333333333333333\n",
      "\n",
      "one 10msec   0.015384615384615385\n",
      "\n",
      "Loriot &   1.0\n",
      "\n",
      "`` ASR   0.005291005291005291\n",
      "\n",
      ", opened   0.0005614823133071309\n",
      "\n",
      "Englund -LRB-   1.0\n",
      "\n",
      "that builds   0.0035460992907801418\n",
      "\n",
      "attitude of   0.5\n",
      "\n",
      "and weapons   0.001445086705202312\n",
      "\n",
      "the opinion   0.0006920415224913495\n",
      "\n",
      "and space   0.001445086705202312\n",
      "\n",
      "was first   0.012987012987012988\n",
      "\n",
      "the machine   0.0006920415224913495\n",
      "\n",
      "words emerge   0.009174311926605505\n",
      "\n",
      "representations .   0.25\n",
      "\n",
      "`` Dogged   0.005291005291005291\n",
      "\n",
      "that make   0.010638297872340425\n",
      "\n",
      "The LexRank   0.005208333333333333\n",
      "\n",
      "the challenge   0.0006920415224913495\n",
      "\n",
      "proved far   0.3333333333333333\n",
      "\n",
      "best -RRB-   0.05555555555555555\n",
      "\n",
      "also attempt   0.014492753623188406\n",
      "\n",
      "problems ,   0.35294117647058826\n",
      "\n",
      "when moved   0.02857142857142857\n",
      "\n",
      "be taken   0.004219409282700422\n",
      "\n",
      "One task   0.07692307692307693\n",
      "\n",
      "to millions   0.0013280212483399733\n",
      "\n",
      "<s> Dictionary-based   0.0007686395080707148\n",
      "\n",
      "media ,   0.5\n",
      "\n",
      "check how   0.5\n",
      "\n",
      "are consumed   0.004149377593360996\n",
      "\n",
      "market to   0.3333333333333333\n",
      "\n",
      "successful in   0.1111111111111111\n",
      "\n",
      "Science Research   0.5\n",
      "\n",
      "to medical   0.0013280212483399733\n",
      "\n",
      "parser and   0.0625\n",
      "\n",
      "a sample   0.001226993865030675\n",
      "\n",
      "'' sentiment   0.005154639175257732\n",
      "\n",
      "the direct   0.0006920415224913495\n",
      "\n",
      "computing .   0.5\n",
      "\n",
      "facing more   1.0\n",
      "\n",
      "as Google   0.003484320557491289\n",
      "\n",
      "Department of   1.0\n",
      "\n",
      "then compute   0.02857142857142857\n",
      "\n",
      "The state-of-the-art   0.005208333333333333\n",
      "\n",
      "series -RRB-   0.125\n",
      "\n",
      "source sentence   0.08333333333333333\n",
      "\n",
      "a name   0.00245398773006135\n",
      "\n",
      "depends on   0.875\n",
      "\n",
      "many of   0.038461538461538464\n",
      "\n",
      "segment .   0.1111111111111111\n",
      "\n",
      "written scripts   0.038461538461538464\n",
      "\n",
      "text generation   0.006289308176100629\n",
      "\n",
      "was attempted   0.012987012987012988\n",
      "\n",
      ": Category   0.00980392156862745\n",
      "\n",
      "for data   0.007220216606498195\n",
      "\n",
      "99 %   1.0\n",
      "\n",
      "fully automatic   0.5\n",
      "\n",
      "imagery ,   1.0\n",
      "\n",
      "<s> Much   0.0023059185242121443\n",
      "\n",
      "Ford Sync   1.0\n",
      "\n",
      "-RRB- Modern   0.0027100271002710027\n",
      "\n",
      "<s> Basic   0.0007686395080707148\n",
      "\n",
      "characters can   0.1875\n",
      "\n",
      "into individual   0.01282051282051282\n",
      "\n",
      "effectiveness in   0.3333333333333333\n",
      "\n",
      "more software   0.010526315789473684\n",
      "\n",
      "a communicative   0.001226993865030675\n",
      "\n",
      "allow discriminative   0.2\n",
      "\n",
      "features .   0.07692307692307693\n",
      "\n",
      "services .   0.6666666666666666\n",
      "\n",
      "or aspect   0.0045045045045045045\n",
      "\n",
      "RDF .   1.0\n",
      "\n",
      ", predicting   0.0005614823133071309\n",
      "\n",
      "it ,   0.017094017094017096\n",
      "\n",
      "dialog with   0.5\n",
      "\n",
      "made WebOCR   0.0625\n",
      "\n",
      "and maximum   0.001445086705202312\n",
      "\n",
      "Ernesto Laclau   1.0\n",
      "\n",
      "segments -LRB-   0.2\n",
      "\n",
      "vocabulary ,   0.125\n",
      "\n",
      "FAA as   0.5\n",
      "\n",
      ", e.g.   0.005614823133071308\n",
      "\n",
      "other applications   0.014285714285714285\n",
      "\n",
      "only complete   0.02631578947368421\n",
      "\n",
      "The vertices   0.005208333333333333\n",
      "\n",
      "the example   0.0020761245674740486\n",
      "\n",
      "processing the   0.018518518518518517\n",
      "\n",
      "full progress   0.2\n",
      "\n",
      "informational content   0.5\n",
      "\n",
      "several million   0.045454545454545456\n",
      "\n",
      "<s> Their   0.0015372790161414297\n",
      "\n",
      "opinions or   0.5\n",
      "\n",
      "tasks defined   0.03125\n",
      "\n",
      "this are   0.02197802197802198\n",
      "\n",
      "Parliament of   0.5\n",
      "\n",
      "the representation   0.0006920415224913495\n",
      "\n",
      "encouraging ,   1.0\n",
      "\n",
      "successful HMM-based   0.1111111111111111\n",
      "\n",
      "Rhetoric Stylistics   1.0\n",
      "\n",
      "the GALE   0.001384083044982699\n",
      "\n",
      "HMM states   0.3333333333333333\n",
      "\n",
      "algorithm optimizes   0.03571428571428571\n",
      "\n",
      "written without   0.038461538461538464\n",
      "\n",
      "centrality ''   0.5\n",
      "\n",
      "more dynamic   0.010526315789473684\n",
      "\n",
      "handling differences   0.5\n",
      "\n",
      "research ,   0.07142857142857142\n",
      "\n",
      "of sequential   0.00089126559714795\n",
      "\n",
      "algorithm essentially   0.03571428571428571\n",
      "\n",
      "May 2009   0.5\n",
      "\n",
      "understanding evaluation   0.030303030303030304\n",
      "\n",
      "there 's   0.025\n",
      "\n",
      "1969 ,   0.5\n",
      "\n",
      "improve recognition   0.15384615384615385\n",
      "\n",
      "noun ''   0.07142857142857142\n",
      "\n",
      "arithmetic expression   1.0\n",
      "\n",
      ", there   0.006176305446378439\n",
      "\n",
      "supervised ''   0.1875\n",
      "\n",
      "and SVOX   0.001445086705202312\n",
      "\n",
      "than other   0.022222222222222223\n",
      "\n",
      "algorithm to   0.07142857142857142\n",
      "\n",
      "the testing   0.0006920415224913495\n",
      "\n",
      "less uninterrupted   0.08333333333333333\n",
      "\n",
      "contain periods   0.08333333333333333\n",
      "\n",
      ", especially   0.0050533408197641775\n",
      "\n",
      "controller ,   0.5\n",
      "\n",
      "following are   0.06666666666666667\n",
      "\n",
      "process may   0.027777777777777776\n",
      "\n",
      "wreck a   1.0\n",
      "\n",
      "College at   0.5\n",
      "\n",
      "Then we   0.2\n",
      "\n",
      "is Reiter   0.0020325203252032522\n",
      "\n",
      "draft document   0.5\n",
      "\n",
      "Several MT   0.3333333333333333\n",
      "\n",
      ", 2   0.0005614823133071309\n",
      "\n",
      ", whose   0.0011229646266142617\n",
      "\n",
      "DeRose 's   0.4\n",
      "\n",
      "popular journals   0.1111111111111111\n",
      "\n",
      "titles and   0.5\n",
      "\n",
      "in driving   0.0018726591760299626\n",
      "\n",
      "mapping the   0.5\n",
      "\n",
      "requires citations   0.0625\n",
      "\n",
      "will ``   0.05714285714285714\n",
      "\n",
      "lexical statistics   0.07692307692307693\n",
      "\n",
      "water .   1.0\n",
      "\n",
      "fidelity of   1.0\n",
      "\n",
      "of pragmatics   0.00089126559714795\n",
      "\n",
      "qualities making   0.5\n",
      "\n",
      "`` Statistical   0.005291005291005291\n",
      "\n",
      "most NLP   0.017241379310344827\n",
      "\n",
      ": Top-down   0.00980392156862745\n",
      "\n",
      "tagging .   0.08\n",
      "\n",
      "R. McDonald   0.16666666666666666\n",
      "\n",
      "should figure   0.05263157894736842\n",
      "\n",
      "often be   0.022727272727272728\n",
      "\n",
      "person may   0.05263157894736842\n",
      "\n",
      "beach ,   1.0\n",
      "\n",
      "mainly from   0.16666666666666666\n",
      "\n",
      "really was   1.0\n",
      "\n",
      "an excerpt   0.007575757575757576\n",
      "\n",
      "this task   0.04395604395604396\n",
      "\n",
      "CFG -LRB-   1.0\n",
      "\n",
      "and Church   0.001445086705202312\n",
      "\n",
      "for machine-translation   0.0036101083032490976\n",
      "\n",
      "documents per   0.02631578947368421\n",
      "\n",
      "first layer   0.030303030303030304\n",
      "\n",
      "segmentation :   0.09090909090909091\n",
      "\n",
      "dependency relations   0.2\n",
      "\n",
      "the similarity   0.0006920415224913495\n",
      "\n",
      "data used   0.025974025974025976\n",
      "\n",
      "total accuracy   0.5\n",
      "\n",
      "two given   0.034482758620689655\n",
      "\n",
      "an ''   0.007575757575757576\n",
      "\n",
      "job ;   0.5\n",
      "\n",
      "` nice   0.0625\n",
      "\n",
      "hand-printed characters   0.25\n",
      "\n",
      "of emails   0.00089126559714795\n",
      "\n",
      "-- often   0.04\n",
      "\n",
      "given -LRB-   0.041666666666666664\n",
      "\n",
      "types ,   0.07142857142857142\n",
      "\n",
      "This has   0.015873015873015872\n",
      "\n",
      "for can   0.0036101083032490976\n",
      "\n",
      "a concept   0.001226993865030675\n",
      "\n",
      "stopwords .   1.0\n",
      "\n",
      "1993 there   0.3333333333333333\n",
      "\n",
      ", you   0.0005614823133071309\n",
      "\n",
      "this time   0.03296703296703297\n",
      "\n",
      "context-free grammar   0.45454545454545453\n",
      "\n",
      "uncertainties at   1.0\n",
      "\n",
      "Individuals with   1.0\n",
      "\n",
      "very useful   0.04878048780487805\n",
      "\n",
      "as from   0.003484320557491289\n",
      "\n",
      "or electronic   0.0045045045045045045\n",
      "\n",
      "Yale University   0.5\n",
      "\n",
      "and associated   0.001445086705202312\n",
      "\n",
      "'s promise   0.0196078431372549\n",
      "\n",
      "or con   0.0045045045045045045\n",
      "\n",
      "might learn   0.038461538461538464\n",
      "\n",
      "their similarity   0.029411764705882353\n",
      "\n",
      "1999 -RRB-   0.5\n",
      "\n",
      "hand -RRB-   0.07142857142857142\n",
      "\n",
      "individual unigrams   0.08333333333333333\n",
      "\n",
      "designed to   0.7142857142857143\n",
      "\n",
      "lip-synch timing   1.0\n",
      "\n",
      "common ,   0.08\n",
      "\n",
      "restricted-domain QA   1.0\n",
      "\n",
      "definitional questions   1.0\n",
      "\n",
      "meaning part   0.043478260869565216\n",
      "\n",
      ", Flickinger   0.0005614823133071309\n",
      "\n",
      "Finally ,   1.0\n",
      "\n",
      "for American   0.0036101083032490976\n",
      "\n",
      "approach applies   0.02857142857142857\n",
      "\n",
      "no means   0.07692307692307693\n",
      "\n",
      "new opportunities   0.041666666666666664\n",
      "\n",
      "same objects   0.04\n",
      "\n",
      "communicative goal   0.6666666666666666\n",
      "\n",
      "often involve   0.022727272727272728\n",
      "\n",
      "called Cross-Sentence   0.05555555555555555\n",
      "\n",
      "grammatical parts   0.09090909090909091\n",
      "\n",
      "automated technologies   0.14285714285714285\n",
      "\n",
      "a piecewise   0.001226993865030675\n",
      "\n",
      "decision trees   1.0\n",
      "\n",
      "from both   0.009615384615384616\n",
      "\n",
      "In 1914   0.009523809523809525\n",
      "\n",
      "systems on   0.008928571428571428\n",
      "\n",
      "Named entity   1.0\n",
      "\n",
      "Many of   0.16666666666666666\n",
      "\n",
      "content words   0.08333333333333333\n",
      "\n",
      "words involved   0.009174311926605505\n",
      "\n",
      "Henry Widdowson   0.5\n",
      "\n",
      "mentioned earlier   0.3333333333333333\n",
      "\n",
      "<s> Therefore   0.0015372790161414297\n",
      "\n",
      "other things   0.04285714285714286\n",
      "\n",
      "<s> Last   0.0007686395080707148\n",
      "\n",
      ", verb   0.0011229646266142617\n",
      "\n",
      "<s> Sentiment   0.003843197540353574\n",
      "\n",
      ": Statistical   0.00980392156862745\n",
      "\n",
      "other cases   0.02857142857142857\n",
      "\n",
      "appears to   0.2\n",
      "\n",
      "<s> Closed-domain   0.0007686395080707148\n",
      "\n",
      "phrase structure   0.2\n",
      "\n",
      "and this   0.001445086705202312\n",
      "\n",
      "video sub-titling   0.2\n",
      "\n",
      "phonemes with   0.16666666666666666\n",
      "\n",
      "grammar that   0.02702702702702703\n",
      "\n",
      "based on   0.8333333333333334\n",
      "\n",
      "they all   0.05\n",
      "\n",
      "have started   0.009615384615384616\n",
      "\n",
      "the vocabulary   0.0006920415224913495\n",
      "\n",
      "similar in   0.037037037037037035\n",
      "\n",
      "part-of-speech tagging   0.4666666666666667\n",
      "\n",
      "builds up   0.5\n",
      "\n",
      "identifying relevant   0.16666666666666666\n",
      "\n",
      "that allows   0.0035460992907801418\n",
      "\n",
      "analysis -LRB-   0.06153846153846154\n",
      "\n",
      "simple and   0.07692307692307693\n",
      "\n",
      "mail ,   0.5\n",
      "\n",
      "disambiguation often   0.1\n",
      "\n",
      "that assigns   0.0035460992907801418\n",
      "\n",
      ", except   0.0005614823133071309\n",
      "\n",
      "than instances   0.022222222222222223\n",
      "\n",
      "correctly .   1.0\n",
      "\n",
      "structured real-world   0.16666666666666666\n",
      "\n",
      "placed in   1.0\n",
      "\n",
      "used .   0.04424778761061947\n",
      "\n",
      "and end   0.001445086705202312\n",
      "\n",
      "preliminary ,   0.3333333333333333\n",
      "\n",
      "`` My   0.005291005291005291\n",
      "\n",
      "Paul Hopper   0.2\n",
      "\n",
      "recognizing entire   0.2\n",
      "\n",
      "not present   0.026785714285714284\n",
      "\n",
      "sponsored by   0.5\n",
      "\n",
      "methods need   0.045454545454545456\n",
      "\n",
      "-RRB- BioCreative   0.0027100271002710027\n",
      "\n",
      "discourse Political   0.027777777777777776\n",
      "\n",
      "subtask of   1.0\n",
      "\n",
      "Noun ,   1.0\n",
      "\n",
      "process automatic   0.027777777777777776\n",
      "\n",
      "-LRB- how   0.008130081300813009\n",
      "\n",
      "feature transformation   0.07692307692307693\n",
      "\n",
      "member of   1.0\n",
      "\n",
      "deeply ,   1.0\n",
      "\n",
      "of giving   0.00089126559714795\n",
      "\n",
      "Nagao in   1.0\n",
      "\n",
      "within an   0.05555555555555555\n",
      "\n",
      "sentence breaking   0.020833333333333332\n",
      "\n",
      "deciding whether   0.3333333333333333\n",
      "\n",
      "only to   0.02631578947368421\n",
      "\n",
      "not produce   0.008928571428571428\n",
      "\n",
      "be compared   0.004219409282700422\n",
      "\n",
      "cross-discipline of   1.0\n",
      "\n",
      "the outside   0.0006920415224913495\n",
      "\n",
      "individual words   0.08333333333333333\n",
      "\n",
      "small ,   0.2222222222222222\n",
      "\n",
      "TextRank does   0.07142857142857142\n",
      "\n",
      "make soft   0.2\n",
      "\n",
      "'' in   0.03608247422680412\n",
      "\n",
      "and whether   0.001445086705202312\n",
      "\n",
      "The unsupervised   0.005208333333333333\n",
      "\n",
      "Engineers ''   0.5\n",
      "\n",
      "is positive   0.0020325203252032522\n",
      "\n",
      "Thai and   0.5\n",
      "\n",
      "solve properly   0.25\n",
      "\n",
      ", TextRank   0.0011229646266142617\n",
      "\n",
      "2010 ?   0.3333333333333333\n",
      "\n",
      "dynamic background   0.2\n",
      "\n",
      "involved the   0.16666666666666666\n",
      "\n",
      "<s> Books   0.0007686395080707148\n",
      "\n",
      ", C   0.0005614823133071309\n",
      "\n",
      "a global   0.001226993865030675\n",
      "\n",
      "often span   0.022727272727272728\n",
      "\n",
      "Morpheme Analysis   1.0\n",
      "\n",
      "the strings   0.0006920415224913495\n",
      "\n",
      "would still   0.018867924528301886\n",
      "\n",
      "approach is   0.14285714285714285\n",
      "\n",
      "experiment was   0.4\n",
      "\n",
      "several years   0.09090909090909091\n",
      "\n",
      "dictates into   1.0\n",
      "\n",
      "deals with   1.0\n",
      "\n",
      "implementing a   1.0\n",
      "\n",
      "graph would   0.07692307692307693\n",
      "\n",
      "of Scotland   0.0017825311942959\n",
      "\n",
      "with collecting   0.00546448087431694\n",
      "\n",
      "final stage   0.1111111111111111\n",
      "\n",
      "rather can   0.0625\n",
      "\n",
      "their lack   0.029411764705882353\n",
      "\n",
      "functional grammar   0.5\n",
      "\n",
      "copied and   0.5\n",
      "\n",
      "detection of   0.5\n",
      "\n",
      "n-dimensional real-valued   1.0\n",
      "\n",
      "analysis Applied   0.015384615384615385\n",
      "\n",
      "in virtually   0.0018726591760299626\n",
      "\n",
      "specialised document   0.5\n",
      "\n",
      "boundaries of   0.09090909090909091\n",
      "\n",
      "easily portable   0.2222222222222222\n",
      "\n",
      "tag of   0.0625\n",
      "\n",
      "of active   0.00089126559714795\n",
      "\n",
      "such large   0.008130081300813009\n",
      "\n",
      "proposes some   1.0\n",
      "\n",
      "performance has   0.05555555555555555\n",
      "\n",
      "adjective or   0.42857142857142855\n",
      "\n",
      "tagger proceeds   0.1111111111111111\n",
      "\n",
      "targets to   1.0\n",
      "\n",
      "entering a   0.5\n",
      "\n",
      "are claiming   0.004149377593360996\n",
      "\n",
      "the order   0.001384083044982699\n",
      "\n",
      "i.e. text   0.05263157894736842\n",
      "\n",
      "Military High-performance   1.0\n",
      "\n",
      "'s dissertation   0.0196078431372549\n",
      "\n",
      "various genres   0.05555555555555555\n",
      "\n",
      "ratings ,   0.1111111111111111\n",
      "\n",
      "in Liu   0.0018726591760299626\n",
      "\n",
      "<s> During   0.0030745580322828594\n",
      "\n",
      "but was   0.014705882352941176\n",
      "\n",
      "summary of   0.07142857142857142\n",
      "\n",
      "computerized language   0.5\n",
      "\n",
      "of identifying   0.00089126559714795\n",
      "\n",
      "noise pertain   0.125\n",
      "\n",
      "1954 on   0.3333333333333333\n",
      "\n",
      "semantics which   0.14285714285714285\n",
      "\n",
      "of input   0.00267379679144385\n",
      "\n",
      "frequently formalized   0.5\n",
      "\n",
      "cosine transform   0.3333333333333333\n",
      "\n",
      "or sentiments   0.0045045045045045045\n",
      "\n",
      "While this   0.2\n",
      "\n",
      "it is   0.20512820512820512\n",
      "\n",
      "Orientation --   1.0\n",
      "\n",
      "a human   0.013496932515337423\n",
      "\n",
      ", word   0.0005614823133071309\n",
      "\n",
      "grammar of   0.05405405405405406\n",
      "\n",
      "typology ,   1.0\n",
      "\n",
      "sentence must   0.020833333333333332\n",
      "\n",
      "target language   0.7272727272727273\n",
      "\n",
      "dialing -LRB-   1.0\n",
      "\n",
      "aircraft -LRB-   0.2857142857142857\n",
      "\n",
      "is widely   0.0040650406504065045\n",
      "\n",
      "be programmed   0.008438818565400843\n",
      "\n",
      "information needed   0.021739130434782608\n",
      "\n",
      "many speech   0.019230769230769232\n",
      "\n",
      "Manual evaluation   0.6666666666666666\n",
      "\n",
      "EHR will   0.3333333333333333\n",
      "\n",
      "Real progress   0.5\n",
      "\n",
      "beings ,   1.0\n",
      "\n",
      "going thus   0.25\n",
      "\n",
      "WordNet ,   0.5\n",
      "\n",
      "`` happy   0.005291005291005291\n",
      "\n",
      "J. Phillips   0.3333333333333333\n",
      "\n",
      "or nature   0.0045045045045045045\n",
      "\n",
      ", recommendations   0.0005614823133071309\n",
      "\n",
      "develop OCR   0.2\n",
      "\n",
      "a part-of-speech   0.001226993865030675\n",
      "\n",
      "created rules   0.14285714285714285\n",
      "\n",
      "relating to   1.0\n",
      "\n",
      "procedures can   0.5\n",
      "\n",
      "this can   0.01098901098901099\n",
      "\n",
      "compare them   0.14285714285714285\n",
      "\n",
      "as 50   0.003484320557491289\n",
      "\n",
      ", translation   0.0011229646266142617\n",
      "\n",
      "make decisions   0.05\n",
      "\n",
      "in isolation   0.0018726591760299626\n",
      "\n",
      "unless the   1.0\n",
      "\n",
      "of extracting   0.00089126559714795\n",
      "\n",
      "analyze a   0.25\n",
      "\n",
      "accumulation of   1.0\n",
      "\n",
      "sentence that   0.041666666666666664\n",
      "\n",
      "statistically evaluated   1.0\n",
      "\n",
      "though much   0.1\n",
      "\n",
      "Junqua and   1.0\n",
      "\n",
      "major algorithms   0.08333333333333333\n",
      "\n",
      "parse garden-path   0.1111111111111111\n",
      "\n",
      "person does   0.05263157894736842\n",
      "\n",
      "arrive at   1.0\n",
      "\n",
      "structure grammar   0.08333333333333333\n",
      "\n",
      "same information   0.04\n",
      "\n",
      "vs. Independence   0.08333333333333333\n",
      "\n",
      ", humans   0.0005614823133071309\n",
      "\n",
      "expected ,   0.14285714285714285\n",
      "\n",
      "distances for   0.5\n",
      "\n",
      "are domain-independent   0.004149377593360996\n",
      "\n",
      "different related   0.02040816326530612\n",
      "\n",
      "articles rarely   0.125\n",
      "\n",
      "for acquiring   0.0036101083032490976\n",
      "\n",
      "to bridge   0.0013280212483399733\n",
      "\n",
      "recognizing named   0.2\n",
      "\n",
      "the times   0.0006920415224913495\n",
      "\n",
      "considered -LRB-   0.1111111111111111\n",
      "\n",
      "the forward-backward   0.0006920415224913495\n",
      "\n",
      "at helping   0.014705882352941176\n",
      "\n",
      "sets of   0.36363636363636365\n",
      "\n",
      "judges ,   0.5\n",
      "\n",
      "evaluation of   0.07407407407407407\n",
      "\n",
      "length .   0.125\n",
      "\n",
      "words surrounding   0.009174311926605505\n",
      "\n",
      "to as   0.005312084993359893\n",
      "\n",
      "Fourier transform   0.6666666666666666\n",
      "\n",
      "effective decision-support   0.16666666666666666\n",
      "\n",
      "`` B   0.005291005291005291\n",
      "\n",
      "States ,   0.14285714285714285\n",
      "\n",
      "identical to   1.0\n",
      "\n",
      "summarization works   0.02\n",
      "\n",
      "dried up   1.0\n",
      "\n",
      "When processing   0.14285714285714285\n",
      "\n",
      "varying degrees   1.0\n",
      "\n",
      "conversation with   0.5\n",
      "\n",
      ", recall   0.0005614823133071309\n",
      "\n",
      "; the   0.0851063829787234\n",
      "\n",
      "recursive productions   1.0\n",
      "\n",
      "then with   0.02857142857142857\n",
      "\n",
      "answer is   0.06666666666666667\n",
      "\n",
      "efforts were   0.14285714285714285\n",
      "\n",
      "better measure   0.1111111111111111\n",
      "\n",
      "already published   0.2\n",
      "\n",
      "up or   0.045454545454545456\n",
      "\n",
      "predicting star   0.5\n",
      "\n",
      "early systems   0.1\n",
      "\n",
      "different methods   0.02040816326530612\n",
      "\n",
      "; but   0.0425531914893617\n",
      "\n",
      "coming between   1.0\n",
      "\n",
      "into intrinsic   0.01282051282051282\n",
      "\n",
      "Two particular   0.14285714285714285\n",
      "\n",
      "readability and   1.0\n",
      "\n",
      "which could   0.007246376811594203\n",
      "\n",
      "requires its   0.0625\n",
      "\n",
      "many debates   0.019230769230769232\n",
      "\n",
      "crossed below   1.0\n",
      "\n",
      "may suffer   0.019230769230769232\n",
      "\n",
      "on democratizing   0.0047169811320754715\n",
      "\n",
      "researchers must   0.1\n",
      "\n",
      "sorting center   1.0\n",
      "\n",
      "of corpus   0.00089126559714795\n",
      "\n",
      "of phrases   0.00089126559714795\n",
      "\n",
      "becoming more   1.0\n",
      "\n",
      "the mean   0.0006920415224913495\n",
      "\n",
      "to threshold   0.0013280212483399733\n",
      "\n",
      "framework .   0.75\n",
      "\n",
      "restricted vocabulary   0.25\n",
      "\n",
      "morphemes .   0.3333333333333333\n",
      "\n",
      "and rule-based   0.001445086705202312\n",
      "\n",
      "securely ;   1.0\n",
      "\n",
      "summary by   0.023809523809523808\n",
      "\n",
      "turns and   0.3333333333333333\n",
      "\n",
      "decide when   0.25\n",
      "\n",
      "emails and   0.5\n",
      "\n",
      "future .   0.3333333333333333\n",
      "\n",
      "Message Understanding   1.0\n",
      "\n",
      "debates ,   1.0\n",
      "\n",
      "to government   0.0013280212483399733\n",
      "\n",
      "argued that   1.0\n",
      "\n",
      "often considered   0.022727272727272728\n",
      "\n",
      "intended for   0.4\n",
      "\n",
      "pragmatics .   0.3333333333333333\n",
      "\n",
      "maintained within   0.5\n",
      "\n",
      "has never   0.023809523809523808\n",
      "\n",
      "hypothesis ``   1.0\n",
      "\n",
      "others more   0.08333333333333333\n",
      "\n",
      "personal computer   0.25\n",
      "\n",
      "examples and   0.16666666666666666\n",
      "\n",
      "optimistic about   1.0\n",
      "\n",
      "performance improvements   0.05555555555555555\n",
      "\n",
      "thought-to-paper communication   1.0\n",
      "\n",
      "meaningful .   0.125\n",
      "\n",
      "by IMR   0.005714285714285714\n",
      "\n",
      "accuracy over   0.03225806451612903\n",
      "\n",
      "real world   0.3333333333333333\n",
      "\n",
      "extracting their   0.2\n",
      "\n",
      ", typical   0.0005614823133071309\n",
      "\n",
      "proper names   0.14285714285714285\n",
      "\n",
      "clarification .   0.3333333333333333\n",
      "\n",
      "high noise   0.05555555555555555\n",
      "\n",
      "by rules   0.005714285714285714\n",
      "\n",
      "he proposed   0.14285714285714285\n",
      "\n",
      "made explicit   0.0625\n",
      "\n",
      "a movie   0.00245398773006135\n",
      "\n",
      "estate advertisements   1.0\n",
      "\n",
      "encoding world   1.0\n",
      "\n",
      "formed Symantec   0.2\n",
      "\n",
      "increasing number   0.3333333333333333\n",
      "\n",
      "but they   0.04411764705882353\n",
      "\n",
      "developments of   0.3333333333333333\n",
      "\n",
      "nodes that   0.14285714285714285\n",
      "\n",
      "running Palm   0.3333333333333333\n",
      "\n",
      "each one   0.044444444444444446\n",
      "\n",
      "even allows   0.037037037037037035\n",
      "\n",
      "difficulties discussed   0.5\n",
      "\n",
      "after removing   0.08333333333333333\n",
      "\n",
      "a Cognitive   0.001226993865030675\n",
      "\n",
      "to generate   0.00796812749003984\n",
      "\n",
      "combining decisions   0.25\n",
      "\n",
      "and pragmatics   0.001445086705202312\n",
      "\n",
      ", consider   0.0005614823133071309\n",
      "\n",
      "By combining   0.3333333333333333\n",
      "\n",
      "detected important   0.5\n",
      "\n",
      "now rely   0.07692307692307693\n",
      "\n",
      "But recognition   0.16666666666666666\n",
      "\n",
      "keyphrases for   0.05714285714285714\n",
      "\n",
      "-LRB- 2001   0.0027100271002710027\n",
      "\n",
      "itself or   0.2\n",
      "\n",
      "data category   0.012987012987012988\n",
      "\n",
      "metrics used   0.1111111111111111\n",
      "\n",
      "often not   0.045454545454545456\n",
      "\n",
      "condense a   1.0\n",
      "\n",
      "traditionally made   0.5\n",
      "\n",
      "Ratliff originally   1.0\n",
      "\n",
      "One way   0.07692307692307693\n",
      "\n",
      "`` speech   0.005291005291005291\n",
      "\n",
      "to accomplish   0.0013280212483399733\n",
      "\n",
      "by other   0.005714285714285714\n",
      "\n",
      "they use   0.025\n",
      "\n",
      "Shift-Reduce parsing   1.0\n",
      "\n",
      "Many different   0.16666666666666666\n",
      "\n",
      "adaptation greatly   0.3333333333333333\n",
      "\n",
      "essentially a   0.25\n",
      "\n",
      "logical representation   0.16666666666666666\n",
      "\n",
      "project compared   0.15384615384615385\n",
      "\n",
      "-LRB- or   0.02710027100271003\n",
      "\n",
      "from Fully   0.009615384615384616\n",
      "\n",
      "The lexer   0.005208333333333333\n",
      "\n",
      "For most   0.01639344262295082\n",
      "\n",
      "techniques is   0.043478260869565216\n",
      "\n",
      "campaigns were   0.5\n",
      "\n",
      "semiotic event   1.0\n",
      "\n",
      "evaluated ,   0.14285714285714285\n",
      "\n",
      "of special   0.00089126559714795\n",
      "\n",
      "envelope based   1.0\n",
      "\n",
      "assumptions ,   0.2\n",
      "\n",
      "error rate   0.4166666666666667\n",
      "\n",
      "glossary or   0.5\n",
      "\n",
      "case is   0.058823529411764705\n",
      "\n",
      "on summarization   0.0047169811320754715\n",
      "\n",
      "world 's   0.06666666666666667\n",
      "\n",
      "finds many   1.0\n",
      "\n",
      "a proper   0.001226993865030675\n",
      "\n",
      "of finite   0.00089126559714795\n",
      "\n",
      "to merge   0.0013280212483399733\n",
      "\n",
      "hyphenated words   1.0\n",
      "\n",
      "of phrase   0.00089126559714795\n",
      "\n",
      "Glass-box evaluation   1.0\n",
      "\n",
      "stochastic ,   0.25\n",
      "\n",
      "keyboard and   0.3333333333333333\n",
      "\n",
      "they create   0.025\n",
      "\n",
      "<s> Data   0.0007686395080707148\n",
      "\n",
      "arbitrary length   0.3333333333333333\n",
      "\n",
      "contrast ,   0.625\n",
      "\n",
      "They can   0.3333333333333333\n",
      "\n",
      "-RRB- Cohesion   0.0027100271002710027\n",
      "\n",
      "ambiguous there   0.08333333333333333\n",
      "\n",
      "'' -RRB-   0.09278350515463918\n",
      "\n",
      "underlying idea   0.3333333333333333\n",
      "\n",
      "tables with   0.3333333333333333\n",
      "\n",
      "compare the   0.2857142857142857\n",
      "\n",
      "whole sentences   0.2222222222222222\n",
      "\n",
      "<s> Imagine   0.0007686395080707148\n",
      "\n",
      "date is   0.3333333333333333\n",
      "\n",
      "speech-to-text -RRB-   0.5\n",
      "\n",
      "aid users   0.25\n",
      "\n",
      "Incorporating diversity   1.0\n",
      "\n",
      "typically from   0.05555555555555555\n",
      "\n",
      "similar to   0.5555555555555556\n",
      "\n",
      "about human   0.025\n",
      "\n",
      "on smaller   0.0047169811320754715\n",
      "\n",
      "its vocabulary   0.02857142857142857\n",
      "\n",
      "results ,   0.09523809523809523\n",
      "\n",
      "and graphics   0.001445086705202312\n",
      "\n",
      "performed in   0.2\n",
      "\n",
      "containing four   0.125\n",
      "\n",
      "and corrected   0.001445086705202312\n",
      "\n",
      "clean it   0.5\n",
      "\n",
      "be approached   0.004219409282700422\n",
      "\n",
      "determines how   0.3333333333333333\n",
      "\n",
      "word being   0.03333333333333333\n",
      "\n",
      "Mariani J.   1.0\n",
      "\n",
      "consecutively and   1.0\n",
      "\n",
      "major limitation   0.08333333333333333\n",
      "\n",
      "insights .   1.0\n",
      "\n",
      "consonants and   0.3333333333333333\n",
      "\n",
      "further discussed   0.125\n",
      "\n",
      "and manipulate   0.001445086705202312\n",
      "\n",
      "Mouffe ,   1.0\n",
      "\n",
      "always ,   0.3333333333333333\n",
      "\n",
      "= no.   0.1111111111111111\n",
      "\n",
      "of costly   0.00089126559714795\n",
      "\n",
      "multilingual questions   0.3333333333333333\n",
      "\n",
      "Plot Units   1.0\n",
      "\n",
      "! <s/>   1.0\n",
      "\n",
      "require that   0.045454545454545456\n",
      "\n",
      "areas --   0.16666666666666666\n",
      "\n",
      "Patent 2,026,329   0.3333333333333333\n",
      "\n",
      "is recognizing   0.0020325203252032522\n",
      "\n",
      "a trivial   0.001226993865030675\n",
      "\n",
      "utility and   0.5\n",
      "\n",
      "system such   0.010752688172043012\n",
      "\n",
      "Technolangue\\/Easy Text   0.5\n",
      "\n",
      "unlimited range   1.0\n",
      "\n",
      "investigation performed   1.0\n",
      "\n",
      "is embedded   0.0020325203252032522\n",
      "\n",
      "studying the   1.0\n",
      "\n",
      "lexical segments   0.07692307692307693\n",
      "\n",
      ", columns   0.0005614823133071309\n",
      "\n",
      "tasks that   0.03125\n",
      "\n",
      "been extended   0.014705882352941176\n",
      "\n",
      ", Court   0.0005614823133071309\n",
      "\n",
      "the translation   0.004152249134948097\n",
      "\n",
      "content and   0.16666666666666666\n",
      "\n",
      "mention how   0.3333333333333333\n",
      "\n",
      "find ways   0.07692307692307693\n",
      "\n",
      "binary classifier   0.25\n",
      "\n",
      "Winograd continued   0.3333333333333333\n",
      "\n",
      "objects listed   0.2\n",
      "\n",
      "on SourceForge   0.0047169811320754715\n",
      "\n",
      ", Thai   0.0005614823133071309\n",
      "\n",
      "use Machine   0.013888888888888888\n",
      "\n",
      "Chinese or   0.14285714285714285\n",
      "\n",
      "users to   0.2222222222222222\n",
      "\n",
      "<s> Topic   0.0007686395080707148\n",
      "\n",
      "have many   0.04807692307692308\n",
      "\n",
      "phonemes in   0.16666666666666666\n",
      "\n",
      "gaming and   1.0\n",
      "\n",
      "it difficult   0.017094017094017096\n",
      "\n",
      "known word   0.038461538461538464\n",
      "\n",
      "following is   0.06666666666666667\n",
      "\n",
      "Evaluation -RRB-   0.2222222222222222\n",
      "\n",
      "<s> Reading   0.0007686395080707148\n",
      "\n",
      "gestures ,   0.5\n",
      "\n",
      ", most   0.004491858506457047\n",
      "\n",
      ": Separate   0.0196078431372549\n",
      "\n",
      "both rules   0.03225806451612903\n",
      "\n",
      "made available   0.0625\n",
      "\n",
      "Chafe ,   1.0\n",
      "\n",
      "rooms ,   1.0\n",
      "\n",
      "Interactional sociolinguistics   1.0\n",
      "\n",
      "k -RRB-   1.0\n",
      "\n",
      "Italian -RRB-   0.5\n",
      "\n",
      "<s> Where   0.0007686395080707148\n",
      "\n",
      "transition network   1.0\n",
      "\n",
      "our everyday   0.2\n",
      "\n",
      "reverse process   0.5\n",
      "\n",
      "being scanned   0.05555555555555555\n",
      "\n",
      "Human languages   0.2\n",
      "\n",
      "intelligence and   0.125\n",
      "\n",
      "; Compute   0.02127659574468085\n",
      "\n",
      "not readily   0.008928571428571428\n",
      "\n",
      "words being   0.009174311926605505\n",
      "\n",
      "camp is   0.25\n",
      "\n",
      "grammar-based methods   1.0\n",
      "\n",
      "Screenshot OCR   1.0\n",
      "\n",
      "<s> Aided   0.0007686395080707148\n",
      "\n",
      "of continuous   0.0017825311942959\n",
      "\n",
      "patterns rather   0.2\n",
      "\n",
      "pronunciation ,   1.0\n",
      "\n",
      "and discuss   0.001445086705202312\n",
      "\n",
      "keyphrases ,   0.05714285714285714\n",
      "\n",
      "be used   0.08016877637130802\n",
      "\n",
      "and language   0.004335260115606936\n",
      "\n",
      "an idea   0.007575757575757576\n",
      "\n",
      "another he   0.07692307692307693\n",
      "\n",
      "Dictionary-based machine   0.5\n",
      "\n",
      "of researchers   0.00089126559714795\n",
      "\n",
      "European Parliament   0.3333333333333333\n",
      "\n",
      "word ,   0.03333333333333333\n",
      "\n",
      "distinguish names   0.2\n",
      "\n",
      "is for   0.0020325203252032522\n",
      "\n",
      "corpora such   0.09090909090909091\n",
      "\n",
      "problem overlaps   0.022727272727272728\n",
      "\n",
      "for POS   0.0036101083032490976\n",
      "\n",
      "IBM Research   0.3333333333333333\n",
      "\n",
      "understanding involves   0.030303030303030304\n",
      "\n",
      "speech which   0.006578947368421052\n",
      "\n",
      "AFTI -RRB-   1.0\n",
      "\n",
      "a cluster   0.00245398773006135\n",
      "\n",
      "thirty years   1.0\n",
      "\n",
      "term language   0.05555555555555555\n",
      "\n",
      "well human-ratings   0.03571428571428571\n",
      "\n",
      "involved ,   0.16666666666666666\n",
      "\n",
      "both cases   0.03225806451612903\n",
      "\n",
      "'' as   0.02577319587628866\n",
      "\n",
      "entries ,   0.5\n",
      "\n",
      "Gripen cockpit   1.0\n",
      "\n",
      "a calculator   0.00245398773006135\n",
      "\n",
      "not remember   0.008928571428571428\n",
      "\n",
      "demonstration of   0.4\n",
      "\n",
      "rates of   0.375\n",
      "\n",
      "relationships of   0.16666666666666666\n",
      "\n",
      "at Yale   0.029411764705882353\n",
      "\n",
      "negligence ''   1.0\n",
      "\n",
      "-RRB- do   0.0027100271002710027\n",
      "\n",
      "for cartoon   0.0036101083032490976\n",
      "\n",
      "only automate   0.02631578947368421\n",
      "\n",
      "or paragraph   0.0045045045045045045\n",
      "\n",
      "attractive recognition   0.3333333333333333\n",
      "\n",
      "Treebank Project   0.16666666666666666\n",
      "\n",
      "9 parts   1.0\n",
      "\n",
      "their input   0.029411764705882353\n",
      "\n",
      "often work   0.022727272727272728\n",
      "\n",
      "involve learning   0.16666666666666666\n",
      "\n",
      "tagger .   0.1111111111111111\n",
      "\n",
      "is contrast   0.0020325203252032522\n",
      "\n",
      "positive sentiment   0.14285714285714285\n",
      "\n",
      "primary output   0.5\n",
      "\n",
      "and previously-written   0.001445086705202312\n",
      "\n",
      "Interactive voice   0.5\n",
      "\n",
      "followed .   0.25\n",
      "\n",
      "had the   0.07142857142857142\n",
      "\n",
      "numeric scores   1.0\n",
      "\n",
      "early AI   0.2\n",
      "\n",
      "The machine-learning   0.005208333333333333\n",
      "\n",
      "Asian language   1.0\n",
      "\n",
      "action applied   0.2\n",
      "\n",
      "array .   1.0\n",
      "\n",
      "on Reader   0.0047169811320754715\n",
      "\n",
      "similarly effective   1.0\n",
      "\n",
      "Company and   0.5\n",
      "\n",
      "be thought   0.004219409282700422\n",
      "\n",
      "the computerization   0.0006920415224913495\n",
      "\n",
      "A. D.   0.2\n",
      "\n",
      "words and   0.06422018348623854\n",
      "\n",
      "Pragmatics ,   1.0\n",
      "\n",
      "in simple   0.0018726591760299626\n",
      "\n",
      "Force and   0.5\n",
      "\n",
      "annotation has   0.25\n",
      "\n",
      "more quickly   0.010526315789473684\n",
      "\n",
      "most fundamental   0.017241379310344827\n",
      "\n",
      "uses several   0.07142857142857142\n",
      "\n",
      "The nodes   0.005208333333333333\n",
      "\n",
      "to them   0.0026560424966799467\n",
      "\n",
      "baseball league   1.0\n",
      "\n",
      "extracting meaningful   0.2\n",
      "\n",
      "A possible   0.02\n",
      "\n",
      "repetitive stress   0.5\n",
      "\n",
      "with .   0.00546448087431694\n",
      "\n",
      "customers .   0.5\n",
      "\n",
      "-LRB- JSF   0.0027100271002710027\n",
      "\n",
      "language input   0.02027027027027027\n",
      "\n",
      "In Europe   0.01904761904761905\n",
      "\n",
      "implicate ``   1.0\n",
      "\n",
      "Speech ''   0.03225806451612903\n",
      "\n",
      "-RRB- formal   0.0027100271002710027\n",
      "\n",
      "but it   0.058823529411764705\n",
      "\n",
      "relying on   1.0\n",
      "\n",
      "accuracy rate   0.06451612903225806\n",
      "\n",
      "and placement   0.001445086705202312\n",
      "\n",
      "between ``   0.02564102564102564\n",
      "\n",
      "was the   0.05194805194805195\n",
      "\n",
      "represents an   0.25\n",
      "\n",
      "over 1,000   0.08333333333333333\n",
      "\n",
      "others they   0.08333333333333333\n",
      "\n",
      "a writer   0.001226993865030675\n",
      "\n",
      "not to   0.008928571428571428\n",
      "\n",
      "undercarriage ,   1.0\n",
      "\n",
      "normally do   0.5\n",
      "\n",
      "employs rule-based   0.5\n",
      "\n",
      "of what   0.0035650623885918\n",
      "\n",
      "reported was   0.2\n",
      "\n",
      "-LRB- F   0.0027100271002710027\n",
      "\n",
      "years after   0.047619047619047616\n",
      "\n",
      "works These   0.5\n",
      "\n",
      "suggest valuable   0.3333333333333333\n",
      "\n",
      "ones are   0.1\n",
      "\n",
      "An important   0.125\n",
      "\n",
      "These edges   0.058823529411764705\n",
      "\n",
      "connected text   0.2\n",
      "\n",
      "was historically   0.012987012987012988\n",
      "\n",
      "the measurement   0.0006920415224913495\n",
      "\n",
      "be found   0.012658227848101266\n",
      "\n",
      "management applications   0.14285714285714285\n",
      "\n",
      "accurate program   0.14285714285714285\n",
      "\n",
      "was followed   0.012987012987012988\n",
      "\n",
      "headlines ,   1.0\n",
      "\n",
      "of Pennsylvania   0.00089126559714795\n",
      "\n",
      "generated readable   0.06666666666666667\n",
      "\n",
      "automated target   0.14285714285714285\n",
      "\n",
      "on pattern   0.0047169811320754715\n",
      "\n",
      "`` an   0.005291005291005291\n",
      "\n",
      "situation where   0.5\n",
      "\n",
      "hardly any   1.0\n",
      "\n",
      "rarely have   0.3333333333333333\n",
      "\n",
      "Grishman R.   1.0\n",
      "\n",
      "' ,   0.3157894736842105\n",
      "\n",
      "context ,   0.12121212121212122\n",
      "\n",
      "Black E.   0.5\n",
      "\n",
      "relations ,   0.16666666666666666\n",
      "\n",
      "successive letters   0.5\n",
      "\n",
      "showed that   0.75\n",
      "\n",
      "hand-crafted rules   0.5\n",
      "\n",
      "for Speech   0.0036101083032490976\n",
      "\n",
      "be understood   0.004219409282700422\n",
      "\n",
      "verbs -LRB-   0.2\n",
      "\n",
      "answering -LRB-   0.08333333333333333\n",
      "\n",
      "quite weak   0.125\n",
      "\n",
      "data annotation   0.012987012987012988\n",
      "\n",
      "Convert information   0.5\n",
      "\n",
      "segmentation between   0.030303030303030304\n",
      "\n",
      ", probabilistic   0.0016844469399213925\n",
      "\n",
      "processing systems   0.05555555555555555\n",
      "\n",
      "<s> Vocalizations   0.0007686395080707148\n",
      "\n",
      "one instance   0.015384615384615385\n",
      "\n",
      "terms in   0.07692307692307693\n",
      "\n",
      ", in   0.01909039865244245\n",
      "\n",
      "-LRB- English   0.0027100271002710027\n",
      "\n",
      "Understanding Conference   0.5\n",
      "\n",
      "Substantial efforts   0.5\n",
      "\n",
      "forms of   0.3333333333333333\n",
      "\n",
      "special ink   0.2\n",
      "\n",
      "the production   0.0006920415224913495\n",
      "\n",
      "best one   0.05555555555555555\n",
      "\n",
      "using general   0.01694915254237288\n",
      "\n",
      "left recursion   0.16666666666666666\n",
      "\n",
      "NLP techniques   0.0425531914893617\n",
      "\n",
      "`` Did   0.005291005291005291\n",
      "\n",
      "reformulate the   1.0\n",
      "\n",
      "each input   0.022222222222222223\n",
      "\n",
      "Products began   0.5\n",
      "\n",
      "-LRB- more   0.005420054200542005\n",
      "\n",
      "The term   0.020833333333333332\n",
      "\n",
      "3rd rev   1.0\n",
      "\n",
      "<s> Solving   0.0007686395080707148\n",
      "\n",
      ": Emergent   0.00980392156862745\n",
      "\n",
      "by interactive   0.005714285714285714\n",
      "\n",
      "speaker dependent   0.05555555555555555\n",
      "\n",
      "shed light   1.0\n",
      "\n",
      "to place   0.0026560424966799467\n",
      "\n",
      "will determine   0.02857142857142857\n",
      "\n",
      "battle management   1.0\n",
      "\n",
      "; no   0.02127659574468085\n",
      "\n",
      "used ,   0.07079646017699115\n",
      "\n",
      "extraction and   0.06451612903225806\n",
      "\n",
      "can form   0.0055248618784530384\n",
      "\n",
      "phrases supported   0.0625\n",
      "\n",
      "a credit   0.00245398773006135\n",
      "\n",
      "assigned keywords   0.5\n",
      "\n",
      "models of   0.038461538461538464\n",
      "\n",
      "research articles   0.023809523809523808\n",
      "\n",
      "Modern general-purpose   0.3333333333333333\n",
      "\n",
      "<s> Components   0.0007686395080707148\n",
      "\n",
      "e.g. person   0.017857142857142856\n",
      "\n",
      "are not   0.02074688796680498\n",
      "\n",
      "words are   0.09174311926605505\n",
      "\n",
      "English-like sentences   0.3333333333333333\n",
      "\n",
      "This research   0.015873015873015872\n",
      "\n",
      "programming algorithms   0.2\n",
      "\n",
      "appraisal theory   1.0\n",
      "\n",
      "Japanese prisoners   0.125\n",
      "\n",
      "approaches can   0.03571428571428571\n",
      "\n",
      "<s> Similarly   0.0007686395080707148\n",
      "\n",
      "exponential number   0.5\n",
      "\n",
      "pieces as   1.0\n",
      "\n",
      "to direct   0.0013280212483399733\n",
      "\n",
      "utterance and   0.3333333333333333\n",
      "\n",
      "of listening   0.00089126559714795\n",
      "\n",
      "step towards   0.06666666666666667\n",
      "\n",
      "sentences '   0.013157894736842105\n",
      "\n",
      "is easy   0.0020325203252032522\n",
      "\n",
      "criterion depends   0.5\n",
      "\n",
      "a larger   0.0049079754601227\n",
      "\n",
      "Street .   0.3333333333333333\n",
      "\n",
      "lot of   0.3333333333333333\n",
      "\n",
      "remains a   0.25\n",
      "\n",
      "-- whole   0.04\n",
      "\n",
      "Few assumptions   1.0\n",
      "\n",
      "Mars Microphone   0.5\n",
      "\n",
      "color images   1.0\n",
      "\n",
      "; e.g.   0.0425531914893617\n",
      "\n",
      "known key   0.038461538461538464\n",
      "\n",
      "3 or   0.2\n",
      "\n",
      "`` bag   0.005291005291005291\n",
      "\n",
      ", statement   0.0005614823133071309\n",
      "\n",
      "to action   0.0013280212483399733\n",
      "\n",
      "; applies   0.02127659574468085\n",
      "\n",
      "the values   0.0006920415224913495\n",
      "\n",
      "in itself   0.0018726591760299626\n",
      "\n",
      "some large   0.012048192771084338\n",
      "\n",
      "real-time character   0.5\n",
      "\n",
      "explicit features   0.2\n",
      "\n",
      "makes sense   0.125\n",
      "\n",
      "applied successfully   0.06666666666666667\n",
      "\n",
      "necessary anymore   0.1\n",
      "\n",
      "eigenvalue 1   1.0\n",
      "\n",
      "does the   0.1\n",
      "\n",
      "larger set   0.0625\n",
      "\n",
      "but deep   0.014705882352941176\n",
      "\n",
      "as classifying   0.003484320557491289\n",
      "\n",
      "in more   0.0018726591760299626\n",
      "\n",
      "language production   0.006756756756756757\n",
      "\n",
      "`` ask   0.005291005291005291\n",
      "\n",
      "develop dedicated   0.2\n",
      "\n",
      "that has   0.02127659574468085\n",
      "\n",
      "possibilities but   0.2\n",
      "\n",
      "machine-aided human   1.0\n",
      "\n",
      "their more   0.029411764705882353\n",
      "\n",
      "field with   0.037037037037037035\n",
      "\n",
      "the complex   0.0006920415224913495\n",
      "\n",
      "text and   0.018867924528301886\n",
      "\n",
      "Verschueren ,   1.0\n",
      "\n",
      ", signed   0.0005614823133071309\n",
      "\n",
      "Different types   1.0\n",
      "\n",
      "ROUGE metric   0.2\n",
      "\n",
      ", queries   0.0005614823133071309\n",
      "\n",
      ", or   0.018528916339135316\n",
      "\n",
      "USA in   1.0\n",
      "\n",
      "results .   0.09523809523809523\n",
      "\n",
      "similarity scores   0.1\n",
      "\n",
      "which consisted   0.007246376811594203\n",
      "\n",
      "used more   0.008849557522123894\n",
      "\n",
      "<s> N   0.0007686395080707148\n",
      "\n",
      "sub-sounds ,   1.0\n",
      "\n",
      "by this   0.005714285714285714\n",
      "\n",
      "Dictionary-based Main   0.5\n",
      "\n",
      "paragraph .   0.3333333333333333\n",
      "\n",
      "part-of-speech markers   0.06666666666666667\n",
      "\n",
      "approached in   0.5\n",
      "\n",
      "operational settings   1.0\n",
      "\n",
      "state automata   0.07142857142857142\n",
      "\n",
      "was Pollen   0.012987012987012988\n",
      "\n",
      "-LRB- NLG   0.008130081300813009\n",
      "\n",
      "solved problem   0.4\n",
      "\n",
      "this kind   0.01098901098901099\n",
      "\n",
      "levels as   0.045454545454545456\n",
      "\n",
      "of implementing   0.00089126559714795\n",
      "\n",
      "representation framework   0.05263157894736842\n",
      "\n",
      "inadequate protection   1.0\n",
      "\n",
      "lexicon ,   0.1111111111111111\n",
      "\n",
      "following years   0.06666666666666667\n",
      "\n",
      "sound .   0.05\n",
      "\n",
      "ambiguous word   0.08333333333333333\n",
      "\n",
      "and context   0.004335260115606936\n",
      "\n",
      "opportunity to   0.5\n",
      "\n",
      "disabilities that   0.25\n",
      "\n",
      "so for   0.03333333333333333\n",
      "\n",
      "started the   0.25\n",
      "\n",
      "MIT .   0.5\n",
      "\n",
      "in many   0.0149812734082397\n",
      "\n",
      "algorithms have   0.08571428571428572\n",
      "\n",
      "is precision   0.0020325203252032522\n",
      "\n",
      "rev ,   1.0\n",
      "\n",
      "straightforward PCFGs   1.0\n",
      "\n",
      "an epidemic   0.007575757575757576\n",
      "\n",
      "raised in   1.0\n",
      "\n",
      "images environment   0.16666666666666666\n",
      "\n",
      "became the   0.2\n",
      "\n",
      "tagging words   0.04\n",
      "\n",
      "While some   0.2\n",
      "\n",
      "of natural   0.0196078431372549\n",
      "\n",
      "is able   0.0020325203252032522\n",
      "\n",
      "Brazil ,   1.0\n",
      "\n",
      "cases --   0.05555555555555555\n",
      "\n",
      "LDA-based projection   1.0\n",
      "\n",
      "funding Measuring   0.125\n",
      "\n",
      "latter as   1.0\n",
      "\n",
      "impossibility of   1.0\n",
      "\n",
      "embedded quotations   0.25\n",
      "\n",
      "more widespread   0.010526315789473684\n",
      "\n",
      "benefits to   0.5\n",
      "\n",
      "problem because   0.022727272727272728\n",
      "\n",
      "not consistently   0.017857142857142856\n",
      "\n",
      "context .   0.21212121212121213\n",
      "\n",
      "rate is   0.18181818181818182\n",
      "\n",
      "handover system   1.0\n",
      "\n",
      "1977 -RRB-   1.0\n",
      "\n",
      "by using   0.017142857142857144\n",
      "\n",
      "statistical language   0.030303030303030304\n",
      "\n",
      "English grammars   0.02702702702702703\n",
      "\n",
      "devices .   0.5\n",
      "\n",
      "rated with   1.0\n",
      "\n",
      "ways to   0.125\n",
      "\n",
      "human-made model   0.5\n",
      "\n",
      "fulfill the   0.5\n",
      "\n",
      "requires a   0.0625\n",
      "\n",
      "single words   0.07142857142857142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "be labeled   0.004219409282700422\n",
      "\n",
      "evaluations such   0.16666666666666666\n",
      "\n",
      "much funding   0.045454545454545456\n",
      "\n",
      "and methods   0.001445086705202312\n",
      "\n",
      "<s> More   0.006149116064565719\n",
      "\n",
      "may depend   0.019230769230769232\n",
      "\n",
      ", spoken   0.0005614823133071309\n",
      "\n",
      "phoneme ,   0.5\n",
      "\n",
      "12 such   0.2\n",
      "\n",
      "corpus in   0.06451612903225806\n",
      "\n",
      ", real   0.0005614823133071309\n",
      "\n",
      "Postal Service   1.0\n",
      "\n",
      "-RRB- Speech   0.0027100271002710027\n",
      "\n",
      "human speech   0.021739130434782608\n",
      "\n",
      "possibilities must   0.2\n",
      "\n",
      "user could   0.07142857142857142\n",
      "\n",
      "is a   0.10975609756097561\n",
      "\n",
      "among others   0.125\n",
      "\n",
      "and inspired   0.001445086705202312\n",
      "\n",
      "answers rather   0.08333333333333333\n",
      "\n",
      ": an   0.00980392156862745\n",
      "\n",
      "Speech Recognition   0.0967741935483871\n",
      "\n",
      "Adriana Bolivar   1.0\n",
      "\n",
      "decade in   0.3333333333333333\n",
      "\n",
      "n being   0.5\n",
      "\n",
      "representation .   0.21052631578947367\n",
      "\n",
      "A well-known   0.02\n",
      "\n",
      "not pre   0.008928571428571428\n",
      "\n",
      "Foucault himself   0.3333333333333333\n",
      "\n",
      "Vocabulary Size   0.3333333333333333\n",
      "\n",
      "rudimentary way   0.5\n",
      "\n",
      "from 71   0.009615384615384616\n",
      "\n",
      "the operation   0.0006920415224913495\n",
      "\n",
      ", leaving   0.0005614823133071309\n",
      "\n",
      "Technology Integration   0.3333333333333333\n",
      "\n",
      "To overcome   0.1111111111111111\n",
      "\n",
      "perhaps surprisingly   0.16666666666666666\n",
      "\n",
      "problems Processes   0.058823529411764705\n",
      "\n",
      "Discourse analysis   1.0\n",
      "\n",
      "the realm   0.0006920415224913495\n",
      "\n",
      "have the   0.009615384615384616\n",
      "\n",
      "a page   0.001226993865030675\n",
      "\n",
      "characters and   0.0625\n",
      "\n",
      "<s> Dynamic   0.0023059185242121443\n",
      "\n",
      "-RRB- by   0.0027100271002710027\n",
      "\n",
      "the closest   0.0006920415224913495\n",
      "\n",
      "Shared tasks   1.0\n",
      "\n",
      "user are   0.07142857142857142\n",
      "\n",
      "features or   0.038461538461538464\n",
      "\n",
      "resources and   0.16666666666666666\n",
      "\n",
      "by further   0.005714285714285714\n",
      "\n",
      "which involves   0.007246376811594203\n",
      "\n",
      "are four   0.004149377593360996\n",
      "\n",
      ", deciding   0.0022459292532285235\n",
      "\n",
      "reliance on   1.0\n",
      "\n",
      "D. ,   0.4\n",
      "\n",
      "automatic is   0.043478260869565216\n",
      "\n",
      "interjection .   1.0\n",
      "\n",
      "set ,   0.05128205128205128\n",
      "\n",
      "for without   0.0036101083032490976\n",
      "\n",
      "presume a   1.0\n",
      "\n",
      "software often   0.037037037037037035\n",
      "\n",
      "mainly the   0.16666666666666666\n",
      "\n",
      "its main   0.02857142857142857\n",
      "\n",
      "single language   0.07142857142857142\n",
      "\n",
      "are unambiguous   0.004149377593360996\n",
      "\n",
      "pre-process data   1.0\n",
      "\n",
      "process The   0.027777777777777776\n",
      "\n",
      "the program   0.0020761245674740486\n",
      "\n",
      "Example-based Main   0.3333333333333333\n",
      "\n",
      ", -RRB-   0.0005614823133071309\n",
      "\n",
      "high ,   0.05555555555555555\n",
      "\n",
      "code .   0.42857142857142855\n",
      "\n",
      "article and   0.06896551724137931\n",
      "\n",
      "with any   0.00546448087431694\n",
      "\n",
      "widespread .   1.0\n",
      "\n",
      "signal can   0.3333333333333333\n",
      "\n",
      "Projects Agency   1.0\n",
      "\n",
      "hopes to   1.0\n",
      "\n",
      "paper used   0.09090909090909091\n",
      "\n",
      "also concluded   0.014492753623188406\n",
      "\n",
      "The umbrella   0.005208333333333333\n",
      "\n",
      "lexicon and   0.1111111111111111\n",
      "\n",
      "defines the   0.5\n",
      "\n",
      "of Hidden   0.00089126559714795\n",
      "\n",
      "is very   0.012195121951219513\n",
      "\n",
      "languages The   0.02\n",
      "\n",
      "the Technolangue\\/Easy   0.0006920415224913495\n",
      "\n",
      "in domains   0.0018726591760299626\n",
      "\n",
      ", then   0.006176305446378439\n",
      "\n",
      "`` dogs   0.021164021164021163\n",
      "\n",
      "epidemic which   1.0\n",
      "\n",
      "speaker as   0.05555555555555555\n",
      "\n",
      "i.e. ,   0.3684210526315789\n",
      "\n",
      "be a   0.05485232067510549\n",
      "\n",
      "use vocal   0.013888888888888888\n",
      "\n",
      "doctors make   0.3333333333333333\n",
      "\n",
      ", rule-based   0.0005614823133071309\n",
      "\n",
      "of retail   0.00089126559714795\n",
      "\n",
      "bilingual corpus   0.5\n",
      "\n",
      "include .   0.037037037037037035\n",
      "\n",
      "removing stopwords   0.5\n",
      "\n",
      "without having   0.07692307692307693\n",
      "\n",
      "` beyond   0.0625\n",
      "\n",
      "other .   0.02857142857142857\n",
      "\n",
      "possessives into   1.0\n",
      "\n",
      "language -LRB-   0.013513513513513514\n",
      "\n",
      "clues not   0.3333333333333333\n",
      "\n",
      "some languages   0.024096385542168676\n",
      "\n",
      "human --   0.021739130434782608\n",
      "\n",
      "Lauriault\\/Loriot ,   1.0\n",
      "\n",
      "Rosa Caldas-Coulthard   1.0\n",
      "\n",
      "meet Wikipedia   0.25\n",
      "\n",
      "a tagging   0.001226993865030675\n",
      "\n",
      "lengths -RRB-   1.0\n",
      "\n",
      "4 ,   0.2\n",
      "\n",
      "of multimedia   0.00089126559714795\n",
      "\n",
      "neutral or   0.5\n",
      "\n",
      ", Reukos   0.0005614823133071309\n",
      "\n",
      "learning such   0.023255813953488372\n",
      "\n",
      "<s> Typically   0.0007686395080707148\n",
      "\n",
      ": it   0.00980392156862745\n",
      "\n",
      "are numerous   0.004149377593360996\n",
      "\n",
      "many written   0.019230769230769232\n",
      "\n",
      "<s> A   0.033820138355111454\n",
      "\n",
      "occur together   0.2\n",
      "\n",
      "often argued   0.022727272727272728\n",
      "\n",
      "computer analysis   0.022727272727272728\n",
      "\n",
      "many NLP   0.019230769230769232\n",
      "\n",
      "the ``   0.0034602076124567475\n",
      "\n",
      "confusable words   1.0\n",
      "\n",
      "trees .   0.3333333333333333\n",
      "\n",
      "article by   0.034482758620689655\n",
      "\n",
      "available on   0.058823529411764705\n",
      "\n",
      "on content   0.0047169811320754715\n",
      "\n",
      "sentence structure   0.020833333333333332\n",
      "\n",
      "coreference resolution   1.0\n",
      "\n",
      "place at   0.25\n",
      "\n",
      "Generally speaking   0.4\n",
      "\n",
      "theory to   0.07692307692307693\n",
      "\n",
      "accepts some   0.5\n",
      "\n",
      "ambiguous and   0.16666666666666666\n",
      "\n",
      "redundancy .   0.3333333333333333\n",
      "\n",
      "the publication   0.001384083044982699\n",
      "\n",
      "levels will   0.09090909090909091\n",
      "\n",
      "or negative   0.009009009009009009\n",
      "\n",
      "might skip   0.038461538461538464\n",
      "\n",
      "remember the   1.0\n",
      "\n",
      "-LRB- also   0.01084010840108401\n",
      "\n",
      "sentiment .   0.04\n",
      "\n",
      "Interface ,   1.0\n",
      "\n",
      "by describing   0.005714285714285714\n",
      "\n",
      "the European   0.001384083044982699\n",
      "\n",
      "profile feature   0.3333333333333333\n",
      "\n",
      "most importantly   0.017241379310344827\n",
      "\n",
      "stream of   0.5\n",
      "\n",
      "Although these   0.125\n",
      "\n",
      "a valid   0.001226993865030675\n",
      "\n",
      "of great   0.00089126559714795\n",
      "\n",
      "allows for   0.125\n",
      "\n",
      "real estate   0.1111111111111111\n",
      "\n",
      "considered an   0.1111111111111111\n",
      "\n",
      "tonal language   1.0\n",
      "\n",
      "NLP problem   0.0425531914893617\n",
      "\n",
      "consistently achieve   0.3333333333333333\n",
      "\n",
      "the narrowest   0.0006920415224913495\n",
      "\n",
      "generating index   0.2\n",
      "\n",
      "revealing socio-psychological   1.0\n",
      "\n",
      "and one   0.001445086705202312\n",
      "\n",
      "summary '   0.023809523809523808\n",
      "\n",
      "final keyphrases   0.2222222222222222\n",
      "\n",
      "n-gram overlaps   0.5\n",
      "\n",
      "Language understanding   0.08333333333333333\n",
      "\n",
      "is much   0.0040650406504065045\n",
      "\n",
      "sufficient .   0.6\n",
      "\n",
      "was quite   0.012987012987012988\n",
      "\n",
      "evaluation looks   0.018518518518518517\n",
      "\n",
      "computer programs   0.045454545454545456\n",
      "\n",
      "operation of   0.5\n",
      "\n",
      "'s the   0.0196078431372549\n",
      "\n",
      "act theory   0.25\n",
      "\n",
      ", usually   0.002807411566535654\n",
      "\n",
      "of accent   0.00089126559714795\n",
      "\n",
      "e.g. echoes   0.017857142857142856\n",
      "\n",
      "processing would   0.018518518518518517\n",
      "\n",
      "parsing have   0.03571428571428571\n",
      "\n",
      "<s> Parsers   0.0015372790161414297\n",
      "\n",
      "those proved   0.045454545454545456\n",
      "\n",
      "generation technology   0.1111111111111111\n",
      "\n",
      "topics ,   0.14285714285714285\n",
      "\n",
      "template containing   0.25\n",
      "\n",
      "resulting classifier   0.25\n",
      "\n",
      "Greene and   1.0\n",
      "\n",
      "based approach   0.018518518518518517\n",
      "\n",
      "vocabulary sizes   0.125\n",
      "\n",
      "million words   0.3333333333333333\n",
      "\n",
      "taggers and   0.2857142857142857\n",
      "\n",
      "identify objects   0.08333333333333333\n",
      "\n",
      "consecutive words   0.5\n",
      "\n",
      "German capitalizes   0.25\n",
      "\n",
      "are in-principle   0.004149377593360996\n",
      "\n",
      "% ,   0.05128205128205128\n",
      "\n",
      "sentence-level syntax   1.0\n",
      "\n",
      "vertices be   0.1111111111111111\n",
      "\n",
      "Office -LRB-   1.0\n",
      "\n",
      "imaging is   1.0\n",
      "\n",
      "when given   0.05714285714285714\n",
      "\n",
      "It approaches   0.02631578947368421\n",
      "\n",
      "performance on   0.05555555555555555\n",
      "\n",
      ", Gail   0.0005614823133071309\n",
      "\n",
      "this application   0.01098901098901099\n",
      "\n",
      "human -RRB-   0.043478260869565216\n",
      "\n",
      "trees ,   0.5\n",
      "\n",
      "walks .   0.5\n",
      "\n",
      "Spontaneous Speech   1.0\n",
      "\n",
      "any domain   0.03225806451612903\n",
      "\n",
      "discover these   1.0\n",
      "\n",
      ", our   0.0005614823133071309\n",
      "\n",
      "'s that   0.0196078431372549\n",
      "\n",
      "such accuracy   0.008130081300813009\n",
      "\n",
      "December 2010   1.0\n",
      "\n",
      "if documents   0.03571428571428571\n",
      "\n",
      "Web as   0.1111111111111111\n",
      "\n",
      "answer type   0.06666666666666667\n",
      "\n",
      "that overlap   0.0035460992907801418\n",
      "\n",
      "in restricted   0.0018726591760299626\n",
      "\n",
      "might provide   0.038461538461538464\n",
      "\n",
      "and paragraphs   0.001445086705202312\n",
      "\n",
      "- keyphrases   0.0625\n",
      "\n",
      "still used   0.06666666666666667\n",
      "\n",
      "field that   0.07407407407407407\n",
      "\n",
      "a different   0.0036809815950920245\n",
      "\n",
      "software to   0.07407407407407407\n",
      "\n",
      "Archaeology of   1.0\n",
      "\n",
      "that it   0.010638297872340425\n",
      "\n",
      "is getting   0.0040650406504065045\n",
      "\n",
      "by applying   0.005714285714285714\n",
      "\n",
      "software Current   0.037037037037037035\n",
      "\n",
      "SVM ,   1.0\n",
      "\n",
      "along with   1.0\n",
      "\n",
      "breadth and   0.5\n",
      "\n",
      "how they   0.10344827586206896\n",
      "\n",
      "using paraphrases   0.01694915254237288\n",
      "\n",
      "from randomly   0.009615384615384616\n",
      "\n",
      "lookup algorithms   1.0\n",
      "\n",
      ", Wendy   0.0005614823133071309\n",
      "\n",
      "each year   0.022222222222222223\n",
      "\n",
      "the conversion   0.0006920415224913495\n",
      "\n",
      "checked after   0.5\n",
      "\n",
      "what categories   0.03125\n",
      "\n",
      "such phrases   0.008130081300813009\n",
      "\n",
      "prolific inventor   1.0\n",
      "\n",
      "the built   0.0006920415224913495\n",
      "\n",
      "opinion has   0.2\n",
      "\n",
      "criteria ,   0.25\n",
      "\n",
      "NLP evaluation   0.06382978723404255\n",
      "\n",
      "development of   0.5833333333333334\n",
      "\n",
      "summaries must   0.023255813953488372\n",
      "\n",
      "<s> Unfortunately   0.0007686395080707148\n",
      "\n",
      "where natural   0.02857142857142857\n",
      "\n",
      "generate text   0.05555555555555555\n",
      "\n",
      "understanding the   0.12121212121212122\n",
      "\n",
      "II in   0.5\n",
      "\n",
      "As this   0.05555555555555555\n",
      "\n",
      "than in   0.022222222222222223\n",
      "\n",
      "use of   0.2916666666666667\n",
      "\n",
      "language interface   0.006756756756756757\n",
      "\n",
      "available from   0.058823529411764705\n",
      "\n",
      "of existing   0.0017825311942959\n",
      "\n",
      "i.e. so   0.05263157894736842\n",
      "\n",
      "be referenced   0.004219409282700422\n",
      "\n",
      "to decide   0.0026560424966799467\n",
      "\n",
      "form an   0.05\n",
      "\n",
      "<s> Tags   0.0007686395080707148\n",
      "\n",
      "running English   0.3333333333333333\n",
      "\n",
      "telephony ,   0.6666666666666666\n",
      "\n",
      "been tried   0.029411764705882353\n",
      "\n",
      "Style Studies   1.0\n",
      "\n",
      "time and   0.09090909090909091\n",
      "\n",
      "summarization program   0.02\n",
      "\n",
      "Recognition or   0.125\n",
      "\n",
      "translation systems   0.02702702702702703\n",
      "\n",
      "-RRB- may   0.0027100271002710027\n",
      "\n",
      "records is   0.25\n",
      "\n",
      "units such   0.14285714285714285\n",
      "\n",
      "the world   0.0020761245674740486\n",
      "\n",
      "titled Natural   1.0\n",
      "\n",
      "reported for   0.2\n",
      "\n",
      "some perception   0.012048192771084338\n",
      "\n",
      "the equipment   0.0006920415224913495\n",
      "\n",
      "segmentation in   0.030303030303030304\n",
      "\n",
      "`` polarity   0.005291005291005291\n",
      "\n",
      "paragraphs in   0.25\n",
      "\n",
      "the stage   0.0006920415224913495\n",
      "\n",
      "an internal   0.022727272727272728\n",
      "\n",
      "bill payment   0.5\n",
      "\n",
      "program with   0.045454545454545456\n",
      "\n",
      "when reading   0.02857142857142857\n",
      "\n",
      "descriptor in   1.0\n",
      "\n",
      "'' ``   0.005154639175257732\n",
      "\n",
      "modules ,   0.5\n",
      "\n",
      "-- i.e.   0.04\n",
      "\n",
      "negative or   0.125\n",
      "\n",
      "involved disabilities   0.16666666666666666\n",
      "\n",
      "forms can   0.16666666666666666\n",
      "\n",
      "parsers can   0.07692307692307693\n",
      "\n",
      "1950s by   0.25\n",
      "\n",
      "machine -RRB-   0.012658227848101266\n",
      "\n",
      "useful work   0.07142857142857142\n",
      "\n",
      "computer-aided language   0.3333333333333333\n",
      "\n",
      "to make   0.005312084993359893\n",
      "\n",
      "into text   0.038461538461538464\n",
      "\n",
      "resources are   0.16666666666666666\n",
      "\n",
      "not able   0.008928571428571428\n",
      "\n",
      "-LRB- free   0.0027100271002710027\n",
      "\n",
      "word-category disambiguation   1.0\n",
      "\n",
      "Both QA   0.3333333333333333\n",
      "\n",
      "human user   0.043478260869565216\n",
      "\n",
      "do this   0.07692307692307693\n",
      "\n",
      "features ?   0.038461538461538464\n",
      "\n",
      "some cases   0.04819277108433735\n",
      "\n",
      "random surfer   0.14285714285714285\n",
      "\n",
      "those pauses   0.045454545454545456\n",
      "\n",
      "texts can   0.058823529411764705\n",
      "\n",
      ", machine-aided   0.0005614823133071309\n",
      "\n",
      "supervised classification   0.125\n",
      "\n",
      "of Sydney   0.00089126559714795\n",
      "\n",
      "Ticket stock   1.0\n",
      "\n",
      "parsing .   0.10714285714285714\n",
      "\n",
      "expensive ,   0.42857142857142855\n",
      "\n",
      "Tigrinya among   1.0\n",
      "\n",
      "have to   0.019230769230769232\n",
      "\n",
      "personal digital   0.25\n",
      "\n",
      "accuracy can   0.03225806451612903\n",
      "\n",
      "vowels depends   0.3333333333333333\n",
      "\n",
      "over 95   0.08333333333333333\n",
      "\n",
      "on speech   0.0047169811320754715\n",
      "\n",
      "tokens that   0.14285714285714285\n",
      "\n",
      "neighbors .   0.3333333333333333\n",
      "\n",
      "for personal   0.0036101083032490976\n",
      "\n",
      "segmentation and   0.06060606060606061\n",
      "\n",
      "recognizing difficult   0.2\n",
      "\n",
      "the shipment   0.0006920415224913495\n",
      "\n",
      "word divider   0.016666666666666666\n",
      "\n",
      "level provides   0.05\n",
      "\n",
      "second important   0.1\n",
      "\n",
      "as length   0.003484320557491289\n",
      "\n",
      "some NLP   0.012048192771084338\n",
      "\n",
      "first of   0.030303030303030304\n",
      "\n",
      "one video   0.015384615384615385\n",
      "\n",
      "-RRB- ^   0.0027100271002710027\n",
      "\n",
      "The result   0.005208333333333333\n",
      "\n",
      "noise problem   0.125\n",
      "\n",
      "the choice   0.0006920415224913495\n",
      "\n",
      "<s> Commercial   0.0015372790161414297\n",
      "\n",
      "text mining   0.012578616352201259\n",
      "\n",
      "containing words   0.125\n",
      "\n",
      "point scale   0.3333333333333333\n",
      "\n",
      "citations for   0.3333333333333333\n",
      "\n",
      "the title   0.0006920415224913495\n",
      "\n",
      "can compensate   0.0055248618784530384\n",
      "\n",
      "on some   0.04245283018867924\n",
      "\n",
      "at processing   0.014705882352941176\n",
      "\n",
      "limit is   0.25\n",
      "\n",
      "process ``   0.027777777777777776\n",
      "\n",
      "approaches the   0.03571428571428571\n",
      "\n",
      "devised primarily   0.5\n",
      "\n",
      "would check   0.018867924528301886\n",
      "\n",
      "evaluating summaries   0.4\n",
      "\n",
      "although usually   0.16666666666666666\n",
      "\n",
      "neural approaches   0.06666666666666667\n",
      "\n",
      "models derived   0.038461538461538464\n",
      "\n",
      "product .   0.14285714285714285\n",
      "\n",
      "because while   0.03333333333333333\n",
      "\n",
      ": rule-based   0.00980392156862745\n",
      "\n",
      "whether ``   0.07692307692307693\n",
      "\n",
      "4 .   0.4\n",
      "\n",
      "times a   0.2\n",
      "\n",
      "researchers to   0.1\n",
      "\n",
      "retrieval --   0.14285714285714285\n",
      "\n",
      "types of   0.8571428571428571\n",
      "\n",
      "word senses   0.016666666666666666\n",
      "\n",
      ", allowing   0.0005614823133071309\n",
      "\n",
      ", news   0.0005614823133071309\n",
      "\n",
      "typically involve   0.05555555555555555\n",
      "\n",
      "related words   0.06666666666666667\n",
      "\n",
      "Why do   0.14285714285714285\n",
      "\n",
      "Newton pioneered   1.0\n",
      "\n",
      "if and   0.03571428571428571\n",
      "\n",
      "of regular   0.00089126559714795\n",
      "\n",
      "to minimize   0.0013280212483399733\n",
      "\n",
      "models ,   0.07692307692307693\n",
      "\n",
      "to re-encode   0.0013280212483399733\n",
      "\n",
      "uses -LRB-   0.07142857142857142\n",
      "\n",
      "Decoding the   0.5\n",
      "\n",
      "illustrates how   0.5\n",
      "\n",
      "2000 -RRB-   0.3333333333333333\n",
      "\n",
      "or knowledge   0.0045045045045045045\n",
      "\n",
      "of new   0.00089126559714795\n",
      "\n",
      "of N   0.00089126559714795\n",
      "\n",
      ", Winograd   0.0005614823133071309\n",
      "\n",
      "second -RRB-   0.1\n",
      "\n",
      "area of   0.45454545454545453\n",
      "\n",
      "e.g. elaboration   0.017857142857142856\n",
      "\n",
      "proposed what   0.1111111111111111\n",
      "\n",
      "most of   0.08620689655172414\n",
      "\n",
      "the ANR-Passage   0.0006920415224913495\n",
      "\n",
      "vertices is   0.1111111111111111\n",
      "\n",
      "- A   0.0625\n",
      "\n",
      "`` Red   0.005291005291005291\n",
      "\n",
      "the disfluences   0.0006920415224913495\n",
      "\n",
      "widely-reported news   1.0\n",
      "\n",
      "% correct   0.02564102564102564\n",
      "\n",
      "never been   0.4\n",
      "\n",
      "believed that   1.0\n",
      "\n",
      "analysis to   0.015384615384615385\n",
      "\n",
      "USAF ,   1.0\n",
      "\n",
      "the BLEU   0.0006920415224913495\n",
      "\n",
      "or people   0.009009009009009009\n",
      "\n",
      "creates new   0.5\n",
      "\n",
      "ideas -RRB-   0.25\n",
      "\n",
      "-LRB- NLP   0.008130081300813009\n",
      "\n",
      "resources ,   0.3333333333333333\n",
      "\n",
      "from single   0.009615384615384616\n",
      "\n",
      "approach involves   0.02857142857142857\n",
      "\n",
      "effectiveness of   0.3333333333333333\n",
      "\n",
      "information retrieval   0.10869565217391304\n",
      "\n",
      "texts written   0.058823529411764705\n",
      "\n",
      "and analytical   0.001445086705202312\n",
      "\n",
      "methods try   0.022727272727272728\n",
      "\n",
      "Blind -LRB-   0.5\n",
      "\n",
      "in medical   0.0018726591760299626\n",
      "\n",
      "be confused   0.004219409282700422\n",
      "\n",
      "Direct Voice   1.0\n",
      "\n",
      "N in   0.3333333333333333\n",
      "\n",
      ", Naive   0.0005614823133071309\n",
      "\n",
      "the phenomenon   0.001384083044982699\n",
      "\n",
      "a factory   0.001226993865030675\n",
      "\n",
      "now largely   0.07692307692307693\n",
      "\n",
      "versus ``   1.0\n",
      "\n",
      "semantic relationship   0.047619047619047616\n",
      "\n",
      "uses only   0.07142857142857142\n",
      "\n",
      "or word-category   0.0045045045045045045\n",
      "\n",
      "components operating   0.2\n",
      "\n",
      "typically how   0.05555555555555555\n",
      "\n",
      "rates on   0.125\n",
      "\n",
      "word segmentation   0.05\n",
      "\n",
      "proper noun   0.14285714285714285\n",
      "\n",
      "the tagset   0.0006920415224913495\n",
      "\n",
      "Turney with   0.1111111111111111\n",
      "\n",
      "undirected and   1.0\n",
      "\n",
      "rules from   0.023255813953488372\n",
      "\n",
      "corporation does   1.0\n",
      "\n",
      "OCR-A font   1.0\n",
      "\n",
      "impact on   0.5\n",
      "\n",
      "be the   0.012658227848101266\n",
      "\n",
      "Du Bois   1.0\n",
      "\n",
      "in linguistic   0.003745318352059925\n",
      "\n",
      "Garfinkel who   1.0\n",
      "\n",
      "nouns or   0.1111111111111111\n",
      "\n",
      "eliminate redundancy   0.5\n",
      "\n",
      "therefore help   0.2\n",
      "\n",
      "term parsing   0.05555555555555555\n",
      "\n",
      "as supervised   0.003484320557491289\n",
      "\n",
      "<s> Beginning   0.0007686395080707148\n",
      "\n",
      "to natural   0.0013280212483399733\n",
      "\n",
      "suitability as   0.5\n",
      "\n",
      "in this   0.018726591760299626\n",
      "\n",
      "yielding thousands   1.0\n",
      "\n",
      "complex than   0.08333333333333333\n",
      "\n",
      "interact with   1.0\n",
      "\n",
      "Press ''   1.0\n",
      "\n",
      "it will   0.017094017094017096\n",
      "\n",
      "Once performed   0.4\n",
      "\n",
      "should we   0.05263157894736842\n",
      "\n",
      "dog to   0.3333333333333333\n",
      "\n",
      "groups within   0.2\n",
      "\n",
      "machine-learning approach   0.25\n",
      "\n",
      "the POS   0.0020761245674740486\n",
      "\n",
      "applications there   0.04\n",
      "\n",
      "is routed   0.0040650406504065045\n",
      "\n",
      "vectors would   0.3333333333333333\n",
      "\n",
      "of planning   0.00089126559714795\n",
      "\n",
      "sentences into   0.039473684210526314\n",
      "\n",
      "areas of   0.3333333333333333\n",
      "\n",
      "Parseval\\/GEIG project   1.0\n",
      "\n",
      "does ,   0.1\n",
      "\n",
      "are explicitly   0.004149377593360996\n",
      "\n",
      "chosen .   0.2\n",
      "\n",
      "continued research   0.2222222222222222\n",
      "\n",
      "Several papers   0.3333333333333333\n",
      "\n",
      "into readable   0.01282051282051282\n",
      "\n",
      "simple procedure   0.038461538461538464\n",
      "\n",
      "structured resources   0.16666666666666666\n",
      "\n",
      "to reflect   0.0013280212483399733\n",
      "\n",
      "Many Electronic   0.08333333333333333\n",
      "\n",
      "table that   0.14285714285714285\n",
      "\n",
      "question-answering abilities   0.5\n",
      "\n",
      "and find   0.001445086705202312\n",
      "\n",
      "accepted ,   1.0\n",
      "\n",
      "2011 campaign   0.5\n",
      "\n",
      "complete sentences   1.0\n",
      "\n",
      "task -LRB-   0.023809523809523808\n",
      "\n",
      "the formal   0.001384083044982699\n",
      "\n",
      "the development   0.0034602076124567475\n",
      "\n",
      "and on   0.002890173410404624\n",
      "\n",
      "no assumptions   0.07692307692307693\n",
      "\n",
      "following example   0.13333333333333333\n",
      "\n",
      "one another   0.015384615384615385\n",
      "\n",
      "identified which   0.2\n",
      "\n",
      "random walks   0.2857142857142857\n",
      "\n",
      "in system   0.0018726591760299626\n",
      "\n",
      "useful as   0.07142857142857142\n",
      "\n",
      "example-generation strategy   1.0\n",
      "\n",
      "they take   0.025\n",
      "\n",
      "from limited   0.009615384615384616\n",
      "\n",
      "a five-star   0.001226993865030675\n",
      "\n",
      "more likely   0.010526315789473684\n",
      "\n",
      "that access   0.0035460992907801418\n",
      "\n",
      "the need   0.0020761245674740486\n",
      "\n",
      "very different   0.07317073170731707\n",
      "\n",
      "many as   0.019230769230769232\n",
      "\n",
      "that difference   0.0035460992907801418\n",
      "\n",
      "modifying words   1.0\n",
      "\n",
      "speed ,   0.2857142857142857\n",
      "\n",
      "grammars often   0.07142857142857142\n",
      "\n",
      "Applied linguistics   0.5\n",
      "\n",
      "judges can   0.5\n",
      "\n",
      "how summarization   0.034482758620689655\n",
      "\n",
      "of spectral-domain   0.00089126559714795\n",
      "\n",
      "measure of   0.18181818181818182\n",
      "\n",
      "proposed as   0.1111111111111111\n",
      "\n",
      ", whether   0.0005614823133071309\n",
      "\n",
      "digitized ,   1.0\n",
      "\n",
      "-LRB- closer   0.0027100271002710027\n",
      "\n",
      "the actual   0.0020761245674740486\n",
      "\n",
      "Mirage aircraft   1.0\n",
      "\n",
      "can use   0.016574585635359115\n",
      "\n",
      "successfully adapted   0.3333333333333333\n",
      "\n",
      "rules --   0.023255813953488372\n",
      "\n",
      "HTML and   1.0\n",
      "\n",
      "features like   0.038461538461538464\n",
      "\n",
      "the identity   0.002768166089965398\n",
      "\n",
      "a gradually   0.001226993865030675\n",
      "\n",
      "first such   0.030303030303030304\n",
      "\n",
      "are too   0.004149377593360996\n",
      "\n",
      "making a   0.14285714285714285\n",
      "\n",
      "' lengths   0.05263157894736842\n",
      "\n",
      "wave is   0.2222222222222222\n",
      "\n",
      "that we   0.010638297872340425\n",
      "\n",
      "a better   0.00245398773006135\n",
      "\n",
      "simply using   0.08333333333333333\n",
      "\n",
      "the question   0.011072664359861591\n",
      "\n",
      "details the   0.5\n",
      "\n",
      "with Optical   0.00546448087431694\n",
      "\n",
      "Working with   1.0\n",
      "\n",
      "decision-making ,   1.0\n",
      "\n",
      "sounds :   0.06666666666666667\n",
      "\n",
      "forecast -LRB-   1.0\n",
      "\n",
      "the effort   0.0006920415224913495\n",
      "\n",
      "several quality   0.045454545454545456\n",
      "\n",
      "information in   0.043478260869565216\n",
      "\n",
      "team led   1.0\n",
      "\n",
      "<s> Markov   0.0007686395080707148\n",
      "\n",
      "Since 2000   0.2\n",
      "\n",
      "for approximating   0.0036101083032490976\n",
      "\n",
      "step the   0.06666666666666667\n",
      "\n",
      "Many ATC   0.08333333333333333\n",
      "\n",
      "keyphrase using   0.05263157894736842\n",
      "\n",
      "poorly defined   1.0\n",
      "\n",
      "summaries of   0.09302325581395349\n",
      "\n",
      "writing SHRDLU   0.1111111111111111\n",
      "\n",
      "input ;   0.024390243902439025\n",
      "\n",
      "incorrect letters   0.3333333333333333\n",
      "\n",
      "and their   0.008670520231213872\n",
      "\n",
      "translation when   0.013513513513513514\n",
      "\n",
      "may be   0.40384615384615385\n",
      "\n",
      "the ROUGE   0.0006920415224913495\n",
      "\n",
      "computers ,   0.2222222222222222\n",
      "\n",
      "adverbs ,   1.0\n",
      "\n",
      "reducing training   0.5\n",
      "\n",
      "Encouraging results   1.0\n",
      "\n",
      "e-communities through   0.5\n",
      "\n",
      ", Speech   0.0016844469399213925\n",
      "\n",
      "last night   0.2\n",
      "\n",
      "by trying   0.005714285714285714\n",
      "\n",
      "to words   0.0013280212483399733\n",
      "\n",
      "recognition and   0.05785123966942149\n",
      "\n",
      "boundary markers   0.16666666666666666\n",
      "\n",
      "recognition research   0.008264462809917356\n",
      "\n",
      "comprehensive survey   0.2\n",
      "\n",
      "In 1983   0.009523809523809525\n",
      "\n",
      "is challenging   0.0020325203252032522\n",
      "\n",
      "other systems   0.02857142857142857\n",
      "\n",
      "paraphrasing sections   1.0\n",
      "\n",
      "factor -LRB-   0.5\n",
      "\n",
      "runs PageRank   1.0\n",
      "\n",
      "MIT wrote   0.5\n",
      "\n",
      "`` up   0.005291005291005291\n",
      "\n",
      "Formal equivalence   1.0\n",
      "\n",
      "had failed   0.14285714285714285\n",
      "\n",
      "paradigm includes   0.3333333333333333\n",
      "\n",
      "Question book-new   0.14285714285714285\n",
      "\n",
      "solely on   1.0\n",
      "\n",
      "Given an   0.07142857142857142\n",
      "\n",
      "Word segmentation   0.14285714285714285\n",
      "\n",
      "stage of   0.4\n",
      "\n",
      "`` Gismo   0.010582010582010581\n",
      "\n",
      "only into   0.02631578947368421\n",
      "\n",
      "a cheque   0.001226993865030675\n",
      "\n",
      "Intelligence ''   0.3333333333333333\n",
      "\n",
      "not well   0.008928571428571428\n",
      "\n",
      "in parametric   0.0018726591760299626\n",
      "\n",
      "design feature   0.25\n",
      "\n",
      "BLEU is   0.3333333333333333\n",
      "\n",
      "recorded speech   0.5\n",
      "\n",
      "plural common   0.2\n",
      "\n",
      "simple voice   0.038461538461538464\n",
      "\n",
      "are interpreted   0.004149377593360996\n",
      "\n",
      ": List   0.00980392156862745\n",
      "\n",
      "content-analysis .   1.0\n",
      "\n",
      "to be   0.057104913678618856\n",
      "\n",
      "rhetoric ,   1.0\n",
      "\n",
      "language Prolog   0.006756756756756757\n",
      "\n",
      "would choose   0.018867924528301886\n",
      "\n",
      "original voice   0.07692307692307693\n",
      "\n",
      "or less   0.018018018018018018\n",
      "\n",
      "of his   0.00267379679144385\n",
      "\n",
      "references ,   0.25\n",
      "\n",
      "running publication   0.3333333333333333\n",
      "\n",
      "<s> BASEBALL   0.0007686395080707148\n",
      "\n",
      ", syntax   0.0011229646266142617\n",
      "\n",
      "<s> Matches   0.0007686395080707148\n",
      "\n",
      "January 13   0.25\n",
      "\n",
      "insight into   1.0\n",
      "\n",
      "be further   0.004219409282700422\n",
      "\n",
      "way to   0.4166666666666667\n",
      "\n",
      "an extrinsic   0.007575757575757576\n",
      "\n",
      "and architecture   0.001445086705202312\n",
      "\n",
      "understand ''   0.14285714285714285\n",
      "\n",
      "a necessary   0.001226993865030675\n",
      "\n",
      "off-line character   1.0\n",
      "\n",
      "helps doctors   0.5\n",
      "\n",
      "semi -   1.0\n",
      "\n",
      "were undertaken   0.024390243902439025\n",
      "\n",
      "phones .   0.5\n",
      "\n",
      "biomedical domain   1.0\n",
      "\n",
      "opens ,   1.0\n",
      "\n",
      "real-world knowledge   0.16666666666666666\n",
      "\n",
      "bills returned   1.0\n",
      "\n",
      "concerned in   0.2\n",
      "\n",
      "'s results   0.0196078431372549\n",
      "\n",
      "engines to   0.3333333333333333\n",
      "\n",
      "entered John   0.5\n",
      "\n",
      "or highly   0.0045045045045045045\n",
      "\n",
      "the true   0.0006920415224913495\n",
      "\n",
      "taggers The   0.14285714285714285\n",
      "\n",
      "standard metric   0.07142857142857142\n",
      "\n",
      "workshops ,   0.5\n",
      "\n",
      "certainty of   1.0\n",
      "\n",
      "system-generated summary   0.5\n",
      "\n",
      "smaller lexical   0.14285714285714285\n",
      "\n",
      "the memory   0.0006920415224913495\n",
      "\n",
      "relationships among   0.16666666666666666\n",
      "\n",
      "the identities   0.0006920415224913495\n",
      "\n",
      "Hardy ,   1.0\n",
      "\n",
      "Search collections   0.5\n",
      "\n",
      "Authorities in   1.0\n",
      "\n",
      "-LRB- Hirschman   0.0027100271002710027\n",
      "\n",
      "languages contain   0.02\n",
      "\n",
      "1965 it   0.25\n",
      "\n",
      "or most   0.0045045045045045045\n",
      "\n",
      "; otherwise   0.02127659574468085\n",
      "\n",
      "distant from   1.0\n",
      "\n",
      "she were   1.0\n",
      "\n",
      "tag probabilities   0.0625\n",
      "\n",
      "words that   0.009174311926605505\n",
      "\n",
      "Tauschek had   0.5\n",
      "\n",
      "methods is   0.022727272727272728\n",
      "\n",
      "parsed by   0.75\n",
      "\n",
      "processing Statistical   0.018518518518518517\n",
      "\n",
      "to a   0.03718459495351926\n",
      "\n",
      ", glossary   0.0011229646266142617\n",
      "\n",
      "are connected   0.004149377593360996\n",
      "\n",
      "and duplicate   0.001445086705202312\n",
      "\n",
      "support question   0.25\n",
      "\n",
      "wide range   0.5\n",
      "\n",
      "to consistently   0.0013280212483399733\n",
      "\n",
      "consideration the   0.3333333333333333\n",
      "\n",
      ", due   0.0005614823133071309\n",
      "\n",
      ", and   0.10612015721504772\n",
      "\n",
      "professionals .   1.0\n",
      "\n",
      "In 2002   0.009523809523809525\n",
      "\n",
      "significantly .   1.0\n",
      "\n",
      "role of   0.25\n",
      "\n",
      "retrieval module   0.14285714285714285\n",
      "\n",
      "accuracy substantially   0.03225806451612903\n",
      "\n",
      "the American   0.001384083044982699\n",
      "\n",
      "their ``   0.029411764705882353\n",
      "\n",
      "parse tree   0.1111111111111111\n",
      "\n",
      "background noise   0.3333333333333333\n",
      "\n",
      "each character   0.022222222222222223\n",
      "\n",
      "Progress mainly   1.0\n",
      "\n",
      "systems depended   0.008928571428571428\n",
      "\n",
      "direct a   0.16666666666666666\n",
      "\n",
      "new complex   0.041666666666666664\n",
      "\n",
      "has little   0.011904761904761904\n",
      "\n",
      "of John   0.00089126559714795\n",
      "\n",
      "need as   0.047619047619047616\n",
      "\n",
      "A technique   0.02\n",
      "\n",
      "they belong   0.025\n",
      "\n",
      "following the   0.06666666666666667\n",
      "\n",
      "field comes   0.037037037037037035\n",
      "\n",
      "recognize all   0.1111111111111111\n",
      "\n",
      "OCR patents   0.02040816326530612\n",
      "\n",
      "itself while   0.2\n",
      "\n",
      "keyboard a   0.3333333333333333\n",
      "\n",
      "applications discussed   0.04\n",
      "\n",
      "e.g. yes-no   0.017857142857142856\n",
      "\n",
      "tasks has   0.03125\n",
      "\n",
      "trained on   0.3333333333333333\n",
      "\n",
      "one within   0.015384615384615385\n",
      "\n",
      "can ''   0.011049723756906077\n",
      "\n",
      "depths of   1.0\n",
      "\n",
      "create ''   0.058823529411764705\n",
      "\n",
      "by Turney   0.005714285714285714\n",
      "\n",
      "to appear   0.0026560424966799467\n",
      "\n",
      "in 1952   0.0018726591760299626\n",
      "\n",
      ", Ruth   0.0005614823133071309\n",
      "\n",
      "first customers   0.030303030303030304\n",
      "\n",
      "also being   0.014492753623188406\n",
      "\n",
      "advertisements .   1.0\n",
      "\n",
      "HMM-based approach   0.6666666666666666\n",
      "\n",
      "maintained by   0.5\n",
      "\n",
      "see the   0.1\n",
      "\n",
      "psychology ,   0.75\n",
      "\n",
      ", Screenshot   0.0005614823133071309\n",
      "\n",
      ", Steven   0.0005614823133071309\n",
      "\n",
      "to return   0.0026560424966799467\n",
      "\n",
      "understanding in   0.030303030303030304\n",
      "\n",
      "proposal for   1.0\n",
      "\n",
      "? ''   0.375\n",
      "\n",
      "Such perceptions   0.125\n",
      "\n",
      "of meaningful   0.00089126559714795\n",
      "\n",
      "problem for   0.022727272727272728\n",
      "\n",
      "and control   0.004335260115606936\n",
      "\n",
      "extract a   0.25\n",
      "\n",
      "DA began   0.3333333333333333\n",
      "\n",
      "stationary probability   0.14285714285714285\n",
      "\n",
      "units ,   0.14285714285714285\n",
      "\n",
      "`` tagged   0.010582010582010581\n",
      "\n",
      "Intelligence and   0.3333333333333333\n",
      "\n",
      "the nautical   0.0006920415224913495\n",
      "\n",
      "after John   0.08333333333333333\n",
      "\n",
      "considers the   0.5\n",
      "\n",
      "use\\/mention distinction   1.0\n",
      "\n",
      "worked out   0.2\n",
      "\n",
      "hub ''   1.0\n",
      "\n",
      "to capture   0.0013280212483399733\n",
      "\n",
      ", ''   0.0016844469399213925\n",
      "\n",
      "history -RRB-   0.25\n",
      "\n",
      "below .   0.4\n",
      "\n",
      "the goals   0.0006920415224913495\n",
      "\n",
      "or opinion   0.0045045045045045045\n",
      "\n",
      "often rely   0.022727272727272728\n",
      "\n",
      ", researchers   0.0011229646266142617\n",
      "\n",
      "Italian ;   0.5\n",
      "\n",
      "future tense   0.3333333333333333\n",
      "\n",
      "during World   0.1\n",
      "\n",
      "by Zellig   0.005714285714285714\n",
      "\n",
      "Unsupervised keyphrase   0.3333333333333333\n",
      "\n",
      "expressions .   0.6666666666666666\n",
      "\n",
      "the more   0.0034602076124567475\n",
      "\n",
      "letters are   0.1\n",
      "\n",
      "can translate   0.0055248618784530384\n",
      "\n",
      "produces Grass   0.25\n",
      "\n",
      "strategies ,   0.5\n",
      "\n",
      "adjectives .   0.3333333333333333\n",
      "\n",
      "semantics ,   0.2857142857142857\n",
      "\n",
      ", Chantal   0.0005614823133071309\n",
      "\n",
      "is having   0.0020325203252032522\n",
      "\n",
      "and neural   0.002890173410404624\n",
      "\n",
      "For the   0.01639344262295082\n",
      "\n",
      "problem is   0.11363636363636363\n",
      "\n",
      "get bunch   0.14285714285714285\n",
      "\n",
      "returned with   0.25\n",
      "\n",
      "thus require   0.1\n",
      "\n",
      "linguistic informational   0.0625\n",
      "\n",
      "word -RRB-   0.016666666666666666\n",
      "\n",
      "post-processing step   0.6666666666666666\n",
      "\n",
      "scale -RRB-   0.16666666666666666\n",
      "\n",
      "point ,   0.6666666666666666\n",
      "\n",
      "project and   0.07692307692307693\n",
      "\n",
      "belongs to   1.0\n",
      "\n",
      "Scansoft ,   1.0\n",
      "\n",
      "<s> Constraints   0.0007686395080707148\n",
      "\n",
      "of assembling   0.00089126559714795\n",
      "\n",
      "in statistical   0.003745318352059925\n",
      "\n",
      ", NLG   0.0005614823133071309\n",
      "\n",
      "singular proper   0.25\n",
      "\n",
      "text-to-speech synthesizer   0.25\n",
      "\n",
      "to submit   0.0013280212483399733\n",
      "\n",
      "These rules   0.058823529411764705\n",
      "\n",
      "intervention :   1.0\n",
      "\n",
      "tend to   1.0\n",
      "\n",
      "the HTK   0.0006920415224913495\n",
      "\n",
      "other areas   0.02857142857142857\n",
      "\n",
      "most summarization   0.017241379310344827\n",
      "\n",
      "Commissioned by   1.0\n",
      "\n",
      "certain cases   0.14285714285714285\n",
      "\n",
      "multimedia -LRB-   0.5\n",
      "\n",
      "we hear   0.022222222222222223\n",
      "\n",
      "thus speech   0.1\n",
      "\n",
      "performed by   0.2\n",
      "\n",
      "for .   0.0036101083032490976\n",
      "\n",
      ": The   0.0392156862745098\n",
      "\n",
      "commands are   0.2\n",
      "\n",
      "language require   0.006756756756756757\n",
      "\n",
      "to 98   0.0013280212483399733\n",
      "\n",
      "Later ,   1.0\n",
      "\n",
      "dividing speech   0.3333333333333333\n",
      "\n",
      "for test   0.0036101083032490976\n",
      "\n",
      "-RRB- This   0.0027100271002710027\n",
      "\n",
      "humans ,   0.16666666666666666\n",
      "\n",
      "Ann Arbor   1.0\n",
      "\n",
      "of unstructured   0.00089126559714795\n",
      "\n",
      "versions of   0.3333333333333333\n",
      "\n",
      "vocabulary and   0.25\n",
      "\n",
      "without inter-word   0.07692307692307693\n",
      "\n",
      "QUALM -LRB-   1.0\n",
      "\n",
      ", pollen   0.0005614823133071309\n",
      "\n",
      "be to   0.008438818565400843\n",
      "\n",
      "the feature   0.0006920415224913495\n",
      "\n",
      "systems were   0.05357142857142857\n",
      "\n",
      "increasingly difficult   0.3333333333333333\n",
      "\n",
      "first came   0.030303030303030304\n",
      "\n",
      "many stochastic   0.019230769230769232\n",
      "\n",
      "training in   0.03571428571428571\n",
      "\n",
      "suitable ontology   0.25\n",
      "\n",
      "perspective so   0.25\n",
      "\n",
      "Please help   0.6666666666666666\n",
      "\n",
      "Deborah Tannen   0.5\n",
      "\n",
      "` the   0.0625\n",
      "\n",
      "Bayes risk   0.3333333333333333\n",
      "\n",
      "some variant   0.012048192771084338\n",
      "\n",
      "reviews ,   0.5\n",
      "\n",
      "technologies have   0.25\n",
      "\n",
      "of large   0.0035650623885918\n",
      "\n",
      "up for   0.09090909090909091\n",
      "\n",
      "of whom   0.00089126559714795\n",
      "\n",
      "converted them   0.3333333333333333\n",
      "\n",
      "walking slowly   0.3333333333333333\n",
      "\n",
      "be distinguished   0.004219409282700422\n",
      "\n",
      "generate textual   0.05555555555555555\n",
      "\n",
      "relative probability   0.3333333333333333\n",
      "\n",
      "pages getting   0.14285714285714285\n",
      "\n",
      ", modern   0.0005614823133071309\n",
      "\n",
      "a patent   0.00245398773006135\n",
      "\n",
      "known to   0.07692307692307693\n",
      "\n",
      "painstakingly ``   1.0\n",
      "\n",
      "the summarization   0.0020761245674740486\n",
      "\n",
      "a widely-reported   0.001226993865030675\n",
      "\n",
      "interactive program   0.25\n",
      "\n",
      "summaries known   0.023255813953488372\n",
      "\n",
      "machine-translation research   0.5\n",
      "\n",
      "now called   0.07692307692307693\n",
      "\n",
      "speech commands   0.006578947368421052\n",
      "\n",
      "performance ,   0.1111111111111111\n",
      "\n",
      "the reCAPTCHA   0.0006920415224913495\n",
      "\n",
      "of 5   0.00089126559714795\n",
      "\n",
      "to rate   0.0026560424966799467\n",
      "\n",
      "disambiguation .   0.1\n",
      "\n",
      "an NLG   0.007575757575757576\n",
      "\n",
      "the emergence   0.0006920415224913495\n",
      "\n",
      "an LDA-based   0.007575757575757576\n",
      "\n",
      "in processing   0.0018726591760299626\n",
      "\n",
      "would thus   0.018867924528301886\n",
      "\n",
      "functional languages   0.5\n",
      "\n",
      "Optophone ,   1.0\n",
      "\n",
      "classifies features   1.0\n",
      "\n",
      "those languages   0.09090909090909091\n",
      "\n",
      "'' corpora   0.005154639175257732\n",
      "\n",
      ", low-resolution   0.0005614823133071309\n",
      "\n",
      "whose easy-to-use   0.3333333333333333\n",
      "\n",
      "the history   0.0006920415224913495\n",
      "\n",
      "from context   0.009615384615384616\n",
      "\n",
      "warping is   0.5\n",
      "\n",
      "Natural Language   0.25\n",
      "\n",
      "modal .   1.0\n",
      "\n",
      "from false   0.009615384615384616\n",
      "\n",
      "see for   0.05\n",
      "\n",
      "simulators with   1.0\n",
      "\n",
      "language constraints   0.006756756756756757\n",
      "\n",
      "Phillips .   1.0\n",
      "\n",
      "are generally   0.016597510373443983\n",
      "\n",
      "the questions   0.0006920415224913495\n",
      "\n",
      "appear ,   0.0625\n",
      "\n",
      "Nelson Francis   1.0\n",
      "\n",
      "may well   0.019230769230769232\n",
      "\n",
      ", Carmen   0.0005614823133071309\n",
      "\n",
      "provide a   0.3333333333333333\n",
      "\n",
      "or custom   0.0045045045045045045\n",
      "\n",
      "logical ,   0.16666666666666666\n",
      "\n",
      "adaptive summarization   0.6666666666666666\n",
      "\n",
      "resulting in   0.25\n",
      "\n",
      "sounds very   0.06666666666666667\n",
      "\n",
      "tagging by   0.04\n",
      "\n",
      "Wendy Lehnert   1.0\n",
      "\n",
      "construct lightweight   0.3333333333333333\n",
      "\n",
      "In theory   0.01904761904761905\n",
      "\n",
      "their closest   0.029411764705882353\n",
      "\n",
      "to databases   0.0013280212483399733\n",
      "\n",
      "analyses ,   0.2\n",
      "\n",
      "displaced by   1.0\n",
      "\n",
      "most important   0.034482758620689655\n",
      "\n",
      "above --   0.07692307692307693\n",
      "\n",
      "Corpus -LRB-   0.0625\n",
      "\n",
      "to news-gathering   0.0013280212483399733\n",
      "\n",
      "appear more   0.0625\n",
      "\n",
      "recognized normal   0.16666666666666666\n",
      "\n",
      "information databases   0.021739130434782608\n",
      "\n",
      "the human-readable   0.0006920415224913495\n",
      "\n",
      "word to   0.016666666666666666\n",
      "\n",
      "of size   0.00089126559714795\n",
      "\n",
      "implied challenges   1.0\n",
      "\n",
      "state .   0.07142857142857142\n",
      "\n",
      "usually with   0.0625\n",
      "\n",
      "and RCA   0.001445086705202312\n",
      "\n",
      "to How   0.0013280212483399733\n",
      "\n",
      "especially statistical   0.06666666666666667\n",
      "\n",
      "on Semantic   0.0047169811320754715\n",
      "\n",
      "get some   0.14285714285714285\n",
      "\n",
      "interpretation .   0.5\n",
      "\n",
      "previously prepared   0.5\n",
      "\n",
      "the Viterbi   0.002768166089965398\n",
      "\n",
      ", we   0.009545199326221224\n",
      "\n",
      "the removal   0.0006920415224913495\n",
      "\n",
      "translated as   0.25\n",
      "\n",
      "for what   0.007220216606498195\n",
      "\n",
      "from Moore   0.009615384615384616\n",
      "\n",
      "further condensation   0.125\n",
      "\n",
      "approaches assume   0.03571428571428571\n",
      "\n",
      "one of   0.2153846153846154\n",
      "\n",
      "is subjectivity\\/objectivity   0.0020325203252032522\n",
      "\n",
      "solving larger   1.0\n",
      "\n",
      "of Knowledge   0.00089126559714795\n",
      "\n",
      "persuasion ,   1.0\n",
      "\n",
      "template-matching OCR   1.0\n",
      "\n",
      "corpus for   0.03225806451612903\n",
      "\n",
      "maximum entropy   0.5\n",
      "\n",
      "would allow   0.018867924528301886\n",
      "\n",
      ", Grishman   0.0005614823133071309\n",
      "\n",
      "EHR .   0.3333333333333333\n",
      "\n",
      "separate words   0.3\n",
      "\n",
      "summarization faces   0.02\n",
      "\n",
      "with capitalization   0.00546448087431694\n",
      "\n",
      "2007 is   0.2\n",
      "\n",
      "received considerable   0.5\n",
      "\n",
      "topic boundaries   0.125\n",
      "\n",
      "yes-no question   1.0\n",
      "\n",
      ", beyond   0.0005614823133071309\n",
      "\n",
      ", answer   0.0005614823133071309\n",
      "\n",
      "commercial system   0.09090909090909091\n",
      "\n",
      ", video   0.0011229646266142617\n",
      "\n",
      ", spacecraft   0.0005614823133071309\n",
      "\n",
      "each template   0.022222222222222223\n",
      "\n",
      "Hard to   0.5\n",
      "\n",
      "the historical   0.0006920415224913495\n",
      "\n",
      "superset of   1.0\n",
      "\n",
      "easily ,   0.1111111111111111\n",
      "\n",
      "a superset   0.001226993865030675\n",
      "\n",
      "to -RRB-   0.0013280212483399733\n",
      "\n",
      "translation .   0.05405405405405406\n",
      "\n",
      "recognition since   0.008264462809917356\n",
      "\n",
      "in machine   0.009363295880149813\n",
      "\n",
      "Bush ''   0.5\n",
      "\n",
      "as they   0.010452961672473868\n",
      "\n",
      "a much   0.0036809815950920245\n",
      "\n",
      "showing comparative   0.5\n",
      "\n",
      "are simple   0.004149377593360996\n",
      "\n",
      "perceptions are   1.0\n",
      "\n",
      "nature of   1.0\n",
      "\n",
      "tag the   0.0625\n",
      "\n",
      "questions pertaining   0.038461538461538464\n",
      "\n",
      "with pilots   0.00546448087431694\n",
      "\n",
      "without understanding   0.07692307692307693\n",
      "\n",
      "informativeness .   0.3333333333333333\n",
      "\n",
      "4 letters   0.2\n",
      "\n",
      "researchers wrote   0.1\n",
      "\n",
      "accommodate direct   0.2\n",
      "\n",
      "prior work   0.3333333333333333\n",
      "\n",
      "from weather   0.009615384615384616\n",
      "\n",
      "and Spanish   0.001445086705202312\n",
      "\n",
      "or emotion   0.0045045045045045045\n",
      "\n",
      "of similar   0.0017825311942959\n",
      "\n",
      "semantic ;   0.047619047619047616\n",
      "\n",
      "learn a   0.23076923076923078\n",
      "\n",
      "result will   0.09090909090909091\n",
      "\n",
      ".5 decision   1.0\n",
      "\n",
      "generally refers   0.09090909090909091\n",
      "\n",
      "virtually any   0.5\n",
      "\n",
      "This way   0.015873015873015872\n",
      "\n",
      "`` features   0.005291005291005291\n",
      "\n",
      "needs .   0.1\n",
      "\n",
      "assistance of   1.0\n",
      "\n",
      "system usability   0.010752688172043012\n",
      "\n",
      "needed ,   0.047619047619047616\n",
      "\n",
      "training document   0.03571428571428571\n",
      "\n",
      "for QA   0.010830324909747292\n",
      "\n",
      "high ranks   0.05555555555555555\n",
      "\n",
      "even ``   0.037037037037037035\n",
      "\n",
      "pollen example   0.07692307692307693\n",
      "\n",
      ", nasality   0.0005614823133071309\n",
      "\n",
      "Every acoustic   1.0\n",
      "\n",
      "that in   0.0070921985815602835\n",
      "\n",
      "out .   0.07142857142857142\n",
      "\n",
      "research focus   0.023809523809523808\n",
      "\n",
      "NLP with   0.02127659574468085\n",
      "\n",
      "its immediate   0.02857142857142857\n",
      "\n",
      ", degraded-images   0.0005614823133071309\n",
      "\n",
      "the late   0.005536332179930796\n",
      "\n",
      "linguistic analysis   0.0625\n",
      "\n",
      "likely not   0.0625\n",
      "\n",
      "have specific   0.009615384615384616\n",
      "\n",
      "based ,   0.037037037037037035\n",
      "\n",
      "delta and   1.0\n",
      "\n",
      "available isolated-word   0.058823529411764705\n",
      "\n",
      "their hands   0.029411764705882353\n",
      "\n",
      "out that   0.07142857142857142\n",
      "\n",
      "summarization and   0.02\n",
      "\n",
      "labeled data   0.3333333333333333\n",
      "\n",
      "longest running   1.0\n",
      "\n",
      ", Teun   0.0005614823133071309\n",
      "\n",
      "raters typically   1.0\n",
      "\n",
      "500 texts   0.5\n",
      "\n",
      "biographical questions   1.0\n",
      "\n",
      "European Union   0.3333333333333333\n",
      "\n",
      "less than   0.25\n",
      "\n",
      "the task   0.004844290657439446\n",
      "\n",
      "rephrase sentences   1.0\n",
      "\n",
      "rules based   0.023255813953488372\n",
      "\n",
      "tasks have   0.03125\n",
      "\n",
      "semantically constrained   1.0\n",
      "\n",
      "that underlies   0.0035460992907801418\n",
      "\n",
      "around Documents   0.125\n",
      "\n",
      "corpus -RRB-   0.12903225806451613\n",
      "\n",
      "each time   0.022222222222222223\n",
      "\n",
      "Virtually any   1.0\n",
      "\n",
      "natural ''   0.02666666666666667\n",
      "\n",
      "named IEEE   0.14285714285714285\n",
      "\n",
      "the controller   0.001384083044982699\n",
      "\n",
      "when necessary   0.02857142857142857\n",
      "\n",
      "program to   0.09090909090909091\n",
      "\n",
      "and represented   0.001445086705202312\n",
      "\n",
      "Answering QA   1.0\n",
      "\n",
      "& Server   0.125\n",
      "\n",
      "% accuracy   0.10256410256410256\n",
      "\n",
      "new sentences   0.041666666666666664\n",
      "\n",
      "when translating   0.02857142857142857\n",
      "\n",
      "modeling has   0.14285714285714285\n",
      "\n",
      "Norman Fairclough   0.5\n",
      "\n",
      "clearly not   0.3333333333333333\n",
      "\n",
      "NLG systems   0.23809523809523808\n",
      "\n",
      "ensure verifiability   1.0\n",
      "\n",
      "field ,   0.037037037037037035\n",
      "\n",
      "question domain   0.023809523809523808\n",
      "\n",
      "examples to   0.041666666666666664\n",
      "\n",
      "dogs -RRB-   0.14285714285714285\n",
      "\n",
      "threshold or   0.5\n",
      "\n",
      "time ,   0.3333333333333333\n",
      "\n",
      "2 descriptions   0.2\n",
      "\n",
      "a Markov   0.001226993865030675\n",
      "\n",
      "a background   0.001226993865030675\n",
      "\n",
      "enterprise customers   1.0\n",
      "\n",
      "the field   0.011764705882352941\n",
      "\n",
      "Method -RRB-   1.0\n",
      "\n",
      "be ?   0.004219409282700422\n",
      "\n",
      "decomposing it   1.0\n",
      "\n",
      "keyphrases and   0.02857142857142857\n",
      "\n",
      "settings .   1.0\n",
      "\n",
      "two benefits   0.034482758620689655\n",
      "\n",
      "are analytical   0.004149377593360996\n",
      "\n",
      "in principle   0.0018726591760299626\n",
      "\n",
      ", approach   0.0005614823133071309\n",
      "\n",
      "'s quality   0.0196078431372549\n",
      "\n",
      "A morphosyntactic   0.02\n",
      "\n",
      "Arabic ,   0.25\n",
      "\n",
      "linked because   0.3333333333333333\n",
      "\n",
      "`` blocks   0.010582010582010581\n",
      "\n",
      "<s> Deep   0.0007686395080707148\n",
      "\n",
      "just as   0.2222222222222222\n",
      "\n",
      "digital speech-to-text   0.14285714285714285\n",
      "\n",
      "A corpus   0.02\n",
      "\n",
      "sound pattern   0.05\n",
      "\n",
      "by periods   0.005714285714285714\n",
      "\n",
      "evaluate an   0.25\n",
      "\n",
      "of Michigan   0.00089126559714795\n",
      "\n",
      "+ R   0.16666666666666666\n",
      "\n",
      "source code   0.041666666666666664\n",
      "\n",
      "are useful   0.004149377593360996\n",
      "\n",
      "are dealing   0.004149377593360996\n",
      "\n",
      "aimed at   1.0\n",
      "\n",
      "algorithms --   0.02857142857142857\n",
      "\n",
      "automatic summaries   0.13043478260869565\n",
      "\n",
      "NLG the   0.047619047619047616\n",
      "\n",
      "might refer   0.038461538461538464\n",
      "\n",
      "1953 U.S.   1.0\n",
      "\n",
      "the strengths   0.0006920415224913495\n",
      "\n",
      "about pronouns   0.025\n",
      "\n",
      "problem involves   0.045454545454545456\n",
      "\n",
      "is expected   0.0020325203252032522\n",
      "\n",
      "about which   0.025\n",
      "\n",
      "The topic   0.005208333333333333\n",
      "\n",
      "Aerospace Establishment   0.5\n",
      "\n",
      "speakers to   0.25\n",
      "\n",
      "separately from   1.0\n",
      "\n",
      "same input   0.08\n",
      "\n",
      "service ,   0.4\n",
      "\n",
      "OCR systems   0.08163265306122448\n",
      "\n",
      "recognizers have   0.5\n",
      "\n",
      "American camp   0.2\n",
      "\n",
      "speaker independent   0.05555555555555555\n",
      "\n",
      "with thought-to-paper   0.00546448087431694\n",
      "\n",
      "involves visual   0.1\n",
      "\n",
      "their effectiveness   0.029411764705882353\n",
      "\n",
      "meaningful information   0.125\n",
      "\n",
      "systems do   0.008928571428571428\n",
      "\n",
      "successful NLG   0.1111111111111111\n",
      "\n",
      "the effectiveness   0.0006920415224913495\n",
      "\n",
      "-LRB- Pallet   0.0027100271002710027\n",
      "\n",
      "components .   0.2\n",
      "\n",
      ", find   0.0011229646266142617\n",
      "\n",
      "unigram ``   0.2\n",
      "\n",
      "following ``   0.06666666666666667\n",
      "\n",
      "the Canadian   0.001384083044982699\n",
      "\n",
      "topic were   0.125\n",
      "\n",
      "simple sentence   0.038461538461538464\n",
      "\n",
      "information then   0.021739130434782608\n",
      "\n",
      "and copying   0.001445086705202312\n",
      "\n",
      "<s> Substantial   0.0007686395080707148\n",
      "\n",
      "It proved   0.02631578947368421\n",
      "\n",
      "learning problem   0.023255813953488372\n",
      "\n",
      "syntactic parsing   0.07692307692307693\n",
      "\n",
      "expanding all   1.0\n",
      "\n",
      "attractive method   0.3333333333333333\n",
      "\n",
      "-- 10   0.04\n",
      "\n",
      "the vagueness   0.0006920415224913495\n",
      "\n",
      "decisions about   0.2\n",
      "\n",
      "to artificial   0.0026560424966799467\n",
      "\n",
      "specific letters   0.047619047619047616\n",
      "\n",
      "-LRB- P   0.0027100271002710027\n",
      "\n",
      "<s> Psycholinguists   0.0007686395080707148\n",
      "\n",
      "French ,   0.125\n",
      "\n",
      "-RRB- automatically   0.0027100271002710027\n",
      "\n",
      "negative examples   0.125\n",
      "\n",
      "summary ''   0.047619047619047616\n",
      "\n",
      "other potential   0.014285714285714285\n",
      "\n",
      "close the   1.0\n",
      "\n",
      "summarization approaches   0.02\n",
      "\n",
      "of overlap   0.00089126559714795\n",
      "\n",
      "computers to   0.1111111111111111\n",
      "\n",
      "research devoted   0.023809523809523808\n",
      "\n",
      "surrounding the   0.2\n",
      "\n",
      "rapidly changing   0.5\n",
      "\n",
      "-RRB- hours   0.0027100271002710027\n",
      "\n",
      "late 1980s   0.4444444444444444\n",
      "\n",
      "spectral-domain of   1.0\n",
      "\n",
      "Jim Martin   1.0\n",
      "\n",
      "linear regression   0.14285714285714285\n",
      "\n",
      "ambiguity .   0.125\n",
      "\n",
      "delta-delta coefficients   1.0\n",
      "\n",
      "tables of   0.3333333333333333\n",
      "\n",
      "equipment was   0.3333333333333333\n",
      "\n",
      "But then   0.16666666666666666\n",
      "\n",
      "period of   0.5\n",
      "\n",
      "of marketing   0.00089126559714795\n",
      "\n",
      "newswire reports   1.0\n",
      "\n",
      "Braille texts   1.0\n",
      "\n",
      "terms such   0.07692307692307693\n",
      "\n",
      "not just   0.008928571428571428\n",
      "\n",
      "the written   0.0006920415224913495\n",
      "\n",
      ", domotic   0.0005614823133071309\n",
      "\n",
      "by Jurafsky   0.005714285714285714\n",
      "\n",
      "systems indicate   0.008928571428571428\n",
      "\n",
      "contrast to   0.25\n",
      "\n",
      "data at   0.012987012987012988\n",
      "\n",
      "published at   0.14285714285714285\n",
      "\n",
      "more -RRB-   0.010526315789473684\n",
      "\n",
      "typical parser   0.1111111111111111\n",
      "\n",
      "using database   0.01694915254237288\n",
      "\n",
      "inference --   0.25\n",
      "\n",
      "to put   0.0026560424966799467\n",
      "\n",
      "the higher   0.0006920415224913495\n",
      "\n",
      "Collection of   1.0\n",
      "\n",
      "be formally   0.004219409282700422\n",
      "\n",
      "is copied   0.0020325203252032522\n",
      "\n",
      "-RRB- work   0.0027100271002710027\n",
      "\n",
      "these ,   0.047619047619047616\n",
      "\n",
      "breaks exist   0.5\n",
      "\n",
      "as 1   0.003484320557491289\n",
      "\n",
      "systems and   0.008928571428571428\n",
      "\n",
      "and instead   0.001445086705202312\n",
      "\n",
      "-- the   0.12\n",
      "\n",
      "environment as   0.16666666666666666\n",
      "\n",
      "the length   0.001384083044982699\n",
      "\n",
      "when working   0.02857142857142857\n",
      "\n",
      "that making   0.0035460992907801418\n",
      "\n",
      "two enabling   0.034482758620689655\n",
      "\n",
      "an RCA   0.015151515151515152\n",
      "\n",
      "<s> Neural   0.0015372790161414297\n",
      "\n",
      "subjective .   0.3333333333333333\n",
      "\n",
      "Stanford ,   0.5\n",
      "\n",
      "Japanese camp   0.125\n",
      "\n",
      "Symantec changed   0.5\n",
      "\n",
      "more sophisticated   0.021052631578947368\n",
      "\n",
      "but vocabulary   0.014705882352941176\n",
      "\n",
      "Sound waves   0.3333333333333333\n",
      "\n",
      "technology This   0.045454545454545456\n",
      "\n",
      "agreement is   0.3333333333333333\n",
      "\n",
      "see above   0.05\n",
      "\n",
      "of January   0.00089126559714795\n",
      "\n",
      "associated with   0.25\n",
      "\n",
      "metrics are   0.1111111111111111\n",
      "\n",
      "within computer   0.05555555555555555\n",
      "\n",
      "better scoring   0.1111111111111111\n",
      "\n",
      "yet been   0.5\n",
      "\n",
      "computer-aided translation   0.3333333333333333\n",
      "\n",
      "distinction of   0.2\n",
      "\n",
      "A precise   0.02\n",
      "\n",
      "unmanageable .   1.0\n",
      "\n",
      "Weaver wrote   1.0\n",
      "\n",
      "the one   0.0006920415224913495\n",
      "\n",
      "kit '   1.0\n",
      "\n",
      "three to   0.3333333333333333\n",
      "\n",
      "factors which   0.3333333333333333\n",
      "\n",
      "of adaptive   0.00089126559714795\n",
      "\n",
      "showed how   0.25\n",
      "\n",
      "use various   0.013888888888888888\n",
      "\n",
      "only be   0.02631578947368421\n",
      "\n",
      "converted it   0.3333333333333333\n",
      "\n",
      "perhaps the   0.16666666666666666\n",
      "\n",
      "concluded that   1.0\n",
      "\n",
      ": Automatically   0.00980392156862745\n",
      "\n",
      "originally developed   0.5\n",
      "\n",
      "summary -RRB-   0.023809523809523808\n",
      "\n",
      "knowledge comes   0.037037037037037035\n",
      "\n",
      "that within   0.0070921985815602835\n",
      "\n",
      "recognition Main   0.008264462809917356\n",
      "\n",
      "phrase -LRB-   0.1\n",
      "\n",
      "existing multilingual   0.2\n",
      "\n",
      "In 2006   0.009523809523809525\n",
      "\n",
      "to speech   0.00398406374501992\n",
      "\n",
      "analyze `   0.25\n",
      "\n",
      "some programming   0.012048192771084338\n",
      "\n",
      "contexts and   0.14285714285714285\n",
      "\n",
      "letter shapes   0.3333333333333333\n",
      "\n",
      "well the   0.03571428571428571\n",
      "\n",
      "especially common   0.13333333333333333\n",
      "\n",
      "with American   0.00546448087431694\n",
      "\n",
      "T ,   0.16666666666666666\n",
      "\n",
      "its performance   0.02857142857142857\n",
      "\n",
      "tasks returning   0.03125\n",
      "\n",
      "photocells ,   1.0\n",
      "\n",
      "no spaces   0.07692307692307693\n",
      "\n",
      "On January   0.16666666666666666\n",
      "\n",
      "below 50   0.2\n",
      "\n",
      "chose different   1.0\n",
      "\n",
      "software user   0.037037037037037035\n",
      "\n",
      "mixture of   1.0\n",
      "\n",
      "phrases to   0.0625\n",
      "\n",
      "containing several   0.125\n",
      "\n",
      "Snyder performed   0.5\n",
      "\n",
      "some assertive   0.012048192771084338\n",
      "\n",
      "taxonomies .   1.0\n",
      "\n",
      "criteria is   0.25\n",
      "\n",
      "realized on   1.0\n",
      "\n",
      "breadth ''   0.5\n",
      "\n",
      "program got   0.045454545454545456\n",
      "\n",
      "estimating the   1.0\n",
      "\n",
      "each segment   0.044444444444444446\n",
      "\n",
      "EMNLP ,   1.0\n",
      "\n",
      "<s> Envelopes   0.0007686395080707148\n",
      "\n",
      "There are   0.5454545454545454\n",
      "\n",
      ", standard   0.0011229646266142617\n",
      "\n",
      "of guessing   0.00089126559714795\n",
      "\n",
      "Applications The   0.5\n",
      "\n",
      ", neural   0.0022459292532285235\n",
      "\n",
      "on each   0.0047169811320754715\n",
      "\n",
      ", Deirdre   0.0005614823133071309\n",
      "\n",
      "most sentiment   0.017241379310344827\n",
      "\n",
      ", when   0.003368893879842785\n",
      "\n",
      "or speed   0.0045045045045045045\n",
      "\n",
      "are Deaf   0.004149377593360996\n",
      "\n",
      "is adaptive   0.0020325203252032522\n",
      "\n",
      "keyphrases by   0.02857142857142857\n",
      "\n",
      "about democratizing   0.025\n",
      "\n",
      "difficult tasks   0.07142857142857142\n",
      "\n",
      "occurred in   1.0\n",
      "\n",
      "when there   0.02857142857142857\n",
      "\n",
      "each known   0.022222222222222223\n",
      "\n",
      "Microsoft Corporation   0.5\n",
      "\n",
      "'' is   0.04639175257731959\n",
      "\n",
      "given loss   0.041666666666666664\n",
      "\n",
      "may explore   0.019230769230769232\n",
      "\n",
      "Matches between   1.0\n",
      "\n",
      "<s> If   0.006149116064565719\n",
      "\n",
      "core elements   0.5\n",
      "\n",
      "These methods   0.17647058823529413\n",
      "\n",
      "European group   0.3333333333333333\n",
      "\n",
      "new .   0.041666666666666664\n",
      "\n",
      "an untagged   0.007575757575757576\n",
      "\n",
      "make the   0.05\n",
      "\n",
      "-LRB- Loriot   0.0027100271002710027\n",
      "\n",
      "turn .   0.16666666666666666\n",
      "\n",
      "integer ,   1.0\n",
      "\n",
      "or in   0.0045045045045045045\n",
      "\n",
      "Canada and   0.16666666666666666\n",
      "\n",
      ", distance   0.0005614823133071309\n",
      "\n",
      "of unknown   0.00089126559714795\n",
      "\n",
      "the problem   0.006228373702422145\n",
      "\n",
      "damping factor   1.0\n",
      "\n",
      "loss function   1.0\n",
      "\n",
      "un-supervised ''   1.0\n",
      "\n",
      "basic level   0.07692307692307693\n",
      "\n",
      "Due to   1.0\n",
      "\n",
      "of n-dimensional   0.00089126559714795\n",
      "\n",
      "you '   0.07692307692307693\n",
      "\n",
      "research has   0.14285714285714285\n",
      "\n",
      "way .   0.041666666666666664\n",
      "\n",
      "alphabetic heritage   1.0\n",
      "\n",
      "breaking -LRB-   0.5\n",
      "\n",
      "predict task-effectiveness   0.3333333333333333\n",
      "\n",
      "and checked   0.001445086705202312\n",
      "\n",
      "are available   0.008298755186721992\n",
      "\n",
      "and segment   0.001445086705202312\n",
      "\n",
      "uses .   0.07142857142857142\n",
      "\n",
      "have any   0.009615384615384616\n",
      "\n",
      "than sixty   0.022222222222222223\n",
      "\n",
      "translation Automotive   0.013513513513513514\n",
      "\n",
      "of approaches   0.00089126559714795\n",
      "\n",
      "semantics formalization   0.07142857142857142\n",
      "\n",
      "the comprehension   0.0006920415224913495\n",
      "\n",
      "consisting of   1.0\n",
      "\n",
      "rule-based translation   0.14285714285714285\n",
      "\n",
      "per page   0.25\n",
      "\n",
      "references -RRB-   0.5\n",
      "\n",
      "even though   0.07407407407407407\n",
      "\n",
      "Ochs ,   1.0\n",
      "\n",
      "speech recognition   0.42105263157894735\n",
      "\n",
      "four together   0.14285714285714285\n",
      "\n",
      "integrate reasoning   1.0\n",
      "\n",
      "in Norman   0.0018726591760299626\n",
      "\n",
      "parliament and   1.0\n",
      "\n",
      "densely connected   1.0\n",
      "\n",
      "techniques that   0.08695652173913043\n",
      "\n",
      "summarization hopes   0.02\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Amharic   0.0036101083032490976\n",
      "\n",
      "flight displays   0.5\n",
      "\n",
      "schemes to   0.5\n",
      "\n",
      "rudimentary translation   0.5\n",
      "\n",
      "n Computer   0.5\n",
      "\n",
      "as dynamic   0.003484320557491289\n",
      "\n",
      "document can   0.027777777777777776\n",
      "\n",
      "a newspaper   0.001226993865030675\n",
      "\n",
      "likely a   0.0625\n",
      "\n",
      "of 80   0.00089126559714795\n",
      "\n",
      "function as   0.125\n",
      "\n",
      "partially influenced   1.0\n",
      "\n",
      "scholars have   0.5\n",
      "\n",
      "a consumer   0.001226993865030675\n",
      "\n",
      "relationships can   0.16666666666666666\n",
      "\n",
      "were SHRDLU   0.024390243902439025\n",
      "\n",
      "and labor   0.001445086705202312\n",
      "\n",
      "for detecting   0.0036101083032490976\n",
      "\n",
      "Who is   0.5\n",
      "\n",
      "similar ``   0.037037037037037035\n",
      "\n",
      "deferred speech   1.0\n",
      "\n",
      "of examples   0.00089126559714795\n",
      "\n",
      "wide variance   0.25\n",
      "\n",
      "ones focus   0.1\n",
      "\n",
      "context that   0.030303030303030304\n",
      "\n",
      "for those   0.007220216606498195\n",
      "\n",
      "many chatterbots   0.019230769230769232\n",
      "\n",
      "paper .   0.09090909090909091\n",
      "\n",
      "a piece   0.00245398773006135\n",
      "\n",
      "keyphrase .   0.05263157894736842\n",
      "\n",
      "WER -RRB-   1.0\n",
      "\n",
      "David H.   0.25\n",
      "\n",
      "out loud   0.07142857142857142\n",
      "\n",
      ", writing   0.0011229646266142617\n",
      "\n",
      "reviews and   0.16666666666666666\n",
      "\n",
      "science that   0.1\n",
      "\n",
      "the new   0.0006920415224913495\n",
      "\n",
      "area -RRB-   0.09090909090909091\n",
      "\n",
      "questions from   0.038461538461538464\n",
      "\n",
      "contain enough   0.08333333333333333\n",
      "\n",
      "and differing   0.001445086705202312\n",
      "\n",
      "overall polarity   0.16666666666666666\n",
      "\n",
      "the conversational   0.0006920415224913495\n",
      "\n",
      "a final   0.001226993865030675\n",
      "\n",
      "and slang   0.001445086705202312\n",
      "\n",
      "has fairly   0.011904761904761904\n",
      "\n",
      "Page\\/Lex\\/TextRank that   1.0\n",
      "\n",
      "look to   0.2\n",
      "\n",
      "Australian physician   0.5\n",
      "\n",
      "MT Hybrid   0.2\n",
      "\n",
      "not accommodate   0.017857142857142856\n",
      "\n",
      "cognition and   1.0\n",
      "\n",
      "by highlighting   0.005714285714285714\n",
      "\n",
      "technique which   0.14285714285714285\n",
      "\n",
      "all handwritten   0.023255813953488372\n",
      "\n",
      "1,000 words   0.5\n",
      "\n",
      "level .   0.05\n",
      "\n",
      "form a   0.15\n",
      "\n",
      "sound blocks   0.05\n",
      "\n",
      "also need   0.014492753623188406\n",
      "\n",
      "in taxonomies   0.0018726591760299626\n",
      "\n",
      "not wear   0.008928571428571428\n",
      "\n",
      "probably ``   0.25\n",
      "\n",
      "methods and   0.022727272727272728\n",
      "\n",
      "greater risk   0.3333333333333333\n",
      "\n",
      "aircraft Substantial   0.14285714285714285\n",
      "\n",
      "above 95   0.07692307692307693\n",
      "\n",
      "character-by-character OCR   1.0\n",
      "\n",
      "highly complex   0.1111111111111111\n",
      "\n",
      "online news   0.125\n",
      "\n",
      "the separate   0.0006920415224913495\n",
      "\n",
      "entertaining last   0.5\n",
      "\n",
      "improvement to   0.25\n",
      "\n",
      "edges after   0.14285714285714285\n",
      "\n",
      "by Joseph   0.005714285714285714\n",
      "\n",
      "error analysis   0.08333333333333333\n",
      "\n",
      "possible unigrams   0.041666666666666664\n",
      "\n",
      "automatically answer   0.047619047619047616\n",
      "\n",
      "operations .   1.0\n",
      "\n",
      "without the   0.07692307692307693\n",
      "\n",
      ", Deborah   0.0011229646266142617\n",
      "\n",
      "to automate   0.0026560424966799467\n",
      "\n",
      "disambiguation -LRB-   0.1\n",
      "\n",
      "provided by   0.4\n",
      "\n",
      "publicly available   1.0\n",
      "\n",
      "Post has   0.5\n",
      "\n",
      "been using   0.029411764705882353\n",
      "\n",
      "a small   0.00245398773006135\n",
      "\n",
      "of just   0.00089126559714795\n",
      "\n",
      "its domain   0.05714285714285714\n",
      "\n",
      "algorithm for   0.07142857142857142\n",
      "\n",
      "Speaker Dependence   0.16666666666666666\n",
      "\n",
      "in full   0.0018726591760299626\n",
      "\n",
      "Although it   0.125\n",
      "\n",
      "segmentation systems   0.030303030303030304\n",
      "\n",
      "customize OCR   0.5\n",
      "\n",
      "tagging system   0.04\n",
      "\n",
      "basic and   0.07692307692307693\n",
      "\n",
      "Basic sound   1.0\n",
      "\n",
      "71 %   1.0\n",
      "\n",
      "summarization It   0.02\n",
      "\n",
      "just ``   0.1111111111111111\n",
      "\n",
      "dedicated to   0.6666666666666666\n",
      "\n",
      "four decades   0.14285714285714285\n",
      "\n",
      "listed on   1.0\n",
      "\n",
      "of individual   0.0017825311942959\n",
      "\n",
      "easier task   0.125\n",
      "\n",
      "the pilot   0.0006920415224913495\n",
      "\n",
      "Air controller   0.3333333333333333\n",
      "\n",
      "successfully for   0.3333333333333333\n",
      "\n",
      "cope with   1.0\n",
      "\n",
      "It 's   0.05263157894736842\n",
      "\n",
      "kind of   0.7272727272727273\n",
      "\n",
      "closed world   1.0\n",
      "\n",
      "vary with   0.16666666666666666\n",
      "\n",
      "been previously   0.014705882352941176\n",
      "\n",
      "work from   0.041666666666666664\n",
      "\n",
      "- not   0.0625\n",
      "\n",
      "have multiple   0.009615384615384616\n",
      "\n",
      "grammar in   0.02702702702702703\n",
      "\n",
      "Words ,   0.25\n",
      "\n",
      "individual cursive   0.08333333333333333\n",
      "\n",
      "handheld scanner   1.0\n",
      "\n",
      "a binary   0.00245398773006135\n",
      "\n",
      "parametric values   1.0\n",
      "\n",
      "not resulted   0.008928571428571428\n",
      "\n",
      "increasingly focused   0.3333333333333333\n",
      "\n",
      "Intra-texual methods   1.0\n",
      "\n",
      "'' ,   0.15463917525773196\n",
      "\n",
      "Canadian parliament   0.5\n",
      "\n",
      "decisions probabilistically   0.1\n",
      "\n",
      "learn tag   0.07692307692307693\n",
      "\n",
      "conveniently as   1.0\n",
      "\n",
      "newspaper articles   0.3333333333333333\n",
      "\n",
      "Wall Street   1.0\n",
      "\n",
      "<s> Turney   0.0007686395080707148\n",
      "\n",
      "rate -LRB-   0.09090909090909091\n",
      "\n",
      "the learner   0.0006920415224913495\n",
      "\n",
      "take advantage   0.4\n",
      "\n",
      "sidestepped the   1.0\n",
      "\n",
      "For keyphrase   0.01639344262295082\n",
      "\n",
      "naturally spoken   0.5\n",
      "\n",
      "has plateaued   0.011904761904761904\n",
      "\n",
      "-LRB- POS   0.005420054200542005\n",
      "\n",
      "possibly others   0.5\n",
      "\n",
      ", inter-texual   0.0005614823133071309\n",
      "\n",
      "edges between   0.14285714285714285\n",
      "\n",
      "that some   0.014184397163120567\n",
      "\n",
      "1955 ,   1.0\n",
      "\n",
      "are time-consuming   0.004149377593360996\n",
      "\n",
      "automatic lip-synch   0.043478260869565216\n",
      "\n",
      "beyond polarity   0.16666666666666666\n",
      "\n",
      "reported there   0.2\n",
      "\n",
      "die or   1.0\n",
      "\n",
      "of all   0.0035650623885918\n",
      "\n",
      "require advanced   0.045454545454545456\n",
      "\n",
      "using both   0.01694915254237288\n",
      "\n",
      "open world   0.25\n",
      "\n",
      ", Englund   0.0005614823133071309\n",
      "\n",
      "for part-of-speech   0.007220216606498195\n",
      "\n",
      "NLG summaries   0.047619047619047616\n",
      "\n",
      "common ground   0.04\n",
      "\n",
      "five different   0.2\n",
      "\n",
      "or meets   0.0045045045045045045\n",
      "\n",
      "extraction task   0.03225806451612903\n",
      "\n",
      "models Main   0.038461538461538464\n",
      "\n",
      "to very   0.0013280212483399733\n",
      "\n",
      "summary covers   0.023809523809523808\n",
      "\n",
      "turns .   0.3333333333333333\n",
      "\n",
      "immunology ,   1.0\n",
      "\n",
      "scientific and   0.5\n",
      "\n",
      "relevant content   0.14285714285714285\n",
      "\n",
      "researched tasks   1.0\n",
      "\n",
      "often quoted   0.022727272727272728\n",
      "\n",
      "very broad   0.04878048780487805\n",
      "\n",
      "absorbing Markov   0.3333333333333333\n",
      "\n",
      "transfer-based machine   0.6666666666666666\n",
      "\n",
      "over vertices   0.08333333333333333\n",
      "\n",
      "of low   0.00089126559714795\n",
      "\n",
      "sound impressive   0.05\n",
      "\n",
      ", resulting   0.0005614823133071309\n",
      "\n",
      "Natural ''   0.08333333333333333\n",
      "\n",
      "task remains   0.023809523809523808\n",
      "\n",
      "and processing   0.001445086705202312\n",
      "\n",
      "the breadth   0.0006920415224913495\n",
      "\n",
      "attribute or   0.5\n",
      "\n",
      "-LRB- ATC   0.0027100271002710027\n",
      "\n",
      "reasonable chance   0.5\n",
      "\n",
      "the possibilities   0.0006920415224913495\n",
      "\n",
      "to various   0.0013280212483399733\n",
      "\n",
      "would ,   0.018867924528301886\n",
      "\n",
      ", Michel   0.0011229646266142617\n",
      "\n",
      "or indiscriminate   0.0045045045045045045\n",
      "\n",
      "source document   0.08333333333333333\n",
      "\n",
      "any safety   0.03225806451612903\n",
      "\n",
      "to these   0.0026560424966799467\n",
      "\n",
      "particular types   0.07692307692307693\n",
      "\n",
      "having considerable   0.2\n",
      "\n",
      "Business-card OCR   1.0\n",
      "\n",
      "interaction with   0.125\n",
      "\n",
      "by paying   0.005714285714285714\n",
      "\n",
      "testing the   0.2\n",
      "\n",
      "the blind   0.0006920415224913495\n",
      "\n",
      "city .   1.0\n",
      "\n",
      "text analytics   0.006289308176100629\n",
      "\n",
      "Evaluation An   0.1111111111111111\n",
      "\n",
      "class they   0.25\n",
      "\n",
      "each ambiguity   0.022222222222222223\n",
      "\n",
      "be separated   0.004219409282700422\n",
      "\n",
      "with attribute   0.00546448087431694\n",
      "\n",
      ", conversation   0.0005614823133071309\n",
      "\n",
      "languages which   0.02\n",
      "\n",
      "-LRB- MPE   0.0027100271002710027\n",
      "\n",
      "is commercially   0.0020325203252032522\n",
      "\n",
      "available ,   0.23529411764705882\n",
      "\n",
      "the subject   0.0034602076124567475\n",
      "\n",
      "sentiment -LRB-   0.04\n",
      "\n",
      "alternative courses   0.3333333333333333\n",
      "\n",
      "Besides the   1.0\n",
      "\n",
      "The 10   0.005208333333333333\n",
      "\n",
      "release parameters   0.3333333333333333\n",
      "\n",
      "clearly many   0.3333333333333333\n",
      "\n",
      "approaches used   0.03571428571428571\n",
      "\n",
      "<s> →   0.0007686395080707148\n",
      "\n",
      "input are   0.024390243902439025\n",
      "\n",
      "the continuously   0.0006920415224913495\n",
      "\n",
      "sentences or   0.013157894736842105\n",
      "\n",
      "recognition conferences   0.008264462809917356\n",
      "\n",
      "be put   0.004219409282700422\n",
      "\n",
      "be approximated   0.004219409282700422\n",
      "\n",
      "pages .   0.2857142857142857\n",
      "\n",
      "-RRB- classifier   0.0027100271002710027\n",
      "\n",
      "full sentenced   0.2\n",
      "\n",
      "even more   0.037037037037037035\n",
      "\n",
      "Correct answers   1.0\n",
      "\n",
      "topics automatically   0.14285714285714285\n",
      "\n",
      ", that   0.0022459292532285235\n",
      "\n",
      "limited amounts   0.1\n",
      "\n",
      "meaning into   0.043478260869565216\n",
      "\n",
      "of process   0.00089126559714795\n",
      "\n",
      "and many   0.001445086705202312\n",
      "\n",
      "decelerations during   1.0\n",
      "\n",
      "abstractive keyphrase   0.16666666666666666\n",
      "\n",
      "position in   0.5\n",
      "\n",
      "archiving and   1.0\n",
      "\n",
      "Document Understanding   0.25\n",
      "\n",
      ", German   0.0011229646266142617\n",
      "\n",
      "to adapt   0.0013280212483399733\n",
      "\n",
      "mention that   0.3333333333333333\n",
      "\n",
      "approximation .   0.16666666666666666\n",
      "\n",
      "were based   0.024390243902439025\n",
      "\n",
      "and world   0.001445086705202312\n",
      "\n",
      "overlap .   0.25\n",
      "\n",
      "template .   0.25\n",
      "\n",
      "he went   0.2857142857142857\n",
      "\n",
      "and algorithms   0.001445086705202312\n",
      "\n",
      "academic research   1.0\n",
      "\n",
      "-LRB- that   0.01084010840108401\n",
      "\n",
      "performance of   0.1111111111111111\n",
      "\n",
      "disciplines ,   1.0\n",
      "\n",
      "relations -LRB-   0.08333333333333333\n",
      "\n",
      "Handbook chapter   1.0\n",
      "\n",
      "1-July-2005 ,   1.0\n",
      "\n",
      "system had   0.010752688172043012\n",
      "\n",
      "to specific   0.0013280212483399733\n",
      "\n",
      "for using   0.0036101083032490976\n",
      "\n",
      "yesterday and   0.3333333333333333\n",
      "\n",
      "Ask.com .   1.0\n",
      "\n",
      "Input for   0.5\n",
      "\n",
      "The algorithms   0.010416666666666666\n",
      "\n",
      "-LRB- For   0.005420054200542005\n",
      "\n",
      "a professor   0.001226993865030675\n",
      "\n",
      "both summarization   0.03225806451612903\n",
      "\n",
      "determine keyphrases   0.043478260869565216\n",
      "\n",
      "ambiguous context-free   0.08333333333333333\n",
      "\n",
      "a comprehensive   0.0036809815950920245\n",
      "\n",
      "on its   0.009433962264150943\n",
      "\n",
      "cost of   0.5\n",
      "\n",
      "chosen is   0.2\n",
      "\n",
      "and Roger   0.001445086705202312\n",
      "\n",
      "things -RRB-   0.3333333333333333\n",
      "\n",
      "Treebank .   0.3333333333333333\n",
      "\n",
      "40 %   1.0\n",
      "\n",
      "the south   0.001384083044982699\n",
      "\n",
      "area includes   0.09090909090909091\n",
      "\n",
      "task because   0.023809523809523808\n",
      "\n",
      "explore critical   0.25\n",
      "\n",
      "1,500 documents   1.0\n",
      "\n",
      "<s> Human   0.0023059185242121443\n",
      "\n",
      "more deterministic   0.021052631578947368\n",
      "\n",
      ", it   0.01347557551937114\n",
      "\n",
      ", special   0.0005614823133071309\n",
      "\n",
      "precision because   0.2\n",
      "\n",
      "the test   0.001384083044982699\n",
      "\n",
      "Interactive QA   0.5\n",
      "\n",
      "the use   0.010380622837370242\n",
      "\n",
      "time on   0.030303030303030304\n",
      "\n",
      "and Audio   0.001445086705202312\n",
      "\n",
      "Markov Models   0.16666666666666666\n",
      "\n",
      "built that   0.3333333333333333\n",
      "\n",
      "to rescore   0.0013280212483399733\n",
      "\n",
      "and answered   0.001445086705202312\n",
      "\n",
      "size ,   0.16666666666666666\n",
      "\n",
      "review as   0.3333333333333333\n",
      "\n",
      "of identifiers   0.00089126559714795\n",
      "\n",
      "Patent 1,915,993   0.3333333333333333\n",
      "\n",
      "<s> Yet   0.0007686395080707148\n",
      "\n",
      "First summarizes   1.0\n",
      "\n",
      "svg This   1.0\n",
      "\n",
      "summarizes that   1.0\n",
      "\n",
      "some heuristic   0.012048192771084338\n",
      "\n",
      "require some   0.045454545454545456\n",
      "\n",
      "help understand   0.1111111111111111\n",
      "\n",
      "is that   0.024390243902439025\n",
      "\n",
      "corpus linguistics   0.0967741935483871\n",
      "\n",
      "first step   0.06060606060606061\n",
      "\n",
      "decided without   0.3333333333333333\n",
      "\n",
      "utility with   0.5\n",
      "\n",
      "ways ,   0.25\n",
      "\n",
      "by many   0.005714285714285714\n",
      "\n",
      "many higher   0.019230769230769232\n",
      "\n",
      ", part-of-speech   0.0011229646266142617\n",
      "\n",
      "Turing published   0.5\n",
      "\n",
      "been automatic   0.014705882352941176\n",
      "\n",
      "commercial OCR   0.18181818181818182\n",
      "\n",
      "rate the   0.09090909090909091\n",
      "\n",
      "phases .   1.0\n",
      "\n",
      "capture the   0.5\n",
      "\n",
      "negative emotions   0.125\n",
      "\n",
      "Digitized Sound   1.0\n",
      "\n",
      "customize the   0.5\n",
      "\n",
      "their corresponding   0.029411764705882353\n",
      "\n",
      "all possibilities   0.023255813953488372\n",
      "\n",
      "much useful   0.045454545454545456\n",
      "\n",
      "and trigram   0.001445086705202312\n",
      "\n",
      "this right   0.01098901098901099\n",
      "\n",
      "Warren Weaver   1.0\n",
      "\n",
      "or applying   0.0045045045045045045\n",
      "\n",
      "writing rules   0.1111111111111111\n",
      "\n",
      "Basically ,   1.0\n",
      "\n",
      "but instead   0.014705882352941176\n",
      "\n",
      "the ambiguity   0.0006920415224913495\n",
      "\n",
      "volume ,   0.25\n",
      "\n",
      "answering There   0.08333333333333333\n",
      "\n",
      "input into   0.024390243902439025\n",
      "\n",
      "represent as   0.1111111111111111\n",
      "\n",
      ", 10   0.0011229646266142617\n",
      "\n",
      "they refer   0.05\n",
      "\n",
      "means the   0.16666666666666666\n",
      "\n",
      "input can   0.024390243902439025\n",
      "\n",
      "standardised text   1.0\n",
      "\n",
      "50 to   0.3333333333333333\n",
      "\n",
      "a very   0.013496932515337423\n",
      "\n",
      "include distinct   0.037037037037037035\n",
      "\n",
      "make them   0.05\n",
      "\n",
      "a quantity   0.001226993865030675\n",
      "\n",
      "were surprisingly   0.024390243902439025\n",
      "\n",
      "working for   0.14285714285714285\n",
      "\n",
      "integrating speech   1.0\n",
      "\n",
      "-LRB- e.g.   0.10298102981029811\n",
      "\n",
      "examples are   0.041666666666666664\n",
      "\n",
      "nets .   1.0\n",
      "\n",
      "Truecasing Statistical   1.0\n",
      "\n",
      "with reference   0.00546448087431694\n",
      "\n",
      "significant -RRB-   0.1111111111111111\n",
      "\n",
      "<s> Political   0.0007686395080707148\n",
      "\n",
      "Strzalkowski T.   1.0\n",
      "\n",
      "processes such   0.2\n",
      "\n",
      "was shown   0.025974025974025976\n",
      "\n",
      ", distinct   0.0005614823133071309\n",
      "\n",
      "actually correct   0.3333333333333333\n",
      "\n",
      "scope of   1.0\n",
      "\n",
      "world of   0.06666666666666667\n",
      "\n",
      "gradual lessening   1.0\n",
      "\n",
      ", parsing   0.0016844469399213925\n",
      "\n",
      "as BLEU   0.003484320557491289\n",
      "\n",
      "semantic parsing   0.047619047619047616\n",
      "\n",
      "a language   0.007361963190184049\n",
      "\n",
      "is going   0.0020325203252032522\n",
      "\n",
      "applications include   0.08\n",
      "\n",
      "possibility to   0.25\n",
      "\n",
      "e.g. space   0.017857142857142856\n",
      "\n",
      "1970s and   0.6666666666666666\n",
      "\n",
      "human would   0.021739130434782608\n",
      "\n",
      "; ``   0.02127659574468085\n",
      "\n",
      "RCA 301   0.2\n",
      "\n",
      "logical assertions   0.16666666666666666\n",
      "\n",
      "to prune   0.0013280212483399733\n",
      "\n",
      "and direction   0.001445086705202312\n",
      "\n",
      "pollen level   0.15384615384615385\n",
      "\n",
      "particularly prone   0.2\n",
      "\n",
      "most notably   0.017241379310344827\n",
      "\n",
      "typically undirected   0.05555555555555555\n",
      "\n",
      "Statistics guided   0.3333333333333333\n",
      "\n",
      "at .   0.014705882352941176\n",
      "\n",
      "interactive use   0.25\n",
      "\n",
      "a second   0.0036809815950920245\n",
      "\n",
      "1982 ,   0.3333333333333333\n",
      "\n",
      "to provide   0.005312084993359893\n",
      "\n",
      "simply apply   0.08333333333333333\n",
      "\n",
      "evaluation considers   0.018518518518518517\n",
      "\n",
      "more fine-grained   0.010526315789473684\n",
      "\n",
      "-RRB- -RRB-   0.005420054200542005\n",
      "\n",
      "which draws   0.007246376811594203\n",
      "\n",
      "size N   0.16666666666666666\n",
      "\n",
      "of more   0.0035650623885918\n",
      "\n",
      "language by   0.006756756756756757\n",
      "\n",
      "this system   0.01098901098901099\n",
      "\n",
      "formalisms\\/languages .   1.0\n",
      "\n",
      "vs. extrinsic   0.08333333333333333\n",
      "\n",
      "If probabilities   0.1\n",
      "\n",
      "appropriate perspective   0.25\n",
      "\n",
      "how strong   0.034482758620689655\n",
      "\n",
      "system on   0.010752688172043012\n",
      "\n",
      "of 1   0.00089126559714795\n",
      "\n",
      "are under   0.004149377593360996\n",
      "\n",
      "Health Organization   0.5\n",
      "\n",
      "a well-defined   0.001226993865030675\n",
      "\n",
      "feasibility study   0.5\n",
      "\n",
      "isolated words   0.2\n",
      "\n",
      "Keyphrase Extraction   0.25\n",
      "\n",
      "topics or   0.14285714285714285\n",
      "\n",
      "is functioning   0.0020325203252032522\n",
      "\n",
      "Issues In   0.5\n",
      "\n",
      "-LRB- IMR   0.0027100271002710027\n",
      "\n",
      "lead-in fighter   1.0\n",
      "\n",
      "six numbers   0.5\n",
      "\n",
      "<s> To   0.006149116064565719\n",
      "\n",
      "sentence Grass   0.020833333333333332\n",
      "\n",
      "World Health   0.14285714285714285\n",
      "\n",
      "controlling flight   1.0\n",
      "\n",
      "Wikipedia and   0.5\n",
      "\n",
      "view of   0.3333333333333333\n",
      "\n",
      "next stage   0.2857142857142857\n",
      "\n",
      "are some   0.004149377593360996\n",
      "\n",
      "processed Airline   0.16666666666666666\n",
      "\n",
      "capitalization at   0.3333333333333333\n",
      "\n",
      "dictionary and   0.14285714285714285\n",
      "\n",
      "'s annual   0.0196078431372549\n",
      "\n",
      "present in   0.8333333333333334\n",
      "\n",
      "images .   0.16666666666666666\n",
      "\n",
      "PhD thesis   1.0\n",
      "\n",
      "the literature   0.0006920415224913495\n",
      "\n",
      "human raters   0.021739130434782608\n",
      "\n",
      "machine-translation approaches   0.5\n",
      "\n",
      "A post   0.02\n",
      "\n",
      "the biomedical   0.0006920415224913495\n",
      "\n",
      "levels for   0.13636363636363635\n",
      "\n",
      "in France   0.003745318352059925\n",
      "\n",
      "typical accuracy   0.1111111111111111\n",
      "\n",
      "domain is   0.05\n",
      "\n",
      ", Roger   0.0005614823133071309\n",
      "\n",
      "Kurzweil sold   0.14285714285714285\n",
      "\n",
      "because two   0.03333333333333333\n",
      "\n",
      "'' exceeded   0.005154639175257732\n",
      "\n",
      "name and   0.2\n",
      "\n",
      "for NLP   0.0036101083032490976\n",
      "\n",
      "of keyphrases   0.00267379679144385\n",
      "\n",
      "transducer verifying   0.5\n",
      "\n",
      "-RRB- are   0.008130081300813009\n",
      "\n",
      "Armed Forces   1.0\n",
      "\n",
      "for naval   0.0036101083032490976\n",
      "\n",
      ", is   0.0072992700729927005\n",
      "\n",
      "release beyond   0.3333333333333333\n",
      "\n",
      "question can   0.023809523809523808\n",
      "\n",
      "visible under   0.3333333333333333\n",
      "\n",
      "evaluation Black-box   0.018518518518518517\n",
      "\n",
      "languages can   0.04\n",
      "\n",
      "character for   0.045454545454545456\n",
      "\n",
      "meaning to   0.08695652173913043\n",
      "\n",
      "-- if   0.08\n",
      "\n",
      "OCR ''   0.04081632653061224\n",
      "\n",
      "abilities .   1.0\n",
      "\n",
      "textual weather   0.2\n",
      "\n",
      "`` case   0.005291005291005291\n",
      "\n",
      "problems for   0.058823529411764705\n",
      "\n",
      "as Scansoft   0.003484320557491289\n",
      "\n",
      "NLP Main   0.02127659574468085\n",
      "\n",
      "scientists ,   1.0\n",
      "\n",
      "then extrapolate   0.02857142857142857\n",
      "\n",
      "of sentences   0.006238859180035651\n",
      "\n",
      "acquiring coarse-grained   1.0\n",
      "\n",
      "formal rules   0.1111111111111111\n",
      "\n",
      "of perspective   0.00089126559714795\n",
      "\n",
      "nine ''   1.0\n",
      "\n",
      "Bible Society   1.0\n",
      "\n",
      "Cognitive psychology   0.3333333333333333\n",
      "\n",
      "improve performance   0.07692307692307693\n",
      "\n",
      "Chinese and   0.14285714285714285\n",
      "\n",
      "The technology   0.005208333333333333\n",
      "\n",
      "are expected   0.004149377593360996\n",
      "\n",
      "corpus contains   0.03225806451612903\n",
      "\n",
      ", meaning   0.0005614823133071309\n",
      "\n",
      "-LRB- ``   0.02168021680216802\n",
      "\n",
      "how many   0.10344827586206896\n",
      "\n",
      "the partial   0.0006920415224913495\n",
      "\n",
      "we register   0.022222222222222223\n",
      "\n",
      "these terms   0.023809523809523808\n",
      "\n",
      "as categories   0.003484320557491289\n",
      "\n",
      "different levels   0.02040816326530612\n",
      "\n",
      "Svenka Savic   1.0\n",
      "\n",
      "good source   0.07692307692307693\n",
      "\n",
      "stationary probabilities   0.14285714285714285\n",
      "\n",
      "requires humans   0.0625\n",
      "\n",
      "earliest-used algorithms   0.5\n",
      "\n",
      "within their   0.05555555555555555\n",
      "\n",
      "TextRank .   0.07142857142857142\n",
      "\n",
      "keep track   0.3333333333333333\n",
      "\n",
      "noun than   0.07142857142857142\n",
      "\n",
      "<s> Vulcan   0.0007686395080707148\n",
      "\n",
      "set and   0.02564102564102564\n",
      "\n",
      "morphological ,   0.3333333333333333\n",
      "\n",
      "the E-set   0.0006920415224913495\n",
      "\n",
      "permuted automatically   1.0\n",
      "\n",
      "Sociologist Harold   1.0\n",
      "\n",
      "level of   0.35\n",
      "\n",
      "<s> Extractive   0.0007686395080707148\n",
      "\n",
      "things ,   0.3333333333333333\n",
      "\n",
      "substantial funding   0.2\n",
      "\n",
      "rely are   0.14285714285714285\n",
      "\n",
      "and see   0.001445086705202312\n",
      "\n",
      "keyphrases as   0.02857142857142857\n",
      "\n",
      "among sentences   0.125\n",
      "\n",
      "hour or   1.0\n",
      "\n",
      "the sizes   0.0006920415224913495\n",
      "\n",
      "turn a   0.16666666666666666\n",
      "\n",
      "be combined   0.004219409282700422\n",
      "\n",
      "degree -LRB-   0.16666666666666666\n",
      "\n",
      "soft decisions   0.5\n",
      "\n",
      "isolation of   0.5\n",
      "\n",
      "One of   0.15384615384615385\n",
      "\n",
      "different speaker   0.02040816326530612\n",
      "\n",
      "others assign   0.08333333333333333\n",
      "\n",
      "case .   0.17647058823529413\n",
      "\n",
      "Task description   0.3333333333333333\n",
      "\n",
      "reference summary   0.375\n",
      "\n",
      "-LRB- 2005   0.0027100271002710027\n",
      "\n",
      "that performance   0.010638297872340425\n",
      "\n",
      "increasing the   0.3333333333333333\n",
      "\n",
      "tested in   0.5\n",
      "\n",
      "rapid access   1.0\n",
      "\n",
      "an investigation   0.007575757575757576\n",
      "\n",
      "elaboration ,   1.0\n",
      "\n",
      "Statistical models   0.1111111111111111\n",
      "\n",
      "recursively .   0.5\n",
      "\n",
      "summarization Machine   0.02\n",
      "\n",
      ": setting   0.00980392156862745\n",
      "\n",
      "with certain   0.00546448087431694\n",
      "\n",
      "summaries There   0.023255813953488372\n",
      "\n",
      "OS or   0.5\n",
      "\n",
      "the goal   0.002768166089965398\n",
      "\n",
      "the differences   0.0006920415224913495\n",
      "\n",
      "' language   0.05263157894736842\n",
      "\n",
      "One study   0.07692307692307693\n",
      "\n",
      "proportional to   1.0\n",
      "\n",
      "the object   0.0006920415224913495\n",
      "\n",
      "which are   0.08695652173913043\n",
      "\n",
      "photos against   1.0\n",
      "\n",
      "keyword matching   1.0\n",
      "\n",
      "<s> Harris   0.0007686395080707148\n",
      "\n",
      "work ,   0.125\n",
      "\n",
      "hard to   0.3333333333333333\n",
      "\n",
      "example ,   0.6666666666666666\n",
      "\n",
      "task-effectiveness well   0.5\n",
      "\n",
      "sentence there   0.020833333333333332\n",
      "\n",
      "-LRB- subject   0.0027100271002710027\n",
      "\n",
      "Cullingford ,   1.0\n",
      "\n",
      "2011 -RRB-   0.5\n",
      "\n",
      "last example   0.2\n",
      "\n",
      "and computational   0.001445086705202312\n",
      "\n",
      "approaches and   0.03571428571428571\n",
      "\n",
      "in Japanese   0.0018726591760299626\n",
      "\n",
      "<s> Hence   0.0015372790161414297\n",
      "\n",
      "silence are   1.0\n",
      "\n",
      "customer service   1.0\n",
      "\n",
      "requires an   0.0625\n",
      "\n",
      "some kind   0.04819277108433735\n",
      "\n",
      "provided a   0.2\n",
      "\n",
      "' stability   0.05263157894736842\n",
      "\n",
      "Hybrid MT   0.5\n",
      "\n",
      "the holder   0.0006920415224913495\n",
      "\n",
      "or automotive   0.0045045045045045045\n",
      "\n",
      "control of   0.6\n",
      "\n",
      "Kurzweil Computer   0.2857142857142857\n",
      "\n",
      "Consider the   1.0\n",
      "\n",
      "considered separately   0.1111111111111111\n",
      "\n",
      "descriptive and   0.3333333333333333\n",
      "\n",
      "Head-driven phrase   1.0\n",
      "\n",
      "Compute features   1.0\n",
      "\n",
      "word boundary   0.016666666666666666\n",
      "\n",
      "new entrants   0.041666666666666664\n",
      "\n",
      "by different   0.005714285714285714\n",
      "\n",
      "query-biased summaries   1.0\n",
      "\n",
      "text or   0.018867924528301886\n",
      "\n",
      "why he   0.2857142857142857\n",
      "\n",
      "analysis on   0.015384615384615385\n",
      "\n",
      "reasoning components   0.14285714285714285\n",
      "\n",
      "issues of   0.2\n",
      "\n",
      "SPOTLIGHT system   1.0\n",
      "\n",
      "2000 .   0.3333333333333333\n",
      "\n",
      "male-female normalization   1.0\n",
      "\n",
      "distinguishes two   0.5\n",
      "\n",
      "<s> Eight   0.0007686395080707148\n",
      "\n",
      "makes intuitive   0.125\n",
      "\n",
      "Hulth showed   0.3333333333333333\n",
      "\n",
      "imagine the   1.0\n",
      "\n",
      "OCR .   0.02040816326530612\n",
      "\n",
      "speaker normalization   0.05555555555555555\n",
      "\n",
      "or what   0.009009009009009009\n",
      "\n",
      "human languages   0.021739130434782608\n",
      "\n",
      "books a   1.0\n",
      "\n",
      "disambiguation Word-sense   0.1\n",
      "\n",
      "bites ''   0.3333333333333333\n",
      "\n",
      "real time   0.1111111111111111\n",
      "\n",
      "resulted in   1.0\n",
      "\n",
      "same in   0.04\n",
      "\n",
      "involve working   0.16666666666666666\n",
      "\n",
      "ambiguities or   0.25\n",
      "\n",
      "The goal   0.005208333333333333\n",
      "\n",
      "to backup   0.0013280212483399733\n",
      "\n",
      "reporter -LRB-   1.0\n",
      "\n",
      "Methods Computers   0.25\n",
      "\n",
      "generated -LRB-   0.06666666666666667\n",
      "\n",
      "originally as   0.5\n",
      "\n",
      "extract the   0.25\n",
      "\n",
      "This analysis   0.015873015873015872\n",
      "\n",
      "or dictionary   0.0045045045045045045\n",
      "\n",
      "or ,   0.0045045045045045045\n",
      "\n",
      "discriminate keyphrases   0.3333333333333333\n",
      "\n",
      "may not   0.09615384615384616\n",
      "\n",
      "for tagging   0.0036101083032490976\n",
      "\n",
      ": task-based   0.00980392156862745\n",
      "\n",
      "often do   0.022727272727272728\n",
      "\n",
      "rocks returned   1.0\n",
      "\n",
      "ATC situation   0.2\n",
      "\n",
      "be representative   0.004219409282700422\n",
      "\n",
      "harder and   0.14285714285714285\n",
      "\n",
      "machines by   0.25\n",
      "\n",
      "alone ,   0.25\n",
      "\n",
      "began to   0.5714285714285714\n",
      "\n",
      "methods parse   0.022727272727272728\n",
      "\n",
      "to represent   0.0013280212483399733\n",
      "\n",
      "associated number   0.25\n",
      "\n",
      "Canada Post   0.16666666666666666\n",
      "\n",
      "unigrams appear   0.08333333333333333\n",
      "\n",
      "version ;   0.3333333333333333\n",
      "\n",
      "the U.S.   0.002768166089965398\n",
      "\n",
      "parsing systems   0.03571428571428571\n",
      "\n",
      "Genres of   1.0\n",
      "\n",
      "predict what   0.16666666666666666\n",
      "\n",
      "been much   0.014705882352941176\n",
      "\n",
      "<s> So   0.0023059185242121443\n",
      "\n",
      "as 10   0.003484320557491289\n",
      "\n",
      "evaluated using   0.14285714285714285\n",
      "\n",
      "fact ambiguous   0.09090909090909091\n",
      "\n",
      "distinguished .   1.0\n",
      "\n",
      "and Zacharov   0.001445086705202312\n",
      "\n",
      "document formats   0.027777777777777776\n",
      "\n",
      "a person   0.013496932515337423\n",
      "\n",
      "which recognized   0.007246376811594203\n",
      "\n",
      "previously-written human   1.0\n",
      "\n",
      "and informativeness   0.001445086705202312\n",
      "\n",
      "co-occurrence graph   0.6666666666666666\n",
      "\n",
      "word was   0.016666666666666666\n",
      "\n",
      "LILOG ,   0.5\n",
      "\n",
      "no information   0.07692307692307693\n",
      "\n",
      "stationary process   0.14285714285714285\n",
      "\n",
      "user needs   0.07142857142857142\n",
      "\n",
      "dogs →   0.14285714285714285\n",
      "\n",
      "and Chinese   0.001445086705202312\n",
      "\n",
      "or evaluation   0.0045045045045045045\n",
      "\n",
      "The systems   0.005208333333333333\n",
      "\n",
      "by mapping   0.005714285714285714\n",
      "\n",
      "well known   0.03571428571428571\n",
      "\n",
      "encyclopedia ''   1.0\n",
      "\n",
      "together .   0.125\n",
      "\n",
      "any supervised   0.03225806451612903\n",
      "\n",
      "including probabilistic   0.07142857142857142\n",
      "\n",
      "returned from   0.5\n",
      "\n",
      "got about   1.0\n",
      "\n",
      "Rates Increase   1.0\n",
      "\n",
      "has meant   0.011904761904761904\n",
      "\n",
      "produced systems   0.2222222222222222\n",
      "\n",
      "glass-box evaluation   1.0\n",
      "\n",
      "the human   0.0020761245674740486\n",
      "\n",
      "text-understanding system   1.0\n",
      "\n",
      "instance text   0.07142857142857142\n",
      "\n",
      "not functioning   0.008928571428571428\n",
      "\n",
      "We can   0.2857142857142857\n",
      "\n",
      "senses .   0.5\n",
      "\n",
      "bi-directional inference   1.0\n",
      "\n",
      "Unsupervised approaches   0.16666666666666666\n",
      "\n",
      "if one   0.03571428571428571\n",
      "\n",
      ", Systran   0.0005614823133071309\n",
      "\n",
      "ones that   0.1\n",
      "\n",
      "these every   0.023809523809523808\n",
      "\n",
      "generated summary   0.06666666666666667\n",
      "\n",
      "document set   0.027777777777777776\n",
      "\n",
      "vector machines   0.3333333333333333\n",
      "\n",
      ", stemming   0.0005614823133071309\n",
      "\n",
      "or names   0.0045045045045045045\n",
      "\n",
      "styles itself   1.0\n",
      "\n",
      "texts and   0.058823529411764705\n",
      "\n",
      "new ,   0.041666666666666664\n",
      "\n",
      "field are   0.037037037037037035\n",
      "\n",
      "counterparts in   1.0\n",
      "\n",
      "detail but   0.5\n",
      "\n",
      "various aspects   0.05555555555555555\n",
      "\n",
      "score .   0.5\n",
      "\n",
      "over the   0.25\n",
      "\n",
      "-LRB- ATN   0.0027100271002710027\n",
      "\n",
      "is analyzed   0.006097560975609756\n",
      "\n",
      "<s> Work   0.0015372790161414297\n",
      "\n",
      "An explicit   0.0625\n",
      "\n",
      "what happens   0.03125\n",
      "\n",
      "program is   0.045454545454545456\n",
      "\n",
      "for multiple   0.0036101083032490976\n",
      "\n",
      "on written   0.0047169811320754715\n",
      "\n",
      "summary -LRB-   0.023809523809523808\n",
      "\n",
      "abbreviations ,   0.4\n",
      "\n",
      "During the   0.5\n",
      "\n",
      "has thousands   0.011904761904761904\n",
      "\n",
      "tagger to   0.1111111111111111\n",
      "\n",
      "dogs the   0.14285714285714285\n",
      "\n",
      "recognition -RRB-   0.008264462809917356\n",
      "\n",
      "One approach   0.07692307692307693\n",
      "\n",
      "sailor dogs   0.2\n",
      "\n",
      "language of   0.006756756756756757\n",
      "\n",
      "in systems   0.003745318352059925\n",
      "\n",
      ", Constraint   0.0005614823133071309\n",
      "\n",
      "President Obama   0.25\n",
      "\n",
      "rules .   0.13953488372093023\n",
      "\n",
      "resolve .   0.25\n",
      "\n",
      "values ,   0.125\n",
      "\n",
      "These standards   0.058823529411764705\n",
      "\n",
      ", medicine   0.0005614823133071309\n",
      "\n",
      "an attempt   0.022727272727272728\n",
      "\n",
      "in operational   0.0018726591760299626\n",
      "\n",
      "some training   0.012048192771084338\n",
      "\n",
      "to wreck   0.0013280212483399733\n",
      "\n",
      ", models   0.0005614823133071309\n",
      "\n",
      "Many systems   0.08333333333333333\n",
      "\n",
      "relative certainty   0.3333333333333333\n",
      "\n",
      "and treat   0.001445086705202312\n",
      "\n",
      "in advanced   0.0018726591760299626\n",
      "\n",
      "to say   0.00398406374501992\n",
      "\n",
      "results were   0.047619047619047616\n",
      "\n",
      "since one   0.1\n",
      "\n",
      "adviser for   1.0\n",
      "\n",
      "Maximum entropy-based   0.3333333333333333\n",
      "\n",
      "are ambiguous   0.004149377593360996\n",
      "\n",
      "and makes   0.001445086705202312\n",
      "\n",
      "is part   0.0020325203252032522\n",
      "\n",
      "popularity as   1.0\n",
      "\n",
      "methods have   0.045454545454545456\n",
      "\n",
      "could be   0.25\n",
      "\n",
      ", LexRank   0.0005614823133071309\n",
      "\n",
      "Turing test   0.5\n",
      "\n",
      "English-like syntax   0.3333333333333333\n",
      "\n",
      "inter-texual and   0.5\n",
      "\n",
      "sets to   0.09090909090909091\n",
      "\n",
      "of linguistic   0.0017825311942959\n",
      "\n",
      "such as   0.7317073170731707\n",
      "\n",
      "-- are   0.08\n",
      "\n",
      "are surprisingly   0.004149377593360996\n",
      "\n",
      "index entries   1.0\n",
      "\n",
      "the judge   0.0006920415224913495\n",
      "\n",
      "to eliminate   0.0026560424966799467\n",
      "\n",
      "developing text   0.25\n",
      "\n",
      "is semantic   0.0020325203252032522\n",
      "\n",
      "Neural Network   0.25\n",
      "\n",
      "the inter-word   0.0006920415224913495\n",
      "\n",
      "and above   0.001445086705202312\n",
      "\n",
      "On a   0.16666666666666666\n",
      "\n",
      "be thousands   0.004219409282700422\n",
      "\n",
      "that cause   0.0035460992907801418\n",
      "\n",
      "13 parsers   0.5\n",
      "\n",
      "UK .   0.5\n",
      "\n",
      "negative up   0.125\n",
      "\n",
      "Online software   0.5\n",
      "\n",
      "has also   0.03571428571428571\n",
      "\n",
      "the probable   0.0006920415224913495\n",
      "\n",
      "strengths and   0.5\n",
      "\n",
      "Robinson ,   1.0\n",
      "\n",
      "About 90   0.5\n",
      "\n",
      "1998 -RRB-   0.5\n",
      "\n",
      "ambiguity and   0.125\n",
      "\n",
      "same in-depth   0.04\n",
      "\n",
      "similarities to   0.5\n",
      "\n",
      "structures that   0.4\n",
      "\n",
      "al. 1989   1.0\n",
      "\n",
      "likelihood for   0.3333333333333333\n",
      "\n",
      "the construction   0.0006920415224913495\n",
      "\n",
      "the Wordnet   0.0006920415224913495\n",
      "\n",
      "rule-based methods   0.14285714285714285\n",
      "\n",
      "automated ,   0.14285714285714285\n",
      "\n",
      "represent a   0.2222222222222222\n",
      "\n",
      "work has   0.08333333333333333\n",
      "\n",
      "<s> Performing   0.0007686395080707148\n",
      "\n",
      "of British   0.00089126559714795\n",
      "\n",
      "Constraints e.g.   0.3333333333333333\n",
      "\n",
      "emotion ,   1.0\n",
      "\n",
      "generate keyphrases   0.05555555555555555\n",
      "\n",
      "chatterbots such   0.5\n",
      "\n",
      "Context-free grammars   1.0\n",
      "\n",
      "at that   0.014705882352941176\n",
      "\n",
      "in deaf   0.0018726591760299626\n",
      "\n",
      "addressee at   1.0\n",
      "\n",
      "probabilities returned   0.09090909090909091\n",
      "\n",
      "several methods   0.045454545454545456\n",
      "\n",
      "name of   0.2\n",
      "\n",
      "coefficients to   0.25\n",
      "\n",
      "to unfamiliar   0.0013280212483399733\n",
      "\n",
      "coordinates and   1.0\n",
      "\n",
      "sentence to   0.020833333333333332\n",
      "\n",
      "<s> Incorporating   0.0007686395080707148\n",
      "\n",
      "and probably   0.001445086705202312\n",
      "\n",
      "samples from   0.5\n",
      "\n",
      "not be   0.10714285714285714\n",
      "\n",
      "input gracefully   0.024390243902439025\n",
      "\n",
      "analysis depends   0.015384615384615385\n",
      "\n",
      "each example   0.044444444444444446\n",
      "\n",
      "very complex   0.024390243902439025\n",
      "\n",
      "intelligence .   0.125\n",
      "\n",
      ", responding   0.0005614823133071309\n",
      "\n",
      "instance when   0.07142857142857142\n",
      "\n",
      "of using   0.00089126559714795\n",
      "\n",
      "bunch of   1.0\n",
      "\n",
      "intra-texual .   1.0\n",
      "\n",
      "Aermacchi M-346   1.0\n",
      "\n",
      "reliable results   0.5\n",
      "\n",
      "data can   0.025974025974025976\n",
      "\n",
      "acoustic modeling   0.3333333333333333\n",
      "\n",
      "house -LRB-   0.5\n",
      "\n",
      "accuracy may   0.03225806451612903\n",
      "\n",
      "as paraphrase   0.003484320557491289\n",
      "\n",
      "Topic segmentation   1.0\n",
      "\n",
      "distance ,   0.6666666666666666\n",
      "\n",
      "higher order   0.14285714285714285\n",
      "\n",
      "into all   0.01282051282051282\n",
      "\n",
      "purposes ,   0.25\n",
      "\n",
      "work for   0.041666666666666664\n",
      "\n",
      "involves doing   0.1\n",
      "\n",
      "The interpretation   0.005208333333333333\n",
      "\n",
      "Answer formulation   0.3333333333333333\n",
      "\n",
      "of product   0.00089126559714795\n",
      "\n",
      "as individual   0.003484320557491289\n",
      "\n",
      "syntactic parsers   0.07692307692307693\n",
      "\n",
      "underlie the   1.0\n",
      "\n",
      "that operated   0.0035460992907801418\n",
      "\n",
      "patterns in   0.2\n",
      "\n",
      "of outputs   0.00089126559714795\n",
      "\n",
      "some major   0.012048192771084338\n",
      "\n",
      "dependent on   0.6666666666666666\n",
      "\n",
      "instead optimize   0.14285714285714285\n",
      "\n",
      "segment to   0.1111111111111111\n",
      "\n",
      "viewed as   1.0\n",
      "\n",
      "systems such   0.017857142857142856\n",
      "\n",
      "when the   0.11428571428571428\n",
      "\n",
      "Before a   0.5\n",
      "\n",
      "late 1950s   0.1111111111111111\n",
      "\n",
      "is meaningful   0.0020325203252032522\n",
      "\n",
      "This new   0.015873015873015872\n",
      "\n",
      "7110.65 details   1.0\n",
      "\n",
      "Cognitive Process   0.3333333333333333\n",
      "\n",
      "statistical methods   0.12121212121212122\n",
      "\n",
      "not sound   0.008928571428571428\n",
      "\n",
      "work well   0.041666666666666664\n",
      "\n",
      "classified into   1.0\n",
      "\n",
      "refined score   1.0\n",
      "\n",
      "<s> Once   0.003843197540353574\n",
      "\n",
      "therefore it   0.6\n",
      "\n",
      "one .   0.03076923076923077\n",
      "\n",
      ", picture   0.0005614823133071309\n",
      "\n",
      "<s> Collection   0.0007686395080707148\n",
      "\n",
      "every 10msec   0.3333333333333333\n",
      "\n",
      "final language   0.1111111111111111\n",
      "\n",
      "Accuracy is   0.14285714285714285\n",
      "\n",
      "or fade   0.0045045045045045045\n",
      "\n",
      "measures of   0.16666666666666666\n",
      "\n",
      "improve .   0.07692307692307693\n",
      "\n",
      "different similarity   0.02040816326530612\n",
      "\n",
      "summaries using   0.023255813953488372\n",
      "\n",
      "to NLP   0.0013280212483399733\n",
      "\n",
      "human-language question   1.0\n",
      "\n",
      "because it   0.1\n",
      "\n",
      "smaller more   0.14285714285714285\n",
      "\n",
      "with regard   0.02185792349726776\n",
      "\n",
      "bore similarities   1.0\n",
      "\n",
      "all nouns   0.023255813953488372\n",
      "\n",
      "between computers   0.02564102564102564\n",
      "\n",
      "even the   0.07407407407407407\n",
      "\n",
      "system with   0.010752688172043012\n",
      "\n",
      "during a   0.2\n",
      "\n",
      "develop innovative   0.2\n",
      "\n",
      "marked by   0.3333333333333333\n",
      "\n",
      "-LRB- predict   0.0027100271002710027\n",
      "\n",
      "or POST   0.0045045045045045045\n",
      "\n",
      "1960s .   0.3333333333333333\n",
      "\n",
      "Using the   0.5\n",
      "\n",
      "F-16 aircraft   0.5\n",
      "\n",
      "domain might   0.05\n",
      "\n",
      "could imagine   0.0625\n",
      "\n",
      "Informally ,   1.0\n",
      "\n",
      "two illustrates   0.034482758620689655\n",
      "\n",
      "as Eugene   0.003484320557491289\n",
      "\n",
      "These findings   0.058823529411764705\n",
      "\n",
      "probabilistic and   0.14285714285714285\n",
      "\n",
      "articles in   0.25\n",
      "\n",
      "because punctuation   0.03333333333333333\n",
      "\n",
      "used is   0.008849557522123894\n",
      "\n",
      "recognition problems   0.008264462809917356\n",
      "\n",
      "summarization task   0.02\n",
      "\n",
      "groups :   0.2\n",
      "\n",
      "most spoken   0.034482758620689655\n",
      "\n",
      "distinguishes these   0.5\n",
      "\n",
      "of User   0.00089126559714795\n",
      "\n",
      "phone error   0.25\n",
      "\n",
      "applied different   0.06666666666666667\n",
      "\n",
      "whether medium   0.07692307692307693\n",
      "\n",
      "used mostly   0.008849557522123894\n",
      "\n",
      "-LRB- like   0.0027100271002710027\n",
      "\n",
      "as semiotics   0.003484320557491289\n",
      "\n",
      "just seen   0.1111111111111111\n",
      "\n",
      "system depend   0.010752688172043012\n",
      "\n",
      "a consideration   0.001226993865030675\n",
      "\n",
      "logic structures   0.25\n",
      "\n",
      "given sequences   0.041666666666666664\n",
      "\n",
      "as words   0.003484320557491289\n",
      "\n",
      "study based   0.25\n",
      "\n",
      "Racter ,   1.0\n",
      "\n",
      "and W.   0.001445086705202312\n",
      "\n",
      "although there   0.16666666666666666\n",
      "\n",
      "US patent   0.2857142857142857\n",
      "\n",
      "and multitude   0.001445086705202312\n",
      "\n",
      "authenticate or   1.0\n",
      "\n",
      "conclusions .   1.0\n",
      "\n",
      "-LRB- DA   0.005420054200542005\n",
      "\n",
      "will need   0.02857142857142857\n",
      "\n",
      "<s> Answer   0.0015372790161414297\n",
      "\n",
      "major constituents   0.08333333333333333\n",
      "\n",
      "often continues   0.022727272727272728\n",
      "\n",
      "camera ,   0.5\n",
      "\n",
      "tokens form   0.14285714285714285\n",
      "\n",
      ", 3   0.0005614823133071309\n",
      "\n",
      "More complex   0.1111111111111111\n",
      "\n",
      "at A.C.   0.014705882352941176\n",
      "\n",
      "language that   0.006756756756756757\n",
      "\n",
      "the Eagles   0.0006920415224913495\n",
      "\n",
      "other forms   0.014285714285714285\n",
      "\n",
      "general principles   0.045454545454545456\n",
      "\n",
      "different aspects   0.02040816326530612\n",
      "\n",
      "search engines   0.18181818181818182\n",
      "\n",
      "case with   0.058823529411764705\n",
      "\n",
      "person\\/persons rather   1.0\n",
      "\n",
      "by spaces   0.005714285714285714\n",
      "\n",
      "artificial languages   0.09090909090909091\n",
      "\n",
      "and captioned   0.001445086705202312\n",
      "\n",
      "expression and   0.2\n",
      "\n",
      "in 2006   0.0018726591760299626\n",
      "\n",
      "can say   0.0055248618784530384\n",
      "\n",
      "on Mandarin   0.0047169811320754715\n",
      "\n",
      "of handwritten   0.00089126559714795\n",
      "\n",
      "prefer to   0.5\n",
      "\n",
      "web site   0.25\n",
      "\n",
      "in 2004   0.0018726591760299626\n",
      "\n",
      "assessments of   1.0\n",
      "\n",
      "preceding token   1.0\n",
      "\n",
      "of training   0.0035650623885918\n",
      "\n",
      "Harvey Sacks   1.0\n",
      "\n",
      "large dictionaries   0.043478260869565216\n",
      "\n",
      "is known   0.006097560975609756\n",
      "\n",
      "used all   0.008849557522123894\n",
      "\n",
      "computer interaction   0.022727272727272728\n",
      "\n",
      "Just which   1.0\n",
      "\n",
      "to encode   0.0013280212483399733\n",
      "\n",
      "Kucera and   1.0\n",
      "\n",
      "the English   0.0020761245674740486\n",
      "\n",
      "recall .   0.6666666666666666\n",
      "\n",
      "speaker and   0.05555555555555555\n",
      "\n",
      "specific contexts   0.047619047619047616\n",
      "\n",
      "neutral .   0.5\n",
      "\n",
      "current efforts   0.14285714285714285\n",
      "\n",
      "nautical context   0.5\n",
      "\n",
      ", consisting   0.0005614823133071309\n",
      "\n",
      "the LOB   0.0006920415224913495\n",
      "\n",
      "centers of   1.0\n",
      "\n",
      "deduction to   1.0\n",
      "\n",
      "unit vertices   0.3333333333333333\n",
      "\n",
      "needs of   0.1\n",
      "\n",
      "triples that   0.3333333333333333\n",
      "\n",
      "detailed background   0.5\n",
      "\n",
      "the LexRank   0.0006920415224913495\n",
      "\n",
      "to judge   0.0026560424966799467\n",
      "\n",
      "tagging Koine   0.04\n",
      "\n",
      "of at   0.00089126559714795\n",
      "\n",
      "comprehend Morse   1.0\n",
      "\n",
      "including web   0.07142857142857142\n",
      "\n",
      "word of   0.016666666666666666\n",
      "\n",
      "why Vice   0.14285714285714285\n",
      "\n",
      "receivers .   1.0\n",
      "\n",
      "centres require   1.0\n",
      "\n",
      "lexicon with   0.1111111111111111\n",
      "\n",
      "by experts   0.005714285714285714\n",
      "\n",
      "of generating   0.00089126559714795\n",
      "\n",
      ", Paul   0.0016844469399213925\n",
      "\n",
      ": Instead   0.00980392156862745\n",
      "\n",
      "way and   0.041666666666666664\n",
      "\n",
      "Call home   1.0\n",
      "\n",
      "Speech can   0.03225806451612903\n",
      "\n",
      "usually faster   0.03125\n",
      "\n",
      "background material   0.3333333333333333\n",
      "\n",
      "but switched   0.014705882352941176\n",
      "\n",
      "in 1953   0.0018726591760299626\n",
      "\n",
      "Post Office   0.5\n",
      "\n",
      "to narrative   0.0013280212483399733\n",
      "\n",
      "attention to   0.5\n",
      "\n",
      "one to   0.03076923076923077\n",
      "\n",
      "account several   0.3333333333333333\n",
      "\n",
      "scale ,   0.3333333333333333\n",
      "\n",
      "subjective Yes\\/No   0.16666666666666666\n",
      "\n",
      "speed .   0.42857142857142855\n",
      "\n",
      "is Shift-Reduce   0.0020325203252032522\n",
      "\n",
      "not worked   0.008928571428571428\n",
      "\n",
      "Apparatus for   1.0\n",
      "\n",
      "Audio ,   0.5\n",
      "\n",
      "steer-point coordinates   1.0\n",
      "\n",
      "helicopter pilot   0.25\n",
      "\n",
      "concerns ;   0.5\n",
      "\n",
      "that nuggets   0.0035460992907801418\n",
      "\n",
      "be studied   0.004219409282700422\n",
      "\n",
      "the postal   0.0006920415224913495\n",
      "\n",
      "conditions ;   0.2\n",
      "\n",
      "Consortium has   1.0\n",
      "\n",
      "web page   0.125\n",
      "\n",
      "sentiment classification   0.04\n",
      "\n",
      "sample is   0.3333333333333333\n",
      "\n",
      "to what   0.005312084993359893\n",
      "\n",
      "its nascent   0.02857142857142857\n",
      "\n",
      "operate on   1.0\n",
      "\n",
      "sufficient include   0.2\n",
      "\n",
      "valuable new   0.5\n",
      "\n",
      "voice in   0.07692307692307693\n",
      "\n",
      "example shows   0.012345679012345678\n",
      "\n",
      "and found   0.001445086705202312\n",
      "\n",
      "problem can   0.022727272727272728\n",
      "\n",
      "way sentiment   0.041666666666666664\n",
      "\n",
      "sentiment in   0.08\n",
      "\n",
      "fast and   1.0\n",
      "\n",
      "see that   0.05\n",
      "\n",
      "language generation   0.033783783783783786\n",
      "\n",
      "are saying   0.004149377593360996\n",
      "\n",
      "country into   0.25\n",
      "\n",
      "Vocabulary is   0.3333333333333333\n",
      "\n",
      "<s> Task   0.0007686395080707148\n",
      "\n",
      "output by   0.038461538461538464\n",
      "\n",
      "Master lead-in   1.0\n",
      "\n",
      "a parser   0.0036809815950920245\n",
      "\n",
      "with implicit   0.00546448087431694\n",
      "\n",
      "An absorbing   0.0625\n",
      "\n",
      "of comprehensive   0.00089126559714795\n",
      "\n",
      "computer processing   0.022727272727272728\n",
      "\n",
      "of sound   0.0017825311942959\n",
      "\n",
      "to multi-platforms   0.0013280212483399733\n",
      "\n",
      "recorded all   0.5\n",
      "\n",
      "scans paper   1.0\n",
      "\n",
      "that when   0.0035460992907801418\n",
      "\n",
      "or she   0.0045045045045045045\n",
      "\n",
      "professional translator   1.0\n",
      "\n",
      ": the   0.0196078431372549\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "several other   0.045454545454545456\n",
      "\n",
      "strongly than   0.5\n",
      "\n",
      "Veterans Administration   1.0\n",
      "\n",
      "opinionated ,   1.0\n",
      "\n",
      "customers ,   0.5\n",
      "\n",
      "speech as   0.013157894736842105\n",
      "\n",
      "<s> Automatic   0.005380476556495004\n",
      "\n",
      "reflect a   1.0\n",
      "\n",
      "input -RRB-   0.024390243902439025\n",
      "\n",
      "Voice2Go -RRB-   1.0\n",
      "\n",
      "than conversation   0.022222222222222223\n",
      "\n",
      "and 2002   0.001445086705202312\n",
      "\n",
      "information extraction   0.021739130434782608\n",
      "\n",
      "networks as   0.07142857142857142\n",
      "\n",
      "correct .   0.2\n",
      "\n",
      "converting printed   0.5\n",
      "\n",
      "the common   0.0006920415224913495\n",
      "\n",
      "-LRB- http:\\/\\/haydn.isi.edu\\/ROUGE\\/   0.0027100271002710027\n",
      "\n",
      "for health   0.0036101083032490976\n",
      "\n",
      "a co-occurrence   0.001226993865030675\n",
      "\n",
      "Martin presents   0.5\n",
      "\n",
      "while an   0.05\n",
      "\n",
      "Since the   0.2\n",
      "\n",
      "divider ,   1.0\n",
      "\n",
      "another .   0.23076923076923078\n",
      "\n",
      "simple world   0.038461538461538464\n",
      "\n",
      "resolution remains   0.25\n",
      "\n",
      "the dynamics   0.0006920415224913495\n",
      "\n",
      "potentially more   0.3333333333333333\n",
      "\n",
      "denote an   0.5\n",
      "\n",
      "as an   0.04529616724738676\n",
      "\n",
      "Statistics derived   0.3333333333333333\n",
      "\n",
      "involve counting   0.16666666666666666\n",
      "\n",
      "each other   0.13333333333333333\n",
      "\n",
      "segments besides   0.2\n",
      "\n",
      "their associated   0.029411764705882353\n",
      "\n",
      "computational concerns   0.1\n",
      "\n",
      "exercises on   1.0\n",
      "\n",
      "project .   0.07692307692307693\n",
      "\n",
      "remembering ,   1.0\n",
      "\n",
      "pitch ,   1.0\n",
      "\n",
      "understanding approximates   0.030303030303030304\n",
      "\n",
      "the keyphrases   0.001384083044982699\n",
      "\n",
      "choose from   0.5\n",
      "\n",
      "instead of   0.5714285714285714\n",
      "\n",
      "Imagine you   1.0\n",
      "\n",
      "stories on   1.0\n",
      "\n",
      "patented and   1.0\n",
      "\n",
      "recognizers into   0.5\n",
      "\n",
      "document 7110.65   0.027777777777777776\n",
      "\n",
      "assessed mainly   1.0\n",
      "\n",
      "to refer   0.0013280212483399733\n",
      "\n",
      "theory ,   0.3076923076923077\n",
      "\n",
      "a multi-way   0.001226993865030675\n",
      "\n",
      "technique in   0.14285714285714285\n",
      "\n",
      "acts ,   0.3333333333333333\n",
      "\n",
      "machine and   0.012658227848101266\n",
      "\n",
      "a long-time   0.001226993865030675\n",
      "\n",
      "by computer   0.017142857142857144\n",
      "\n",
      "business data   0.25\n",
      "\n",
      "even lower   0.037037037037037035\n",
      "\n",
      "Some critics   0.047619047619047616\n",
      "\n",
      "for recognizing   0.0036101083032490976\n",
      "\n",
      "Optical Character   0.3333333333333333\n",
      "\n",
      ", Paroubek   0.0005614823133071309\n",
      "\n",
      "the Reader   0.0006920415224913495\n",
      "\n",
      "'' http:\\/\\/arxiv.org\\/abs\\/1104.2086   0.005154639175257732\n",
      "\n",
      "as part   0.006968641114982578\n",
      "\n",
      "distinguish reliably   0.2\n",
      "\n",
      "is sufficient   0.0040650406504065045\n",
      "\n",
      "automatically to   0.047619047619047616\n",
      "\n",
      "are instructed   0.004149377593360996\n",
      "\n",
      "related in   0.06666666666666667\n",
      "\n",
      "By 1985   0.3333333333333333\n",
      "\n",
      "known keyphrases   0.15384615384615385\n",
      "\n",
      "assumed that   1.0\n",
      "\n",
      "standard -LRB-   0.14285714285714285\n",
      "\n",
      "Intrinsic evaluations   0.3333333333333333\n",
      "\n",
      "is why   0.0020325203252032522\n",
      "\n",
      "optimizes parameters   1.0\n",
      "\n",
      "predicted value   0.5\n",
      "\n",
      "tag ''   0.0625\n",
      "\n",
      "additional citations   0.16666666666666666\n",
      "\n",
      "negligibly rare   1.0\n",
      "\n",
      "When the   0.14285714285714285\n",
      "\n",
      "call routing   0.3333333333333333\n",
      "\n",
      "automatic procedures   0.043478260869565216\n",
      "\n",
      "steady increase   0.5\n",
      "\n",
      "% in   0.02564102564102564\n",
      "\n",
      "`` hub   0.005291005291005291\n",
      "\n",
      "ASR ''   0.16666666666666666\n",
      "\n",
      "sense that   0.125\n",
      "\n",
      "recording conditions   1.0\n",
      "\n",
      "wave as   0.1111111111111111\n",
      "\n",
      "summaries and   0.046511627906976744\n",
      "\n",
      "characters that   0.0625\n",
      "\n",
      "reason why   0.25\n",
      "\n",
      "distribution ;   0.25\n",
      "\n",
      ", coughing   0.0005614823133071309\n",
      "\n",
      "better guide   0.1111111111111111\n",
      "\n",
      "allows users   0.25\n",
      "\n",
      ", Santoni   0.0005614823133071309\n",
      "\n",
      "issue of   0.125\n",
      "\n",
      "-RRB- Parsing   0.0027100271002710027\n",
      "\n",
      "informational structures   0.5\n",
      "\n",
      "of hidden   0.00089126559714795\n",
      "\n",
      "never went   0.2\n",
      "\n",
      "Fowler ,   1.0\n",
      "\n",
      "governmental proceedings   1.0\n",
      "\n",
      "higher than   0.14285714285714285\n",
      "\n",
      "robot questions   0.5\n",
      "\n",
      "ambiguous English   0.08333333333333333\n",
      "\n",
      "took Harris   1.0\n",
      "\n",
      "Talmy Givón   1.0\n",
      "\n",
      "1980s the   0.1111111111111111\n",
      "\n",
      "topics and   0.14285714285714285\n",
      "\n",
      "and power   0.001445086705202312\n",
      "\n",
      "1 %   0.5\n",
      "\n",
      "the strength   0.001384083044982699\n",
      "\n",
      "good results   0.07692307692307693\n",
      "\n",
      "source language   0.125\n",
      "\n",
      "relaxed parser   1.0\n",
      "\n",
      "at least   0.07352941176470588\n",
      "\n",
      "character stream   0.045454545454545456\n",
      "\n",
      "Comparing these   1.0\n",
      "\n",
      "-- makes   0.04\n",
      "\n",
      "was not   0.025974025974025976\n",
      "\n",
      "Subsumption -LRB-   1.0\n",
      "\n",
      "<s> Further   0.0023059185242121443\n",
      "\n",
      ", results   0.0005614823133071309\n",
      "\n",
      "procedure for   0.3333333333333333\n",
      "\n",
      "an era   0.007575757575757576\n",
      "\n",
      "problem with   0.022727272727272728\n",
      "\n",
      "time or   0.030303030303030304\n",
      "\n",
      "Paul W.   0.2\n",
      "\n",
      "own ;   0.16666666666666666\n",
      "\n",
      ", 5000   0.0005614823133071309\n",
      "\n",
      "To find   0.1111111111111111\n",
      "\n",
      "stop character   1.0\n",
      "\n",
      "as people   0.003484320557491289\n",
      "\n",
      "candidates instead   0.2\n",
      "\n",
      "about this   0.025\n",
      "\n",
      "in our   0.0018726591760299626\n",
      "\n",
      "Sentence boundaries   0.2\n",
      "\n",
      ": Extract   0.00980392156862745\n",
      "\n",
      "ontologies -LRB-   0.16666666666666666\n",
      "\n",
      "and right-most   0.001445086705202312\n",
      "\n",
      "measures can   0.3333333333333333\n",
      "\n",
      "high recognition   0.05555555555555555\n",
      "\n",
      "in 1954   0.003745318352059925\n",
      "\n",
      "a complex   0.006134969325153374\n",
      "\n",
      "then spoke   0.02857142857142857\n",
      "\n",
      "records and   0.25\n",
      "\n",
      "term meaning   0.05555555555555555\n",
      "\n",
      "script .   0.5\n",
      "\n",
      "The USAF   0.005208333333333333\n",
      "\n",
      "of various   0.00089126559714795\n",
      "\n",
      "with edit   0.00546448087431694\n",
      "\n",
      "Further information   0.3333333333333333\n",
      "\n",
      "can present   0.0055248618784530384\n",
      "\n",
      "and developed   0.002890173410404624\n",
      "\n",
      "'s tagger   0.0196078431372549\n",
      "\n",
      "determining sentiment   0.16666666666666666\n",
      "\n",
      "reducing the   0.5\n",
      "\n",
      "called grammatical   0.05555555555555555\n",
      "\n",
      "choices that   0.2\n",
      "\n",
      "degree .   0.16666666666666666\n",
      "\n",
      "together with   0.125\n",
      "\n",
      ": how   0.00980392156862745\n",
      "\n",
      "a web   0.001226993865030675\n",
      "\n",
      "type ,   0.07142857142857142\n",
      "\n",
      "shifted priorities   1.0\n",
      "\n",
      "specific error   0.047619047619047616\n",
      "\n",
      "sentences instead   0.013157894736842105\n",
      "\n",
      "to database   0.0013280212483399733\n",
      "\n",
      ": Natural   0.00980392156862745\n",
      "\n",
      "supported by   1.0\n",
      "\n",
      "a classification   0.001226993865030675\n",
      "\n",
      "ambiguity because   0.125\n",
      "\n",
      "the statistical   0.001384083044982699\n",
      "\n",
      "for real-world   0.007220216606498195\n",
      "\n",
      ", recorded   0.0005614823133071309\n",
      "\n",
      "a news   0.00245398773006135\n",
      "\n",
      "marking abbreviations   0.5\n",
      "\n",
      "still the   0.06666666666666667\n",
      "\n",
      "derived meaning   0.16666666666666666\n",
      "\n",
      "the factors   0.0006920415224913495\n",
      "\n",
      "<s> Furthermore   0.004611837048424289\n",
      "\n",
      "while Church   0.05\n",
      "\n",
      "with different   0.01092896174863388\n",
      "\n",
      "reasoned views   1.0\n",
      "\n",
      "total number   0.5\n",
      "\n",
      "of course   0.0017825311942959\n",
      "\n",
      "the Bayes   0.0006920415224913495\n",
      "\n",
      "a naval   0.001226993865030675\n",
      "\n",
      "within different   0.05555555555555555\n",
      "\n",
      "SR while   0.3333333333333333\n",
      "\n",
      "the full   0.0020761245674740486\n",
      "\n",
      "earliest example   0.5\n",
      "\n",
      "the sentences   0.005536332179930796\n",
      "\n",
      "may require   0.038461538461538464\n",
      "\n",
      "Campaigns -RRB-   1.0\n",
      "\n",
      "informative with   0.5\n",
      "\n",
      "techniques fall   0.043478260869565216\n",
      "\n",
      "the 1980s   0.001384083044982699\n",
      "\n",
      "TaleSpin -LRB-   1.0\n",
      "\n",
      "disambiguation concerns   0.1\n",
      "\n",
      "critical that   0.25\n",
      "\n",
      "from NLP   0.009615384615384616\n",
      "\n",
      "leads ,   1.0\n",
      "\n",
      "accuracy include   0.03225806451612903\n",
      "\n",
      "Where such   1.0\n",
      "\n",
      "citation needed   1.0\n",
      "\n",
      "have focused   0.019230769230769232\n",
      "\n",
      "the state-of-the-art   0.0006920415224913495\n",
      "\n",
      "of smoothing   0.00089126559714795\n",
      "\n",
      "noise in   0.125\n",
      "\n",
      "prize .   1.0\n",
      "\n",
      "some methods   0.024096385542168676\n",
      "\n",
      "known .   0.038461538461538464\n",
      "\n",
      "<s> Importance   0.0007686395080707148\n",
      "\n",
      "and Thai   0.001445086705202312\n",
      "\n",
      "been popular   0.014705882352941176\n",
      "\n",
      "annotation or   0.25\n",
      "\n",
      "researchers have   0.3\n",
      "\n",
      "differ from   0.3333333333333333\n",
      "\n",
      "prestige ''   1.0\n",
      "\n",
      "structure .   0.16666666666666666\n",
      "\n",
      "specific trade   0.047619047619047616\n",
      "\n",
      "mail since   0.5\n",
      "\n",
      "Romanseval campaigns   1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    n_gram_dict=read_model(\"./bigram.model\")\n",
    "    for i in n_gram_dict:\n",
    "        print(i,n_gram_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c', 'd e f', 'b c d', 'c d e']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b c\n",
      "d e f\n",
      "b c d\n",
      "c d e\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9e400c5b9b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mt_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_new_n_gram_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-239fdd3da63b>\u001b[0m in \u001b[0;36mcalc_new_n_gram_dict\u001b[0;34m(old_n_gram_dict, n)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mold_n_gram_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_n_gram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mnew_n_gram_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_n_gram_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mold_n_gram_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold_n_gram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_n_gram_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[2, 3, 4]\n",
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "t_=[1,2,3,4,5]\n",
    "n_len=3\n",
    "for i in range(n_len):\n",
    "    print(t_[i:i+n_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
